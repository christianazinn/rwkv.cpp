{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 37.16012084592145,
  "eval_steps": 50,
  "global_step": 123000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015105740181268883,
      "grad_norm": 0.6733978390693665,
      "learning_rate": 2.2553557436376076e-05,
      "loss": 9.5036,
      "step": 50
    },
    {
      "epoch": 0.030211480362537766,
      "grad_norm": 0.6721529960632324,
      "learning_rate": 2.6549682900599912e-05,
      "loss": 8.9065,
      "step": 100
    },
    {
      "epoch": 0.045317220543806644,
      "grad_norm": 0.5536141991615295,
      "learning_rate": 2.8887266445347776e-05,
      "loss": 8.4786,
      "step": 150
    },
    {
      "epoch": 0.06042296072507553,
      "grad_norm": 0.5375335812568665,
      "learning_rate": 3.054580836482375e-05,
      "loss": 8.2107,
      "step": 200
    },
    {
      "epoch": 0.0755287009063444,
      "grad_norm": 0.6360388994216919,
      "learning_rate": 3.18322734224522e-05,
      "loss": 7.9881,
      "step": 250
    },
    {
      "epoch": 0.09063444108761329,
      "grad_norm": 0.8129155039787292,
      "learning_rate": 3.288339190957161e-05,
      "loss": 7.8147,
      "step": 300
    },
    {
      "epoch": 0.10574018126888217,
      "grad_norm": 0.7044464945793152,
      "learning_rate": 3.377209992752458e-05,
      "loss": 7.6374,
      "step": 350
    },
    {
      "epoch": 0.12084592145015106,
      "grad_norm": 0.9129141569137573,
      "learning_rate": 3.454193382904758e-05,
      "loss": 7.471,
      "step": 400
    },
    {
      "epoch": 0.13595166163141995,
      "grad_norm": 1.0072544813156128,
      "learning_rate": 3.5220975454319476e-05,
      "loss": 7.2664,
      "step": 450
    },
    {
      "epoch": 0.1510574018126888,
      "grad_norm": 1.688743233680725,
      "learning_rate": 3.582839888667603e-05,
      "loss": 7.1426,
      "step": 500
    },
    {
      "epoch": 0.1510574018126888,
      "eval_loss": 7.125041961669922,
      "eval_runtime": 1533.6343,
      "eval_samples_per_second": 34.623,
      "eval_steps_per_second": 0.271,
      "step": 500
    },
    {
      "epoch": 0.1661631419939577,
      "grad_norm": 2.083834171295166,
      "learning_rate": 3.637788021935366e-05,
      "loss": 6.9733,
      "step": 550
    },
    {
      "epoch": 0.1661631419939577,
      "eval_loss": 6.947968006134033,
      "eval_runtime": 1463.0111,
      "eval_samples_per_second": 36.294,
      "eval_steps_per_second": 0.284,
      "step": 550
    },
    {
      "epoch": 0.18126888217522658,
      "grad_norm": 2.4985079765319824,
      "learning_rate": 3.687951737379544e-05,
      "loss": 6.8012,
      "step": 600
    },
    {
      "epoch": 0.18126888217522658,
      "eval_loss": 6.770869731903076,
      "eval_runtime": 1993.6043,
      "eval_samples_per_second": 26.635,
      "eval_steps_per_second": 0.208,
      "step": 600
    },
    {
      "epoch": 0.19637462235649547,
      "grad_norm": 3.228285789489746,
      "learning_rate": 3.7340978822864956e-05,
      "loss": 6.5701,
      "step": 650
    },
    {
      "epoch": 0.19637462235649547,
      "eval_loss": 6.52642822265625,
      "eval_runtime": 1595.8126,
      "eval_samples_per_second": 33.274,
      "eval_steps_per_second": 0.26,
      "step": 650
    },
    {
      "epoch": 0.21148036253776434,
      "grad_norm": 3.685845375061035,
      "learning_rate": 3.776822539174842e-05,
      "loss": 6.3404,
      "step": 700
    },
    {
      "epoch": 0.21148036253776434,
      "eval_loss": 6.313558101654053,
      "eval_runtime": 1563.8341,
      "eval_samples_per_second": 33.954,
      "eval_steps_per_second": 0.265,
      "step": 700
    },
    {
      "epoch": 0.22658610271903323,
      "grad_norm": 5.476799011230469,
      "learning_rate": 3.81659824314239e-05,
      "loss": 6.1185,
      "step": 750
    },
    {
      "epoch": 0.22658610271903323,
      "eval_loss": 6.130445957183838,
      "eval_runtime": 1578.4393,
      "eval_samples_per_second": 33.64,
      "eval_steps_per_second": 0.263,
      "step": 750
    },
    {
      "epoch": 0.24169184290030213,
      "grad_norm": 2.924147844314575,
      "learning_rate": 3.853805929327141e-05,
      "loss": 5.9587,
      "step": 800
    },
    {
      "epoch": 0.24169184290030213,
      "eval_loss": 5.945860385894775,
      "eval_runtime": 1515.5178,
      "eval_samples_per_second": 35.037,
      "eval_steps_per_second": 0.274,
      "step": 800
    },
    {
      "epoch": 0.256797583081571,
      "grad_norm": 3.6207571029663086,
      "learning_rate": 3.8887571780365265e-05,
      "loss": 5.7587,
      "step": 850
    },
    {
      "epoch": 0.256797583081571,
      "eval_loss": 5.770865440368652,
      "eval_runtime": 1535.5763,
      "eval_samples_per_second": 34.579,
      "eval_steps_per_second": 0.27,
      "step": 850
    },
    {
      "epoch": 0.2719033232628399,
      "grad_norm": 5.4798712730407715,
      "learning_rate": 3.9217100918543305e-05,
      "loss": 5.6024,
      "step": 900
    },
    {
      "epoch": 0.2719033232628399,
      "eval_loss": 5.641273498535156,
      "eval_runtime": 1559.0385,
      "eval_samples_per_second": 34.059,
      "eval_steps_per_second": 0.266,
      "step": 900
    },
    {
      "epoch": 0.28700906344410876,
      "grad_norm": 7.464140892028809,
      "learning_rate": 3.952880874302502e-05,
      "loss": 5.4705,
      "step": 950
    },
    {
      "epoch": 0.28700906344410876,
      "eval_loss": 5.520482063293457,
      "eval_runtime": 1465.7374,
      "eval_samples_per_second": 36.227,
      "eval_steps_per_second": 0.283,
      "step": 950
    },
    {
      "epoch": 0.3021148036253776,
      "grad_norm": 5.679163455963135,
      "learning_rate": 3.982452435089986e-05,
      "loss": 5.3524,
      "step": 1000
    },
    {
      "epoch": 0.3021148036253776,
      "eval_loss": 5.398557662963867,
      "eval_runtime": 1539.8129,
      "eval_samples_per_second": 34.484,
      "eval_steps_per_second": 0.27,
      "step": 1000
    },
    {
      "epoch": 0.31722054380664655,
      "grad_norm": 6.398766994476318,
      "learning_rate": 4.010580893649628e-05,
      "loss": 5.2552,
      "step": 1050
    },
    {
      "epoch": 0.31722054380664655,
      "eval_loss": 5.294626712799072,
      "eval_runtime": 2084.6018,
      "eval_samples_per_second": 25.472,
      "eval_steps_per_second": 0.199,
      "step": 1050
    },
    {
      "epoch": 0.3323262839879154,
      "grad_norm": 3.8286356925964355,
      "learning_rate": 4.0374005683577486e-05,
      "loss": 5.1416,
      "step": 1100
    },
    {
      "epoch": 0.3323262839879154,
      "eval_loss": 5.170400142669678,
      "eval_runtime": 1591.3013,
      "eval_samples_per_second": 33.368,
      "eval_steps_per_second": 0.261,
      "step": 1100
    },
    {
      "epoch": 0.3474320241691843,
      "grad_norm": 6.947875022888184,
      "learning_rate": 4.063027855796968e-05,
      "loss": 5.0431,
      "step": 1150
    },
    {
      "epoch": 0.3474320241691843,
      "eval_loss": 5.060932636260986,
      "eval_runtime": 1497.1143,
      "eval_samples_per_second": 35.468,
      "eval_steps_per_second": 0.277,
      "step": 1150
    },
    {
      "epoch": 0.36253776435045315,
      "grad_norm": 7.115135669708252,
      "learning_rate": 4.087564283801928e-05,
      "loss": 4.9374,
      "step": 1200
    },
    {
      "epoch": 0.36253776435045315,
      "eval_loss": 4.9813618659973145,
      "eval_runtime": 1499.072,
      "eval_samples_per_second": 35.421,
      "eval_steps_per_second": 0.277,
      "step": 1200
    },
    {
      "epoch": 0.3776435045317221,
      "grad_norm": 3.9557435512542725,
      "learning_rate": 4.1110989408528324e-05,
      "loss": 4.8468,
      "step": 1250
    },
    {
      "epoch": 0.3776435045317221,
      "eval_loss": 4.885934829711914,
      "eval_runtime": 1497.8969,
      "eval_samples_per_second": 35.449,
      "eval_steps_per_second": 0.277,
      "step": 1250
    },
    {
      "epoch": 0.39274924471299094,
      "grad_norm": 7.9804582595825195,
      "learning_rate": 4.13371042870888e-05,
      "loss": 4.7912,
      "step": 1300
    },
    {
      "epoch": 0.39274924471299094,
      "eval_loss": 4.802469730377197,
      "eval_runtime": 1506.1587,
      "eval_samples_per_second": 35.255,
      "eval_steps_per_second": 0.276,
      "step": 1300
    },
    {
      "epoch": 0.4078549848942598,
      "grad_norm": 7.077103614807129,
      "learning_rate": 4.1554684463291176e-05,
      "loss": 4.6936,
      "step": 1350
    },
    {
      "epoch": 0.4078549848942598,
      "eval_loss": 4.7329630851745605,
      "eval_runtime": 1579.7502,
      "eval_samples_per_second": 33.612,
      "eval_steps_per_second": 0.263,
      "step": 1350
    },
    {
      "epoch": 0.4229607250755287,
      "grad_norm": 4.552875995635986,
      "learning_rate": 4.1764350855972255e-05,
      "loss": 4.6189,
      "step": 1400
    },
    {
      "epoch": 0.4229607250755287,
      "eval_loss": 4.660074710845947,
      "eval_runtime": 1568.736,
      "eval_samples_per_second": 33.848,
      "eval_steps_per_second": 0.265,
      "step": 1400
    },
    {
      "epoch": 0.4380664652567976,
      "grad_norm": 4.794299125671387,
      "learning_rate": 4.196665899572081e-05,
      "loss": 4.5537,
      "step": 1450
    },
    {
      "epoch": 0.4380664652567976,
      "eval_loss": 4.589061737060547,
      "eval_runtime": 1529.7605,
      "eval_samples_per_second": 34.711,
      "eval_steps_per_second": 0.271,
      "step": 1450
    },
    {
      "epoch": 0.45317220543806647,
      "grad_norm": 4.75712776184082,
      "learning_rate": 4.216210789564773e-05,
      "loss": 4.4848,
      "step": 1500
    },
    {
      "epoch": 0.45317220543806647,
      "eval_loss": 4.536383628845215,
      "eval_runtime": 1491.263,
      "eval_samples_per_second": 35.607,
      "eval_steps_per_second": 0.278,
      "step": 1500
    },
    {
      "epoch": 0.46827794561933533,
      "grad_norm": 6.140926837921143,
      "learning_rate": 4.2351147467076834e-05,
      "loss": 4.4246,
      "step": 1550
    },
    {
      "epoch": 0.46827794561933533,
      "eval_loss": 4.473043918609619,
      "eval_runtime": 1644.8141,
      "eval_samples_per_second": 32.283,
      "eval_steps_per_second": 0.252,
      "step": 1550
    },
    {
      "epoch": 0.48338368580060426,
      "grad_norm": 6.507010459899902,
      "learning_rate": 4.253418475749524e-05,
      "loss": 4.3954,
      "step": 1600
    },
    {
      "epoch": 0.48338368580060426,
      "eval_loss": 4.409413814544678,
      "eval_runtime": 1567.3093,
      "eval_samples_per_second": 33.879,
      "eval_steps_per_second": 0.265,
      "step": 1600
    },
    {
      "epoch": 0.4984894259818731,
      "grad_norm": 8.261065483093262,
      "learning_rate": 4.271158922832535e-05,
      "loss": 4.2854,
      "step": 1650
    },
    {
      "epoch": 0.4984894259818731,
      "eval_loss": 4.354878902435303,
      "eval_runtime": 1480.3274,
      "eval_samples_per_second": 35.87,
      "eval_steps_per_second": 0.28,
      "step": 1650
    },
    {
      "epoch": 0.513595166163142,
      "grad_norm": 5.425293922424316,
      "learning_rate": 4.2883697244589094e-05,
      "loss": 4.2444,
      "step": 1700
    },
    {
      "epoch": 0.513595166163142,
      "eval_loss": 4.286937236785889,
      "eval_runtime": 1473.0897,
      "eval_samples_per_second": 36.046,
      "eval_steps_per_second": 0.282,
      "step": 1700
    },
    {
      "epoch": 0.5287009063444109,
      "grad_norm": 6.009269714355469,
      "learning_rate": 4.30508159136007e-05,
      "loss": 4.1941,
      "step": 1750
    },
    {
      "epoch": 0.5287009063444109,
      "eval_loss": 4.225527286529541,
      "eval_runtime": 2802.1647,
      "eval_samples_per_second": 18.949,
      "eval_steps_per_second": 0.148,
      "step": 1750
    },
    {
      "epoch": 0.5438066465256798,
      "grad_norm": 5.255600929260254,
      "learning_rate": 4.321322638276714e-05,
      "loss": 4.1305,
      "step": 1800
    },
    {
      "epoch": 0.5438066465256798,
      "eval_loss": 4.1775736808776855,
      "eval_runtime": 1527.4313,
      "eval_samples_per_second": 34.764,
      "eval_steps_per_second": 0.272,
      "step": 1800
    },
    {
      "epoch": 0.5589123867069486,
      "grad_norm": 7.08139181137085,
      "learning_rate": 4.337118668545248e-05,
      "loss": 4.0487,
      "step": 1850
    },
    {
      "epoch": 0.5589123867069486,
      "eval_loss": 4.133334159851074,
      "eval_runtime": 2194.2843,
      "eval_samples_per_second": 24.199,
      "eval_steps_per_second": 0.189,
      "step": 1850
    },
    {
      "epoch": 0.5740181268882175,
      "grad_norm": 4.344417572021484,
      "learning_rate": 4.352493420724886e-05,
      "loss": 4.0441,
      "step": 1900
    },
    {
      "epoch": 0.5740181268882175,
      "eval_loss": 4.08273458480835,
      "eval_runtime": 1490.8771,
      "eval_samples_per_second": 35.616,
      "eval_steps_per_second": 0.278,
      "step": 1900
    },
    {
      "epoch": 0.5891238670694864,
      "grad_norm": 8.365995407104492,
      "learning_rate": 4.367468783183666e-05,
      "loss": 3.9868,
      "step": 1950
    },
    {
      "epoch": 0.5891238670694864,
      "eval_loss": 4.0394673347473145,
      "eval_runtime": 1500.5982,
      "eval_samples_per_second": 35.385,
      "eval_steps_per_second": 0.277,
      "step": 1950
    },
    {
      "epoch": 0.6042296072507553,
      "grad_norm": 4.814155101776123,
      "learning_rate": 4.3820649815123704e-05,
      "loss": 3.9451,
      "step": 2000
    },
    {
      "epoch": 0.6042296072507553,
      "eval_loss": 4.004324436187744,
      "eval_runtime": 1494.4841,
      "eval_samples_per_second": 35.53,
      "eval_steps_per_second": 0.278,
      "step": 2000
    },
    {
      "epoch": 0.6193353474320241,
      "grad_norm": 5.34413480758667,
      "learning_rate": 4.3963007427933843e-05,
      "loss": 3.9067,
      "step": 2050
    },
    {
      "epoch": 0.6193353474320241,
      "eval_loss": 3.9446678161621094,
      "eval_runtime": 1554.0278,
      "eval_samples_per_second": 34.169,
      "eval_steps_per_second": 0.267,
      "step": 2050
    },
    {
      "epoch": 0.6344410876132931,
      "grad_norm": 5.753972053527832,
      "learning_rate": 4.410193440072012e-05,
      "loss": 3.8652,
      "step": 2100
    },
    {
      "epoch": 0.6344410876132931,
      "eval_loss": 3.9057021141052246,
      "eval_runtime": 1499.7576,
      "eval_samples_per_second": 35.405,
      "eval_steps_per_second": 0.277,
      "step": 2100
    },
    {
      "epoch": 0.649546827794562,
      "grad_norm": 4.4148640632629395,
      "learning_rate": 4.423759219826143e-05,
      "loss": 3.8396,
      "step": 2150
    },
    {
      "epoch": 0.649546827794562,
      "eval_loss": 3.8707077503204346,
      "eval_runtime": 1447.639,
      "eval_samples_per_second": 36.68,
      "eval_steps_per_second": 0.287,
      "step": 2150
    },
    {
      "epoch": 0.6646525679758308,
      "grad_norm": 6.639167308807373,
      "learning_rate": 4.437013114780132e-05,
      "loss": 3.7793,
      "step": 2200
    },
    {
      "epoch": 0.6646525679758308,
      "eval_loss": 3.8344664573669434,
      "eval_runtime": 1524.4565,
      "eval_samples_per_second": 34.831,
      "eval_steps_per_second": 0.272,
      "step": 2200
    },
    {
      "epoch": 0.6797583081570997,
      "grad_norm": 5.520598888397217,
      "learning_rate": 4.4499691440395596e-05,
      "loss": 3.7373,
      "step": 2250
    },
    {
      "epoch": 0.6797583081570997,
      "eval_loss": 3.7898001670837402,
      "eval_runtime": 1567.7056,
      "eval_samples_per_second": 33.871,
      "eval_steps_per_second": 0.265,
      "step": 2250
    },
    {
      "epoch": 0.6948640483383686,
      "grad_norm": 6.727752685546875,
      "learning_rate": 4.462640402219352e-05,
      "loss": 3.7142,
      "step": 2300
    },
    {
      "epoch": 0.6948640483383686,
      "eval_loss": 3.758624315261841,
      "eval_runtime": 1552.6904,
      "eval_samples_per_second": 34.198,
      "eval_steps_per_second": 0.267,
      "step": 2300
    },
    {
      "epoch": 0.7099697885196374,
      "grad_norm": 6.4783735275268555,
      "learning_rate": 4.4750391389858914e-05,
      "loss": 3.6637,
      "step": 2350
    },
    {
      "epoch": 0.7099697885196374,
      "eval_loss": 3.7123138904571533,
      "eval_runtime": 1498.3882,
      "eval_samples_per_second": 35.437,
      "eval_steps_per_second": 0.277,
      "step": 2350
    },
    {
      "epoch": 0.7250755287009063,
      "grad_norm": 4.460286617279053,
      "learning_rate": 4.487176830224311e-05,
      "loss": 3.6389,
      "step": 2400
    },
    {
      "epoch": 0.7250755287009063,
      "eval_loss": 3.685603618621826,
      "eval_runtime": 1567.5415,
      "eval_samples_per_second": 33.874,
      "eval_steps_per_second": 0.265,
      "step": 2400
    },
    {
      "epoch": 0.7401812688821753,
      "grad_norm": 4.528999328613281,
      "learning_rate": 4.4990642418673096e-05,
      "loss": 3.5912,
      "step": 2450
    },
    {
      "epoch": 0.7401812688821753,
      "eval_loss": 3.648576021194458,
      "eval_runtime": 1567.4139,
      "eval_samples_per_second": 33.877,
      "eval_steps_per_second": 0.265,
      "step": 2450
    },
    {
      "epoch": 0.7552870090634441,
      "grad_norm": 5.282404899597168,
      "learning_rate": 4.510711487275215e-05,
      "loss": 3.5561,
      "step": 2500
    },
    {
      "epoch": 0.7552870090634441,
      "eval_loss": 3.612118721008301,
      "eval_runtime": 1498.4454,
      "eval_samples_per_second": 35.436,
      "eval_steps_per_second": 0.277,
      "step": 2500
    },
    {
      "epoch": 0.770392749244713,
      "grad_norm": 6.464050769805908,
      "learning_rate": 4.522128078933696e-05,
      "loss": 3.5212,
      "step": 2550
    },
    {
      "epoch": 0.770392749244713,
      "eval_loss": 3.5780153274536133,
      "eval_runtime": 1472.1166,
      "eval_samples_per_second": 36.07,
      "eval_steps_per_second": 0.282,
      "step": 2550
    },
    {
      "epoch": 0.7854984894259819,
      "grad_norm": 5.839052200317383,
      "learning_rate": 4.5333229751312635e-05,
      "loss": 3.5147,
      "step": 2600
    },
    {
      "epoch": 0.7854984894259819,
      "eval_loss": 3.5369856357574463,
      "eval_runtime": 1544.5221,
      "eval_samples_per_second": 34.379,
      "eval_steps_per_second": 0.269,
      "step": 2600
    },
    {
      "epoch": 0.8006042296072508,
      "grad_norm": 4.9076385498046875,
      "learning_rate": 4.544304622190464e-05,
      "loss": 3.4581,
      "step": 2650
    },
    {
      "epoch": 0.8006042296072508,
      "eval_loss": 3.4973771572113037,
      "eval_runtime": 1564.3236,
      "eval_samples_per_second": 33.944,
      "eval_steps_per_second": 0.265,
      "step": 2650
    },
    {
      "epoch": 0.8157099697885196,
      "grad_norm": 6.568053245544434,
      "learning_rate": 4.5550809927515005e-05,
      "loss": 3.4027,
      "step": 2700
    },
    {
      "epoch": 0.8157099697885196,
      "eval_loss": 3.4609086513519287,
      "eval_runtime": 1531.6797,
      "eval_samples_per_second": 34.667,
      "eval_steps_per_second": 0.271,
      "step": 2700
    },
    {
      "epoch": 0.8308157099697885,
      "grad_norm": 6.379318714141846,
      "learning_rate": 4.565659620542978e-05,
      "loss": 3.3708,
      "step": 2750
    },
    {
      "epoch": 0.8308157099697885,
      "eval_loss": 3.420051097869873,
      "eval_runtime": 1540.0446,
      "eval_samples_per_second": 34.479,
      "eval_steps_per_second": 0.269,
      "step": 2750
    },
    {
      "epoch": 0.8459214501510574,
      "grad_norm": 6.544897079467773,
      "learning_rate": 4.5760476320196084e-05,
      "loss": 3.3512,
      "step": 2800
    },
    {
      "epoch": 0.8459214501510574,
      "eval_loss": 3.3891751766204834,
      "eval_runtime": 1546.2695,
      "eval_samples_per_second": 34.34,
      "eval_steps_per_second": 0.268,
      "step": 2800
    },
    {
      "epoch": 0.8610271903323263,
      "grad_norm": 3.61928391456604,
      "learning_rate": 4.5862517751996714e-05,
      "loss": 3.3047,
      "step": 2850
    },
    {
      "epoch": 0.8610271903323263,
      "eval_loss": 3.3519692420959473,
      "eval_runtime": 1553.3027,
      "eval_samples_per_second": 34.185,
      "eval_steps_per_second": 0.267,
      "step": 2850
    },
    {
      "epoch": 0.8761329305135952,
      "grad_norm": 9.868937492370605,
      "learning_rate": 4.5962784459944646e-05,
      "loss": 3.2718,
      "step": 2900
    },
    {
      "epoch": 0.8761329305135952,
      "eval_loss": 3.328024387359619,
      "eval_runtime": 1495.3049,
      "eval_samples_per_second": 35.51,
      "eval_steps_per_second": 0.278,
      "step": 2900
    },
    {
      "epoch": 0.8912386706948641,
      "grad_norm": 3.7998454570770264,
      "learning_rate": 4.606133712287027e-05,
      "loss": 3.2242,
      "step": 2950
    },
    {
      "epoch": 0.8912386706948641,
      "eval_loss": 3.27851939201355,
      "eval_runtime": 1474.0684,
      "eval_samples_per_second": 36.022,
      "eval_steps_per_second": 0.282,
      "step": 2950
    },
    {
      "epoch": 0.9063444108761329,
      "grad_norm": 5.898553371429443,
      "learning_rate": 4.615823335987156e-05,
      "loss": 3.1948,
      "step": 3000
    },
    {
      "epoch": 0.9063444108761329,
      "eval_loss": 3.2405481338500977,
      "eval_runtime": 1501.5499,
      "eval_samples_per_second": 35.363,
      "eval_steps_per_second": 0.276,
      "step": 3000
    },
    {
      "epoch": 0.9214501510574018,
      "grad_norm": 6.391921520233154,
      "learning_rate": 4.6253527932634186e-05,
      "loss": 3.1757,
      "step": 3050
    },
    {
      "epoch": 0.9214501510574018,
      "eval_loss": 3.209028482437134,
      "eval_runtime": 1547.857,
      "eval_samples_per_second": 34.305,
      "eval_steps_per_second": 0.268,
      "step": 3050
    },
    {
      "epoch": 0.9365558912386707,
      "grad_norm": 7.213789463043213,
      "learning_rate": 4.634727293130066e-05,
      "loss": 3.1279,
      "step": 3100
    },
    {
      "epoch": 0.9365558912386707,
      "eval_loss": 3.174515724182129,
      "eval_runtime": 1531.5433,
      "eval_samples_per_second": 34.67,
      "eval_steps_per_second": 0.271,
      "step": 3100
    },
    {
      "epoch": 0.9516616314199395,
      "grad_norm": 6.4954938888549805,
      "learning_rate": 4.6439517945467976e-05,
      "loss": 3.1078,
      "step": 3150
    },
    {
      "epoch": 0.9516616314199395,
      "eval_loss": 3.13554048538208,
      "eval_runtime": 1530.8733,
      "eval_samples_per_second": 34.685,
      "eval_steps_per_second": 0.271,
      "step": 3150
    },
    {
      "epoch": 0.9667673716012085,
      "grad_norm": 9.080803871154785,
      "learning_rate": 4.6530310221719085e-05,
      "loss": 3.081,
      "step": 3200
    },
    {
      "epoch": 0.9667673716012085,
      "eval_loss": 3.1011345386505127,
      "eval_runtime": 1455.7934,
      "eval_samples_per_second": 36.474,
      "eval_steps_per_second": 0.285,
      "step": 3200
    },
    {
      "epoch": 0.9818731117824774,
      "grad_norm": 4.857671737670898,
      "learning_rate": 4.6619694808941076e-05,
      "loss": 2.9959,
      "step": 3250
    },
    {
      "epoch": 0.9818731117824774,
      "eval_loss": 3.064384698867798,
      "eval_runtime": 1480.4595,
      "eval_samples_per_second": 35.867,
      "eval_steps_per_second": 0.28,
      "step": 3250
    },
    {
      "epoch": 0.9969788519637462,
      "grad_norm": 6.33370304107666,
      "learning_rate": 4.6707714692549186e-05,
      "loss": 3.0035,
      "step": 3300
    },
    {
      "epoch": 0.9969788519637462,
      "eval_loss": 3.028984308242798,
      "eval_runtime": 1516.7733,
      "eval_samples_per_second": 35.008,
      "eval_steps_per_second": 0.274,
      "step": 3300
    },
    {
      "epoch": 1.012084592145015,
      "grad_norm": 7.725071430206299,
      "learning_rate": 4.6794410918617316e-05,
      "loss": 2.9759,
      "step": 3350
    },
    {
      "epoch": 1.012084592145015,
      "eval_loss": 3.006023406982422,
      "eval_runtime": 1521.697,
      "eval_samples_per_second": 34.895,
      "eval_steps_per_second": 0.273,
      "step": 3350
    },
    {
      "epoch": 1.027190332326284,
      "grad_norm": 7.09116792678833,
      "learning_rate": 4.687982270881292e-05,
      "loss": 2.9322,
      "step": 3400
    },
    {
      "epoch": 1.027190332326284,
      "eval_loss": 2.9693491458892822,
      "eval_runtime": 1500.0231,
      "eval_samples_per_second": 35.399,
      "eval_steps_per_second": 0.277,
      "step": 3400
    },
    {
      "epoch": 1.042296072507553,
      "grad_norm": 8.734650611877441,
      "learning_rate": 4.6963987566941375e-05,
      "loss": 2.8649,
      "step": 3450
    },
    {
      "epoch": 1.042296072507553,
      "eval_loss": 2.9455013275146484,
      "eval_runtime": 1546.4624,
      "eval_samples_per_second": 34.336,
      "eval_steps_per_second": 0.268,
      "step": 3450
    },
    {
      "epoch": 1.0574018126888218,
      "grad_norm": 5.179593086242676,
      "learning_rate": 4.704694137782454e-05,
      "loss": 2.8459,
      "step": 3500
    },
    {
      "epoch": 1.0574018126888218,
      "eval_loss": 2.9113006591796875,
      "eval_runtime": 1489.5101,
      "eval_samples_per_second": 35.649,
      "eval_steps_per_second": 0.279,
      "step": 3500
    },
    {
      "epoch": 1.0725075528700907,
      "grad_norm": 5.62029504776001,
      "learning_rate": 4.7128718499165905e-05,
      "loss": 2.8232,
      "step": 3550
    },
    {
      "epoch": 1.0725075528700907,
      "eval_loss": 2.884855031967163,
      "eval_runtime": 1529.2531,
      "eval_samples_per_second": 34.722,
      "eval_steps_per_second": 0.271,
      "step": 3550
    },
    {
      "epoch": 1.0876132930513596,
      "grad_norm": 5.767152309417725,
      "learning_rate": 4.720935184699098e-05,
      "loss": 2.8096,
      "step": 3600
    },
    {
      "epoch": 1.0876132930513596,
      "eval_loss": 2.8560328483581543,
      "eval_runtime": 1553.3493,
      "eval_samples_per_second": 34.184,
      "eval_steps_per_second": 0.267,
      "step": 3600
    },
    {
      "epoch": 1.1027190332326284,
      "grad_norm": 5.330660820007324,
      "learning_rate": 4.728887297519457e-05,
      "loss": 2.7975,
      "step": 3650
    },
    {
      "epoch": 1.1027190332326284,
      "eval_loss": 2.8184285163879395,
      "eval_runtime": 1509.5041,
      "eval_samples_per_second": 35.176,
      "eval_steps_per_second": 0.275,
      "step": 3650
    },
    {
      "epoch": 1.1178247734138973,
      "grad_norm": 5.425539493560791,
      "learning_rate": 4.736731214967631e-05,
      "loss": 2.7311,
      "step": 3700
    },
    {
      "epoch": 1.1178247734138973,
      "eval_loss": 2.797427177429199,
      "eval_runtime": 1500.0444,
      "eval_samples_per_second": 35.398,
      "eval_steps_per_second": 0.277,
      "step": 3700
    },
    {
      "epoch": 1.1329305135951662,
      "grad_norm": 5.898379802703857,
      "learning_rate": 4.744469841750002e-05,
      "loss": 2.72,
      "step": 3750
    },
    {
      "epoch": 1.1329305135951662,
      "eval_loss": 2.7644197940826416,
      "eval_runtime": 1517.0527,
      "eval_samples_per_second": 35.001,
      "eval_steps_per_second": 0.274,
      "step": 3750
    },
    {
      "epoch": 1.148036253776435,
      "grad_norm": 7.584801197052002,
      "learning_rate": 4.752105967147269e-05,
      "loss": 2.6823,
      "step": 3800
    },
    {
      "epoch": 1.148036253776435,
      "eval_loss": 2.743957757949829,
      "eval_runtime": 1557.7319,
      "eval_samples_per_second": 34.087,
      "eval_steps_per_second": 0.266,
      "step": 3800
    },
    {
      "epoch": 1.163141993957704,
      "grad_norm": 5.9124860763549805,
      "learning_rate": 4.7596422710502164e-05,
      "loss": 2.7015,
      "step": 3850
    },
    {
      "epoch": 1.163141993957704,
      "eval_loss": 2.7225747108459473,
      "eval_runtime": 1556.2972,
      "eval_samples_per_second": 34.119,
      "eval_steps_per_second": 0.267,
      "step": 3850
    },
    {
      "epoch": 1.1782477341389728,
      "grad_norm": 5.030533790588379,
      "learning_rate": 4.767081329606049e-05,
      "loss": 2.6524,
      "step": 3900
    },
    {
      "epoch": 1.1782477341389728,
      "eval_loss": 2.689763069152832,
      "eval_runtime": 1546.1377,
      "eval_samples_per_second": 34.343,
      "eval_steps_per_second": 0.268,
      "step": 3900
    },
    {
      "epoch": 1.1933534743202416,
      "grad_norm": 5.680314064025879,
      "learning_rate": 4.7744256205050565e-05,
      "loss": 2.6453,
      "step": 3950
    },
    {
      "epoch": 1.1933534743202416,
      "eval_loss": 2.6701245307922363,
      "eval_runtime": 1565.3776,
      "eval_samples_per_second": 33.921,
      "eval_steps_per_second": 0.265,
      "step": 3950
    },
    {
      "epoch": 1.2084592145015105,
      "grad_norm": 4.9074883460998535,
      "learning_rate": 4.781677527934753e-05,
      "loss": 2.5709,
      "step": 4000
    },
    {
      "epoch": 1.2084592145015105,
      "eval_loss": 2.6414151191711426,
      "eval_runtime": 1543.47,
      "eval_samples_per_second": 34.402,
      "eval_steps_per_second": 0.269,
      "step": 4000
    },
    {
      "epoch": 1.2235649546827794,
      "grad_norm": 8.887981414794922,
      "learning_rate": 4.788839347226287e-05,
      "loss": 2.5595,
      "step": 4050
    },
    {
      "epoch": 1.2235649546827794,
      "eval_loss": 2.632658004760742,
      "eval_runtime": 1478.3104,
      "eval_samples_per_second": 35.919,
      "eval_steps_per_second": 0.281,
      "step": 4050
    },
    {
      "epoch": 1.2386706948640485,
      "grad_norm": 10.364733695983887,
      "learning_rate": 4.795913289215768e-05,
      "loss": 2.5916,
      "step": 4100
    },
    {
      "epoch": 1.2386706948640485,
      "eval_loss": 2.604804754257202,
      "eval_runtime": 1560.9141,
      "eval_samples_per_second": 34.018,
      "eval_steps_per_second": 0.266,
      "step": 4100
    },
    {
      "epoch": 1.2537764350453173,
      "grad_norm": 3.974773406982422,
      "learning_rate": 4.8029014843412554e-05,
      "loss": 2.5631,
      "step": 4150
    },
    {
      "epoch": 1.2537764350453173,
      "eval_loss": 2.581084966659546,
      "eval_runtime": 1552.0028,
      "eval_samples_per_second": 34.213,
      "eval_steps_per_second": 0.267,
      "step": 4150
    },
    {
      "epoch": 1.2688821752265862,
      "grad_norm": 5.290199279785156,
      "learning_rate": 4.809805986494395e-05,
      "loss": 2.5168,
      "step": 4200
    },
    {
      "epoch": 1.2688821752265862,
      "eval_loss": 2.5512325763702393,
      "eval_runtime": 1788.3723,
      "eval_samples_per_second": 29.691,
      "eval_steps_per_second": 0.232,
      "step": 4200
    },
    {
      "epoch": 1.283987915407855,
      "grad_norm": 6.1190314292907715,
      "learning_rate": 4.8166287766441385e-05,
      "loss": 2.4885,
      "step": 4250
    },
    {
      "epoch": 1.283987915407855,
      "eval_loss": 2.5430421829223633,
      "eval_runtime": 1566.7487,
      "eval_samples_per_second": 33.891,
      "eval_steps_per_second": 0.265,
      "step": 4250
    },
    {
      "epoch": 1.299093655589124,
      "grad_norm": 4.381198406219482,
      "learning_rate": 4.8233717662485256e-05,
      "loss": 2.4729,
      "step": 4300
    },
    {
      "epoch": 1.299093655589124,
      "eval_loss": 2.508636474609375,
      "eval_runtime": 1544.5778,
      "eval_samples_per_second": 34.378,
      "eval_steps_per_second": 0.269,
      "step": 4300
    },
    {
      "epoch": 1.3141993957703928,
      "grad_norm": 6.9565749168396,
      "learning_rate": 4.830036800469251e-05,
      "loss": 2.4521,
      "step": 4350
    },
    {
      "epoch": 1.3141993957703928,
      "eval_loss": 2.5022454261779785,
      "eval_runtime": 1655.3156,
      "eval_samples_per_second": 32.078,
      "eval_steps_per_second": 0.251,
      "step": 4350
    },
    {
      "epoch": 1.3293051359516617,
      "grad_norm": 4.466794013977051,
      "learning_rate": 4.836625661202516e-05,
      "loss": 2.4342,
      "step": 4400
    },
    {
      "epoch": 1.3293051359516617,
      "eval_loss": 2.4786550998687744,
      "eval_runtime": 1526.4428,
      "eval_samples_per_second": 34.786,
      "eval_steps_per_second": 0.272,
      "step": 4400
    },
    {
      "epoch": 1.3444108761329305,
      "grad_norm": 4.880309581756592,
      "learning_rate": 4.843140069938648e-05,
      "loss": 2.4318,
      "step": 4450
    },
    {
      "epoch": 1.3444108761329305,
      "eval_loss": 2.453714370727539,
      "eval_runtime": 3355.2935,
      "eval_samples_per_second": 15.825,
      "eval_steps_per_second": 0.124,
      "step": 4450
    },
    {
      "epoch": 1.3595166163141994,
      "grad_norm": 5.004522323608398,
      "learning_rate": 4.849581690461943e-05,
      "loss": 2.3826,
      "step": 4500
    },
    {
      "epoch": 1.3595166163141994,
      "eval_loss": 2.438323974609375,
      "eval_runtime": 2810.1358,
      "eval_samples_per_second": 18.896,
      "eval_steps_per_second": 0.148,
      "step": 4500
    },
    {
      "epoch": 1.3746223564954683,
      "grad_norm": 4.776670932769775,
      "learning_rate": 4.855952131401347e-05,
      "loss": 2.3789,
      "step": 4550
    },
    {
      "epoch": 1.3746223564954683,
      "eval_loss": 2.4277291297912598,
      "eval_runtime": 1783.9755,
      "eval_samples_per_second": 29.764,
      "eval_steps_per_second": 0.233,
      "step": 4550
    },
    {
      "epoch": 1.3897280966767371,
      "grad_norm": 4.922896862030029,
      "learning_rate": 4.8622529486417354e-05,
      "loss": 2.3548,
      "step": 4600
    },
    {
      "epoch": 1.3897280966767371,
      "eval_loss": 2.41351056098938,
      "eval_runtime": 1541.7476,
      "eval_samples_per_second": 34.441,
      "eval_steps_per_second": 0.269,
      "step": 4600
    },
    {
      "epoch": 1.404833836858006,
      "grad_norm": 3.668757438659668,
      "learning_rate": 4.868485647604854e-05,
      "loss": 2.3663,
      "step": 4650
    },
    {
      "epoch": 1.404833836858006,
      "eval_loss": 2.388211965560913,
      "eval_runtime": 1530.3993,
      "eval_samples_per_second": 34.696,
      "eval_steps_per_second": 0.271,
      "step": 4650
    },
    {
      "epoch": 1.4199395770392749,
      "grad_norm": 5.765085220336914,
      "learning_rate": 4.874651685408274e-05,
      "loss": 2.3631,
      "step": 4700
    },
    {
      "epoch": 1.4199395770392749,
      "eval_loss": 2.377788782119751,
      "eval_runtime": 1533.8074,
      "eval_samples_per_second": 34.619,
      "eval_steps_per_second": 0.271,
      "step": 4700
    },
    {
      "epoch": 1.4350453172205437,
      "grad_norm": 4.995696544647217,
      "learning_rate": 4.880752472910114e-05,
      "loss": 2.356,
      "step": 4750
    },
    {
      "epoch": 1.4350453172205437,
      "eval_loss": 2.3550608158111572,
      "eval_runtime": 1549.2066,
      "eval_samples_per_second": 34.275,
      "eval_steps_per_second": 0.268,
      "step": 4750
    },
    {
      "epoch": 1.4501510574018126,
      "grad_norm": 5.0024309158325195,
      "learning_rate": 4.886789376646694e-05,
      "loss": 2.2958,
      "step": 4800
    },
    {
      "epoch": 1.4501510574018126,
      "eval_loss": 2.348954200744629,
      "eval_runtime": 1548.4972,
      "eval_samples_per_second": 34.291,
      "eval_steps_per_second": 0.268,
      "step": 4800
    },
    {
      "epoch": 1.4652567975830815,
      "grad_norm": 5.925265789031982,
      "learning_rate": 4.892763720669796e-05,
      "loss": 2.2648,
      "step": 4850
    },
    {
      "epoch": 1.4652567975830815,
      "eval_loss": 2.3317689895629883,
      "eval_runtime": 1644.0295,
      "eval_samples_per_second": 32.298,
      "eval_steps_per_second": 0.252,
      "step": 4850
    },
    {
      "epoch": 1.4803625377643503,
      "grad_norm": 4.571678638458252,
      "learning_rate": 4.898676788289693e-05,
      "loss": 2.2596,
      "step": 4900
    },
    {
      "epoch": 1.4803625377643503,
      "eval_loss": 2.3160722255706787,
      "eval_runtime": 1510.7794,
      "eval_samples_per_second": 35.147,
      "eval_steps_per_second": 0.275,
      "step": 4900
    },
    {
      "epoch": 1.4954682779456192,
      "grad_norm": 4.8588762283325195,
      "learning_rate": 4.904529823729705e-05,
      "loss": 2.2551,
      "step": 4950
    },
    {
      "epoch": 1.4954682779456192,
      "eval_loss": 2.30143141746521,
      "eval_runtime": 1682.991,
      "eval_samples_per_second": 31.55,
      "eval_steps_per_second": 0.247,
      "step": 4950
    },
    {
      "epoch": 1.510574018126888,
      "grad_norm": 3.9412145614624023,
      "learning_rate": 4.9103240336975995e-05,
      "loss": 2.2491,
      "step": 5000
    },
    {
      "epoch": 1.510574018126888,
      "eval_loss": 2.2868971824645996,
      "eval_runtime": 1543.9591,
      "eval_samples_per_second": 34.391,
      "eval_steps_per_second": 0.269,
      "step": 5000
    },
    {
      "epoch": 1.525679758308157,
      "grad_norm": 3.805911064147949,
      "learning_rate": 4.916060588878805e-05,
      "loss": 2.2508,
      "step": 5050
    },
    {
      "epoch": 1.525679758308157,
      "eval_loss": 2.2729861736297607,
      "eval_runtime": 2206.8555,
      "eval_samples_per_second": 24.061,
      "eval_steps_per_second": 0.188,
      "step": 5050
    },
    {
      "epoch": 1.540785498489426,
      "grad_norm": 4.083517551422119,
      "learning_rate": 4.9217406253560794e-05,
      "loss": 2.2419,
      "step": 5100
    },
    {
      "epoch": 1.540785498489426,
      "eval_loss": 2.259709358215332,
      "eval_runtime": 1526.5887,
      "eval_samples_per_second": 34.783,
      "eval_steps_per_second": 0.272,
      "step": 5100
    },
    {
      "epoch": 1.555891238670695,
      "grad_norm": 3.632260799407959,
      "learning_rate": 4.9273652459599024e-05,
      "loss": 2.237,
      "step": 5150
    },
    {
      "epoch": 1.555891238670695,
      "eval_loss": 2.2465927600860596,
      "eval_runtime": 2331.8043,
      "eval_samples_per_second": 22.772,
      "eval_steps_per_second": 0.178,
      "step": 5150
    },
    {
      "epoch": 1.5709969788519638,
      "grad_norm": 4.401129722595215,
      "learning_rate": 4.9329355215536464e-05,
      "loss": 2.1829,
      "step": 5200
    },
    {
      "epoch": 1.5709969788519638,
      "eval_loss": 2.2410049438476562,
      "eval_runtime": 1430.4364,
      "eval_samples_per_second": 37.121,
      "eval_steps_per_second": 0.29,
      "step": 5200
    },
    {
      "epoch": 1.5861027190332326,
      "grad_norm": 3.7393510341644287,
      "learning_rate": 4.93845249225724e-05,
      "loss": 2.1969,
      "step": 5250
    },
    {
      "epoch": 1.5861027190332326,
      "eval_loss": 2.2294647693634033,
      "eval_runtime": 1898.2068,
      "eval_samples_per_second": 27.973,
      "eval_steps_per_second": 0.219,
      "step": 5250
    },
    {
      "epoch": 1.6012084592145015,
      "grad_norm": 3.3485934734344482,
      "learning_rate": 4.943917168612847e-05,
      "loss": 2.2004,
      "step": 5300
    },
    {
      "epoch": 1.6012084592145015,
      "eval_loss": 2.219233512878418,
      "eval_runtime": 1570.9326,
      "eval_samples_per_second": 33.801,
      "eval_steps_per_second": 0.264,
      "step": 5300
    },
    {
      "epoch": 1.6163141993957704,
      "grad_norm": 3.6001601219177246,
      "learning_rate": 4.9493305326958014e-05,
      "loss": 2.1461,
      "step": 5350
    },
    {
      "epoch": 1.6163141993957704,
      "eval_loss": 2.207705020904541,
      "eval_runtime": 1711.7297,
      "eval_samples_per_second": 31.021,
      "eval_steps_per_second": 0.242,
      "step": 5350
    },
    {
      "epoch": 1.6314199395770392,
      "grad_norm": 3.5738332271575928,
      "learning_rate": 4.954693539173885e-05,
      "loss": 2.1584,
      "step": 5400
    },
    {
      "epoch": 1.6314199395770392,
      "eval_loss": 2.188380241394043,
      "eval_runtime": 1503.8596,
      "eval_samples_per_second": 35.308,
      "eval_steps_per_second": 0.276,
      "step": 5400
    },
    {
      "epoch": 1.646525679758308,
      "grad_norm": 3.938762664794922,
      "learning_rate": 4.960007116317775e-05,
      "loss": 2.1546,
      "step": 5450
    },
    {
      "epoch": 1.646525679758308,
      "eval_loss": 2.1817378997802734,
      "eval_runtime": 1516.3839,
      "eval_samples_per_second": 35.017,
      "eval_steps_per_second": 0.274,
      "step": 5450
    },
    {
      "epoch": 1.6616314199395772,
      "grad_norm": 4.569939613342285,
      "learning_rate": 4.965272166965361e-05,
      "loss": 2.1396,
      "step": 5500
    },
    {
      "epoch": 1.6616314199395772,
      "eval_loss": 2.1735854148864746,
      "eval_runtime": 1531.3991,
      "eval_samples_per_second": 34.674,
      "eval_steps_per_second": 0.271,
      "step": 5500
    },
    {
      "epoch": 1.676737160120846,
      "grad_norm": 3.730491876602173,
      "learning_rate": 4.970489569442417e-05,
      "loss": 2.0957,
      "step": 5550
    },
    {
      "epoch": 1.676737160120846,
      "eval_loss": 2.1691339015960693,
      "eval_runtime": 1457.6745,
      "eval_samples_per_second": 36.427,
      "eval_steps_per_second": 0.285,
      "step": 5550
    },
    {
      "epoch": 1.691842900302115,
      "grad_norm": 4.2818803787231445,
      "learning_rate": 4.9756601784419926e-05,
      "loss": 2.105,
      "step": 5600
    },
    {
      "epoch": 1.691842900302115,
      "eval_loss": 2.1563706398010254,
      "eval_runtime": 1632.7008,
      "eval_samples_per_second": 32.522,
      "eval_steps_per_second": 0.254,
      "step": 5600
    },
    {
      "epoch": 1.7069486404833838,
      "grad_norm": 3.1461703777313232,
      "learning_rate": 4.980784825864709e-05,
      "loss": 2.0887,
      "step": 5650
    },
    {
      "epoch": 1.7069486404833838,
      "eval_loss": 2.1427767276763916,
      "eval_runtime": 1485.0188,
      "eval_samples_per_second": 35.756,
      "eval_steps_per_second": 0.279,
      "step": 5650
    },
    {
      "epoch": 1.7220543806646527,
      "grad_norm": 3.2258875370025635,
      "learning_rate": 4.985864321622055e-05,
      "loss": 2.0998,
      "step": 5700
    },
    {
      "epoch": 1.7220543806646527,
      "eval_loss": 2.13578724861145,
      "eval_runtime": 1770.5107,
      "eval_samples_per_second": 29.991,
      "eval_steps_per_second": 0.234,
      "step": 5700
    },
    {
      "epoch": 1.7371601208459215,
      "grad_norm": 3.8033204078674316,
      "learning_rate": 4.9908994544045796e-05,
      "loss": 2.0723,
      "step": 5750
    },
    {
      "epoch": 1.7371601208459215,
      "eval_loss": 2.1276843547821045,
      "eval_runtime": 2327.4149,
      "eval_samples_per_second": 22.815,
      "eval_steps_per_second": 0.178,
      "step": 5750
    },
    {
      "epoch": 1.7522658610271904,
      "grad_norm": 5.076063632965088,
      "learning_rate": 4.9958909924168475e-05,
      "loss": 2.0711,
      "step": 5800
    },
    {
      "epoch": 1.7522658610271904,
      "eval_loss": 2.115973949432373,
      "eval_runtime": 1679.1589,
      "eval_samples_per_second": 31.622,
      "eval_steps_per_second": 0.247,
      "step": 5800
    },
    {
      "epoch": 1.7673716012084593,
      "grad_norm": 3.513103485107422,
      "learning_rate": 5.000839684080836e-05,
      "loss": 2.0541,
      "step": 5850
    },
    {
      "epoch": 1.7673716012084593,
      "eval_loss": 2.106630563735962,
      "eval_runtime": 1726.378,
      "eval_samples_per_second": 30.757,
      "eval_steps_per_second": 0.24,
      "step": 5850
    },
    {
      "epoch": 1.7824773413897281,
      "grad_norm": 1.9379901885986328,
      "learning_rate": 5.005746258709411e-05,
      "loss": 2.0882,
      "step": 5900
    },
    {
      "epoch": 1.7824773413897281,
      "eval_loss": 2.0992109775543213,
      "eval_runtime": 1492.7173,
      "eval_samples_per_second": 35.572,
      "eval_steps_per_second": 0.278,
      "step": 5900
    },
    {
      "epoch": 1.797583081570997,
      "grad_norm": 3.9612436294555664,
      "learning_rate": 5.0106114271513765e-05,
      "loss": 2.0701,
      "step": 5950
    },
    {
      "epoch": 1.797583081570997,
      "eval_loss": 2.0949957370758057,
      "eval_runtime": 1639.4689,
      "eval_samples_per_second": 32.388,
      "eval_steps_per_second": 0.253,
      "step": 5950
    },
    {
      "epoch": 1.8126888217522659,
      "grad_norm": 2.9468443393707275,
      "learning_rate": 5.01543588240954e-05,
      "loss": 2.0564,
      "step": 6000
    },
    {
      "epoch": 1.8126888217522659,
      "eval_loss": 2.083503246307373,
      "eval_runtime": 1643.2969,
      "eval_samples_per_second": 32.312,
      "eval_steps_per_second": 0.253,
      "step": 6000
    },
    {
      "epoch": 1.8277945619335347,
      "grad_norm": 3.656550884246826,
      "learning_rate": 5.020220300233124e-05,
      "loss": 2.0191,
      "step": 6050
    },
    {
      "epoch": 1.8277945619335347,
      "eval_loss": 2.0736324787139893,
      "eval_runtime": 1541.8408,
      "eval_samples_per_second": 34.439,
      "eval_steps_per_second": 0.269,
      "step": 6050
    },
    {
      "epoch": 1.8429003021148036,
      "grad_norm": 3.548609733581543,
      "learning_rate": 5.024965339685802e-05,
      "loss": 2.0359,
      "step": 6100
    },
    {
      "epoch": 1.8429003021148036,
      "eval_loss": 2.0660839080810547,
      "eval_runtime": 1687.0084,
      "eval_samples_per_second": 31.475,
      "eval_steps_per_second": 0.246,
      "step": 6100
    },
    {
      "epoch": 1.8580060422960725,
      "grad_norm": 6.553991794586182,
      "learning_rate": 5.029671643690555e-05,
      "loss": 2.0407,
      "step": 6150
    },
    {
      "epoch": 1.8580060422960725,
      "eval_loss": 2.0681068897247314,
      "eval_runtime": 1970.6401,
      "eval_samples_per_second": 26.945,
      "eval_steps_per_second": 0.211,
      "step": 6150
    },
    {
      "epoch": 1.8731117824773413,
      "grad_norm": 2.76086688041687,
      "learning_rate": 5.03433983955245e-05,
      "loss": 2.0141,
      "step": 6200
    },
    {
      "epoch": 1.8731117824773413,
      "eval_loss": 2.0510029792785645,
      "eval_runtime": 1558.7735,
      "eval_samples_per_second": 34.065,
      "eval_steps_per_second": 0.266,
      "step": 6200
    },
    {
      "epoch": 1.8882175226586102,
      "grad_norm": 2.7623331546783447,
      "learning_rate": 5.0389705394604444e-05,
      "loss": 2.0124,
      "step": 6250
    },
    {
      "epoch": 1.8882175226586102,
      "eval_loss": 2.045393466949463,
      "eval_runtime": 1483.3979,
      "eval_samples_per_second": 35.796,
      "eval_steps_per_second": 0.28,
      "step": 6250
    },
    {
      "epoch": 1.903323262839879,
      "grad_norm": 2.7858519554138184,
      "learning_rate": 5.043564340969181e-05,
      "loss": 2.0034,
      "step": 6300
    },
    {
      "epoch": 1.903323262839879,
      "eval_loss": 2.0419538021087646,
      "eval_runtime": 1615.2585,
      "eval_samples_per_second": 32.873,
      "eval_steps_per_second": 0.257,
      "step": 6300
    },
    {
      "epoch": 1.918429003021148,
      "grad_norm": 3.0503249168395996,
      "learning_rate": 5.04812182746175e-05,
      "loss": 2.0061,
      "step": 6350
    },
    {
      "epoch": 1.918429003021148,
      "eval_loss": 2.034919261932373,
      "eval_runtime": 1573.7056,
      "eval_samples_per_second": 33.741,
      "eval_steps_per_second": 0.264,
      "step": 6350
    },
    {
      "epoch": 1.9335347432024168,
      "grad_norm": 2.858863115310669,
      "learning_rate": 5.052643568594291e-05,
      "loss": 1.9873,
      "step": 6400
    },
    {
      "epoch": 1.9335347432024168,
      "eval_loss": 2.027510166168213,
      "eval_runtime": 2600.9051,
      "eval_samples_per_second": 20.416,
      "eval_steps_per_second": 0.16,
      "step": 6400
    },
    {
      "epoch": 1.9486404833836857,
      "grad_norm": 2.684464693069458,
      "learning_rate": 5.057130120723312e-05,
      "loss": 1.9932,
      "step": 6450
    },
    {
      "epoch": 1.9486404833836857,
      "eval_loss": 2.019197463989258,
      "eval_runtime": 1553.9548,
      "eval_samples_per_second": 34.17,
      "eval_steps_per_second": 0.267,
      "step": 6450
    },
    {
      "epoch": 1.9637462235649545,
      "grad_norm": 2.3061814308166504,
      "learning_rate": 5.061582027316491e-05,
      "loss": 1.9782,
      "step": 6500
    },
    {
      "epoch": 1.9637462235649545,
      "eval_loss": 2.0093860626220703,
      "eval_runtime": 1673.7259,
      "eval_samples_per_second": 31.725,
      "eval_steps_per_second": 0.248,
      "step": 6500
    },
    {
      "epoch": 1.9788519637462234,
      "grad_norm": 2.5565707683563232,
      "learning_rate": 5.065999819347751e-05,
      "loss": 1.9747,
      "step": 6550
    },
    {
      "epoch": 1.9788519637462234,
      "eval_loss": 2.0062122344970703,
      "eval_runtime": 1520.3703,
      "eval_samples_per_second": 34.925,
      "eval_steps_per_second": 0.273,
      "step": 6550
    },
    {
      "epoch": 1.9939577039274925,
      "grad_norm": 3.13024640083313,
      "learning_rate": 5.070384015677302e-05,
      "loss": 1.9517,
      "step": 6600
    },
    {
      "epoch": 1.9939577039274925,
      "eval_loss": 1.9993292093276978,
      "eval_runtime": 1505.4784,
      "eval_samples_per_second": 35.271,
      "eval_steps_per_second": 0.276,
      "step": 6600
    },
    {
      "epoch": 2.009063444108761,
      "grad_norm": 3.2770369052886963,
      "learning_rate": 5.074735123417353e-05,
      "loss": 1.9888,
      "step": 6650
    },
    {
      "epoch": 2.009063444108761,
      "eval_loss": 1.998500943183899,
      "eval_runtime": 2626.9607,
      "eval_samples_per_second": 20.213,
      "eval_steps_per_second": 0.158,
      "step": 6650
    },
    {
      "epoch": 2.02416918429003,
      "grad_norm": 2.3977479934692383,
      "learning_rate": 5.079053638284115e-05,
      "loss": 1.9588,
      "step": 6700
    },
    {
      "epoch": 2.02416918429003,
      "eval_loss": 1.9912453889846802,
      "eval_runtime": 1624.2915,
      "eval_samples_per_second": 32.691,
      "eval_steps_per_second": 0.255,
      "step": 6700
    },
    {
      "epoch": 2.039274924471299,
      "grad_norm": 2.3917667865753174,
      "learning_rate": 5.083340044936729e-05,
      "loss": 1.9662,
      "step": 6750
    },
    {
      "epoch": 2.039274924471299,
      "eval_loss": 1.9830982685089111,
      "eval_runtime": 1573.6751,
      "eval_samples_per_second": 33.742,
      "eval_steps_per_second": 0.264,
      "step": 6750
    },
    {
      "epoch": 2.054380664652568,
      "grad_norm": 2.9068267345428467,
      "learning_rate": 5.087594817303676e-05,
      "loss": 1.9588,
      "step": 6800
    },
    {
      "epoch": 2.054380664652568,
      "eval_loss": 1.977151870727539,
      "eval_runtime": 1609.5741,
      "eval_samples_per_second": 32.989,
      "eval_steps_per_second": 0.258,
      "step": 6800
    },
    {
      "epoch": 2.069486404833837,
      "grad_norm": 3.0669455528259277,
      "learning_rate": 5.091818418897238e-05,
      "loss": 1.9735,
      "step": 6850
    },
    {
      "epoch": 2.069486404833837,
      "eval_loss": 1.9709548950195312,
      "eval_runtime": 1553.9455,
      "eval_samples_per_second": 34.17,
      "eval_steps_per_second": 0.267,
      "step": 6850
    },
    {
      "epoch": 2.084592145015106,
      "grad_norm": 2.503401279449463,
      "learning_rate": 5.096011303116521e-05,
      "loss": 1.9348,
      "step": 6900
    },
    {
      "epoch": 2.084592145015106,
      "eval_loss": 1.9656944274902344,
      "eval_runtime": 1871.6003,
      "eval_samples_per_second": 28.371,
      "eval_steps_per_second": 0.222,
      "step": 6900
    },
    {
      "epoch": 2.099697885196375,
      "grad_norm": 2.2885589599609375,
      "learning_rate": 5.100173913539542e-05,
      "loss": 1.9319,
      "step": 6950
    },
    {
      "epoch": 2.099697885196375,
      "eval_loss": 1.9621546268463135,
      "eval_runtime": 1572.327,
      "eval_samples_per_second": 33.771,
      "eval_steps_per_second": 0.264,
      "step": 6950
    },
    {
      "epoch": 2.1148036253776437,
      "grad_norm": 3.2248032093048096,
      "learning_rate": 5.1043066842048375e-05,
      "loss": 1.9028,
      "step": 7000
    },
    {
      "epoch": 2.1148036253776437,
      "eval_loss": 1.9566134214401245,
      "eval_runtime": 2187.7488,
      "eval_samples_per_second": 24.271,
      "eval_steps_per_second": 0.19,
      "step": 7000
    },
    {
      "epoch": 2.1299093655589125,
      "grad_norm": 3.1406216621398926,
      "learning_rate": 5.108410039883061e-05,
      "loss": 1.9095,
      "step": 7050
    },
    {
      "epoch": 2.1299093655589125,
      "eval_loss": 1.9521476030349731,
      "eval_runtime": 1616.5751,
      "eval_samples_per_second": 32.847,
      "eval_steps_per_second": 0.257,
      "step": 7050
    },
    {
      "epoch": 2.1450151057401814,
      "grad_norm": 2.2976627349853516,
      "learning_rate": 5.112484396338974e-05,
      "loss": 1.9204,
      "step": 7100
    },
    {
      "epoch": 2.1450151057401814,
      "eval_loss": 1.9472594261169434,
      "eval_runtime": 1596.941,
      "eval_samples_per_second": 33.25,
      "eval_steps_per_second": 0.26,
      "step": 7100
    },
    {
      "epoch": 2.1601208459214503,
      "grad_norm": 2.704317092895508,
      "learning_rate": 5.1165301605842544e-05,
      "loss": 1.8946,
      "step": 7150
    },
    {
      "epoch": 2.1601208459214503,
      "eval_loss": 1.9434475898742676,
      "eval_runtime": 1546.6033,
      "eval_samples_per_second": 34.333,
      "eval_steps_per_second": 0.268,
      "step": 7150
    },
    {
      "epoch": 2.175226586102719,
      "grad_norm": 2.220698833465576,
      "learning_rate": 5.1205477311214806e-05,
      "loss": 1.9174,
      "step": 7200
    },
    {
      "epoch": 2.175226586102719,
      "eval_loss": 1.9355554580688477,
      "eval_runtime": 1562.5449,
      "eval_samples_per_second": 33.982,
      "eval_steps_per_second": 0.266,
      "step": 7200
    },
    {
      "epoch": 2.190332326283988,
      "grad_norm": 2.9099302291870117,
      "learning_rate": 5.124537498179693e-05,
      "loss": 1.9011,
      "step": 7250
    },
    {
      "epoch": 2.190332326283988,
      "eval_loss": 1.9380371570587158,
      "eval_runtime": 1701.7265,
      "eval_samples_per_second": 31.203,
      "eval_steps_per_second": 0.244,
      "step": 7250
    },
    {
      "epoch": 2.205438066465257,
      "grad_norm": 2.5961132049560547,
      "learning_rate": 5.12849984394184e-05,
      "loss": 1.9289,
      "step": 7300
    },
    {
      "epoch": 2.205438066465257,
      "eval_loss": 1.9269932508468628,
      "eval_runtime": 1610.2583,
      "eval_samples_per_second": 32.975,
      "eval_steps_per_second": 0.258,
      "step": 7300
    },
    {
      "epoch": 2.2205438066465257,
      "grad_norm": 1.9793245792388916,
      "learning_rate": 5.132435142764479e-05,
      "loss": 1.8869,
      "step": 7350
    },
    {
      "epoch": 2.2205438066465257,
      "eval_loss": 1.9271644353866577,
      "eval_runtime": 1609.4603,
      "eval_samples_per_second": 32.992,
      "eval_steps_per_second": 0.258,
      "step": 7350
    },
    {
      "epoch": 2.2356495468277946,
      "grad_norm": 2.4701430797576904,
      "learning_rate": 5.1363437613900144e-05,
      "loss": 1.8975,
      "step": 7400
    },
    {
      "epoch": 2.2356495468277946,
      "eval_loss": 1.9233217239379883,
      "eval_runtime": 1849.4712,
      "eval_samples_per_second": 28.71,
      "eval_steps_per_second": 0.224,
      "step": 7400
    },
    {
      "epoch": 2.2507552870090635,
      "grad_norm": 3.164809465408325,
      "learning_rate": 5.1402260591518016e-05,
      "loss": 1.8875,
      "step": 7450
    },
    {
      "epoch": 2.2507552870090635,
      "eval_loss": 1.914413571357727,
      "eval_runtime": 1578.7509,
      "eval_samples_per_second": 33.634,
      "eval_steps_per_second": 0.263,
      "step": 7450
    },
    {
      "epoch": 2.2658610271903323,
      "grad_norm": 3.436420440673828,
      "learning_rate": 5.144082388172385e-05,
      "loss": 1.8687,
      "step": 7500
    },
    {
      "epoch": 2.2658610271903323,
      "eval_loss": 1.915343999862671,
      "eval_runtime": 1543.3955,
      "eval_samples_per_second": 34.404,
      "eval_steps_per_second": 0.269,
      "step": 7500
    },
    {
      "epoch": 2.280966767371601,
      "grad_norm": 2.1025819778442383,
      "learning_rate": 5.1479130935551504e-05,
      "loss": 1.893,
      "step": 7550
    },
    {
      "epoch": 2.280966767371601,
      "eval_loss": 1.911228060722351,
      "eval_runtime": 1624.1125,
      "eval_samples_per_second": 32.694,
      "eval_steps_per_second": 0.256,
      "step": 7550
    },
    {
      "epoch": 2.29607250755287,
      "grad_norm": 2.2796080112457275,
      "learning_rate": 5.151718513569652e-05,
      "loss": 1.8928,
      "step": 7600
    },
    {
      "epoch": 2.29607250755287,
      "eval_loss": 1.90692138671875,
      "eval_runtime": 3394.0161,
      "eval_samples_per_second": 15.645,
      "eval_steps_per_second": 0.122,
      "step": 7600
    },
    {
      "epoch": 2.311178247734139,
      "grad_norm": 2.5909247398376465,
      "learning_rate": 5.155498979830866e-05,
      "loss": 1.874,
      "step": 7650
    },
    {
      "epoch": 2.311178247734139,
      "eval_loss": 1.9020755290985107,
      "eval_runtime": 1527.0458,
      "eval_samples_per_second": 34.772,
      "eval_steps_per_second": 0.272,
      "step": 7650
    },
    {
      "epoch": 2.326283987915408,
      "grad_norm": 2.4745967388153076,
      "learning_rate": 5.1592548174726e-05,
      "loss": 1.8573,
      "step": 7700
    },
    {
      "epoch": 2.326283987915408,
      "eval_loss": 1.9003746509552002,
      "eval_runtime": 1603.3403,
      "eval_samples_per_second": 33.118,
      "eval_steps_per_second": 0.259,
      "step": 7700
    },
    {
      "epoch": 2.3413897280966767,
      "grad_norm": 1.6530345678329468,
      "learning_rate": 5.162986345315296e-05,
      "loss": 1.8648,
      "step": 7750
    },
    {
      "epoch": 2.3413897280966767,
      "eval_loss": 1.894288182258606,
      "eval_runtime": 2338.3775,
      "eval_samples_per_second": 22.708,
      "eval_steps_per_second": 0.177,
      "step": 7750
    },
    {
      "epoch": 2.3564954682779455,
      "grad_norm": 2.9230875968933105,
      "learning_rate": 5.166693876028432e-05,
      "loss": 1.8405,
      "step": 7800
    },
    {
      "epoch": 2.3564954682779455,
      "eval_loss": 1.893078327178955,
      "eval_runtime": 1538.1829,
      "eval_samples_per_second": 34.521,
      "eval_steps_per_second": 0.27,
      "step": 7800
    },
    {
      "epoch": 2.3716012084592144,
      "grad_norm": 2.2702908515930176,
      "learning_rate": 5.1703777162877444e-05,
      "loss": 1.8629,
      "step": 7850
    },
    {
      "epoch": 2.3716012084592144,
      "eval_loss": 1.8865364789962769,
      "eval_runtime": 1524.9299,
      "eval_samples_per_second": 34.821,
      "eval_steps_per_second": 0.272,
      "step": 7850
    },
    {
      "epoch": 2.3867069486404833,
      "grad_norm": 3.789170503616333,
      "learning_rate": 5.1740381669274394e-05,
      "loss": 1.8591,
      "step": 7900
    },
    {
      "epoch": 2.3867069486404833,
      "eval_loss": 1.8861039876937866,
      "eval_runtime": 1562.549,
      "eval_samples_per_second": 33.982,
      "eval_steps_per_second": 0.266,
      "step": 7900
    },
    {
      "epoch": 2.401812688821752,
      "grad_norm": 3.1122872829437256,
      "learning_rate": 5.177675523087633e-05,
      "loss": 1.8665,
      "step": 7950
    },
    {
      "epoch": 2.401812688821752,
      "eval_loss": 1.878684639930725,
      "eval_runtime": 1589.8642,
      "eval_samples_per_second": 33.398,
      "eval_steps_per_second": 0.261,
      "step": 7950
    },
    {
      "epoch": 2.416918429003021,
      "grad_norm": 2.5315730571746826,
      "learning_rate": 5.181290074357137e-05,
      "loss": 1.8349,
      "step": 8000
    },
    {
      "epoch": 2.416918429003021,
      "eval_loss": 1.8738237619400024,
      "eval_runtime": 1681.2554,
      "eval_samples_per_second": 31.583,
      "eval_steps_per_second": 0.247,
      "step": 8000
    },
    {
      "epoch": 2.43202416918429,
      "grad_norm": 3.0381455421447754,
      "learning_rate": 5.1848821049118195e-05,
      "loss": 1.8294,
      "step": 8050
    },
    {
      "epoch": 2.43202416918429,
      "eval_loss": 1.8732060194015503,
      "eval_runtime": 1730.8314,
      "eval_samples_per_second": 30.678,
      "eval_steps_per_second": 0.24,
      "step": 8050
    },
    {
      "epoch": 2.4471299093655587,
      "grad_norm": 2.0776214599609375,
      "learning_rate": 5.1884518936486705e-05,
      "loss": 1.8357,
      "step": 8100
    },
    {
      "epoch": 2.4471299093655587,
      "eval_loss": 1.8701461553573608,
      "eval_runtime": 1562.6947,
      "eval_samples_per_second": 33.979,
      "eval_steps_per_second": 0.266,
      "step": 8100
    },
    {
      "epoch": 2.4622356495468276,
      "grad_norm": 2.7436532974243164,
      "learning_rate": 5.1919997143157495e-05,
      "loss": 1.8348,
      "step": 8150
    },
    {
      "epoch": 2.4622356495468276,
      "eval_loss": 1.8654290437698364,
      "eval_runtime": 1698.3035,
      "eval_samples_per_second": 31.266,
      "eval_steps_per_second": 0.244,
      "step": 8150
    },
    {
      "epoch": 2.477341389728097,
      "grad_norm": 2.584636688232422,
      "learning_rate": 5.1955258356381515e-05,
      "loss": 1.8371,
      "step": 8200
    },
    {
      "epoch": 2.477341389728097,
      "eval_loss": 1.8632899522781372,
      "eval_runtime": 1575.9766,
      "eval_samples_per_second": 33.693,
      "eval_steps_per_second": 0.263,
      "step": 8200
    },
    {
      "epoch": 2.4924471299093653,
      "grad_norm": 1.9711283445358276,
      "learning_rate": 5.199030521440147e-05,
      "loss": 1.8231,
      "step": 8250
    },
    {
      "epoch": 2.4924471299093653,
      "eval_loss": 1.8630186319351196,
      "eval_runtime": 1512.178,
      "eval_samples_per_second": 35.114,
      "eval_steps_per_second": 0.274,
      "step": 8250
    },
    {
      "epoch": 2.5075528700906347,
      "grad_norm": 2.348336935043335,
      "learning_rate": 5.202514030763639e-05,
      "loss": 1.8212,
      "step": 8300
    },
    {
      "epoch": 2.5075528700906347,
      "eval_loss": 1.860134243965149,
      "eval_runtime": 2166.822,
      "eval_samples_per_second": 24.505,
      "eval_steps_per_second": 0.192,
      "step": 8300
    },
    {
      "epoch": 2.522658610271903,
      "grad_norm": 2.7900445461273193,
      "learning_rate": 5.205976617983046e-05,
      "loss": 1.8041,
      "step": 8350
    },
    {
      "epoch": 2.522658610271903,
      "eval_loss": 1.857113003730774,
      "eval_runtime": 1654.5952,
      "eval_samples_per_second": 32.092,
      "eval_steps_per_second": 0.251,
      "step": 8350
    },
    {
      "epoch": 2.5377643504531724,
      "grad_norm": 2.3563263416290283,
      "learning_rate": 5.209418532916778e-05,
      "loss": 1.8164,
      "step": 8400
    },
    {
      "epoch": 2.5377643504531724,
      "eval_loss": 1.8537794351577759,
      "eval_runtime": 1566.4317,
      "eval_samples_per_second": 33.898,
      "eval_steps_per_second": 0.265,
      "step": 8400
    },
    {
      "epoch": 2.552870090634441,
      "grad_norm": 1.956373691558838,
      "learning_rate": 5.2128400209353836e-05,
      "loss": 1.7863,
      "step": 8450
    },
    {
      "epoch": 2.552870090634441,
      "eval_loss": 1.8514918088912964,
      "eval_runtime": 1569.8213,
      "eval_samples_per_second": 33.825,
      "eval_steps_per_second": 0.264,
      "step": 8450
    },
    {
      "epoch": 2.56797583081571,
      "grad_norm": 2.672489881515503,
      "learning_rate": 5.216241323066522e-05,
      "loss": 1.8399,
      "step": 8500
    },
    {
      "epoch": 2.56797583081571,
      "eval_loss": 1.8477665185928345,
      "eval_runtime": 1588.336,
      "eval_samples_per_second": 33.431,
      "eval_steps_per_second": 0.261,
      "step": 8500
    },
    {
      "epoch": 2.583081570996979,
      "grad_norm": 2.6884841918945312,
      "learning_rate": 5.219622676096842e-05,
      "loss": 1.8273,
      "step": 8550
    },
    {
      "epoch": 2.583081570996979,
      "eval_loss": 1.8471723794937134,
      "eval_runtime": 1562.8415,
      "eval_samples_per_second": 33.976,
      "eval_steps_per_second": 0.266,
      "step": 8550
    },
    {
      "epoch": 2.598187311178248,
      "grad_norm": 1.679509162902832,
      "learning_rate": 5.222984312670909e-05,
      "loss": 1.7659,
      "step": 8600
    },
    {
      "epoch": 2.598187311178248,
      "eval_loss": 1.8398977518081665,
      "eval_runtime": 1610.1652,
      "eval_samples_per_second": 32.977,
      "eval_steps_per_second": 0.258,
      "step": 8600
    },
    {
      "epoch": 2.6132930513595167,
      "grad_norm": 3.357074737548828,
      "learning_rate": 5.22632646138725e-05,
      "loss": 1.7826,
      "step": 8650
    },
    {
      "epoch": 2.6132930513595167,
      "eval_loss": 1.8380610942840576,
      "eval_runtime": 1753.8694,
      "eval_samples_per_second": 30.275,
      "eval_steps_per_second": 0.237,
      "step": 8650
    },
    {
      "epoch": 2.6283987915407856,
      "grad_norm": 2.8619937896728516,
      "learning_rate": 5.229649346891634e-05,
      "loss": 1.8018,
      "step": 8700
    },
    {
      "epoch": 2.6283987915407856,
      "eval_loss": 1.8328354358673096,
      "eval_runtime": 1823.6684,
      "eval_samples_per_second": 29.117,
      "eval_steps_per_second": 0.228,
      "step": 8700
    },
    {
      "epoch": 2.6435045317220545,
      "grad_norm": 1.843437671661377,
      "learning_rate": 5.232953189967684e-05,
      "loss": 1.7741,
      "step": 8750
    },
    {
      "epoch": 2.6435045317220545,
      "eval_loss": 1.8355951309204102,
      "eval_runtime": 1488.1956,
      "eval_samples_per_second": 35.68,
      "eval_steps_per_second": 0.279,
      "step": 8750
    },
    {
      "epoch": 2.6586102719033233,
      "grad_norm": 3.111252784729004,
      "learning_rate": 5.2362382076248994e-05,
      "loss": 1.7686,
      "step": 8800
    },
    {
      "epoch": 2.6586102719033233,
      "eval_loss": 1.833828330039978,
      "eval_runtime": 1645.565,
      "eval_samples_per_second": 32.268,
      "eval_steps_per_second": 0.252,
      "step": 8800
    },
    {
      "epoch": 2.673716012084592,
      "grad_norm": 2.2376315593719482,
      "learning_rate": 5.239504613184197e-05,
      "loss": 1.7876,
      "step": 8850
    },
    {
      "epoch": 2.673716012084592,
      "eval_loss": 1.8290082216262817,
      "eval_runtime": 1517.5975,
      "eval_samples_per_second": 34.989,
      "eval_steps_per_second": 0.273,
      "step": 8850
    },
    {
      "epoch": 2.688821752265861,
      "grad_norm": 1.4987202882766724,
      "learning_rate": 5.242752616361031e-05,
      "loss": 1.7891,
      "step": 8900
    },
    {
      "epoch": 2.688821752265861,
      "eval_loss": 1.8223235607147217,
      "eval_runtime": 1884.8613,
      "eval_samples_per_second": 28.171,
      "eval_steps_per_second": 0.22,
      "step": 8900
    },
    {
      "epoch": 2.70392749244713,
      "grad_norm": 1.9603327512741089,
      "learning_rate": 5.245982423346186e-05,
      "loss": 1.793,
      "step": 8950
    },
    {
      "epoch": 2.70392749244713,
      "eval_loss": 1.8211606740951538,
      "eval_runtime": 1888.3446,
      "eval_samples_per_second": 28.119,
      "eval_steps_per_second": 0.22,
      "step": 8950
    },
    {
      "epoch": 2.719033232628399,
      "grad_norm": 2.7799010276794434,
      "learning_rate": 5.249194236884327e-05,
      "loss": 1.799,
      "step": 9000
    },
    {
      "epoch": 2.719033232628399,
      "eval_loss": 1.8211371898651123,
      "eval_runtime": 1581.2225,
      "eval_samples_per_second": 33.581,
      "eval_steps_per_second": 0.262,
      "step": 9000
    },
    {
      "epoch": 2.7341389728096677,
      "grad_norm": 2.0097086429595947,
      "learning_rate": 5.2523882563503655e-05,
      "loss": 1.7983,
      "step": 9050
    },
    {
      "epoch": 2.7341389728096677,
      "eval_loss": 1.816415786743164,
      "eval_runtime": 1514.9439,
      "eval_samples_per_second": 35.05,
      "eval_steps_per_second": 0.274,
      "step": 9050
    },
    {
      "epoch": 2.7492447129909365,
      "grad_norm": 3.7031729221343994,
      "learning_rate": 5.2555646778237305e-05,
      "loss": 1.7666,
      "step": 9100
    },
    {
      "epoch": 2.7492447129909365,
      "eval_loss": 1.8141729831695557,
      "eval_runtime": 1575.4186,
      "eval_samples_per_second": 33.705,
      "eval_steps_per_second": 0.263,
      "step": 9100
    },
    {
      "epoch": 2.7643504531722054,
      "grad_norm": 1.8726683855056763,
      "learning_rate": 5.258723694160589e-05,
      "loss": 1.7801,
      "step": 9150
    },
    {
      "epoch": 2.7643504531722054,
      "eval_loss": 1.8131051063537598,
      "eval_runtime": 1615.7322,
      "eval_samples_per_second": 32.864,
      "eval_steps_per_second": 0.257,
      "step": 9150
    },
    {
      "epoch": 2.7794561933534743,
      "grad_norm": 1.9402482509613037,
      "learning_rate": 5.261865495064118e-05,
      "loss": 1.7788,
      "step": 9200
    },
    {
      "epoch": 2.7794561933534743,
      "eval_loss": 1.8078467845916748,
      "eval_runtime": 1596.0245,
      "eval_samples_per_second": 33.27,
      "eval_steps_per_second": 0.26,
      "step": 9200
    },
    {
      "epoch": 2.794561933534743,
      "grad_norm": 1.798927664756775,
      "learning_rate": 5.26499026715286e-05,
      "loss": 1.7583,
      "step": 9250
    },
    {
      "epoch": 2.794561933534743,
      "eval_loss": 1.8068326711654663,
      "eval_runtime": 1491.5158,
      "eval_samples_per_second": 35.601,
      "eval_steps_per_second": 0.278,
      "step": 9250
    },
    {
      "epoch": 2.809667673716012,
      "grad_norm": 1.4784694910049438,
      "learning_rate": 5.268098194027237e-05,
      "loss": 1.773,
      "step": 9300
    },
    {
      "epoch": 2.809667673716012,
      "eval_loss": 1.8045036792755127,
      "eval_runtime": 1888.8668,
      "eval_samples_per_second": 28.112,
      "eval_steps_per_second": 0.22,
      "step": 9300
    },
    {
      "epoch": 2.824773413897281,
      "grad_norm": 1.7778676748275757,
      "learning_rate": 5.271189456334283e-05,
      "loss": 1.7699,
      "step": 9350
    },
    {
      "epoch": 2.824773413897281,
      "eval_loss": 1.8033993244171143,
      "eval_runtime": 1676.3491,
      "eval_samples_per_second": 31.675,
      "eval_steps_per_second": 0.248,
      "step": 9350
    },
    {
      "epoch": 2.8398791540785497,
      "grad_norm": 3.4525160789489746,
      "learning_rate": 5.274264231830657e-05,
      "loss": 1.7843,
      "step": 9400
    },
    {
      "epoch": 2.8398791540785497,
      "eval_loss": 1.8015178442001343,
      "eval_runtime": 1502.0193,
      "eval_samples_per_second": 35.352,
      "eval_steps_per_second": 0.276,
      "step": 9400
    },
    {
      "epoch": 2.8549848942598186,
      "grad_norm": 2.2750604152679443,
      "learning_rate": 5.277322695443969e-05,
      "loss": 1.7625,
      "step": 9450
    },
    {
      "epoch": 2.8549848942598186,
      "eval_loss": 1.7999014854431152,
      "eval_runtime": 1595.3731,
      "eval_samples_per_second": 33.283,
      "eval_steps_per_second": 0.26,
      "step": 9450
    },
    {
      "epoch": 2.8700906344410875,
      "grad_norm": 2.1305885314941406,
      "learning_rate": 5.280365019332498e-05,
      "loss": 1.8068,
      "step": 9500
    },
    {
      "epoch": 2.8700906344410875,
      "eval_loss": 1.7962433099746704,
      "eval_runtime": 1630.5985,
      "eval_samples_per_second": 32.564,
      "eval_steps_per_second": 0.255,
      "step": 9500
    },
    {
      "epoch": 2.8851963746223563,
      "grad_norm": 1.9378949403762817,
      "learning_rate": 5.283391372943349e-05,
      "loss": 1.7729,
      "step": 9550
    },
    {
      "epoch": 2.8851963746223563,
      "eval_loss": 1.7923001050949097,
      "eval_runtime": 1736.0587,
      "eval_samples_per_second": 30.586,
      "eval_steps_per_second": 0.239,
      "step": 9550
    },
    {
      "epoch": 2.900302114803625,
      "grad_norm": 1.746591567993164,
      "learning_rate": 5.286401923069078e-05,
      "loss": 1.7425,
      "step": 9600
    },
    {
      "epoch": 2.900302114803625,
      "eval_loss": 1.7892529964447021,
      "eval_runtime": 1503.6484,
      "eval_samples_per_second": 35.313,
      "eval_steps_per_second": 0.276,
      "step": 9600
    },
    {
      "epoch": 2.9154078549848945,
      "grad_norm": 1.7407784461975098,
      "learning_rate": 5.28939683390285e-05,
      "loss": 1.763,
      "step": 9650
    },
    {
      "epoch": 2.9154078549848945,
      "eval_loss": 1.790202260017395,
      "eval_runtime": 1700.0309,
      "eval_samples_per_second": 31.234,
      "eval_steps_per_second": 0.244,
      "step": 9650
    },
    {
      "epoch": 2.930513595166163,
      "grad_norm": 2.2238616943359375,
      "learning_rate": 5.292376267092179e-05,
      "loss": 1.771,
      "step": 9700
    },
    {
      "epoch": 2.930513595166163,
      "eval_loss": 1.7872958183288574,
      "eval_runtime": 1683.9495,
      "eval_samples_per_second": 31.532,
      "eval_steps_per_second": 0.246,
      "step": 9700
    },
    {
      "epoch": 2.9456193353474323,
      "grad_norm": 1.9737889766693115,
      "learning_rate": 5.295340381791279e-05,
      "loss": 1.7609,
      "step": 9750
    },
    {
      "epoch": 2.9456193353474323,
      "eval_loss": 1.7845306396484375,
      "eval_runtime": 1568.9894,
      "eval_samples_per_second": 33.843,
      "eval_steps_per_second": 0.265,
      "step": 9750
    },
    {
      "epoch": 2.9607250755287007,
      "grad_norm": 1.9473896026611328,
      "learning_rate": 5.298289334712077e-05,
      "loss": 1.7662,
      "step": 9800
    },
    {
      "epoch": 2.9607250755287007,
      "eval_loss": 1.7810255289077759,
      "eval_runtime": 1556.1834,
      "eval_samples_per_second": 34.121,
      "eval_steps_per_second": 0.267,
      "step": 9800
    },
    {
      "epoch": 2.97583081570997,
      "grad_norm": 2.0808863639831543,
      "learning_rate": 5.3012232801739305e-05,
      "loss": 1.7629,
      "step": 9850
    },
    {
      "epoch": 2.97583081570997,
      "eval_loss": 1.780672550201416,
      "eval_runtime": 1492.8527,
      "eval_samples_per_second": 35.569,
      "eval_steps_per_second": 0.278,
      "step": 9850
    },
    {
      "epoch": 2.9909365558912384,
      "grad_norm": 2.3992738723754883,
      "learning_rate": 5.3041423701520886e-05,
      "loss": 1.7225,
      "step": 9900
    },
    {
      "epoch": 2.9909365558912384,
      "eval_loss": 1.7811529636383057,
      "eval_runtime": 1573.9495,
      "eval_samples_per_second": 33.736,
      "eval_steps_per_second": 0.264,
      "step": 9900
    },
    {
      "epoch": 3.0060422960725077,
      "grad_norm": 1.8752745389938354,
      "learning_rate": 5.3070467543249225e-05,
      "loss": 1.7421,
      "step": 9950
    },
    {
      "epoch": 3.0060422960725077,
      "eval_loss": 1.7755322456359863,
      "eval_runtime": 1588.9415,
      "eval_samples_per_second": 33.418,
      "eval_steps_per_second": 0.261,
      "step": 9950
    },
    {
      "epoch": 3.0211480362537766,
      "grad_norm": 1.6226997375488281,
      "learning_rate": 5.3099365801199825e-05,
      "loss": 1.7233,
      "step": 10000
    },
    {
      "epoch": 3.0211480362537766,
      "eval_loss": 1.7730813026428223,
      "eval_runtime": 1522.648,
      "eval_samples_per_second": 34.873,
      "eval_steps_per_second": 0.273,
      "step": 10000
    },
    {
      "epoch": 3.0362537764350455,
      "grad_norm": 2.0835087299346924,
      "learning_rate": 5.312811992758902e-05,
      "loss": 1.7429,
      "step": 10050
    },
    {
      "epoch": 3.0362537764350455,
      "eval_loss": 1.770429253578186,
      "eval_runtime": 1520.0341,
      "eval_samples_per_second": 34.933,
      "eval_steps_per_second": 0.273,
      "step": 10050
    },
    {
      "epoch": 3.0513595166163143,
      "grad_norm": 2.060105323791504,
      "learning_rate": 5.315673135301189e-05,
      "loss": 1.7326,
      "step": 10100
    },
    {
      "epoch": 3.0513595166163143,
      "eval_loss": 1.7716542482376099,
      "eval_runtime": 1557.1945,
      "eval_samples_per_second": 34.099,
      "eval_steps_per_second": 0.267,
      "step": 10100
    },
    {
      "epoch": 3.066465256797583,
      "grad_norm": 1.9955823421478271,
      "learning_rate": 5.318520148686931e-05,
      "loss": 1.7397,
      "step": 10150
    },
    {
      "epoch": 3.066465256797583,
      "eval_loss": 1.7691689729690552,
      "eval_runtime": 1701.3473,
      "eval_samples_per_second": 31.21,
      "eval_steps_per_second": 0.244,
      "step": 10150
    },
    {
      "epoch": 3.081570996978852,
      "grad_norm": 1.9460891485214233,
      "learning_rate": 5.3213531717784616e-05,
      "loss": 1.722,
      "step": 10200
    },
    {
      "epoch": 3.081570996978852,
      "eval_loss": 1.7679873704910278,
      "eval_runtime": 1495.0223,
      "eval_samples_per_second": 35.517,
      "eval_steps_per_second": 0.278,
      "step": 10200
    },
    {
      "epoch": 3.096676737160121,
      "grad_norm": 1.9078941345214844,
      "learning_rate": 5.324172341400998e-05,
      "loss": 1.7329,
      "step": 10250
    },
    {
      "epoch": 3.096676737160121,
      "eval_loss": 1.764411449432373,
      "eval_runtime": 1523.8899,
      "eval_samples_per_second": 34.844,
      "eval_steps_per_second": 0.272,
      "step": 10250
    },
    {
      "epoch": 3.11178247734139,
      "grad_norm": 2.122284412384033,
      "learning_rate": 5.326977792382286e-05,
      "loss": 1.7007,
      "step": 10300
    },
    {
      "epoch": 3.11178247734139,
      "eval_loss": 1.7611907720565796,
      "eval_runtime": 1495.123,
      "eval_samples_per_second": 35.515,
      "eval_steps_per_second": 0.278,
      "step": 10300
    },
    {
      "epoch": 3.1268882175226587,
      "grad_norm": 1.5505059957504272,
      "learning_rate": 5.329769657591307e-05,
      "loss": 1.7421,
      "step": 10350
    },
    {
      "epoch": 3.1268882175226587,
      "eval_loss": 1.7592917680740356,
      "eval_runtime": 1643.8602,
      "eval_samples_per_second": 32.301,
      "eval_steps_per_second": 0.252,
      "step": 10350
    },
    {
      "epoch": 3.1419939577039275,
      "grad_norm": 1.5534768104553223,
      "learning_rate": 5.33254806797603e-05,
      "loss": 1.7544,
      "step": 10400
    },
    {
      "epoch": 3.1419939577039275,
      "eval_loss": 1.7623629570007324,
      "eval_runtime": 1950.2137,
      "eval_samples_per_second": 27.227,
      "eval_steps_per_second": 0.213,
      "step": 10400
    },
    {
      "epoch": 3.1570996978851964,
      "grad_norm": 1.8227765560150146,
      "learning_rate": 5.33531315260026e-05,
      "loss": 1.7377,
      "step": 10450
    },
    {
      "epoch": 3.1570996978851964,
      "eval_loss": 1.7567635774612427,
      "eval_runtime": 1560.1087,
      "eval_samples_per_second": 34.035,
      "eval_steps_per_second": 0.266,
      "step": 10450
    },
    {
      "epoch": 3.1722054380664653,
      "grad_norm": 3.0239017009735107,
      "learning_rate": 5.338065038679624e-05,
      "loss": 1.7552,
      "step": 10500
    },
    {
      "epoch": 3.1722054380664653,
      "eval_loss": 1.7559359073638916,
      "eval_runtime": 1505.2655,
      "eval_samples_per_second": 35.276,
      "eval_steps_per_second": 0.276,
      "step": 10500
    },
    {
      "epoch": 3.187311178247734,
      "grad_norm": 2.0634844303131104,
      "learning_rate": 5.3408038516166846e-05,
      "loss": 1.7367,
      "step": 10550
    },
    {
      "epoch": 3.187311178247734,
      "eval_loss": 1.7553412914276123,
      "eval_runtime": 1772.3656,
      "eval_samples_per_second": 29.959,
      "eval_steps_per_second": 0.234,
      "step": 10550
    },
    {
      "epoch": 3.202416918429003,
      "grad_norm": 2.557811737060547,
      "learning_rate": 5.34352971503523e-05,
      "loss": 1.7273,
      "step": 10600
    },
    {
      "epoch": 3.202416918429003,
      "eval_loss": 1.7607728242874146,
      "eval_runtime": 1551.3744,
      "eval_samples_per_second": 34.227,
      "eval_steps_per_second": 0.268,
      "step": 10600
    },
    {
      "epoch": 3.217522658610272,
      "grad_norm": 2.0726850032806396,
      "learning_rate": 5.346242750813761e-05,
      "loss": 1.7126,
      "step": 10650
    },
    {
      "epoch": 3.217522658610272,
      "eval_loss": 1.7538076639175415,
      "eval_runtime": 2361.1891,
      "eval_samples_per_second": 22.488,
      "eval_steps_per_second": 0.176,
      "step": 10650
    },
    {
      "epoch": 3.2326283987915407,
      "grad_norm": 1.5889695882797241,
      "learning_rate": 5.3489430791181836e-05,
      "loss": 1.729,
      "step": 10700
    },
    {
      "epoch": 3.2326283987915407,
      "eval_loss": 1.7494418621063232,
      "eval_runtime": 1516.212,
      "eval_samples_per_second": 35.021,
      "eval_steps_per_second": 0.274,
      "step": 10700
    },
    {
      "epoch": 3.2477341389728096,
      "grad_norm": 1.6382269859313965,
      "learning_rate": 5.3516308184337554e-05,
      "loss": 1.714,
      "step": 10750
    },
    {
      "epoch": 3.2477341389728096,
      "eval_loss": 1.7430638074874878,
      "eval_runtime": 1504.6271,
      "eval_samples_per_second": 35.29,
      "eval_steps_per_second": 0.276,
      "step": 10750
    },
    {
      "epoch": 3.2628398791540785,
      "grad_norm": 1.7232997417449951,
      "learning_rate": 5.3543060855962677e-05,
      "loss": 1.6944,
      "step": 10800
    },
    {
      "epoch": 3.2628398791540785,
      "eval_loss": 1.7465472221374512,
      "eval_runtime": 1580.2722,
      "eval_samples_per_second": 33.601,
      "eval_steps_per_second": 0.263,
      "step": 10800
    },
    {
      "epoch": 3.2779456193353473,
      "grad_norm": 1.742687702178955,
      "learning_rate": 5.3569689958225334e-05,
      "loss": 1.698,
      "step": 10850
    },
    {
      "epoch": 3.2779456193353473,
      "eval_loss": 1.7470173835754395,
      "eval_runtime": 1564.539,
      "eval_samples_per_second": 33.939,
      "eval_steps_per_second": 0.265,
      "step": 10850
    },
    {
      "epoch": 3.293051359516616,
      "grad_norm": 1.6014065742492676,
      "learning_rate": 5.359619662740158e-05,
      "loss": 1.6844,
      "step": 10900
    },
    {
      "epoch": 3.293051359516616,
      "eval_loss": 1.7424144744873047,
      "eval_runtime": 1589.9597,
      "eval_samples_per_second": 33.396,
      "eval_steps_per_second": 0.261,
      "step": 10900
    },
    {
      "epoch": 3.308157099697885,
      "grad_norm": 2.1858017444610596,
      "learning_rate": 5.362258198416627e-05,
      "loss": 1.677,
      "step": 10950
    },
    {
      "epoch": 3.308157099697885,
      "eval_loss": 1.738993763923645,
      "eval_runtime": 1649.7052,
      "eval_samples_per_second": 32.187,
      "eval_steps_per_second": 0.252,
      "step": 10950
    },
    {
      "epoch": 3.323262839879154,
      "grad_norm": 1.9509592056274414,
      "learning_rate": 5.364884713387744e-05,
      "loss": 1.6957,
      "step": 11000
    },
    {
      "epoch": 3.323262839879154,
      "eval_loss": 1.7375781536102295,
      "eval_runtime": 1487.6627,
      "eval_samples_per_second": 35.693,
      "eval_steps_per_second": 0.279,
      "step": 11000
    },
    {
      "epoch": 3.338368580060423,
      "grad_norm": 1.8746615648269653,
      "learning_rate": 5.367499316685415e-05,
      "loss": 1.7109,
      "step": 11050
    },
    {
      "epoch": 3.338368580060423,
      "eval_loss": 1.7363417148590088,
      "eval_runtime": 1516.7523,
      "eval_samples_per_second": 35.008,
      "eval_steps_per_second": 0.274,
      "step": 11050
    },
    {
      "epoch": 3.3534743202416917,
      "grad_norm": 1.864235758781433,
      "learning_rate": 5.3701021158648e-05,
      "loss": 1.7192,
      "step": 11100
    },
    {
      "epoch": 3.3534743202416917,
      "eval_loss": 1.735471248626709,
      "eval_runtime": 1576.7747,
      "eval_samples_per_second": 33.676,
      "eval_steps_per_second": 0.263,
      "step": 11100
    },
    {
      "epoch": 3.3685800604229605,
      "grad_norm": 1.789646863937378,
      "learning_rate": 5.3726932170308764e-05,
      "loss": 1.7145,
      "step": 11150
    },
    {
      "epoch": 3.3685800604229605,
      "eval_loss": 1.7319109439849854,
      "eval_runtime": 2057.1686,
      "eval_samples_per_second": 25.812,
      "eval_steps_per_second": 0.202,
      "step": 11150
    },
    {
      "epoch": 3.38368580060423,
      "grad_norm": 1.4919058084487915,
      "learning_rate": 5.375272724864375e-05,
      "loss": 1.7068,
      "step": 11200
    },
    {
      "epoch": 3.38368580060423,
      "eval_loss": 1.7304775714874268,
      "eval_runtime": 1766.6579,
      "eval_samples_per_second": 30.056,
      "eval_steps_per_second": 0.235,
      "step": 11200
    },
    {
      "epoch": 3.3987915407854983,
      "grad_norm": 2.4867100715637207,
      "learning_rate": 5.3778407426471716e-05,
      "loss": 1.7123,
      "step": 11250
    },
    {
      "epoch": 3.3987915407854983,
      "eval_loss": 1.7309125661849976,
      "eval_runtime": 1494.6691,
      "eval_samples_per_second": 35.526,
      "eval_steps_per_second": 0.278,
      "step": 11250
    },
    {
      "epoch": 3.4138972809667676,
      "grad_norm": 2.450247287750244,
      "learning_rate": 5.380397372287093e-05,
      "loss": 1.6946,
      "step": 11300
    },
    {
      "epoch": 3.4138972809667676,
      "eval_loss": 1.7265963554382324,
      "eval_runtime": 2255.6171,
      "eval_samples_per_second": 23.541,
      "eval_steps_per_second": 0.184,
      "step": 11300
    },
    {
      "epoch": 3.429003021148036,
      "grad_norm": 1.648632287979126,
      "learning_rate": 5.3829427143421825e-05,
      "loss": 1.6738,
      "step": 11350
    },
    {
      "epoch": 3.429003021148036,
      "eval_loss": 1.7246074676513672,
      "eval_runtime": 1568.7833,
      "eval_samples_per_second": 33.847,
      "eval_steps_per_second": 0.265,
      "step": 11350
    },
    {
      "epoch": 3.4441087613293053,
      "grad_norm": 1.532883644104004,
      "learning_rate": 5.3854768680444386e-05,
      "loss": 1.6979,
      "step": 11400
    },
    {
      "epoch": 3.4441087613293053,
      "eval_loss": 1.7265431880950928,
      "eval_runtime": 1821.6728,
      "eval_samples_per_second": 29.148,
      "eval_steps_per_second": 0.228,
      "step": 11400
    },
    {
      "epoch": 3.459214501510574,
      "grad_norm": 2.034012794494629,
      "learning_rate": 5.3879999313230205e-05,
      "loss": 1.6784,
      "step": 11450
    },
    {
      "epoch": 3.459214501510574,
      "eval_loss": 1.7240405082702637,
      "eval_runtime": 1540.7661,
      "eval_samples_per_second": 34.463,
      "eval_steps_per_second": 0.269,
      "step": 11450
    },
    {
      "epoch": 3.474320241691843,
      "grad_norm": 1.6335468292236328,
      "learning_rate": 5.390512000826964e-05,
      "loss": 1.6795,
      "step": 11500
    },
    {
      "epoch": 3.474320241691843,
      "eval_loss": 1.7241528034210205,
      "eval_runtime": 1573.7222,
      "eval_samples_per_second": 33.741,
      "eval_steps_per_second": 0.264,
      "step": 11500
    },
    {
      "epoch": 3.489425981873112,
      "grad_norm": 1.8558193445205688,
      "learning_rate": 5.3930131719473857e-05,
      "loss": 1.6887,
      "step": 11550
    },
    {
      "epoch": 3.489425981873112,
      "eval_loss": 1.7218799591064453,
      "eval_runtime": 1546.6218,
      "eval_samples_per_second": 34.332,
      "eval_steps_per_second": 0.268,
      "step": 11550
    },
    {
      "epoch": 3.504531722054381,
      "grad_norm": 1.308425784111023,
      "learning_rate": 5.3955035388392304e-05,
      "loss": 1.7141,
      "step": 11600
    },
    {
      "epoch": 3.504531722054381,
      "eval_loss": 1.7178428173065186,
      "eval_runtime": 1579.0871,
      "eval_samples_per_second": 33.626,
      "eval_steps_per_second": 0.263,
      "step": 11600
    },
    {
      "epoch": 3.5196374622356497,
      "grad_norm": 1.6990803480148315,
      "learning_rate": 5.397983194442531e-05,
      "loss": 1.6966,
      "step": 11650
    },
    {
      "epoch": 3.5196374622356497,
      "eval_loss": 1.7200939655303955,
      "eval_runtime": 1537.8816,
      "eval_samples_per_second": 34.527,
      "eval_steps_per_second": 0.27,
      "step": 11650
    },
    {
      "epoch": 3.5347432024169185,
      "grad_norm": 1.5667399168014526,
      "learning_rate": 5.400452230503219e-05,
      "loss": 1.6795,
      "step": 11700
    },
    {
      "epoch": 3.5347432024169185,
      "eval_loss": 1.7168092727661133,
      "eval_runtime": 1521.3261,
      "eval_samples_per_second": 34.903,
      "eval_steps_per_second": 0.273,
      "step": 11700
    },
    {
      "epoch": 3.5498489425981874,
      "grad_norm": 1.309912085533142,
      "learning_rate": 5.402910737593503e-05,
      "loss": 1.6888,
      "step": 11750
    },
    {
      "epoch": 3.5498489425981874,
      "eval_loss": 1.7196694612503052,
      "eval_runtime": 1476.1389,
      "eval_samples_per_second": 35.972,
      "eval_steps_per_second": 0.281,
      "step": 11750
    },
    {
      "epoch": 3.5649546827794563,
      "grad_norm": 2.980238437652588,
      "learning_rate": 5.405358805131794e-05,
      "loss": 1.682,
      "step": 11800
    },
    {
      "epoch": 3.5649546827794563,
      "eval_loss": 1.71134352684021,
      "eval_runtime": 4456.5285,
      "eval_samples_per_second": 11.915,
      "eval_steps_per_second": 0.093,
      "step": 11800
    },
    {
      "epoch": 3.580060422960725,
      "grad_norm": 1.4526987075805664,
      "learning_rate": 5.407796521402227e-05,
      "loss": 1.6661,
      "step": 11850
    },
    {
      "epoch": 3.580060422960725,
      "eval_loss": 1.7126294374465942,
      "eval_runtime": 1633.7597,
      "eval_samples_per_second": 32.501,
      "eval_steps_per_second": 0.254,
      "step": 11850
    },
    {
      "epoch": 3.595166163141994,
      "grad_norm": 1.3365758657455444,
      "learning_rate": 5.41022397357376e-05,
      "loss": 1.708,
      "step": 11900
    },
    {
      "epoch": 3.595166163141994,
      "eval_loss": 1.7093641757965088,
      "eval_runtime": 1524.2127,
      "eval_samples_per_second": 34.837,
      "eval_steps_per_second": 0.272,
      "step": 11900
    },
    {
      "epoch": 3.610271903323263,
      "grad_norm": 1.5847434997558594,
      "learning_rate": 5.412641247718883e-05,
      "loss": 1.7103,
      "step": 11950
    },
    {
      "epoch": 3.610271903323263,
      "eval_loss": 1.708329439163208,
      "eval_runtime": 1545.5836,
      "eval_samples_per_second": 34.355,
      "eval_steps_per_second": 0.269,
      "step": 11950
    },
    {
      "epoch": 3.6253776435045317,
      "grad_norm": 1.7128303050994873,
      "learning_rate": 5.4150484288319226e-05,
      "loss": 1.6872,
      "step": 12000
    },
    {
      "epoch": 3.6253776435045317,
      "eval_loss": 1.7027350664138794,
      "eval_runtime": 1582.5326,
      "eval_samples_per_second": 33.553,
      "eval_steps_per_second": 0.262,
      "step": 12000
    },
    {
      "epoch": 3.6404833836858006,
      "grad_norm": 1.8024399280548096,
      "learning_rate": 5.4174456008469856e-05,
      "loss": 1.6493,
      "step": 12050
    },
    {
      "epoch": 3.6404833836858006,
      "eval_loss": 1.7069288492202759,
      "eval_runtime": 1506.5724,
      "eval_samples_per_second": 35.245,
      "eval_steps_per_second": 0.275,
      "step": 12050
    },
    {
      "epoch": 3.6555891238670695,
      "grad_norm": 1.4696415662765503,
      "learning_rate": 5.419832846655507e-05,
      "loss": 1.6969,
      "step": 12100
    },
    {
      "epoch": 3.6555891238670695,
      "eval_loss": 1.7062100172042847,
      "eval_runtime": 1549.5008,
      "eval_samples_per_second": 34.268,
      "eval_steps_per_second": 0.268,
      "step": 12100
    },
    {
      "epoch": 3.6706948640483383,
      "grad_norm": 1.8004567623138428,
      "learning_rate": 5.422210248123456e-05,
      "loss": 1.6897,
      "step": 12150
    },
    {
      "epoch": 3.6706948640483383,
      "eval_loss": 1.7030550241470337,
      "eval_runtime": 2044.1759,
      "eval_samples_per_second": 25.976,
      "eval_steps_per_second": 0.203,
      "step": 12150
    },
    {
      "epoch": 3.685800604229607,
      "grad_norm": 1.1768782138824463,
      "learning_rate": 5.424577886108186e-05,
      "loss": 1.6713,
      "step": 12200
    },
    {
      "epoch": 3.685800604229607,
      "eval_loss": 1.7029592990875244,
      "eval_runtime": 1628.7948,
      "eval_samples_per_second": 32.6,
      "eval_steps_per_second": 0.255,
      "step": 12200
    },
    {
      "epoch": 3.700906344410876,
      "grad_norm": 1.4889709949493408,
      "learning_rate": 5.426935840474921e-05,
      "loss": 1.6749,
      "step": 12250
    },
    {
      "epoch": 3.700906344410876,
      "eval_loss": 1.6995843648910522,
      "eval_runtime": 1714.1879,
      "eval_samples_per_second": 30.976,
      "eval_steps_per_second": 0.242,
      "step": 12250
    },
    {
      "epoch": 3.716012084592145,
      "grad_norm": 2.364004611968994,
      "learning_rate": 5.429284190112937e-05,
      "loss": 1.6748,
      "step": 12300
    },
    {
      "epoch": 3.716012084592145,
      "eval_loss": 1.6994907855987549,
      "eval_runtime": 1502.4284,
      "eval_samples_per_second": 35.342,
      "eval_steps_per_second": 0.276,
      "step": 12300
    },
    {
      "epoch": 3.731117824773414,
      "grad_norm": 1.513004183769226,
      "learning_rate": 5.431623012951391e-05,
      "loss": 1.6462,
      "step": 12350
    },
    {
      "epoch": 3.731117824773414,
      "eval_loss": 1.695951223373413,
      "eval_runtime": 1570.3019,
      "eval_samples_per_second": 33.815,
      "eval_steps_per_second": 0.264,
      "step": 12350
    },
    {
      "epoch": 3.7462235649546827,
      "grad_norm": 1.5161845684051514,
      "learning_rate": 5.4339523859748335e-05,
      "loss": 1.6661,
      "step": 12400
    },
    {
      "epoch": 3.7462235649546827,
      "eval_loss": 1.6929303407669067,
      "eval_runtime": 1598.1477,
      "eval_samples_per_second": 33.225,
      "eval_steps_per_second": 0.26,
      "step": 12400
    },
    {
      "epoch": 3.7613293051359515,
      "grad_norm": 1.6355665922164917,
      "learning_rate": 5.436272385238425e-05,
      "loss": 1.6759,
      "step": 12450
    },
    {
      "epoch": 3.7613293051359515,
      "eval_loss": 1.6924304962158203,
      "eval_runtime": 1503.6233,
      "eval_samples_per_second": 35.314,
      "eval_steps_per_second": 0.276,
      "step": 12450
    },
    {
      "epoch": 3.7764350453172204,
      "grad_norm": 1.452528476715088,
      "learning_rate": 5.438583085882828e-05,
      "loss": 1.6515,
      "step": 12500
    },
    {
      "epoch": 3.7764350453172204,
      "eval_loss": 1.6966478824615479,
      "eval_runtime": 2102.5653,
      "eval_samples_per_second": 25.254,
      "eval_steps_per_second": 0.197,
      "step": 12500
    },
    {
      "epoch": 3.7915407854984893,
      "grad_norm": 1.531099796295166,
      "learning_rate": 5.4408845621488114e-05,
      "loss": 1.6612,
      "step": 12550
    },
    {
      "epoch": 3.7915407854984893,
      "eval_loss": 1.6928510665893555,
      "eval_runtime": 1452.8311,
      "eval_samples_per_second": 36.549,
      "eval_steps_per_second": 0.286,
      "step": 12550
    },
    {
      "epoch": 3.806646525679758,
      "grad_norm": 1.6561771631240845,
      "learning_rate": 5.443176887391564e-05,
      "loss": 1.6426,
      "step": 12600
    },
    {
      "epoch": 3.806646525679758,
      "eval_loss": 1.695342779159546,
      "eval_runtime": 1527.8432,
      "eval_samples_per_second": 34.754,
      "eval_steps_per_second": 0.272,
      "step": 12600
    },
    {
      "epoch": 3.8217522658610275,
      "grad_norm": 1.5404466390609741,
      "learning_rate": 5.445460134094726e-05,
      "loss": 1.6492,
      "step": 12650
    },
    {
      "epoch": 3.8217522658610275,
      "eval_loss": 1.6873773336410522,
      "eval_runtime": 1596.6138,
      "eval_samples_per_second": 33.257,
      "eval_steps_per_second": 0.26,
      "step": 12650
    },
    {
      "epoch": 3.836858006042296,
      "grad_norm": 1.8955914974212646,
      "learning_rate": 5.447734373884133e-05,
      "loss": 1.6635,
      "step": 12700
    },
    {
      "epoch": 3.836858006042296,
      "eval_loss": 1.6900690793991089,
      "eval_runtime": 1574.5527,
      "eval_samples_per_second": 33.723,
      "eval_steps_per_second": 0.264,
      "step": 12700
    },
    {
      "epoch": 3.851963746223565,
      "grad_norm": 1.380613088607788,
      "learning_rate": 5.4499996775413085e-05,
      "loss": 1.6627,
      "step": 12750
    },
    {
      "epoch": 3.851963746223565,
      "eval_loss": 1.6918448209762573,
      "eval_runtime": 1638.4391,
      "eval_samples_per_second": 32.408,
      "eval_steps_per_second": 0.253,
      "step": 12750
    },
    {
      "epoch": 3.8670694864048336,
      "grad_norm": 1.1013760566711426,
      "learning_rate": 5.452256115016674e-05,
      "loss": 1.6494,
      "step": 12800
    },
    {
      "epoch": 3.8670694864048336,
      "eval_loss": 1.686432957649231,
      "eval_runtime": 1488.946,
      "eval_samples_per_second": 35.662,
      "eval_steps_per_second": 0.279,
      "step": 12800
    },
    {
      "epoch": 3.882175226586103,
      "grad_norm": 1.4818313121795654,
      "learning_rate": 5.454503755442518e-05,
      "loss": 1.6615,
      "step": 12850
    },
    {
      "epoch": 3.882175226586103,
      "eval_loss": 1.682967185974121,
      "eval_runtime": 1528.4022,
      "eval_samples_per_second": 34.742,
      "eval_steps_per_second": 0.272,
      "step": 12850
    },
    {
      "epoch": 3.8972809667673713,
      "grad_norm": 1.1294431686401367,
      "learning_rate": 5.4567426671456956e-05,
      "loss": 1.6351,
      "step": 12900
    },
    {
      "epoch": 3.8972809667673713,
      "eval_loss": 1.6834393739700317,
      "eval_runtime": 1534.2217,
      "eval_samples_per_second": 34.61,
      "eval_steps_per_second": 0.27,
      "step": 12900
    },
    {
      "epoch": 3.9123867069486407,
      "grad_norm": 1.2401001453399658,
      "learning_rate": 5.4589729176600985e-05,
      "loss": 1.6506,
      "step": 12950
    },
    {
      "epoch": 3.9123867069486407,
      "eval_loss": 1.6807533502578735,
      "eval_runtime": 1518.1722,
      "eval_samples_per_second": 34.976,
      "eval_steps_per_second": 0.273,
      "step": 12950
    },
    {
      "epoch": 3.9274924471299095,
      "grad_norm": 1.2051678895950317,
      "learning_rate": 5.461194573738874e-05,
      "loss": 1.654,
      "step": 13000
    },
    {
      "epoch": 3.9274924471299095,
      "eval_loss": 1.6818829774856567,
      "eval_runtime": 1570.4111,
      "eval_samples_per_second": 33.812,
      "eval_steps_per_second": 0.264,
      "step": 13000
    },
    {
      "epoch": 3.9425981873111784,
      "grad_norm": 1.3394657373428345,
      "learning_rate": 5.46340770136642e-05,
      "loss": 1.6746,
      "step": 13050
    },
    {
      "epoch": 3.9425981873111784,
      "eval_loss": 1.6800730228424072,
      "eval_runtime": 1549.4239,
      "eval_samples_per_second": 34.27,
      "eval_steps_per_second": 0.268,
      "step": 13050
    },
    {
      "epoch": 3.9577039274924473,
      "grad_norm": 1.5627816915512085,
      "learning_rate": 5.465612365770134e-05,
      "loss": 1.671,
      "step": 13100
    },
    {
      "epoch": 3.9577039274924473,
      "eval_loss": 1.6777350902557373,
      "eval_runtime": 1525.1223,
      "eval_samples_per_second": 34.816,
      "eval_steps_per_second": 0.272,
      "step": 13100
    },
    {
      "epoch": 3.972809667673716,
      "grad_norm": 1.4362536668777466,
      "learning_rate": 5.4678086314319564e-05,
      "loss": 1.6574,
      "step": 13150
    },
    {
      "epoch": 3.972809667673716,
      "eval_loss": 1.6778600215911865,
      "eval_runtime": 1467.0417,
      "eval_samples_per_second": 36.195,
      "eval_steps_per_second": 0.283,
      "step": 13150
    },
    {
      "epoch": 3.987915407854985,
      "grad_norm": 1.2927595376968384,
      "learning_rate": 5.469996562099686e-05,
      "loss": 1.6461,
      "step": 13200
    },
    {
      "epoch": 3.987915407854985,
      "eval_loss": 1.6761627197265625,
      "eval_runtime": 1513.5266,
      "eval_samples_per_second": 35.083,
      "eval_steps_per_second": 0.274,
      "step": 13200
    },
    {
      "epoch": 4.003021148036254,
      "grad_norm": 1.153567910194397,
      "learning_rate": 5.472176220798075e-05,
      "loss": 1.6547,
      "step": 13250
    },
    {
      "epoch": 4.003021148036254,
      "eval_loss": 1.680189609527588,
      "eval_runtime": 1505.0723,
      "eval_samples_per_second": 35.28,
      "eval_steps_per_second": 0.276,
      "step": 13250
    },
    {
      "epoch": 4.018126888217522,
      "grad_norm": 1.5449836254119873,
      "learning_rate": 5.4743476698397364e-05,
      "loss": 1.6572,
      "step": 13300
    },
    {
      "epoch": 4.018126888217522,
      "eval_loss": 1.6762892007827759,
      "eval_runtime": 1461.1598,
      "eval_samples_per_second": 36.34,
      "eval_steps_per_second": 0.284,
      "step": 13300
    },
    {
      "epoch": 4.033232628398792,
      "grad_norm": 1.3978744745254517,
      "learning_rate": 5.476510970835817e-05,
      "loss": 1.654,
      "step": 13350
    },
    {
      "epoch": 4.033232628398792,
      "eval_loss": 1.6735508441925049,
      "eval_runtime": 1672.1622,
      "eval_samples_per_second": 31.755,
      "eval_steps_per_second": 0.248,
      "step": 13350
    },
    {
      "epoch": 4.04833836858006,
      "grad_norm": 1.3993797302246094,
      "learning_rate": 5.478666184706498e-05,
      "loss": 1.6525,
      "step": 13400
    },
    {
      "epoch": 4.04833836858006,
      "eval_loss": 1.6737463474273682,
      "eval_runtime": 1449.5452,
      "eval_samples_per_second": 36.631,
      "eval_steps_per_second": 0.286,
      "step": 13400
    },
    {
      "epoch": 4.063444108761329,
      "grad_norm": 1.5931569337844849,
      "learning_rate": 5.480813371691286e-05,
      "loss": 1.6683,
      "step": 13450
    },
    {
      "epoch": 4.063444108761329,
      "eval_loss": 1.6691093444824219,
      "eval_runtime": 2097.5181,
      "eval_samples_per_second": 25.315,
      "eval_steps_per_second": 0.198,
      "step": 13450
    },
    {
      "epoch": 4.078549848942598,
      "grad_norm": 1.2848920822143555,
      "learning_rate": 5.4829525913591125e-05,
      "loss": 1.6617,
      "step": 13500
    },
    {
      "epoch": 4.078549848942598,
      "eval_loss": 1.670547366142273,
      "eval_runtime": 1524.3893,
      "eval_samples_per_second": 34.833,
      "eval_steps_per_second": 0.272,
      "step": 13500
    },
    {
      "epoch": 4.093655589123867,
      "grad_norm": 1.8204262256622314,
      "learning_rate": 5.4850839026182534e-05,
      "loss": 1.6467,
      "step": 13550
    },
    {
      "epoch": 4.093655589123867,
      "eval_loss": 1.6694824695587158,
      "eval_runtime": 1517.4106,
      "eval_samples_per_second": 34.993,
      "eval_steps_per_second": 0.273,
      "step": 13550
    },
    {
      "epoch": 4.108761329305136,
      "grad_norm": 1.6040066480636597,
      "learning_rate": 5.4872073637260595e-05,
      "loss": 1.6397,
      "step": 13600
    },
    {
      "epoch": 4.108761329305136,
      "eval_loss": 1.6664636135101318,
      "eval_runtime": 1495.9649,
      "eval_samples_per_second": 35.495,
      "eval_steps_per_second": 0.277,
      "step": 13600
    },
    {
      "epoch": 4.123867069486405,
      "grad_norm": 1.785775065422058,
      "learning_rate": 5.489323032298516e-05,
      "loss": 1.6464,
      "step": 13650
    },
    {
      "epoch": 4.123867069486405,
      "eval_loss": 1.6662918329238892,
      "eval_runtime": 1443.7011,
      "eval_samples_per_second": 36.78,
      "eval_steps_per_second": 0.287,
      "step": 13650
    },
    {
      "epoch": 4.138972809667674,
      "grad_norm": 1.5837525129318237,
      "learning_rate": 5.491430965319621e-05,
      "loss": 1.611,
      "step": 13700
    },
    {
      "epoch": 4.138972809667674,
      "eval_loss": 1.667128562927246,
      "eval_runtime": 1438.8559,
      "eval_samples_per_second": 36.904,
      "eval_steps_per_second": 0.288,
      "step": 13700
    },
    {
      "epoch": 4.1540785498489425,
      "grad_norm": 1.2131997346878052,
      "learning_rate": 5.4935312191505905e-05,
      "loss": 1.626,
      "step": 13750
    },
    {
      "epoch": 4.1540785498489425,
      "eval_loss": 1.663098931312561,
      "eval_runtime": 1531.9095,
      "eval_samples_per_second": 34.662,
      "eval_steps_per_second": 0.271,
      "step": 13750
    },
    {
      "epoch": 4.169184290030212,
      "grad_norm": 1.0712347030639648,
      "learning_rate": 5.495623849538905e-05,
      "loss": 1.6437,
      "step": 13800
    },
    {
      "epoch": 4.169184290030212,
      "eval_loss": 1.664278268814087,
      "eval_runtime": 1522.8738,
      "eval_samples_per_second": 34.868,
      "eval_steps_per_second": 0.273,
      "step": 13800
    },
    {
      "epoch": 4.18429003021148,
      "grad_norm": 1.369005799293518,
      "learning_rate": 5.497708911627188e-05,
      "loss": 1.63,
      "step": 13850
    },
    {
      "epoch": 4.18429003021148,
      "eval_loss": 1.6628401279449463,
      "eval_runtime": 1475.8652,
      "eval_samples_per_second": 35.978,
      "eval_steps_per_second": 0.281,
      "step": 13850
    },
    {
      "epoch": 4.19939577039275,
      "grad_norm": 1.5253559350967407,
      "learning_rate": 5.499786459961925e-05,
      "loss": 1.6351,
      "step": 13900
    },
    {
      "epoch": 4.19939577039275,
      "eval_loss": 1.6605889797210693,
      "eval_runtime": 1456.052,
      "eval_samples_per_second": 36.468,
      "eval_steps_per_second": 0.285,
      "step": 13900
    },
    {
      "epoch": 4.214501510574018,
      "grad_norm": 2.093093156814575,
      "learning_rate": 5.5018565485020234e-05,
      "loss": 1.5988,
      "step": 13950
    },
    {
      "epoch": 4.214501510574018,
      "eval_loss": 1.6602076292037964,
      "eval_runtime": 1711.8956,
      "eval_samples_per_second": 31.018,
      "eval_steps_per_second": 0.242,
      "step": 13950
    },
    {
      "epoch": 4.229607250755287,
      "grad_norm": 2.1111674308776855,
      "learning_rate": 5.503919230627221e-05,
      "loss": 1.6246,
      "step": 14000
    },
    {
      "epoch": 4.229607250755287,
      "eval_loss": 1.6602013111114502,
      "eval_runtime": 1645.4879,
      "eval_samples_per_second": 32.269,
      "eval_steps_per_second": 0.252,
      "step": 14000
    },
    {
      "epoch": 4.244712990936556,
      "grad_norm": 1.5206063985824585,
      "learning_rate": 5.50597455914635e-05,
      "loss": 1.6328,
      "step": 14050
    },
    {
      "epoch": 4.244712990936556,
      "eval_loss": 1.6593009233474731,
      "eval_runtime": 1430.2936,
      "eval_samples_per_second": 37.125,
      "eval_steps_per_second": 0.29,
      "step": 14050
    },
    {
      "epoch": 4.259818731117825,
      "grad_norm": 1.391859769821167,
      "learning_rate": 5.508022586305444e-05,
      "loss": 1.6354,
      "step": 14100
    },
    {
      "epoch": 4.259818731117825,
      "eval_loss": 1.6581873893737793,
      "eval_runtime": 2066.8245,
      "eval_samples_per_second": 25.691,
      "eval_steps_per_second": 0.201,
      "step": 14100
    },
    {
      "epoch": 4.2749244712990935,
      "grad_norm": 1.2655830383300781,
      "learning_rate": 5.510063363795711e-05,
      "loss": 1.6292,
      "step": 14150
    },
    {
      "epoch": 4.2749244712990935,
      "eval_loss": 1.6529937982559204,
      "eval_runtime": 1901.9658,
      "eval_samples_per_second": 27.918,
      "eval_steps_per_second": 0.218,
      "step": 14150
    },
    {
      "epoch": 4.290030211480363,
      "grad_norm": 1.9089362621307373,
      "learning_rate": 5.512096942761358e-05,
      "loss": 1.6178,
      "step": 14200
    },
    {
      "epoch": 4.290030211480363,
      "eval_loss": 1.6529881954193115,
      "eval_runtime": 2438.1994,
      "eval_samples_per_second": 21.778,
      "eval_steps_per_second": 0.17,
      "step": 14200
    },
    {
      "epoch": 4.305135951661631,
      "grad_norm": 1.156970739364624,
      "learning_rate": 5.514123373807285e-05,
      "loss": 1.6261,
      "step": 14250
    },
    {
      "epoch": 4.305135951661631,
      "eval_loss": 1.6535266637802124,
      "eval_runtime": 1857.7013,
      "eval_samples_per_second": 28.583,
      "eval_steps_per_second": 0.223,
      "step": 14250
    },
    {
      "epoch": 4.3202416918429005,
      "grad_norm": 1.5250493288040161,
      "learning_rate": 5.516142707006637e-05,
      "loss": 1.6409,
      "step": 14300
    },
    {
      "epoch": 4.3202416918429005,
      "eval_loss": 1.6506290435791016,
      "eval_runtime": 3160.5528,
      "eval_samples_per_second": 16.801,
      "eval_steps_per_second": 0.131,
      "step": 14300
    },
    {
      "epoch": 4.335347432024169,
      "grad_norm": 1.4449015855789185,
      "learning_rate": 5.518154991908236e-05,
      "loss": 1.6199,
      "step": 14350
    },
    {
      "epoch": 4.335347432024169,
      "eval_loss": 1.6494544744491577,
      "eval_runtime": 1449.3178,
      "eval_samples_per_second": 36.637,
      "eval_steps_per_second": 0.286,
      "step": 14350
    },
    {
      "epoch": 4.350453172205438,
      "grad_norm": 1.5874507427215576,
      "learning_rate": 5.520160277543864e-05,
      "loss": 1.632,
      "step": 14400
    },
    {
      "epoch": 4.350453172205438,
      "eval_loss": 1.6499663591384888,
      "eval_runtime": 1780.9261,
      "eval_samples_per_second": 29.815,
      "eval_steps_per_second": 0.233,
      "step": 14400
    },
    {
      "epoch": 4.365558912386707,
      "grad_norm": 0.8974785208702087,
      "learning_rate": 5.522158612435445e-05,
      "loss": 1.6103,
      "step": 14450
    },
    {
      "epoch": 4.365558912386707,
      "eval_loss": 1.6467738151550293,
      "eval_runtime": 1581.292,
      "eval_samples_per_second": 33.58,
      "eval_steps_per_second": 0.262,
      "step": 14450
    },
    {
      "epoch": 4.380664652567976,
      "grad_norm": 1.3885266780853271,
      "learning_rate": 5.524150044602076e-05,
      "loss": 1.6286,
      "step": 14500
    },
    {
      "epoch": 4.380664652567976,
      "eval_loss": 1.6466017961502075,
      "eval_runtime": 1443.8512,
      "eval_samples_per_second": 36.776,
      "eval_steps_per_second": 0.287,
      "step": 14500
    },
    {
      "epoch": 4.395770392749244,
      "grad_norm": 1.432836890220642,
      "learning_rate": 5.526134621566965e-05,
      "loss": 1.6024,
      "step": 14550
    },
    {
      "epoch": 4.395770392749244,
      "eval_loss": 1.6478428840637207,
      "eval_runtime": 2114.0756,
      "eval_samples_per_second": 25.117,
      "eval_steps_per_second": 0.196,
      "step": 14550
    },
    {
      "epoch": 4.410876132930514,
      "grad_norm": 1.4516962766647339,
      "learning_rate": 5.5281123903642244e-05,
      "loss": 1.621,
      "step": 14600
    },
    {
      "epoch": 4.410876132930514,
      "eval_loss": 1.6489144563674927,
      "eval_runtime": 1483.0613,
      "eval_samples_per_second": 35.804,
      "eval_steps_per_second": 0.28,
      "step": 14600
    },
    {
      "epoch": 4.425981873111782,
      "grad_norm": 1.157859206199646,
      "learning_rate": 5.5300833975455625e-05,
      "loss": 1.6317,
      "step": 14650
    },
    {
      "epoch": 4.425981873111782,
      "eval_loss": 1.645517349243164,
      "eval_runtime": 1549.463,
      "eval_samples_per_second": 34.269,
      "eval_steps_per_second": 0.268,
      "step": 14650
    },
    {
      "epoch": 4.4410876132930515,
      "grad_norm": 1.2204053401947021,
      "learning_rate": 5.5320476891868625e-05,
      "loss": 1.6072,
      "step": 14700
    },
    {
      "epoch": 4.4410876132930515,
      "eval_loss": 1.6440744400024414,
      "eval_runtime": 1965.6292,
      "eval_samples_per_second": 27.014,
      "eval_steps_per_second": 0.211,
      "step": 14700
    },
    {
      "epoch": 4.45619335347432,
      "grad_norm": 1.4159091711044312,
      "learning_rate": 5.53400531089464e-05,
      "loss": 1.6285,
      "step": 14750
    },
    {
      "epoch": 4.45619335347432,
      "eval_loss": 1.6434770822525024,
      "eval_runtime": 1535.8668,
      "eval_samples_per_second": 34.573,
      "eval_steps_per_second": 0.27,
      "step": 14750
    },
    {
      "epoch": 4.471299093655589,
      "grad_norm": 1.3214998245239258,
      "learning_rate": 5.535956307812398e-05,
      "loss": 1.6043,
      "step": 14800
    },
    {
      "epoch": 4.471299093655589,
      "eval_loss": 1.6405878067016602,
      "eval_runtime": 1844.9864,
      "eval_samples_per_second": 28.78,
      "eval_steps_per_second": 0.225,
      "step": 14800
    },
    {
      "epoch": 4.486404833836858,
      "grad_norm": 1.3472915887832642,
      "learning_rate": 5.5379007246268757e-05,
      "loss": 1.6185,
      "step": 14850
    },
    {
      "epoch": 4.486404833836858,
      "eval_loss": 1.6459821462631226,
      "eval_runtime": 1586.8968,
      "eval_samples_per_second": 33.461,
      "eval_steps_per_second": 0.262,
      "step": 14850
    },
    {
      "epoch": 4.501510574018127,
      "grad_norm": 1.3142553567886353,
      "learning_rate": 5.539838605574185e-05,
      "loss": 1.6208,
      "step": 14900
    },
    {
      "epoch": 4.501510574018127,
      "eval_loss": 1.6425782442092896,
      "eval_runtime": 1515.5376,
      "eval_samples_per_second": 35.036,
      "eval_steps_per_second": 0.274,
      "step": 14900
    },
    {
      "epoch": 4.516616314199396,
      "grad_norm": 1.464569330215454,
      "learning_rate": 5.541769994445857e-05,
      "loss": 1.626,
      "step": 14950
    },
    {
      "epoch": 4.516616314199396,
      "eval_loss": 1.6416800022125244,
      "eval_runtime": 1467.2827,
      "eval_samples_per_second": 36.189,
      "eval_steps_per_second": 0.283,
      "step": 14950
    },
    {
      "epoch": 4.531722054380665,
      "grad_norm": 1.5207678079605103,
      "learning_rate": 5.543694934594769e-05,
      "loss": 1.6094,
      "step": 15000
    },
    {
      "epoch": 4.531722054380665,
      "eval_loss": 1.6379776000976562,
      "eval_runtime": 1752.1279,
      "eval_samples_per_second": 30.305,
      "eval_steps_per_second": 0.237,
      "step": 15000
    },
    {
      "epoch": 4.546827794561933,
      "grad_norm": 1.162063479423523,
      "learning_rate": 5.5456134689409933e-05,
      "loss": 1.614,
      "step": 15050
    },
    {
      "epoch": 4.546827794561933,
      "eval_loss": 1.638575792312622,
      "eval_runtime": 1747.3426,
      "eval_samples_per_second": 30.388,
      "eval_steps_per_second": 0.238,
      "step": 15050
    },
    {
      "epoch": 4.561933534743202,
      "grad_norm": 1.302361249923706,
      "learning_rate": 5.547525639977534e-05,
      "loss": 1.6062,
      "step": 15100
    },
    {
      "epoch": 4.561933534743202,
      "eval_loss": 1.6359692811965942,
      "eval_runtime": 1466.9365,
      "eval_samples_per_second": 36.197,
      "eval_steps_per_second": 0.283,
      "step": 15100
    },
    {
      "epoch": 4.577039274924472,
      "grad_norm": 1.0863630771636963,
      "learning_rate": 5.549431489775976e-05,
      "loss": 1.6039,
      "step": 15150
    },
    {
      "epoch": 4.577039274924472,
      "eval_loss": 1.635263442993164,
      "eval_runtime": 1694.6575,
      "eval_samples_per_second": 31.333,
      "eval_steps_per_second": 0.245,
      "step": 15150
    },
    {
      "epoch": 4.59214501510574,
      "grad_norm": 2.261315107345581,
      "learning_rate": 5.551331059992036e-05,
      "loss": 1.6068,
      "step": 15200
    },
    {
      "epoch": 4.59214501510574,
      "eval_loss": 1.6360676288604736,
      "eval_runtime": 1461.721,
      "eval_samples_per_second": 36.326,
      "eval_steps_per_second": 0.284,
      "step": 15200
    },
    {
      "epoch": 4.6072507552870094,
      "grad_norm": 1.108888030052185,
      "learning_rate": 5.553224391871032e-05,
      "loss": 1.6116,
      "step": 15250
    },
    {
      "epoch": 4.6072507552870094,
      "eval_loss": 1.6318506002426147,
      "eval_runtime": 2181.4744,
      "eval_samples_per_second": 24.341,
      "eval_steps_per_second": 0.19,
      "step": 15250
    },
    {
      "epoch": 4.622356495468278,
      "grad_norm": 1.1450880765914917,
      "learning_rate": 5.5551115262532494e-05,
      "loss": 1.6194,
      "step": 15300
    },
    {
      "epoch": 4.622356495468278,
      "eval_loss": 1.6336321830749512,
      "eval_runtime": 1430.3102,
      "eval_samples_per_second": 37.124,
      "eval_steps_per_second": 0.29,
      "step": 15300
    },
    {
      "epoch": 4.637462235649547,
      "grad_norm": 1.465790867805481,
      "learning_rate": 5.5569925035792326e-05,
      "loss": 1.5999,
      "step": 15350
    },
    {
      "epoch": 4.637462235649547,
      "eval_loss": 1.6321762800216675,
      "eval_runtime": 1593.8021,
      "eval_samples_per_second": 33.316,
      "eval_steps_per_second": 0.26,
      "step": 15350
    },
    {
      "epoch": 4.652567975830816,
      "grad_norm": 1.4050474166870117,
      "learning_rate": 5.5588673638949835e-05,
      "loss": 1.6069,
      "step": 15400
    },
    {
      "epoch": 4.652567975830816,
      "eval_loss": 1.6279932260513306,
      "eval_runtime": 2352.9038,
      "eval_samples_per_second": 22.567,
      "eval_steps_per_second": 0.176,
      "step": 15400
    },
    {
      "epoch": 4.667673716012085,
      "grad_norm": 1.4785815477371216,
      "learning_rate": 5.5607361468570724e-05,
      "loss": 1.605,
      "step": 15450
    },
    {
      "epoch": 4.667673716012085,
      "eval_loss": 1.6264218091964722,
      "eval_runtime": 1464.7292,
      "eval_samples_per_second": 36.252,
      "eval_steps_per_second": 0.283,
      "step": 15450
    },
    {
      "epoch": 4.682779456193353,
      "grad_norm": 1.731096863746643,
      "learning_rate": 5.562598891737679e-05,
      "loss": 1.5932,
      "step": 15500
    },
    {
      "epoch": 4.682779456193353,
      "eval_loss": 1.6292804479599,
      "eval_runtime": 1594.4924,
      "eval_samples_per_second": 33.302,
      "eval_steps_per_second": 0.26,
      "step": 15500
    },
    {
      "epoch": 4.697885196374623,
      "grad_norm": 1.1421908140182495,
      "learning_rate": 5.5644556374295374e-05,
      "loss": 1.5992,
      "step": 15550
    },
    {
      "epoch": 4.697885196374623,
      "eval_loss": 1.6292543411254883,
      "eval_runtime": 1544.5064,
      "eval_samples_per_second": 34.379,
      "eval_steps_per_second": 0.269,
      "step": 15550
    },
    {
      "epoch": 4.712990936555891,
      "grad_norm": 1.1303961277008057,
      "learning_rate": 5.566306422450816e-05,
      "loss": 1.5744,
      "step": 15600
    },
    {
      "epoch": 4.712990936555891,
      "eval_loss": 1.6272040605545044,
      "eval_runtime": 1481.1935,
      "eval_samples_per_second": 35.849,
      "eval_steps_per_second": 0.28,
      "step": 15600
    },
    {
      "epoch": 4.72809667673716,
      "grad_norm": 1.1541553735733032,
      "learning_rate": 5.568151284949901e-05,
      "loss": 1.6068,
      "step": 15650
    },
    {
      "epoch": 4.72809667673716,
      "eval_loss": 1.6262842416763306,
      "eval_runtime": 1479.5971,
      "eval_samples_per_second": 35.887,
      "eval_steps_per_second": 0.28,
      "step": 15650
    },
    {
      "epoch": 4.743202416918429,
      "grad_norm": 1.413742184638977,
      "learning_rate": 5.5699902627101273e-05,
      "loss": 1.5833,
      "step": 15700
    },
    {
      "epoch": 4.743202416918429,
      "eval_loss": 1.6260182857513428,
      "eval_runtime": 1561.5379,
      "eval_samples_per_second": 34.004,
      "eval_steps_per_second": 0.266,
      "step": 15700
    },
    {
      "epoch": 4.758308157099698,
      "grad_norm": 1.4308542013168335,
      "learning_rate": 5.571823393154411e-05,
      "loss": 1.5943,
      "step": 15750
    },
    {
      "epoch": 4.758308157099698,
      "eval_loss": 1.6223222017288208,
      "eval_runtime": 2132.1697,
      "eval_samples_per_second": 24.904,
      "eval_steps_per_second": 0.195,
      "step": 15750
    },
    {
      "epoch": 4.7734138972809665,
      "grad_norm": 0.9719618558883667,
      "learning_rate": 5.573650713349823e-05,
      "loss": 1.5909,
      "step": 15800
    },
    {
      "epoch": 4.7734138972809665,
      "eval_loss": 1.6245678663253784,
      "eval_runtime": 1479.4833,
      "eval_samples_per_second": 35.89,
      "eval_steps_per_second": 0.281,
      "step": 15800
    },
    {
      "epoch": 4.788519637462236,
      "grad_norm": 1.230398178100586,
      "learning_rate": 5.5754722600120915e-05,
      "loss": 1.5916,
      "step": 15850
    },
    {
      "epoch": 4.788519637462236,
      "eval_loss": 1.6216570138931274,
      "eval_runtime": 2852.0988,
      "eval_samples_per_second": 18.618,
      "eval_steps_per_second": 0.146,
      "step": 15850
    },
    {
      "epoch": 4.803625377643504,
      "grad_norm": 1.290566086769104,
      "learning_rate": 5.577288069510017e-05,
      "loss": 1.6035,
      "step": 15900
    },
    {
      "epoch": 4.803625377643504,
      "eval_loss": 1.6231920719146729,
      "eval_runtime": 1539.0227,
      "eval_samples_per_second": 34.502,
      "eval_steps_per_second": 0.27,
      "step": 15900
    },
    {
      "epoch": 4.818731117824774,
      "grad_norm": 1.380930781364441,
      "learning_rate": 5.5790981778698384e-05,
      "loss": 1.5679,
      "step": 15950
    },
    {
      "epoch": 4.818731117824774,
      "eval_loss": 1.6206210851669312,
      "eval_runtime": 1527.6127,
      "eval_samples_per_second": 34.759,
      "eval_steps_per_second": 0.272,
      "step": 15950
    },
    {
      "epoch": 4.833836858006042,
      "grad_norm": 1.3278172016143799,
      "learning_rate": 5.5809026207795205e-05,
      "loss": 1.6014,
      "step": 16000
    },
    {
      "epoch": 4.833836858006042,
      "eval_loss": 1.6184008121490479,
      "eval_runtime": 1551.2076,
      "eval_samples_per_second": 34.231,
      "eval_steps_per_second": 0.268,
      "step": 16000
    },
    {
      "epoch": 4.848942598187311,
      "grad_norm": 1.1563122272491455,
      "learning_rate": 5.5827014335929714e-05,
      "loss": 1.5656,
      "step": 16050
    },
    {
      "epoch": 4.848942598187311,
      "eval_loss": 1.6197090148925781,
      "eval_runtime": 1499.071,
      "eval_samples_per_second": 35.421,
      "eval_steps_per_second": 0.277,
      "step": 16050
    },
    {
      "epoch": 4.86404833836858,
      "grad_norm": 1.926559567451477,
      "learning_rate": 5.5844946513342024e-05,
      "loss": 1.5801,
      "step": 16100
    },
    {
      "epoch": 4.86404833836858,
      "eval_loss": 1.6168936491012573,
      "eval_runtime": 1523.1562,
      "eval_samples_per_second": 34.861,
      "eval_steps_per_second": 0.272,
      "step": 16100
    },
    {
      "epoch": 4.879154078549849,
      "grad_norm": 1.1648070812225342,
      "learning_rate": 5.5862823087014197e-05,
      "loss": 1.5992,
      "step": 16150
    },
    {
      "epoch": 4.879154078549849,
      "eval_loss": 1.6186134815216064,
      "eval_runtime": 1458.0937,
      "eval_samples_per_second": 36.417,
      "eval_steps_per_second": 0.285,
      "step": 16150
    },
    {
      "epoch": 4.8942598187311175,
      "grad_norm": 1.0903260707855225,
      "learning_rate": 5.588064440071054e-05,
      "loss": 1.5802,
      "step": 16200
    },
    {
      "epoch": 4.8942598187311175,
      "eval_loss": 1.6155073642730713,
      "eval_runtime": 1458.6388,
      "eval_samples_per_second": 36.403,
      "eval_steps_per_second": 0.285,
      "step": 16200
    },
    {
      "epoch": 4.909365558912387,
      "grad_norm": 1.1285128593444824,
      "learning_rate": 5.589841079501721e-05,
      "loss": 1.5904,
      "step": 16250
    },
    {
      "epoch": 4.909365558912387,
      "eval_loss": 1.6137093305587769,
      "eval_runtime": 1449.1595,
      "eval_samples_per_second": 36.641,
      "eval_steps_per_second": 0.286,
      "step": 16250
    },
    {
      "epoch": 4.924471299093655,
      "grad_norm": 1.0925310850143433,
      "learning_rate": 5.591612260738133e-05,
      "loss": 1.5863,
      "step": 16300
    },
    {
      "epoch": 4.924471299093655,
      "eval_loss": 1.6116963624954224,
      "eval_runtime": 1431.7875,
      "eval_samples_per_second": 37.086,
      "eval_steps_per_second": 0.29,
      "step": 16300
    },
    {
      "epoch": 4.9395770392749245,
      "grad_norm": 1.4059280157089233,
      "learning_rate": 5.593378017214944e-05,
      "loss": 1.5804,
      "step": 16350
    },
    {
      "epoch": 4.9395770392749245,
      "eval_loss": 1.6162277460098267,
      "eval_runtime": 1511.7545,
      "eval_samples_per_second": 35.124,
      "eval_steps_per_second": 0.275,
      "step": 16350
    },
    {
      "epoch": 4.954682779456194,
      "grad_norm": 1.0835083723068237,
      "learning_rate": 5.5951383820605344e-05,
      "loss": 1.6051,
      "step": 16400
    },
    {
      "epoch": 4.954682779456194,
      "eval_loss": 1.6142680644989014,
      "eval_runtime": 1450.8507,
      "eval_samples_per_second": 36.599,
      "eval_steps_per_second": 0.286,
      "step": 16400
    },
    {
      "epoch": 4.969788519637462,
      "grad_norm": 1.1503974199295044,
      "learning_rate": 5.5968933881007414e-05,
      "loss": 1.5857,
      "step": 16450
    },
    {
      "epoch": 4.969788519637462,
      "eval_loss": 1.609796166419983,
      "eval_runtime": 1524.3566,
      "eval_samples_per_second": 34.834,
      "eval_steps_per_second": 0.272,
      "step": 16450
    },
    {
      "epoch": 4.984894259818731,
      "grad_norm": 1.0420690774917603,
      "learning_rate": 5.5986430678625306e-05,
      "loss": 1.5675,
      "step": 16500
    },
    {
      "epoch": 4.984894259818731,
      "eval_loss": 1.6127160787582397,
      "eval_runtime": 1507.7533,
      "eval_samples_per_second": 35.217,
      "eval_steps_per_second": 0.275,
      "step": 16500
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0335994958877563,
      "learning_rate": 5.600387453577617e-05,
      "loss": 1.5864,
      "step": 16550
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6111681461334229,
      "eval_runtime": 1505.3672,
      "eval_samples_per_second": 35.273,
      "eval_steps_per_second": 0.276,
      "step": 16550
    },
    {
      "epoch": 5.015105740181269,
      "grad_norm": 1.2506699562072754,
      "learning_rate": 5.6021265771860226e-05,
      "loss": 1.5814,
      "step": 16600
    },
    {
      "epoch": 5.015105740181269,
      "eval_loss": 1.6080029010772705,
      "eval_runtime": 1528.4946,
      "eval_samples_per_second": 34.739,
      "eval_steps_per_second": 0.272,
      "step": 16600
    },
    {
      "epoch": 5.030211480362538,
      "grad_norm": 1.013489842414856,
      "learning_rate": 5.603860470339587e-05,
      "loss": 1.5874,
      "step": 16650
    },
    {
      "epoch": 5.030211480362538,
      "eval_loss": 1.6114416122436523,
      "eval_runtime": 1446.5656,
      "eval_samples_per_second": 36.707,
      "eval_steps_per_second": 0.287,
      "step": 16650
    },
    {
      "epoch": 5.045317220543807,
      "grad_norm": 1.1984771490097046,
      "learning_rate": 5.605589164405429e-05,
      "loss": 1.5875,
      "step": 16700
    },
    {
      "epoch": 5.045317220543807,
      "eval_loss": 1.6092888116836548,
      "eval_runtime": 1550.6149,
      "eval_samples_per_second": 34.244,
      "eval_steps_per_second": 0.268,
      "step": 16700
    },
    {
      "epoch": 5.0604229607250755,
      "grad_norm": 1.2070813179016113,
      "learning_rate": 5.607312690469345e-05,
      "loss": 1.5839,
      "step": 16750
    },
    {
      "epoch": 5.0604229607250755,
      "eval_loss": 1.608344316482544,
      "eval_runtime": 1553.6877,
      "eval_samples_per_second": 34.176,
      "eval_steps_per_second": 0.267,
      "step": 16750
    },
    {
      "epoch": 5.075528700906345,
      "grad_norm": 1.1538761854171753,
      "learning_rate": 5.609031079339162e-05,
      "loss": 1.5755,
      "step": 16800
    },
    {
      "epoch": 5.075528700906345,
      "eval_loss": 1.6071935892105103,
      "eval_runtime": 1448.3317,
      "eval_samples_per_second": 36.662,
      "eval_steps_per_second": 0.287,
      "step": 16800
    },
    {
      "epoch": 5.090634441087613,
      "grad_norm": 1.0877116918563843,
      "learning_rate": 5.6107443615480494e-05,
      "loss": 1.5742,
      "step": 16850
    },
    {
      "epoch": 5.090634441087613,
      "eval_loss": 1.604561448097229,
      "eval_runtime": 1538.4684,
      "eval_samples_per_second": 34.514,
      "eval_steps_per_second": 0.27,
      "step": 16850
    },
    {
      "epoch": 5.1057401812688825,
      "grad_norm": 1.6620433330535889,
      "learning_rate": 5.612452567357768e-05,
      "loss": 1.5708,
      "step": 16900
    },
    {
      "epoch": 5.1057401812688825,
      "eval_loss": 1.608849048614502,
      "eval_runtime": 1431.4916,
      "eval_samples_per_second": 37.093,
      "eval_steps_per_second": 0.29,
      "step": 16900
    },
    {
      "epoch": 5.120845921450151,
      "grad_norm": 1.1776784658432007,
      "learning_rate": 5.614155726761879e-05,
      "loss": 1.5547,
      "step": 16950
    },
    {
      "epoch": 5.120845921450151,
      "eval_loss": 1.609220266342163,
      "eval_runtime": 1468.2225,
      "eval_samples_per_second": 36.165,
      "eval_steps_per_second": 0.283,
      "step": 16950
    },
    {
      "epoch": 5.13595166163142,
      "grad_norm": 1.1836926937103271,
      "learning_rate": 5.615853869488906e-05,
      "loss": 1.5904,
      "step": 17000
    },
    {
      "epoch": 5.13595166163142,
      "eval_loss": 1.603798270225525,
      "eval_runtime": 1447.9959,
      "eval_samples_per_second": 36.671,
      "eval_steps_per_second": 0.287,
      "step": 17000
    },
    {
      "epoch": 5.151057401812689,
      "grad_norm": 1.1054943799972534,
      "learning_rate": 5.617547025005441e-05,
      "loss": 1.5593,
      "step": 17050
    },
    {
      "epoch": 5.151057401812689,
      "eval_loss": 1.6032848358154297,
      "eval_runtime": 1594.5929,
      "eval_samples_per_second": 33.299,
      "eval_steps_per_second": 0.26,
      "step": 17050
    },
    {
      "epoch": 5.166163141993958,
      "grad_norm": 1.0708473920822144,
      "learning_rate": 5.619235222519226e-05,
      "loss": 1.593,
      "step": 17100
    },
    {
      "epoch": 5.166163141993958,
      "eval_loss": 1.601128339767456,
      "eval_runtime": 1516.6357,
      "eval_samples_per_second": 35.011,
      "eval_steps_per_second": 0.274,
      "step": 17100
    },
    {
      "epoch": 5.181268882175226,
      "grad_norm": 1.102449893951416,
      "learning_rate": 5.620918490982161e-05,
      "loss": 1.5648,
      "step": 17150
    },
    {
      "epoch": 5.181268882175226,
      "eval_loss": 1.6015301942825317,
      "eval_runtime": 1501.5105,
      "eval_samples_per_second": 35.364,
      "eval_steps_per_second": 0.276,
      "step": 17150
    },
    {
      "epoch": 5.196374622356496,
      "grad_norm": 1.0207380056381226,
      "learning_rate": 5.622596859093293e-05,
      "loss": 1.5623,
      "step": 17200
    },
    {
      "epoch": 5.196374622356496,
      "eval_loss": 1.5998231172561646,
      "eval_runtime": 1531.2856,
      "eval_samples_per_second": 34.676,
      "eval_steps_per_second": 0.271,
      "step": 17200
    },
    {
      "epoch": 5.211480362537764,
      "grad_norm": 1.13689386844635,
      "learning_rate": 5.624270355301751e-05,
      "loss": 1.5745,
      "step": 17250
    },
    {
      "epoch": 5.211480362537764,
      "eval_loss": 1.6003845930099487,
      "eval_runtime": 1554.6699,
      "eval_samples_per_second": 34.155,
      "eval_steps_per_second": 0.267,
      "step": 17250
    },
    {
      "epoch": 5.2265861027190335,
      "grad_norm": 1.0937399864196777,
      "learning_rate": 5.6259390078096334e-05,
      "loss": 1.5802,
      "step": 17300
    },
    {
      "epoch": 5.2265861027190335,
      "eval_loss": 1.5978407859802246,
      "eval_runtime": 1539.2633,
      "eval_samples_per_second": 34.496,
      "eval_steps_per_second": 0.27,
      "step": 17300
    },
    {
      "epoch": 5.241691842900302,
      "grad_norm": 1.3146132230758667,
      "learning_rate": 5.627602844574868e-05,
      "loss": 1.5745,
      "step": 17350
    },
    {
      "epoch": 5.241691842900302,
      "eval_loss": 1.597303032875061,
      "eval_runtime": 1495.0494,
      "eval_samples_per_second": 35.517,
      "eval_steps_per_second": 0.278,
      "step": 17350
    },
    {
      "epoch": 5.256797583081571,
      "grad_norm": 1.304673433303833,
      "learning_rate": 5.6292618933140175e-05,
      "loss": 1.5522,
      "step": 17400
    },
    {
      "epoch": 5.256797583081571,
      "eval_loss": 1.5947245359420776,
      "eval_runtime": 1611.4979,
      "eval_samples_per_second": 32.95,
      "eval_steps_per_second": 0.258,
      "step": 17400
    },
    {
      "epoch": 5.27190332326284,
      "grad_norm": 1.2277910709381104,
      "learning_rate": 5.630916181505048e-05,
      "loss": 1.5774,
      "step": 17450
    },
    {
      "epoch": 5.27190332326284,
      "eval_loss": 1.5942349433898926,
      "eval_runtime": 1505.5535,
      "eval_samples_per_second": 35.269,
      "eval_steps_per_second": 0.276,
      "step": 17450
    },
    {
      "epoch": 5.287009063444109,
      "grad_norm": 1.3762341737747192,
      "learning_rate": 5.6325657363900666e-05,
      "loss": 1.5563,
      "step": 17500
    },
    {
      "epoch": 5.287009063444109,
      "eval_loss": 1.5946071147918701,
      "eval_runtime": 1541.7742,
      "eval_samples_per_second": 34.44,
      "eval_steps_per_second": 0.269,
      "step": 17500
    },
    {
      "epoch": 5.302114803625377,
      "grad_norm": 0.9947209358215332,
      "learning_rate": 5.634210584978006e-05,
      "loss": 1.5741,
      "step": 17550
    },
    {
      "epoch": 5.302114803625377,
      "eval_loss": 1.5933843851089478,
      "eval_runtime": 1418.3714,
      "eval_samples_per_second": 37.437,
      "eval_steps_per_second": 0.293,
      "step": 17550
    },
    {
      "epoch": 5.317220543806647,
      "grad_norm": 1.0164566040039062,
      "learning_rate": 5.6358507540472816e-05,
      "loss": 1.5659,
      "step": 17600
    },
    {
      "epoch": 5.317220543806647,
      "eval_loss": 1.597857117652893,
      "eval_runtime": 1654.7266,
      "eval_samples_per_second": 32.089,
      "eval_steps_per_second": 0.251,
      "step": 17600
    },
    {
      "epoch": 5.332326283987915,
      "grad_norm": 1.3799799680709839,
      "learning_rate": 5.63748627014841e-05,
      "loss": 1.5938,
      "step": 17650
    },
    {
      "epoch": 5.332326283987915,
      "eval_loss": 1.5960667133331299,
      "eval_runtime": 1493.7215,
      "eval_samples_per_second": 35.548,
      "eval_steps_per_second": 0.278,
      "step": 17650
    },
    {
      "epoch": 5.347432024169184,
      "grad_norm": 1.1523326635360718,
      "learning_rate": 5.63911715960658e-05,
      "loss": 1.5625,
      "step": 17700
    },
    {
      "epoch": 5.347432024169184,
      "eval_loss": 1.5947844982147217,
      "eval_runtime": 1792.4554,
      "eval_samples_per_second": 29.624,
      "eval_steps_per_second": 0.232,
      "step": 17700
    },
    {
      "epoch": 5.362537764350453,
      "grad_norm": 1.1897109746932983,
      "learning_rate": 5.640743448524203e-05,
      "loss": 1.557,
      "step": 17750
    },
    {
      "epoch": 5.362537764350453,
      "eval_loss": 1.5927107334136963,
      "eval_runtime": 1428.326,
      "eval_samples_per_second": 37.176,
      "eval_steps_per_second": 0.291,
      "step": 17750
    },
    {
      "epoch": 5.377643504531722,
      "grad_norm": 1.1795456409454346,
      "learning_rate": 5.642365162783414e-05,
      "loss": 1.5789,
      "step": 17800
    },
    {
      "epoch": 5.377643504531722,
      "eval_loss": 1.5892773866653442,
      "eval_runtime": 1523.1892,
      "eval_samples_per_second": 34.86,
      "eval_steps_per_second": 0.272,
      "step": 17800
    },
    {
      "epoch": 5.3927492447129906,
      "grad_norm": 1.0512738227844238,
      "learning_rate": 5.643982328048546e-05,
      "loss": 1.5653,
      "step": 17850
    },
    {
      "epoch": 5.3927492447129906,
      "eval_loss": 1.5933407545089722,
      "eval_runtime": 1446.9318,
      "eval_samples_per_second": 36.698,
      "eval_steps_per_second": 0.287,
      "step": 17850
    },
    {
      "epoch": 5.40785498489426,
      "grad_norm": 1.0994199514389038,
      "learning_rate": 5.6455949697685694e-05,
      "loss": 1.5705,
      "step": 17900
    },
    {
      "epoch": 5.40785498489426,
      "eval_loss": 1.5893887281417847,
      "eval_runtime": 1569.464,
      "eval_samples_per_second": 33.833,
      "eval_steps_per_second": 0.264,
      "step": 17900
    },
    {
      "epoch": 5.422960725075528,
      "grad_norm": 1.1412569284439087,
      "learning_rate": 5.647203113179485e-05,
      "loss": 1.548,
      "step": 17950
    },
    {
      "epoch": 5.422960725075528,
      "eval_loss": 1.5895179510116577,
      "eval_runtime": 1445.2718,
      "eval_samples_per_second": 36.74,
      "eval_steps_per_second": 0.287,
      "step": 17950
    },
    {
      "epoch": 5.438066465256798,
      "grad_norm": 1.194297432899475,
      "learning_rate": 5.64880678330671e-05,
      "loss": 1.5481,
      "step": 18000
    },
    {
      "epoch": 5.438066465256798,
      "eval_loss": 1.5843676328659058,
      "eval_runtime": 1483.414,
      "eval_samples_per_second": 35.795,
      "eval_steps_per_second": 0.28,
      "step": 18000
    },
    {
      "epoch": 5.453172205438067,
      "grad_norm": 1.058351993560791,
      "learning_rate": 5.6504060049673967e-05,
      "loss": 1.5678,
      "step": 18050
    },
    {
      "epoch": 5.453172205438067,
      "eval_loss": 1.5865882635116577,
      "eval_runtime": 1524.0112,
      "eval_samples_per_second": 34.842,
      "eval_steps_per_second": 0.272,
      "step": 18050
    },
    {
      "epoch": 5.468277945619335,
      "grad_norm": 1.2097259759902954,
      "learning_rate": 5.65200080277275e-05,
      "loss": 1.5547,
      "step": 18100
    },
    {
      "epoch": 5.468277945619335,
      "eval_loss": 1.5851689577102661,
      "eval_runtime": 1538.3146,
      "eval_samples_per_second": 34.518,
      "eval_steps_per_second": 0.27,
      "step": 18100
    },
    {
      "epoch": 5.483383685800605,
      "grad_norm": 1.1506356000900269,
      "learning_rate": 5.653591201130293e-05,
      "loss": 1.5622,
      "step": 18150
    },
    {
      "epoch": 5.483383685800605,
      "eval_loss": 1.5846421718597412,
      "eval_runtime": 1551.8308,
      "eval_samples_per_second": 34.217,
      "eval_steps_per_second": 0.267,
      "step": 18150
    },
    {
      "epoch": 5.498489425981873,
      "grad_norm": 1.1594997644424438,
      "learning_rate": 5.655177224246114e-05,
      "loss": 1.57,
      "step": 18200
    },
    {
      "epoch": 5.498489425981873,
      "eval_loss": 1.583403468132019,
      "eval_runtime": 1525.6347,
      "eval_samples_per_second": 34.805,
      "eval_steps_per_second": 0.272,
      "step": 18200
    },
    {
      "epoch": 5.513595166163142,
      "grad_norm": 1.3078513145446777,
      "learning_rate": 5.656758896127069e-05,
      "loss": 1.5587,
      "step": 18250
    },
    {
      "epoch": 5.513595166163142,
      "eval_loss": 1.5858204364776611,
      "eval_runtime": 1447.3262,
      "eval_samples_per_second": 36.688,
      "eval_steps_per_second": 0.287,
      "step": 18250
    },
    {
      "epoch": 5.528700906344411,
      "grad_norm": 1.4641209840774536,
      "learning_rate": 5.658336240582972e-05,
      "loss": 1.566,
      "step": 18300
    },
    {
      "epoch": 5.528700906344411,
      "eval_loss": 1.5840727090835571,
      "eval_runtime": 1529.7092,
      "eval_samples_per_second": 34.712,
      "eval_steps_per_second": 0.271,
      "step": 18300
    },
    {
      "epoch": 5.54380664652568,
      "grad_norm": 1.011207103729248,
      "learning_rate": 5.659909281228737e-05,
      "loss": 1.5585,
      "step": 18350
    },
    {
      "epoch": 5.54380664652568,
      "eval_loss": 1.5824177265167236,
      "eval_runtime": 1527.7971,
      "eval_samples_per_second": 34.755,
      "eval_steps_per_second": 0.272,
      "step": 18350
    },
    {
      "epoch": 5.5589123867069485,
      "grad_norm": 0.9365096092224121,
      "learning_rate": 5.661478041486502e-05,
      "loss": 1.5738,
      "step": 18400
    },
    {
      "epoch": 5.5589123867069485,
      "eval_loss": 1.583540678024292,
      "eval_runtime": 1661.1725,
      "eval_samples_per_second": 31.965,
      "eval_steps_per_second": 0.25,
      "step": 18400
    },
    {
      "epoch": 5.574018126888218,
      "grad_norm": 1.0667790174484253,
      "learning_rate": 5.663042544587725e-05,
      "loss": 1.5702,
      "step": 18450
    },
    {
      "epoch": 5.574018126888218,
      "eval_loss": 1.5799024105072021,
      "eval_runtime": 1486.9884,
      "eval_samples_per_second": 35.709,
      "eval_steps_per_second": 0.279,
      "step": 18450
    },
    {
      "epoch": 5.589123867069486,
      "grad_norm": 0.8525143265724182,
      "learning_rate": 5.664602813575243e-05,
      "loss": 1.5288,
      "step": 18500
    },
    {
      "epoch": 5.589123867069486,
      "eval_loss": 1.5798685550689697,
      "eval_runtime": 1570.2304,
      "eval_samples_per_second": 33.816,
      "eval_steps_per_second": 0.264,
      "step": 18500
    },
    {
      "epoch": 5.604229607250756,
      "grad_norm": 0.9446711540222168,
      "learning_rate": 5.666158871305314e-05,
      "loss": 1.5643,
      "step": 18550
    },
    {
      "epoch": 5.604229607250756,
      "eval_loss": 1.5784372091293335,
      "eval_runtime": 1635.7981,
      "eval_samples_per_second": 32.461,
      "eval_steps_per_second": 0.254,
      "step": 18550
    },
    {
      "epoch": 5.619335347432024,
      "grad_norm": 0.986559271812439,
      "learning_rate": 5.6677107404496205e-05,
      "loss": 1.5479,
      "step": 18600
    },
    {
      "epoch": 5.619335347432024,
      "eval_loss": 1.5793311595916748,
      "eval_runtime": 1503.753,
      "eval_samples_per_second": 35.311,
      "eval_steps_per_second": 0.276,
      "step": 18600
    },
    {
      "epoch": 5.634441087613293,
      "grad_norm": 1.2730216979980469,
      "learning_rate": 5.669258443497252e-05,
      "loss": 1.522,
      "step": 18650
    },
    {
      "epoch": 5.634441087613293,
      "eval_loss": 1.581121802330017,
      "eval_runtime": 1445.0413,
      "eval_samples_per_second": 36.746,
      "eval_steps_per_second": 0.287,
      "step": 18650
    },
    {
      "epoch": 5.649546827794562,
      "grad_norm": 0.9064896106719971,
      "learning_rate": 5.670802002756667e-05,
      "loss": 1.5553,
      "step": 18700
    },
    {
      "epoch": 5.649546827794562,
      "eval_loss": 1.5793085098266602,
      "eval_runtime": 1550.1114,
      "eval_samples_per_second": 34.255,
      "eval_steps_per_second": 0.268,
      "step": 18700
    },
    {
      "epoch": 5.664652567975831,
      "grad_norm": 0.9690034985542297,
      "learning_rate": 5.672341440357614e-05,
      "loss": 1.557,
      "step": 18750
    },
    {
      "epoch": 5.664652567975831,
      "eval_loss": 1.5776935815811157,
      "eval_runtime": 1636.3721,
      "eval_samples_per_second": 32.449,
      "eval_steps_per_second": 0.254,
      "step": 18750
    },
    {
      "epoch": 5.6797583081570995,
      "grad_norm": 1.1446183919906616,
      "learning_rate": 5.673876778253041e-05,
      "loss": 1.5459,
      "step": 18800
    },
    {
      "epoch": 5.6797583081570995,
      "eval_loss": 1.5771458148956299,
      "eval_runtime": 1518.0632,
      "eval_samples_per_second": 34.978,
      "eval_steps_per_second": 0.273,
      "step": 18800
    },
    {
      "epoch": 5.694864048338369,
      "grad_norm": 0.9383087754249573,
      "learning_rate": 5.67540803822097e-05,
      "loss": 1.5568,
      "step": 18850
    },
    {
      "epoch": 5.694864048338369,
      "eval_loss": 1.577142596244812,
      "eval_runtime": 1469.7527,
      "eval_samples_per_second": 36.128,
      "eval_steps_per_second": 0.282,
      "step": 18850
    },
    {
      "epoch": 5.709969788519637,
      "grad_norm": 1.022148847579956,
      "learning_rate": 5.676935241866352e-05,
      "loss": 1.5515,
      "step": 18900
    },
    {
      "epoch": 5.709969788519637,
      "eval_loss": 1.5745328664779663,
      "eval_runtime": 1614.8713,
      "eval_samples_per_second": 32.881,
      "eval_steps_per_second": 0.257,
      "step": 18900
    },
    {
      "epoch": 5.7250755287009065,
      "grad_norm": 1.1835596561431885,
      "learning_rate": 5.678458410622897e-05,
      "loss": 1.5354,
      "step": 18950
    },
    {
      "epoch": 5.7250755287009065,
      "eval_loss": 1.5755740404129028,
      "eval_runtime": 1566.1788,
      "eval_samples_per_second": 33.904,
      "eval_steps_per_second": 0.265,
      "step": 18950
    },
    {
      "epoch": 5.740181268882175,
      "grad_norm": 0.9269928336143494,
      "learning_rate": 5.6799775657548813e-05,
      "loss": 1.5328,
      "step": 19000
    },
    {
      "epoch": 5.740181268882175,
      "eval_loss": 1.5759698152542114,
      "eval_runtime": 1530.5879,
      "eval_samples_per_second": 34.692,
      "eval_steps_per_second": 0.271,
      "step": 19000
    },
    {
      "epoch": 5.755287009063444,
      "grad_norm": 1.1636226177215576,
      "learning_rate": 5.681492728358919e-05,
      "loss": 1.5517,
      "step": 19050
    },
    {
      "epoch": 5.755287009063444,
      "eval_loss": 1.5716420412063599,
      "eval_runtime": 1572.9006,
      "eval_samples_per_second": 33.759,
      "eval_steps_per_second": 0.264,
      "step": 19050
    },
    {
      "epoch": 5.770392749244713,
      "grad_norm": 1.3104172945022583,
      "learning_rate": 5.683003919365733e-05,
      "loss": 1.5686,
      "step": 19100
    },
    {
      "epoch": 5.770392749244713,
      "eval_loss": 1.5752570629119873,
      "eval_runtime": 1476.6221,
      "eval_samples_per_second": 35.96,
      "eval_steps_per_second": 0.281,
      "step": 19100
    },
    {
      "epoch": 5.785498489425982,
      "grad_norm": 0.9527880549430847,
      "learning_rate": 5.6845111595418774e-05,
      "loss": 1.5856,
      "step": 19150
    },
    {
      "epoch": 5.785498489425982,
      "eval_loss": 1.5729739665985107,
      "eval_runtime": 1463.8579,
      "eval_samples_per_second": 36.273,
      "eval_steps_per_second": 0.283,
      "step": 19150
    },
    {
      "epoch": 5.80060422960725,
      "grad_norm": 1.0288925170898438,
      "learning_rate": 5.6860144694914614e-05,
      "loss": 1.5448,
      "step": 19200
    },
    {
      "epoch": 5.80060422960725,
      "eval_loss": 1.5717835426330566,
      "eval_runtime": 1513.0117,
      "eval_samples_per_second": 35.095,
      "eval_steps_per_second": 0.274,
      "step": 19200
    },
    {
      "epoch": 5.81570996978852,
      "grad_norm": 0.9903888702392578,
      "learning_rate": 5.6875138696578284e-05,
      "loss": 1.5503,
      "step": 19250
    },
    {
      "epoch": 5.81570996978852,
      "eval_loss": 1.568789005279541,
      "eval_runtime": 1462.9261,
      "eval_samples_per_second": 36.296,
      "eval_steps_per_second": 0.284,
      "step": 19250
    },
    {
      "epoch": 5.830815709969788,
      "grad_norm": 0.9560209512710571,
      "learning_rate": 5.6890093803252335e-05,
      "loss": 1.5273,
      "step": 19300
    },
    {
      "epoch": 5.830815709969788,
      "eval_loss": 1.5685800313949585,
      "eval_runtime": 1468.2684,
      "eval_samples_per_second": 36.164,
      "eval_steps_per_second": 0.283,
      "step": 19300
    },
    {
      "epoch": 5.8459214501510575,
      "grad_norm": 0.955924928188324,
      "learning_rate": 5.6905010216204827e-05,
      "loss": 1.5531,
      "step": 19350
    },
    {
      "epoch": 5.8459214501510575,
      "eval_loss": 1.5686029195785522,
      "eval_runtime": 1804.6216,
      "eval_samples_per_second": 29.424,
      "eval_steps_per_second": 0.23,
      "step": 19350
    },
    {
      "epoch": 5.861027190332326,
      "grad_norm": 1.261426568031311,
      "learning_rate": 5.691988813514562e-05,
      "loss": 1.5162,
      "step": 19400
    },
    {
      "epoch": 5.861027190332326,
      "eval_loss": 1.5688281059265137,
      "eval_runtime": 1468.3442,
      "eval_samples_per_second": 36.163,
      "eval_steps_per_second": 0.283,
      "step": 19400
    },
    {
      "epoch": 5.876132930513595,
      "grad_norm": 1.0806446075439453,
      "learning_rate": 5.693472775824244e-05,
      "loss": 1.5455,
      "step": 19450
    },
    {
      "epoch": 5.876132930513595,
      "eval_loss": 1.5683887004852295,
      "eval_runtime": 1531.085,
      "eval_samples_per_second": 34.681,
      "eval_steps_per_second": 0.271,
      "step": 19450
    },
    {
      "epoch": 5.8912386706948645,
      "grad_norm": 0.9892242550849915,
      "learning_rate": 5.694952928213662e-05,
      "loss": 1.5618,
      "step": 19500
    },
    {
      "epoch": 5.8912386706948645,
      "eval_loss": 1.5695154666900635,
      "eval_runtime": 1701.9229,
      "eval_samples_per_second": 31.199,
      "eval_steps_per_second": 0.244,
      "step": 19500
    },
    {
      "epoch": 5.906344410876133,
      "grad_norm": 0.9992854595184326,
      "learning_rate": 5.6964292901958864e-05,
      "loss": 1.5443,
      "step": 19550
    },
    {
      "epoch": 5.906344410876133,
      "eval_loss": 1.5638911724090576,
      "eval_runtime": 1537.3038,
      "eval_samples_per_second": 34.54,
      "eval_steps_per_second": 0.27,
      "step": 19550
    },
    {
      "epoch": 5.921450151057401,
      "grad_norm": 1.0742549896240234,
      "learning_rate": 5.697901881134459e-05,
      "loss": 1.5551,
      "step": 19600
    },
    {
      "epoch": 5.921450151057401,
      "eval_loss": 1.565291166305542,
      "eval_runtime": 1554.09,
      "eval_samples_per_second": 34.167,
      "eval_steps_per_second": 0.267,
      "step": 19600
    },
    {
      "epoch": 5.936555891238671,
      "grad_norm": 0.8661607503890991,
      "learning_rate": 5.699370720244921e-05,
      "loss": 1.528,
      "step": 19650
    },
    {
      "epoch": 5.936555891238671,
      "eval_loss": 1.5672122240066528,
      "eval_runtime": 1538.6327,
      "eval_samples_per_second": 34.511,
      "eval_steps_per_second": 0.27,
      "step": 19650
    },
    {
      "epoch": 5.95166163141994,
      "grad_norm": 1.0081392526626587,
      "learning_rate": 5.7008358265963134e-05,
      "loss": 1.5582,
      "step": 19700
    },
    {
      "epoch": 5.95166163141994,
      "eval_loss": 1.565605878829956,
      "eval_runtime": 1577.4515,
      "eval_samples_per_second": 33.661,
      "eval_steps_per_second": 0.263,
      "step": 19700
    },
    {
      "epoch": 5.966767371601208,
      "grad_norm": 1.0498976707458496,
      "learning_rate": 5.702297219112669e-05,
      "loss": 1.5218,
      "step": 19750
    },
    {
      "epoch": 5.966767371601208,
      "eval_loss": 1.5633565187454224,
      "eval_runtime": 1629.493,
      "eval_samples_per_second": 32.586,
      "eval_steps_per_second": 0.255,
      "step": 19750
    },
    {
      "epoch": 5.981873111782478,
      "grad_norm": 1.0251197814941406,
      "learning_rate": 5.7037549165744715e-05,
      "loss": 1.5448,
      "step": 19800
    },
    {
      "epoch": 5.981873111782478,
      "eval_loss": 1.5649163722991943,
      "eval_runtime": 1522.3926,
      "eval_samples_per_second": 34.879,
      "eval_steps_per_second": 0.273,
      "step": 19800
    },
    {
      "epoch": 5.996978851963746,
      "grad_norm": 1.111977458000183,
      "learning_rate": 5.7052089376201103e-05,
      "loss": 1.5502,
      "step": 19850
    },
    {
      "epoch": 5.996978851963746,
      "eval_loss": 1.5665056705474854,
      "eval_runtime": 1540.5176,
      "eval_samples_per_second": 34.468,
      "eval_steps_per_second": 0.269,
      "step": 19850
    },
    {
      "epoch": 6.0120845921450154,
      "grad_norm": 0.8431882858276367,
      "learning_rate": 5.706659300747306e-05,
      "loss": 1.5423,
      "step": 19900
    },
    {
      "epoch": 6.0120845921450154,
      "eval_loss": 1.5599627494812012,
      "eval_runtime": 1557.8271,
      "eval_samples_per_second": 34.085,
      "eval_steps_per_second": 0.266,
      "step": 19900
    },
    {
      "epoch": 6.027190332326284,
      "grad_norm": 1.0624638795852661,
      "learning_rate": 5.708106024314522e-05,
      "loss": 1.5364,
      "step": 19950
    },
    {
      "epoch": 6.027190332326284,
      "eval_loss": 1.5601210594177246,
      "eval_runtime": 1552.6661,
      "eval_samples_per_second": 34.199,
      "eval_steps_per_second": 0.267,
      "step": 19950
    },
    {
      "epoch": 6.042296072507553,
      "grad_norm": 1.0190602540969849,
      "learning_rate": 5.709549126542365e-05,
      "loss": 1.5492,
      "step": 20000
    },
    {
      "epoch": 6.042296072507553,
      "eval_loss": 1.562229037284851,
      "eval_runtime": 1729.4089,
      "eval_samples_per_second": 30.704,
      "eval_steps_per_second": 0.24,
      "step": 20000
    },
    {
      "epoch": 6.057401812688822,
      "grad_norm": 0.8393253087997437,
      "learning_rate": 5.710988625514955e-05,
      "loss": 1.5158,
      "step": 20050
    },
    {
      "epoch": 6.057401812688822,
      "eval_loss": 1.5582319498062134,
      "eval_runtime": 1519.8441,
      "eval_samples_per_second": 34.937,
      "eval_steps_per_second": 0.273,
      "step": 20050
    },
    {
      "epoch": 6.072507552870091,
      "grad_norm": 1.021301507949829,
      "learning_rate": 5.712424539181286e-05,
      "loss": 1.545,
      "step": 20100
    },
    {
      "epoch": 6.072507552870091,
      "eval_loss": 1.5625931024551392,
      "eval_runtime": 1479.7445,
      "eval_samples_per_second": 35.884,
      "eval_steps_per_second": 0.28,
      "step": 20100
    },
    {
      "epoch": 6.087613293051359,
      "grad_norm": 1.1540859937667847,
      "learning_rate": 5.713856885356572e-05,
      "loss": 1.5307,
      "step": 20150
    },
    {
      "epoch": 6.087613293051359,
      "eval_loss": 1.5592806339263916,
      "eval_runtime": 1558.5016,
      "eval_samples_per_second": 34.071,
      "eval_steps_per_second": 0.266,
      "step": 20150
    },
    {
      "epoch": 6.102719033232629,
      "grad_norm": 0.8471071124076843,
      "learning_rate": 5.7152856817235717e-05,
      "loss": 1.5004,
      "step": 20200
    },
    {
      "epoch": 6.102719033232629,
      "eval_loss": 1.5578936338424683,
      "eval_runtime": 1522.4499,
      "eval_samples_per_second": 34.877,
      "eval_steps_per_second": 0.273,
      "step": 20200
    },
    {
      "epoch": 6.117824773413897,
      "grad_norm": 0.925706148147583,
      "learning_rate": 5.7167109458339e-05,
      "loss": 1.5436,
      "step": 20250
    },
    {
      "epoch": 6.117824773413897,
      "eval_loss": 1.5595225095748901,
      "eval_runtime": 1572.5215,
      "eval_samples_per_second": 33.767,
      "eval_steps_per_second": 0.264,
      "step": 20250
    },
    {
      "epoch": 6.132930513595166,
      "grad_norm": 1.1292622089385986,
      "learning_rate": 5.7181326951093146e-05,
      "loss": 1.5416,
      "step": 20300
    },
    {
      "epoch": 6.132930513595166,
      "eval_loss": 1.5570366382598877,
      "eval_runtime": 1531.8211,
      "eval_samples_per_second": 34.664,
      "eval_steps_per_second": 0.271,
      "step": 20300
    },
    {
      "epoch": 6.148036253776435,
      "grad_norm": 1.1942161321640015,
      "learning_rate": 5.719550946843005e-05,
      "loss": 1.5201,
      "step": 20350
    },
    {
      "epoch": 6.148036253776435,
      "eval_loss": 1.5563775300979614,
      "eval_runtime": 1561.7652,
      "eval_samples_per_second": 33.999,
      "eval_steps_per_second": 0.266,
      "step": 20350
    },
    {
      "epoch": 6.163141993957704,
      "grad_norm": 1.2314465045928955,
      "learning_rate": 5.720965718200845e-05,
      "loss": 1.5295,
      "step": 20400
    },
    {
      "epoch": 6.163141993957704,
      "eval_loss": 1.5535517930984497,
      "eval_runtime": 1547.0492,
      "eval_samples_per_second": 34.323,
      "eval_steps_per_second": 0.268,
      "step": 20400
    },
    {
      "epoch": 6.1782477341389725,
      "grad_norm": 0.9095554351806641,
      "learning_rate": 5.7223770262226456e-05,
      "loss": 1.5454,
      "step": 20450
    },
    {
      "epoch": 6.1782477341389725,
      "eval_loss": 1.5573257207870483,
      "eval_runtime": 1469.6621,
      "eval_samples_per_second": 36.13,
      "eval_steps_per_second": 0.282,
      "step": 20450
    },
    {
      "epoch": 6.193353474320242,
      "grad_norm": 0.8643770813941956,
      "learning_rate": 5.7237848878233806e-05,
      "loss": 1.5225,
      "step": 20500
    },
    {
      "epoch": 6.193353474320242,
      "eval_loss": 1.555884838104248,
      "eval_runtime": 1511.6715,
      "eval_samples_per_second": 35.126,
      "eval_steps_per_second": 0.275,
      "step": 20500
    },
    {
      "epoch": 6.20845921450151,
      "grad_norm": 1.0395621061325073,
      "learning_rate": 5.725189319794408e-05,
      "loss": 1.5296,
      "step": 20550
    },
    {
      "epoch": 6.20845921450151,
      "eval_loss": 1.5527175664901733,
      "eval_runtime": 1476.0938,
      "eval_samples_per_second": 35.973,
      "eval_steps_per_second": 0.281,
      "step": 20550
    },
    {
      "epoch": 6.22356495468278,
      "grad_norm": 0.9421601295471191,
      "learning_rate": 5.726590338804669e-05,
      "loss": 1.5225,
      "step": 20600
    },
    {
      "epoch": 6.22356495468278,
      "eval_loss": 1.5543701648712158,
      "eval_runtime": 1588.6881,
      "eval_samples_per_second": 33.423,
      "eval_steps_per_second": 0.261,
      "step": 20600
    },
    {
      "epoch": 6.238670694864048,
      "grad_norm": 0.9498827457427979,
      "learning_rate": 5.727987961401878e-05,
      "loss": 1.5244,
      "step": 20650
    },
    {
      "epoch": 6.238670694864048,
      "eval_loss": 1.5528582334518433,
      "eval_runtime": 1561.3265,
      "eval_samples_per_second": 34.009,
      "eval_steps_per_second": 0.266,
      "step": 20650
    },
    {
      "epoch": 6.253776435045317,
      "grad_norm": 0.7734204530715942,
      "learning_rate": 5.7293822040136904e-05,
      "loss": 1.5393,
      "step": 20700
    },
    {
      "epoch": 6.253776435045317,
      "eval_loss": 1.5523176193237305,
      "eval_runtime": 1501.7871,
      "eval_samples_per_second": 35.357,
      "eval_steps_per_second": 0.276,
      "step": 20700
    },
    {
      "epoch": 6.268882175226586,
      "grad_norm": 0.9343314170837402,
      "learning_rate": 5.7307730829488675e-05,
      "loss": 1.5293,
      "step": 20750
    },
    {
      "epoch": 6.268882175226586,
      "eval_loss": 1.5538556575775146,
      "eval_runtime": 1638.0361,
      "eval_samples_per_second": 32.416,
      "eval_steps_per_second": 0.253,
      "step": 20750
    },
    {
      "epoch": 6.283987915407855,
      "grad_norm": 1.04215407371521,
      "learning_rate": 5.732160614398413e-05,
      "loss": 1.5375,
      "step": 20800
    },
    {
      "epoch": 6.283987915407855,
      "eval_loss": 1.5486739873886108,
      "eval_runtime": 1568.9484,
      "eval_samples_per_second": 33.844,
      "eval_steps_per_second": 0.265,
      "step": 20800
    },
    {
      "epoch": 6.2990936555891235,
      "grad_norm": 0.9656937122344971,
      "learning_rate": 5.7335448144367114e-05,
      "loss": 1.5146,
      "step": 20850
    },
    {
      "epoch": 6.2990936555891235,
      "eval_loss": 1.5501059293746948,
      "eval_runtime": 1574.6192,
      "eval_samples_per_second": 33.722,
      "eval_steps_per_second": 0.264,
      "step": 20850
    },
    {
      "epoch": 6.314199395770393,
      "grad_norm": 0.8738700747489929,
      "learning_rate": 5.734925699022643e-05,
      "loss": 1.5194,
      "step": 20900
    },
    {
      "epoch": 6.314199395770393,
      "eval_loss": 1.5540398359298706,
      "eval_runtime": 1557.3753,
      "eval_samples_per_second": 34.095,
      "eval_steps_per_second": 0.266,
      "step": 20900
    },
    {
      "epoch": 6.329305135951661,
      "grad_norm": 1.009638786315918,
      "learning_rate": 5.736303284000685e-05,
      "loss": 1.514,
      "step": 20950
    },
    {
      "epoch": 6.329305135951661,
      "eval_loss": 1.551545262336731,
      "eval_runtime": 1589.2725,
      "eval_samples_per_second": 33.411,
      "eval_steps_per_second": 0.261,
      "step": 20950
    },
    {
      "epoch": 6.3444108761329305,
      "grad_norm": 1.0693777799606323,
      "learning_rate": 5.737677585102007e-05,
      "loss": 1.5349,
      "step": 21000
    },
    {
      "epoch": 6.3444108761329305,
      "eval_loss": 1.5518012046813965,
      "eval_runtime": 1694.0698,
      "eval_samples_per_second": 31.344,
      "eval_steps_per_second": 0.245,
      "step": 21000
    },
    {
      "epoch": 6.359516616314199,
      "grad_norm": 0.9404475092887878,
      "learning_rate": 5.739048617945545e-05,
      "loss": 1.5146,
      "step": 21050
    },
    {
      "epoch": 6.359516616314199,
      "eval_loss": 1.551261305809021,
      "eval_runtime": 1545.7585,
      "eval_samples_per_second": 34.351,
      "eval_steps_per_second": 0.268,
      "step": 21050
    },
    {
      "epoch": 6.374622356495468,
      "grad_norm": 0.8936114311218262,
      "learning_rate": 5.7404163980390676e-05,
      "loss": 1.507,
      "step": 21100
    },
    {
      "epoch": 6.374622356495468,
      "eval_loss": 1.5491724014282227,
      "eval_runtime": 1525.6874,
      "eval_samples_per_second": 34.803,
      "eval_steps_per_second": 0.272,
      "step": 21100
    },
    {
      "epoch": 6.389728096676738,
      "grad_norm": 0.8406453132629395,
      "learning_rate": 5.74178094078023e-05,
      "loss": 1.5288,
      "step": 21150
    },
    {
      "epoch": 6.389728096676738,
      "eval_loss": 1.5478708744049072,
      "eval_runtime": 1558.3623,
      "eval_samples_per_second": 34.074,
      "eval_steps_per_second": 0.266,
      "step": 21150
    },
    {
      "epoch": 6.404833836858006,
      "grad_norm": 0.9596729278564453,
      "learning_rate": 5.743142261457613e-05,
      "loss": 1.5104,
      "step": 21200
    },
    {
      "epoch": 6.404833836858006,
      "eval_loss": 1.5500143766403198,
      "eval_runtime": 1558.3892,
      "eval_samples_per_second": 34.073,
      "eval_steps_per_second": 0.266,
      "step": 21200
    },
    {
      "epoch": 6.419939577039275,
      "grad_norm": 0.9892860054969788,
      "learning_rate": 5.7445003752517506e-05,
      "loss": 1.529,
      "step": 21250
    },
    {
      "epoch": 6.419939577039275,
      "eval_loss": 1.5455551147460938,
      "eval_runtime": 1870.2682,
      "eval_samples_per_second": 28.391,
      "eval_steps_per_second": 0.222,
      "step": 21250
    },
    {
      "epoch": 6.435045317220544,
      "grad_norm": 1.0317281484603882,
      "learning_rate": 5.745855297236144e-05,
      "loss": 1.5231,
      "step": 21300
    },
    {
      "epoch": 6.435045317220544,
      "eval_loss": 1.545761227607727,
      "eval_runtime": 1777.2943,
      "eval_samples_per_second": 29.876,
      "eval_steps_per_second": 0.234,
      "step": 21300
    },
    {
      "epoch": 6.450151057401813,
      "grad_norm": 0.9653975963592529,
      "learning_rate": 5.747207042378269e-05,
      "loss": 1.5124,
      "step": 21350
    },
    {
      "epoch": 6.450151057401813,
      "eval_loss": 1.544903039932251,
      "eval_runtime": 1525.2081,
      "eval_samples_per_second": 34.814,
      "eval_steps_per_second": 0.272,
      "step": 21350
    },
    {
      "epoch": 6.4652567975830815,
      "grad_norm": 0.9335447549819946,
      "learning_rate": 5.748555625540568e-05,
      "loss": 1.527,
      "step": 21400
    },
    {
      "epoch": 6.4652567975830815,
      "eval_loss": 1.5444629192352295,
      "eval_runtime": 1539.092,
      "eval_samples_per_second": 34.5,
      "eval_steps_per_second": 0.27,
      "step": 21400
    },
    {
      "epoch": 6.480362537764351,
      "grad_norm": 0.7308769226074219,
      "learning_rate": 5.749901061481423e-05,
      "loss": 1.5258,
      "step": 21450
    },
    {
      "epoch": 6.480362537764351,
      "eval_loss": 1.5412627458572388,
      "eval_runtime": 1847.5662,
      "eval_samples_per_second": 28.74,
      "eval_steps_per_second": 0.225,
      "step": 21450
    },
    {
      "epoch": 6.495468277945619,
      "grad_norm": 0.9395747184753418,
      "learning_rate": 5.7512433648561376e-05,
      "loss": 1.5203,
      "step": 21500
    },
    {
      "epoch": 6.495468277945619,
      "eval_loss": 1.547357201576233,
      "eval_runtime": 1692.706,
      "eval_samples_per_second": 31.369,
      "eval_steps_per_second": 0.245,
      "step": 21500
    },
    {
      "epoch": 6.5105740181268885,
      "grad_norm": 0.9959808588027954,
      "learning_rate": 5.752582550217884e-05,
      "loss": 1.5172,
      "step": 21550
    },
    {
      "epoch": 6.5105740181268885,
      "eval_loss": 1.5421788692474365,
      "eval_runtime": 1499.4478,
      "eval_samples_per_second": 35.412,
      "eval_steps_per_second": 0.277,
      "step": 21550
    },
    {
      "epoch": 6.525679758308157,
      "grad_norm": 1.2468972206115723,
      "learning_rate": 5.753918632018651e-05,
      "loss": 1.4945,
      "step": 21600
    },
    {
      "epoch": 6.525679758308157,
      "eval_loss": 1.5427101850509644,
      "eval_runtime": 1590.5452,
      "eval_samples_per_second": 33.384,
      "eval_steps_per_second": 0.261,
      "step": 21600
    },
    {
      "epoch": 6.540785498489426,
      "grad_norm": 0.8853557705879211,
      "learning_rate": 5.755251624610187e-05,
      "loss": 1.5128,
      "step": 21650
    },
    {
      "epoch": 6.540785498489426,
      "eval_loss": 1.5427554845809937,
      "eval_runtime": 1482.5075,
      "eval_samples_per_second": 35.817,
      "eval_steps_per_second": 0.28,
      "step": 21650
    },
    {
      "epoch": 6.555891238670695,
      "grad_norm": 1.0644609928131104,
      "learning_rate": 5.7565815422449176e-05,
      "loss": 1.5237,
      "step": 21700
    },
    {
      "epoch": 6.555891238670695,
      "eval_loss": 1.5409002304077148,
      "eval_runtime": 1614.5456,
      "eval_samples_per_second": 32.888,
      "eval_steps_per_second": 0.257,
      "step": 21700
    },
    {
      "epoch": 6.570996978851964,
      "grad_norm": 0.8963823914527893,
      "learning_rate": 5.757908399076863e-05,
      "loss": 1.5198,
      "step": 21750
    },
    {
      "epoch": 6.570996978851964,
      "eval_loss": 1.5412354469299316,
      "eval_runtime": 1521.503,
      "eval_samples_per_second": 34.899,
      "eval_steps_per_second": 0.273,
      "step": 21750
    },
    {
      "epoch": 6.586102719033232,
      "grad_norm": 1.0391682386398315,
      "learning_rate": 5.759232209162542e-05,
      "loss": 1.523,
      "step": 21800
    },
    {
      "epoch": 6.586102719033232,
      "eval_loss": 1.5377388000488281,
      "eval_runtime": 1569.0944,
      "eval_samples_per_second": 33.841,
      "eval_steps_per_second": 0.264,
      "step": 21800
    },
    {
      "epoch": 6.601208459214502,
      "grad_norm": 0.7799740433692932,
      "learning_rate": 5.760552986461863e-05,
      "loss": 1.5287,
      "step": 21850
    },
    {
      "epoch": 6.601208459214502,
      "eval_loss": 1.5396934747695923,
      "eval_runtime": 1527.1429,
      "eval_samples_per_second": 34.77,
      "eval_steps_per_second": 0.272,
      "step": 21850
    },
    {
      "epoch": 6.61631419939577,
      "grad_norm": 1.054304838180542,
      "learning_rate": 5.76187074483901e-05,
      "loss": 1.5019,
      "step": 21900
    },
    {
      "epoch": 6.61631419939577,
      "eval_loss": 1.5404795408248901,
      "eval_runtime": 1526.7362,
      "eval_samples_per_second": 34.779,
      "eval_steps_per_second": 0.272,
      "step": 21900
    },
    {
      "epoch": 6.6314199395770395,
      "grad_norm": 0.8999956846237183,
      "learning_rate": 5.763185498063318e-05,
      "loss": 1.5449,
      "step": 21950
    },
    {
      "epoch": 6.6314199395770395,
      "eval_loss": 1.5385704040527344,
      "eval_runtime": 1559.0837,
      "eval_samples_per_second": 34.058,
      "eval_steps_per_second": 0.266,
      "step": 21950
    },
    {
      "epoch": 6.646525679758308,
      "grad_norm": 0.8075788617134094,
      "learning_rate": 5.764497259810128e-05,
      "loss": 1.5253,
      "step": 22000
    },
    {
      "epoch": 6.646525679758308,
      "eval_loss": 1.5398240089416504,
      "eval_runtime": 1456.9863,
      "eval_samples_per_second": 36.444,
      "eval_steps_per_second": 0.285,
      "step": 22000
    },
    {
      "epoch": 6.661631419939577,
      "grad_norm": 0.9080978035926819,
      "learning_rate": 5.765806043661648e-05,
      "loss": 1.5095,
      "step": 22050
    },
    {
      "epoch": 6.661631419939577,
      "eval_loss": 1.5410147905349731,
      "eval_runtime": 1506.1841,
      "eval_samples_per_second": 35.254,
      "eval_steps_per_second": 0.276,
      "step": 22050
    },
    {
      "epoch": 6.676737160120846,
      "grad_norm": 1.2284764051437378,
      "learning_rate": 5.7671118631077974e-05,
      "loss": 1.5027,
      "step": 22100
    },
    {
      "epoch": 6.676737160120846,
      "eval_loss": 1.5411131381988525,
      "eval_runtime": 1545.033,
      "eval_samples_per_second": 34.368,
      "eval_steps_per_second": 0.269,
      "step": 22100
    },
    {
      "epoch": 6.691842900302115,
      "grad_norm": 0.8462603688240051,
      "learning_rate": 5.768414731547034e-05,
      "loss": 1.5224,
      "step": 22150
    },
    {
      "epoch": 6.691842900302115,
      "eval_loss": 1.5353175401687622,
      "eval_runtime": 1546.907,
      "eval_samples_per_second": 34.326,
      "eval_steps_per_second": 0.268,
      "step": 22150
    },
    {
      "epoch": 6.706948640483383,
      "grad_norm": 0.871752917766571,
      "learning_rate": 5.769714662287184e-05,
      "loss": 1.5302,
      "step": 22200
    },
    {
      "epoch": 6.706948640483383,
      "eval_loss": 1.5353198051452637,
      "eval_runtime": 1559.7731,
      "eval_samples_per_second": 34.043,
      "eval_steps_per_second": 0.266,
      "step": 22200
    },
    {
      "epoch": 6.722054380664653,
      "grad_norm": 0.9186472296714783,
      "learning_rate": 5.771011668546259e-05,
      "loss": 1.4936,
      "step": 22250
    },
    {
      "epoch": 6.722054380664653,
      "eval_loss": 1.535351276397705,
      "eval_runtime": 1562.9834,
      "eval_samples_per_second": 33.973,
      "eval_steps_per_second": 0.266,
      "step": 22250
    },
    {
      "epoch": 6.737160120845921,
      "grad_norm": 0.7862803339958191,
      "learning_rate": 5.77230576345326e-05,
      "loss": 1.5179,
      "step": 22300
    },
    {
      "epoch": 6.737160120845921,
      "eval_loss": 1.5333251953125,
      "eval_runtime": 1524.4033,
      "eval_samples_per_second": 34.833,
      "eval_steps_per_second": 0.272,
      "step": 22300
    },
    {
      "epoch": 6.75226586102719,
      "grad_norm": 0.7750319242477417,
      "learning_rate": 5.773596960048972e-05,
      "loss": 1.5163,
      "step": 22350
    },
    {
      "epoch": 6.75226586102719,
      "eval_loss": 1.536050796508789,
      "eval_runtime": 1536.2207,
      "eval_samples_per_second": 34.565,
      "eval_steps_per_second": 0.27,
      "step": 22350
    },
    {
      "epoch": 6.76737160120846,
      "grad_norm": 1.0112051963806152,
      "learning_rate": 5.774885271286758e-05,
      "loss": 1.4986,
      "step": 22400
    },
    {
      "epoch": 6.76737160120846,
      "eval_loss": 1.5353928804397583,
      "eval_runtime": 1501.1071,
      "eval_samples_per_second": 35.373,
      "eval_steps_per_second": 0.276,
      "step": 22400
    },
    {
      "epoch": 6.782477341389728,
      "grad_norm": 0.8157763481140137,
      "learning_rate": 5.776170710033338e-05,
      "loss": 1.49,
      "step": 22450
    },
    {
      "epoch": 6.782477341389728,
      "eval_loss": 1.5368108749389648,
      "eval_runtime": 1809.3693,
      "eval_samples_per_second": 29.347,
      "eval_steps_per_second": 0.229,
      "step": 22450
    },
    {
      "epoch": 6.7975830815709966,
      "grad_norm": 0.8529718518257141,
      "learning_rate": 5.777453289069555e-05,
      "loss": 1.5095,
      "step": 22500
    },
    {
      "epoch": 6.7975830815709966,
      "eval_loss": 1.5348905324935913,
      "eval_runtime": 1465.8588,
      "eval_samples_per_second": 36.224,
      "eval_steps_per_second": 0.283,
      "step": 22500
    },
    {
      "epoch": 6.812688821752266,
      "grad_norm": 1.1266365051269531,
      "learning_rate": 5.7787330210911424e-05,
      "loss": 1.4961,
      "step": 22550
    },
    {
      "epoch": 6.812688821752266,
      "eval_loss": 1.5307480096817017,
      "eval_runtime": 1487.4138,
      "eval_samples_per_second": 35.699,
      "eval_steps_per_second": 0.279,
      "step": 22550
    },
    {
      "epoch": 6.827794561933535,
      "grad_norm": 0.8516042828559875,
      "learning_rate": 5.7800099187094765e-05,
      "loss": 1.5052,
      "step": 22600
    },
    {
      "epoch": 6.827794561933535,
      "eval_loss": 1.5323336124420166,
      "eval_runtime": 1548.927,
      "eval_samples_per_second": 34.281,
      "eval_steps_per_second": 0.268,
      "step": 22600
    },
    {
      "epoch": 6.842900302114804,
      "grad_norm": 0.9106903672218323,
      "learning_rate": 5.781283994452321e-05,
      "loss": 1.501,
      "step": 22650
    },
    {
      "epoch": 6.842900302114804,
      "eval_loss": 1.5351048707962036,
      "eval_runtime": 1466.8585,
      "eval_samples_per_second": 36.199,
      "eval_steps_per_second": 0.283,
      "step": 22650
    },
    {
      "epoch": 6.858006042296072,
      "grad_norm": 0.9307205677032471,
      "learning_rate": 5.782555260764566e-05,
      "loss": 1.4966,
      "step": 22700
    },
    {
      "epoch": 6.858006042296072,
      "eval_loss": 1.5339338779449463,
      "eval_runtime": 1509.7181,
      "eval_samples_per_second": 35.171,
      "eval_steps_per_second": 0.275,
      "step": 22700
    },
    {
      "epoch": 6.873111782477341,
      "grad_norm": 0.896737277507782,
      "learning_rate": 5.783823730008958e-05,
      "loss": 1.4992,
      "step": 22750
    },
    {
      "epoch": 6.873111782477341,
      "eval_loss": 1.5319331884384155,
      "eval_runtime": 1472.8183,
      "eval_samples_per_second": 36.053,
      "eval_steps_per_second": 0.282,
      "step": 22750
    },
    {
      "epoch": 6.888217522658611,
      "grad_norm": 0.8505275845527649,
      "learning_rate": 5.7850894144668215e-05,
      "loss": 1.4776,
      "step": 22800
    },
    {
      "epoch": 6.888217522658611,
      "eval_loss": 1.529669165611267,
      "eval_runtime": 1570.1479,
      "eval_samples_per_second": 33.818,
      "eval_steps_per_second": 0.264,
      "step": 22800
    },
    {
      "epoch": 6.903323262839879,
      "grad_norm": 0.8837029337882996,
      "learning_rate": 5.786352326338768e-05,
      "loss": 1.5072,
      "step": 22850
    },
    {
      "epoch": 6.903323262839879,
      "eval_loss": 1.5321636199951172,
      "eval_runtime": 1519.1759,
      "eval_samples_per_second": 34.953,
      "eval_steps_per_second": 0.273,
      "step": 22850
    },
    {
      "epoch": 6.918429003021148,
      "grad_norm": 0.9636221528053284,
      "learning_rate": 5.787612477745405e-05,
      "loss": 1.5232,
      "step": 22900
    },
    {
      "epoch": 6.918429003021148,
      "eval_loss": 1.526656150817871,
      "eval_runtime": 1500.9533,
      "eval_samples_per_second": 35.377,
      "eval_steps_per_second": 0.276,
      "step": 22900
    },
    {
      "epoch": 6.933534743202417,
      "grad_norm": 1.222399115562439,
      "learning_rate": 5.788869880728036e-05,
      "loss": 1.5057,
      "step": 22950
    },
    {
      "epoch": 6.933534743202417,
      "eval_loss": 1.5291624069213867,
      "eval_runtime": 1547.4059,
      "eval_samples_per_second": 34.315,
      "eval_steps_per_second": 0.268,
      "step": 22950
    },
    {
      "epoch": 6.948640483383686,
      "grad_norm": 0.8739312887191772,
      "learning_rate": 5.7901245472493474e-05,
      "loss": 1.5205,
      "step": 23000
    },
    {
      "epoch": 6.948640483383686,
      "eval_loss": 1.5278013944625854,
      "eval_runtime": 1510.7728,
      "eval_samples_per_second": 35.147,
      "eval_steps_per_second": 0.275,
      "step": 23000
    },
    {
      "epoch": 6.9637462235649545,
      "grad_norm": 0.8499232530593872,
      "learning_rate": 5.791376489194092e-05,
      "loss": 1.4831,
      "step": 23050
    },
    {
      "epoch": 6.9637462235649545,
      "eval_loss": 1.5272396802902222,
      "eval_runtime": 1506.6527,
      "eval_samples_per_second": 35.243,
      "eval_steps_per_second": 0.275,
      "step": 23050
    },
    {
      "epoch": 6.978851963746224,
      "grad_norm": 0.9083736538887024,
      "learning_rate": 5.792625718369769e-05,
      "loss": 1.5142,
      "step": 23100
    },
    {
      "epoch": 6.978851963746224,
      "eval_loss": 1.5260429382324219,
      "eval_runtime": 1509.0753,
      "eval_samples_per_second": 35.186,
      "eval_steps_per_second": 0.275,
      "step": 23100
    },
    {
      "epoch": 6.993957703927492,
      "grad_norm": 0.8636196255683899,
      "learning_rate": 5.793872246507284e-05,
      "loss": 1.5195,
      "step": 23150
    },
    {
      "epoch": 6.993957703927492,
      "eval_loss": 1.5246130228042603,
      "eval_runtime": 1562.68,
      "eval_samples_per_second": 33.979,
      "eval_steps_per_second": 0.266,
      "step": 23150
    },
    {
      "epoch": 7.009063444108762,
      "grad_norm": 0.9762661457061768,
      "learning_rate": 5.795116085261614e-05,
      "loss": 1.5044,
      "step": 23200
    },
    {
      "epoch": 7.009063444108762,
      "eval_loss": 1.5278775691986084,
      "eval_runtime": 1530.938,
      "eval_samples_per_second": 34.684,
      "eval_steps_per_second": 0.271,
      "step": 23200
    },
    {
      "epoch": 7.02416918429003,
      "grad_norm": 0.9436269998550415,
      "learning_rate": 5.7963572462124654e-05,
      "loss": 1.4878,
      "step": 23250
    },
    {
      "epoch": 7.02416918429003,
      "eval_loss": 1.527361512184143,
      "eval_runtime": 1461.8734,
      "eval_samples_per_second": 36.323,
      "eval_steps_per_second": 0.284,
      "step": 23250
    },
    {
      "epoch": 7.039274924471299,
      "grad_norm": 0.8725103139877319,
      "learning_rate": 5.797595740864913e-05,
      "loss": 1.5161,
      "step": 23300
    },
    {
      "epoch": 7.039274924471299,
      "eval_loss": 1.5260027647018433,
      "eval_runtime": 1520.3196,
      "eval_samples_per_second": 34.926,
      "eval_steps_per_second": 0.273,
      "step": 23300
    },
    {
      "epoch": 7.054380664652568,
      "grad_norm": 0.9778568148612976,
      "learning_rate": 5.798831580650048e-05,
      "loss": 1.4964,
      "step": 23350
    },
    {
      "epoch": 7.054380664652568,
      "eval_loss": 1.5256330966949463,
      "eval_runtime": 1517.5068,
      "eval_samples_per_second": 34.991,
      "eval_steps_per_second": 0.273,
      "step": 23350
    },
    {
      "epoch": 7.069486404833837,
      "grad_norm": 0.8694519996643066,
      "learning_rate": 5.800064776925603e-05,
      "loss": 1.4866,
      "step": 23400
    },
    {
      "epoch": 7.069486404833837,
      "eval_loss": 1.5237780809402466,
      "eval_runtime": 1541.4314,
      "eval_samples_per_second": 34.448,
      "eval_steps_per_second": 0.269,
      "step": 23400
    },
    {
      "epoch": 7.0845921450151055,
      "grad_norm": 0.9390477538108826,
      "learning_rate": 5.801295340976582e-05,
      "loss": 1.4776,
      "step": 23450
    },
    {
      "epoch": 7.0845921450151055,
      "eval_loss": 1.5255845785140991,
      "eval_runtime": 1660.3541,
      "eval_samples_per_second": 31.981,
      "eval_steps_per_second": 0.25,
      "step": 23450
    },
    {
      "epoch": 7.099697885196375,
      "grad_norm": 0.8411892056465149,
      "learning_rate": 5.8025232840158864e-05,
      "loss": 1.5235,
      "step": 23500
    },
    {
      "epoch": 7.099697885196375,
      "eval_loss": 1.5238502025604248,
      "eval_runtime": 1468.2181,
      "eval_samples_per_second": 36.166,
      "eval_steps_per_second": 0.283,
      "step": 23500
    },
    {
      "epoch": 7.114803625377643,
      "grad_norm": 0.8566805124282837,
      "learning_rate": 5.803748617184914e-05,
      "loss": 1.4851,
      "step": 23550
    },
    {
      "epoch": 7.114803625377643,
      "eval_loss": 1.5246737003326416,
      "eval_runtime": 1545.3577,
      "eval_samples_per_second": 34.36,
      "eval_steps_per_second": 0.269,
      "step": 23550
    },
    {
      "epoch": 7.1299093655589125,
      "grad_norm": 1.0351892709732056,
      "learning_rate": 5.8049713515541775e-05,
      "loss": 1.4898,
      "step": 23600
    },
    {
      "epoch": 7.1299093655589125,
      "eval_loss": 1.5230473279953003,
      "eval_runtime": 1498.3948,
      "eval_samples_per_second": 35.437,
      "eval_steps_per_second": 0.277,
      "step": 23600
    },
    {
      "epoch": 7.145015105740181,
      "grad_norm": 0.9881289601325989,
      "learning_rate": 5.8061914981239e-05,
      "loss": 1.491,
      "step": 23650
    },
    {
      "epoch": 7.145015105740181,
      "eval_loss": 1.5218278169631958,
      "eval_runtime": 1542.7702,
      "eval_samples_per_second": 34.418,
      "eval_steps_per_second": 0.269,
      "step": 23650
    },
    {
      "epoch": 7.16012084592145,
      "grad_norm": 0.7726302742958069,
      "learning_rate": 5.807409067824611e-05,
      "loss": 1.4941,
      "step": 23700
    },
    {
      "epoch": 7.16012084592145,
      "eval_loss": 1.5218079090118408,
      "eval_runtime": 1622.9291,
      "eval_samples_per_second": 32.718,
      "eval_steps_per_second": 0.256,
      "step": 23700
    },
    {
      "epoch": 7.175226586102719,
      "grad_norm": 1.004997730255127,
      "learning_rate": 5.808624071517727e-05,
      "loss": 1.4966,
      "step": 23750
    },
    {
      "epoch": 7.175226586102719,
      "eval_loss": 1.5209980010986328,
      "eval_runtime": 1529.0691,
      "eval_samples_per_second": 34.726,
      "eval_steps_per_second": 0.271,
      "step": 23750
    },
    {
      "epoch": 7.190332326283988,
      "grad_norm": 0.7270485162734985,
      "learning_rate": 5.8098365199961436e-05,
      "loss": 1.492,
      "step": 23800
    },
    {
      "epoch": 7.190332326283988,
      "eval_loss": 1.5243366956710815,
      "eval_runtime": 1466.5001,
      "eval_samples_per_second": 36.208,
      "eval_steps_per_second": 0.283,
      "step": 23800
    },
    {
      "epoch": 7.205438066465256,
      "grad_norm": 0.7803418636322021,
      "learning_rate": 5.8110464239848025e-05,
      "loss": 1.5057,
      "step": 23850
    },
    {
      "epoch": 7.205438066465256,
      "eval_loss": 1.5171515941619873,
      "eval_runtime": 1541.0434,
      "eval_samples_per_second": 34.457,
      "eval_steps_per_second": 0.269,
      "step": 23850
    },
    {
      "epoch": 7.220543806646526,
      "grad_norm": 0.9516370296478271,
      "learning_rate": 5.8122537941412664e-05,
      "loss": 1.5166,
      "step": 23900
    },
    {
      "epoch": 7.220543806646526,
      "eval_loss": 1.5186687707901,
      "eval_runtime": 1578.0035,
      "eval_samples_per_second": 33.649,
      "eval_steps_per_second": 0.263,
      "step": 23900
    },
    {
      "epoch": 7.235649546827794,
      "grad_norm": 0.8839627504348755,
      "learning_rate": 5.813458641056274e-05,
      "loss": 1.4857,
      "step": 23950
    },
    {
      "epoch": 7.235649546827794,
      "eval_loss": 1.5177072286605835,
      "eval_runtime": 1546.1991,
      "eval_samples_per_second": 34.342,
      "eval_steps_per_second": 0.268,
      "step": 23950
    },
    {
      "epoch": 7.2507552870090635,
      "grad_norm": 0.8237761855125427,
      "learning_rate": 5.814660975254306e-05,
      "loss": 1.4901,
      "step": 24000
    },
    {
      "epoch": 7.2507552870090635,
      "eval_loss": 1.5219576358795166,
      "eval_runtime": 1572.2181,
      "eval_samples_per_second": 33.773,
      "eval_steps_per_second": 0.264,
      "step": 24000
    },
    {
      "epoch": 7.265861027190333,
      "grad_norm": 0.9011479020118713,
      "learning_rate": 5.815860807194136e-05,
      "loss": 1.4918,
      "step": 24050
    },
    {
      "epoch": 7.265861027190333,
      "eval_loss": 1.5196682214736938,
      "eval_runtime": 1544.1321,
      "eval_samples_per_second": 34.388,
      "eval_steps_per_second": 0.269,
      "step": 24050
    },
    {
      "epoch": 7.280966767371601,
      "grad_norm": 1.0469728708267212,
      "learning_rate": 5.817058147269369e-05,
      "loss": 1.5152,
      "step": 24100
    },
    {
      "epoch": 7.280966767371601,
      "eval_loss": 1.519372582435608,
      "eval_runtime": 1576.1136,
      "eval_samples_per_second": 33.69,
      "eval_steps_per_second": 0.263,
      "step": 24100
    },
    {
      "epoch": 7.29607250755287,
      "grad_norm": 0.8074968457221985,
      "learning_rate": 5.818253005808989e-05,
      "loss": 1.5069,
      "step": 24150
    },
    {
      "epoch": 7.29607250755287,
      "eval_loss": 1.517693281173706,
      "eval_runtime": 1592.9593,
      "eval_samples_per_second": 33.334,
      "eval_steps_per_second": 0.261,
      "step": 24150
    },
    {
      "epoch": 7.311178247734139,
      "grad_norm": 0.8578328490257263,
      "learning_rate": 5.81944539307789e-05,
      "loss": 1.5045,
      "step": 24200
    },
    {
      "epoch": 7.311178247734139,
      "eval_loss": 1.5177913904190063,
      "eval_runtime": 1590.1084,
      "eval_samples_per_second": 33.393,
      "eval_steps_per_second": 0.261,
      "step": 24200
    },
    {
      "epoch": 7.326283987915408,
      "grad_norm": 0.8150762915611267,
      "learning_rate": 5.820635319277407e-05,
      "loss": 1.4956,
      "step": 24250
    },
    {
      "epoch": 7.326283987915408,
      "eval_loss": 1.5142525434494019,
      "eval_runtime": 1526.3202,
      "eval_samples_per_second": 34.789,
      "eval_steps_per_second": 0.272,
      "step": 24250
    },
    {
      "epoch": 7.341389728096677,
      "grad_norm": 1.000636100769043,
      "learning_rate": 5.82182279454584e-05,
      "loss": 1.5174,
      "step": 24300
    },
    {
      "epoch": 7.341389728096677,
      "eval_loss": 1.5182043313980103,
      "eval_runtime": 1567.7321,
      "eval_samples_per_second": 33.87,
      "eval_steps_per_second": 0.265,
      "step": 24300
    },
    {
      "epoch": 7.356495468277946,
      "grad_norm": 0.8351430296897888,
      "learning_rate": 5.8230078289589685e-05,
      "loss": 1.5034,
      "step": 24350
    },
    {
      "epoch": 7.356495468277946,
      "eval_loss": 1.515207290649414,
      "eval_runtime": 1528.5486,
      "eval_samples_per_second": 34.738,
      "eval_steps_per_second": 0.271,
      "step": 24350
    },
    {
      "epoch": 7.371601208459214,
      "grad_norm": 0.7738264799118042,
      "learning_rate": 5.8241904325305687e-05,
      "loss": 1.5008,
      "step": 24400
    },
    {
      "epoch": 7.371601208459214,
      "eval_loss": 1.5154834985733032,
      "eval_runtime": 1563.125,
      "eval_samples_per_second": 33.97,
      "eval_steps_per_second": 0.265,
      "step": 24400
    },
    {
      "epoch": 7.386706948640484,
      "grad_norm": 0.8300372958183289,
      "learning_rate": 5.8253706152129195e-05,
      "loss": 1.497,
      "step": 24450
    },
    {
      "epoch": 7.386706948640484,
      "eval_loss": 1.5140454769134521,
      "eval_runtime": 1549.0533,
      "eval_samples_per_second": 34.278,
      "eval_steps_per_second": 0.268,
      "step": 24450
    },
    {
      "epoch": 7.401812688821752,
      "grad_norm": 0.8767375349998474,
      "learning_rate": 5.8265483868973045e-05,
      "loss": 1.4872,
      "step": 24500
    },
    {
      "epoch": 7.401812688821752,
      "eval_loss": 1.511866569519043,
      "eval_runtime": 1492.6248,
      "eval_samples_per_second": 35.574,
      "eval_steps_per_second": 0.278,
      "step": 24500
    },
    {
      "epoch": 7.4169184290030215,
      "grad_norm": 0.9090880751609802,
      "learning_rate": 5.827723757414511e-05,
      "loss": 1.4859,
      "step": 24550
    },
    {
      "epoch": 7.4169184290030215,
      "eval_loss": 1.512521505355835,
      "eval_runtime": 1510.2762,
      "eval_samples_per_second": 35.158,
      "eval_steps_per_second": 0.275,
      "step": 24550
    },
    {
      "epoch": 7.43202416918429,
      "grad_norm": 0.7602941393852234,
      "learning_rate": 5.8288967365353215e-05,
      "loss": 1.4853,
      "step": 24600
    },
    {
      "epoch": 7.43202416918429,
      "eval_loss": 1.5155500173568726,
      "eval_runtime": 1750.9242,
      "eval_samples_per_second": 30.326,
      "eval_steps_per_second": 0.237,
      "step": 24600
    },
    {
      "epoch": 7.447129909365559,
      "grad_norm": 0.8516448736190796,
      "learning_rate": 5.830067333970999e-05,
      "loss": 1.5095,
      "step": 24650
    },
    {
      "epoch": 7.447129909365559,
      "eval_loss": 1.5132272243499756,
      "eval_runtime": 1782.7984,
      "eval_samples_per_second": 29.784,
      "eval_steps_per_second": 0.233,
      "step": 24650
    },
    {
      "epoch": 7.462235649546828,
      "grad_norm": 0.7899646162986755,
      "learning_rate": 5.831235559373774e-05,
      "loss": 1.4735,
      "step": 24700
    },
    {
      "epoch": 7.462235649546828,
      "eval_loss": 1.5122554302215576,
      "eval_runtime": 1502.173,
      "eval_samples_per_second": 35.348,
      "eval_steps_per_second": 0.276,
      "step": 24700
    },
    {
      "epoch": 7.477341389728097,
      "grad_norm": 0.7938946485519409,
      "learning_rate": 5.832401422337318e-05,
      "loss": 1.4621,
      "step": 24750
    },
    {
      "epoch": 7.477341389728097,
      "eval_loss": 1.5124610662460327,
      "eval_runtime": 1441.7284,
      "eval_samples_per_second": 36.83,
      "eval_steps_per_second": 0.288,
      "step": 24750
    },
    {
      "epoch": 7.492447129909365,
      "grad_norm": 0.9458903074264526,
      "learning_rate": 5.833564932397217e-05,
      "loss": 1.4916,
      "step": 24800
    },
    {
      "epoch": 7.492447129909365,
      "eval_loss": 1.5106360912322998,
      "eval_runtime": 1841.1207,
      "eval_samples_per_second": 28.841,
      "eval_steps_per_second": 0.225,
      "step": 24800
    },
    {
      "epoch": 7.507552870090635,
      "grad_norm": 1.0356192588806152,
      "learning_rate": 5.834726099031442e-05,
      "loss": 1.5034,
      "step": 24850
    },
    {
      "epoch": 7.507552870090635,
      "eval_loss": 1.5112224817276,
      "eval_runtime": 1506.5717,
      "eval_samples_per_second": 35.245,
      "eval_steps_per_second": 0.275,
      "step": 24850
    },
    {
      "epoch": 7.522658610271903,
      "grad_norm": 0.8781578540802002,
      "learning_rate": 5.835884931660808e-05,
      "loss": 1.4746,
      "step": 24900
    },
    {
      "epoch": 7.522658610271903,
      "eval_loss": 1.514145016670227,
      "eval_runtime": 1502.6669,
      "eval_samples_per_second": 35.337,
      "eval_steps_per_second": 0.276,
      "step": 24900
    },
    {
      "epoch": 7.537764350453172,
      "grad_norm": 0.78439861536026,
      "learning_rate": 5.837041439649438e-05,
      "loss": 1.4988,
      "step": 24950
    },
    {
      "epoch": 7.537764350453172,
      "eval_loss": 1.5102527141571045,
      "eval_runtime": 1926.0165,
      "eval_samples_per_second": 27.569,
      "eval_steps_per_second": 0.215,
      "step": 24950
    },
    {
      "epoch": 7.552870090634441,
      "grad_norm": 0.747100830078125,
      "learning_rate": 5.8381956323052116e-05,
      "loss": 1.4816,
      "step": 25000
    },
    {
      "epoch": 7.552870090634441,
      "eval_loss": 1.5110543966293335,
      "eval_runtime": 1541.2828,
      "eval_samples_per_second": 34.451,
      "eval_steps_per_second": 0.269,
      "step": 25000
    },
    {
      "epoch": 7.56797583081571,
      "grad_norm": 0.7865355014801025,
      "learning_rate": 5.839347518880216e-05,
      "loss": 1.477,
      "step": 25050
    },
    {
      "epoch": 7.56797583081571,
      "eval_loss": 1.5090551376342773,
      "eval_runtime": 1540.2175,
      "eval_samples_per_second": 34.475,
      "eval_steps_per_second": 0.269,
      "step": 25050
    },
    {
      "epoch": 7.5830815709969785,
      "grad_norm": 0.6768439412117004,
      "learning_rate": 5.840497108571195e-05,
      "loss": 1.4694,
      "step": 25100
    },
    {
      "epoch": 7.5830815709969785,
      "eval_loss": 1.5077182054519653,
      "eval_runtime": 1637.5049,
      "eval_samples_per_second": 32.427,
      "eval_steps_per_second": 0.253,
      "step": 25100
    },
    {
      "epoch": 7.598187311178248,
      "grad_norm": 0.8172615170478821,
      "learning_rate": 5.841644410519983e-05,
      "loss": 1.5084,
      "step": 25150
    },
    {
      "epoch": 7.598187311178248,
      "eval_loss": 1.5103040933609009,
      "eval_runtime": 1500.3311,
      "eval_samples_per_second": 35.392,
      "eval_steps_per_second": 0.277,
      "step": 25150
    },
    {
      "epoch": 7.613293051359516,
      "grad_norm": 0.7894237041473389,
      "learning_rate": 5.842789433813948e-05,
      "loss": 1.4765,
      "step": 25200
    },
    {
      "epoch": 7.613293051359516,
      "eval_loss": 1.509181261062622,
      "eval_runtime": 1584.6884,
      "eval_samples_per_second": 33.508,
      "eval_steps_per_second": 0.262,
      "step": 25200
    },
    {
      "epoch": 7.628398791540786,
      "grad_norm": 0.7888267040252686,
      "learning_rate": 5.8439321874864185e-05,
      "loss": 1.4611,
      "step": 25250
    },
    {
      "epoch": 7.628398791540786,
      "eval_loss": 1.5065137147903442,
      "eval_runtime": 1485.3616,
      "eval_samples_per_second": 35.748,
      "eval_steps_per_second": 0.279,
      "step": 25250
    },
    {
      "epoch": 7.643504531722054,
      "grad_norm": 0.9637020826339722,
      "learning_rate": 5.845072680517109e-05,
      "loss": 1.4931,
      "step": 25300
    },
    {
      "epoch": 7.643504531722054,
      "eval_loss": 1.5043739080429077,
      "eval_runtime": 1546.2244,
      "eval_samples_per_second": 34.341,
      "eval_steps_per_second": 0.268,
      "step": 25300
    },
    {
      "epoch": 7.658610271903323,
      "grad_norm": 0.8008793592453003,
      "learning_rate": 5.846210921832555e-05,
      "loss": 1.4607,
      "step": 25350
    },
    {
      "epoch": 7.658610271903323,
      "eval_loss": 1.5063581466674805,
      "eval_runtime": 1527.004,
      "eval_samples_per_second": 34.773,
      "eval_steps_per_second": 0.272,
      "step": 25350
    },
    {
      "epoch": 7.673716012084592,
      "grad_norm": 0.9069855809211731,
      "learning_rate": 5.847346920306516e-05,
      "loss": 1.4854,
      "step": 25400
    },
    {
      "epoch": 7.673716012084592,
      "eval_loss": 1.5050299167633057,
      "eval_runtime": 1503.6464,
      "eval_samples_per_second": 35.313,
      "eval_steps_per_second": 0.276,
      "step": 25400
    },
    {
      "epoch": 7.688821752265861,
      "grad_norm": 0.784870445728302,
      "learning_rate": 5.848480684760406e-05,
      "loss": 1.4532,
      "step": 25450
    },
    {
      "epoch": 7.688821752265861,
      "eval_loss": 1.5066132545471191,
      "eval_runtime": 1687.8876,
      "eval_samples_per_second": 31.459,
      "eval_steps_per_second": 0.246,
      "step": 25450
    },
    {
      "epoch": 7.70392749244713,
      "grad_norm": 0.679259181022644,
      "learning_rate": 5.8496122239636914e-05,
      "loss": 1.4774,
      "step": 25500
    },
    {
      "epoch": 7.70392749244713,
      "eval_loss": 1.5052999258041382,
      "eval_runtime": 1493.5903,
      "eval_samples_per_second": 35.551,
      "eval_steps_per_second": 0.278,
      "step": 25500
    },
    {
      "epoch": 7.719033232628399,
      "grad_norm": 0.8548454642295837,
      "learning_rate": 5.850741546634308e-05,
      "loss": 1.49,
      "step": 25550
    },
    {
      "epoch": 7.719033232628399,
      "eval_loss": 1.5054329633712769,
      "eval_runtime": 1476.1357,
      "eval_samples_per_second": 35.972,
      "eval_steps_per_second": 0.281,
      "step": 25550
    },
    {
      "epoch": 7.734138972809667,
      "grad_norm": 0.8058690428733826,
      "learning_rate": 5.851868661439057e-05,
      "loss": 1.4814,
      "step": 25600
    },
    {
      "epoch": 7.734138972809667,
      "eval_loss": 1.5054863691329956,
      "eval_runtime": 1523.5132,
      "eval_samples_per_second": 34.853,
      "eval_steps_per_second": 0.272,
      "step": 25600
    },
    {
      "epoch": 7.7492447129909365,
      "grad_norm": 0.8996003270149231,
      "learning_rate": 5.852993576994012e-05,
      "loss": 1.4595,
      "step": 25650
    },
    {
      "epoch": 7.7492447129909365,
      "eval_loss": 1.5064446926116943,
      "eval_runtime": 1537.6302,
      "eval_samples_per_second": 34.533,
      "eval_steps_per_second": 0.27,
      "step": 25650
    },
    {
      "epoch": 7.764350453172206,
      "grad_norm": 0.9362824559211731,
      "learning_rate": 5.8541163018649016e-05,
      "loss": 1.4803,
      "step": 25700
    },
    {
      "epoch": 7.764350453172206,
      "eval_loss": 1.5042107105255127,
      "eval_runtime": 1791.1188,
      "eval_samples_per_second": 29.646,
      "eval_steps_per_second": 0.232,
      "step": 25700
    },
    {
      "epoch": 7.779456193353474,
      "grad_norm": 0.6890206336975098,
      "learning_rate": 5.8552368445675145e-05,
      "loss": 1.4555,
      "step": 25750
    },
    {
      "epoch": 7.779456193353474,
      "eval_loss": 1.5016026496887207,
      "eval_runtime": 1531.9874,
      "eval_samples_per_second": 34.66,
      "eval_steps_per_second": 0.271,
      "step": 25750
    },
    {
      "epoch": 7.794561933534744,
      "grad_norm": 0.7278085350990295,
      "learning_rate": 5.856355213568079e-05,
      "loss": 1.4736,
      "step": 25800
    },
    {
      "epoch": 7.794561933534744,
      "eval_loss": 1.5024125576019287,
      "eval_runtime": 1615.5982,
      "eval_samples_per_second": 32.866,
      "eval_steps_per_second": 0.257,
      "step": 25800
    },
    {
      "epoch": 7.809667673716012,
      "grad_norm": 0.7326859831809998,
      "learning_rate": 5.857471417283648e-05,
      "loss": 1.4609,
      "step": 25850
    },
    {
      "epoch": 7.809667673716012,
      "eval_loss": 1.5022437572479248,
      "eval_runtime": 1560.0724,
      "eval_samples_per_second": 34.036,
      "eval_steps_per_second": 0.266,
      "step": 25850
    },
    {
      "epoch": 7.824773413897281,
      "grad_norm": 0.7950003743171692,
      "learning_rate": 5.858585464082482e-05,
      "loss": 1.4685,
      "step": 25900
    },
    {
      "epoch": 7.824773413897281,
      "eval_loss": 1.5029230117797852,
      "eval_runtime": 1850.4973,
      "eval_samples_per_second": 28.694,
      "eval_steps_per_second": 0.224,
      "step": 25900
    },
    {
      "epoch": 7.83987915407855,
      "grad_norm": 0.7767884135246277,
      "learning_rate": 5.85969736228442e-05,
      "loss": 1.4775,
      "step": 25950
    },
    {
      "epoch": 7.83987915407855,
      "eval_loss": 1.4990794658660889,
      "eval_runtime": 1538.9235,
      "eval_samples_per_second": 34.504,
      "eval_steps_per_second": 0.27,
      "step": 25950
    },
    {
      "epoch": 7.854984894259819,
      "grad_norm": 0.9729999899864197,
      "learning_rate": 5.8608071201612584e-05,
      "loss": 1.4888,
      "step": 26000
    },
    {
      "epoch": 7.854984894259819,
      "eval_loss": 1.5039035081863403,
      "eval_runtime": 1521.4326,
      "eval_samples_per_second": 34.901,
      "eval_steps_per_second": 0.273,
      "step": 26000
    },
    {
      "epoch": 7.8700906344410875,
      "grad_norm": 0.7730022072792053,
      "learning_rate": 5.8619147459371166e-05,
      "loss": 1.4824,
      "step": 26050
    },
    {
      "epoch": 7.8700906344410875,
      "eval_loss": 1.4988528490066528,
      "eval_runtime": 1510.7753,
      "eval_samples_per_second": 35.147,
      "eval_steps_per_second": 0.275,
      "step": 26050
    },
    {
      "epoch": 7.885196374622357,
      "grad_norm": 0.7317925095558167,
      "learning_rate": 5.863020247788803e-05,
      "loss": 1.4682,
      "step": 26100
    },
    {
      "epoch": 7.885196374622357,
      "eval_loss": 1.5009552240371704,
      "eval_runtime": 2241.5274,
      "eval_samples_per_second": 23.689,
      "eval_steps_per_second": 0.185,
      "step": 26100
    },
    {
      "epoch": 7.900302114803625,
      "grad_norm": 0.9079797863960266,
      "learning_rate": 5.8641236338461805e-05,
      "loss": 1.4572,
      "step": 26150
    },
    {
      "epoch": 7.900302114803625,
      "eval_loss": 1.4997243881225586,
      "eval_runtime": 1466.9571,
      "eval_samples_per_second": 36.197,
      "eval_steps_per_second": 0.283,
      "step": 26150
    },
    {
      "epoch": 7.9154078549848945,
      "grad_norm": 0.8765535950660706,
      "learning_rate": 5.8652249121925176e-05,
      "loss": 1.5026,
      "step": 26200
    },
    {
      "epoch": 7.9154078549848945,
      "eval_loss": 1.5000756978988647,
      "eval_runtime": 1461.9041,
      "eval_samples_per_second": 36.322,
      "eval_steps_per_second": 0.284,
      "step": 26200
    },
    {
      "epoch": 7.930513595166163,
      "grad_norm": 0.7940713763237,
      "learning_rate": 5.866324090864853e-05,
      "loss": 1.4927,
      "step": 26250
    },
    {
      "epoch": 7.930513595166163,
      "eval_loss": 1.4972598552703857,
      "eval_runtime": 1552.7038,
      "eval_samples_per_second": 34.198,
      "eval_steps_per_second": 0.267,
      "step": 26250
    },
    {
      "epoch": 7.945619335347432,
      "grad_norm": 0.6925522089004517,
      "learning_rate": 5.8674211778543406e-05,
      "loss": 1.4611,
      "step": 26300
    },
    {
      "epoch": 7.945619335347432,
      "eval_loss": 1.500069260597229,
      "eval_runtime": 1530.766,
      "eval_samples_per_second": 34.688,
      "eval_steps_per_second": 0.271,
      "step": 26300
    },
    {
      "epoch": 7.960725075528701,
      "grad_norm": 1.0551007986068726,
      "learning_rate": 5.868516181106602e-05,
      "loss": 1.4771,
      "step": 26350
    },
    {
      "epoch": 7.960725075528701,
      "eval_loss": 1.4978752136230469,
      "eval_runtime": 1491.3285,
      "eval_samples_per_second": 35.605,
      "eval_steps_per_second": 0.278,
      "step": 26350
    },
    {
      "epoch": 7.97583081570997,
      "grad_norm": 0.8542880415916443,
      "learning_rate": 5.8696091085220694e-05,
      "loss": 1.4621,
      "step": 26400
    },
    {
      "epoch": 7.97583081570997,
      "eval_loss": 1.4983242750167847,
      "eval_runtime": 1530.3036,
      "eval_samples_per_second": 34.698,
      "eval_steps_per_second": 0.271,
      "step": 26400
    },
    {
      "epoch": 7.990936555891238,
      "grad_norm": 0.7867832183837891,
      "learning_rate": 5.870699967956329e-05,
      "loss": 1.4672,
      "step": 26450
    },
    {
      "epoch": 7.990936555891238,
      "eval_loss": 1.501059651374817,
      "eval_runtime": 1558.8688,
      "eval_samples_per_second": 34.063,
      "eval_steps_per_second": 0.266,
      "step": 26450
    },
    {
      "epoch": 8.006042296072508,
      "grad_norm": 0.9486009478569031,
      "learning_rate": 5.871788767220459e-05,
      "loss": 1.4838,
      "step": 26500
    },
    {
      "epoch": 8.006042296072508,
      "eval_loss": 1.498825192451477,
      "eval_runtime": 1477.0551,
      "eval_samples_per_second": 35.949,
      "eval_steps_per_second": 0.281,
      "step": 26500
    },
    {
      "epoch": 8.021148036253777,
      "grad_norm": 0.7188326716423035,
      "learning_rate": 5.8728755140813674e-05,
      "loss": 1.4704,
      "step": 26550
    },
    {
      "epoch": 8.021148036253777,
      "eval_loss": 1.497586965560913,
      "eval_runtime": 1834.7261,
      "eval_samples_per_second": 28.941,
      "eval_steps_per_second": 0.226,
      "step": 26550
    },
    {
      "epoch": 8.036253776435045,
      "grad_norm": 0.9089282155036926,
      "learning_rate": 5.87396021626212e-05,
      "loss": 1.4541,
      "step": 26600
    },
    {
      "epoch": 8.036253776435045,
      "eval_loss": 1.493985891342163,
      "eval_runtime": 1511.9944,
      "eval_samples_per_second": 35.119,
      "eval_steps_per_second": 0.274,
      "step": 26600
    },
    {
      "epoch": 8.051359516616314,
      "grad_norm": 0.7923935651779175,
      "learning_rate": 5.875042881442273e-05,
      "loss": 1.4591,
      "step": 26650
    },
    {
      "epoch": 8.051359516616314,
      "eval_loss": 1.4966187477111816,
      "eval_runtime": 1593.3565,
      "eval_samples_per_second": 33.325,
      "eval_steps_per_second": 0.26,
      "step": 26650
    },
    {
      "epoch": 8.066465256797583,
      "grad_norm": 0.8259040713310242,
      "learning_rate": 5.8761235172582e-05,
      "loss": 1.4714,
      "step": 26700
    },
    {
      "epoch": 8.066465256797583,
      "eval_loss": 1.495448350906372,
      "eval_runtime": 2922.9188,
      "eval_samples_per_second": 18.166,
      "eval_steps_per_second": 0.142,
      "step": 26700
    },
    {
      "epoch": 8.081570996978853,
      "grad_norm": 0.7864974141120911,
      "learning_rate": 5.8772021313034134e-05,
      "loss": 1.4658,
      "step": 26750
    },
    {
      "epoch": 8.081570996978853,
      "eval_loss": 1.4925761222839355,
      "eval_runtime": 1565.1304,
      "eval_samples_per_second": 33.926,
      "eval_steps_per_second": 0.265,
      "step": 26750
    },
    {
      "epoch": 8.09667673716012,
      "grad_norm": 0.8416922092437744,
      "learning_rate": 5.8782787311288816e-05,
      "loss": 1.4629,
      "step": 26800
    },
    {
      "epoch": 8.09667673716012,
      "eval_loss": 1.4958710670471191,
      "eval_runtime": 1516.6397,
      "eval_samples_per_second": 35.011,
      "eval_steps_per_second": 0.274,
      "step": 26800
    },
    {
      "epoch": 8.11178247734139,
      "grad_norm": 0.7750604152679443,
      "learning_rate": 5.879353324243355e-05,
      "loss": 1.4759,
      "step": 26850
    },
    {
      "epoch": 8.11178247734139,
      "eval_loss": 1.4968136548995972,
      "eval_runtime": 1503.0833,
      "eval_samples_per_second": 35.327,
      "eval_steps_per_second": 0.276,
      "step": 26850
    },
    {
      "epoch": 8.126888217522659,
      "grad_norm": 0.8089643120765686,
      "learning_rate": 5.88042591811367e-05,
      "loss": 1.4861,
      "step": 26900
    },
    {
      "epoch": 8.126888217522659,
      "eval_loss": 1.4955883026123047,
      "eval_runtime": 1735.155,
      "eval_samples_per_second": 30.602,
      "eval_steps_per_second": 0.239,
      "step": 26900
    },
    {
      "epoch": 8.141993957703928,
      "grad_norm": 0.8994342088699341,
      "learning_rate": 5.881496520165068e-05,
      "loss": 1.4676,
      "step": 26950
    },
    {
      "epoch": 8.141993957703928,
      "eval_loss": 1.4951786994934082,
      "eval_runtime": 1552.6416,
      "eval_samples_per_second": 34.199,
      "eval_steps_per_second": 0.267,
      "step": 26950
    },
    {
      "epoch": 8.157099697885196,
      "grad_norm": 0.7134727835655212,
      "learning_rate": 5.882565137781496e-05,
      "loss": 1.4645,
      "step": 27000
    },
    {
      "epoch": 8.157099697885196,
      "eval_loss": 1.4921338558197021,
      "eval_runtime": 1571.7723,
      "eval_samples_per_second": 33.783,
      "eval_steps_per_second": 0.264,
      "step": 27000
    },
    {
      "epoch": 8.172205438066465,
      "grad_norm": 0.7674537897109985,
      "learning_rate": 5.883631778305925e-05,
      "loss": 1.4738,
      "step": 27050
    },
    {
      "epoch": 8.172205438066465,
      "eval_loss": 1.4916437864303589,
      "eval_runtime": 1546.0693,
      "eval_samples_per_second": 34.345,
      "eval_steps_per_second": 0.268,
      "step": 27050
    },
    {
      "epoch": 8.187311178247734,
      "grad_norm": 0.6596293449401855,
      "learning_rate": 5.884696449040636e-05,
      "loss": 1.471,
      "step": 27100
    },
    {
      "epoch": 8.187311178247734,
      "eval_loss": 1.4941744804382324,
      "eval_runtime": 1565.6041,
      "eval_samples_per_second": 33.916,
      "eval_steps_per_second": 0.265,
      "step": 27100
    },
    {
      "epoch": 8.202416918429003,
      "grad_norm": 0.8591505289077759,
      "learning_rate": 5.8857591572475355e-05,
      "loss": 1.4866,
      "step": 27150
    },
    {
      "epoch": 8.202416918429003,
      "eval_loss": 1.4919627904891968,
      "eval_runtime": 1524.5106,
      "eval_samples_per_second": 34.83,
      "eval_steps_per_second": 0.272,
      "step": 27150
    },
    {
      "epoch": 8.217522658610273,
      "grad_norm": 0.8873967528343201,
      "learning_rate": 5.8868199101484424e-05,
      "loss": 1.4788,
      "step": 27200
    },
    {
      "epoch": 8.217522658610273,
      "eval_loss": 1.4917899370193481,
      "eval_runtime": 1550.0895,
      "eval_samples_per_second": 34.255,
      "eval_steps_per_second": 0.268,
      "step": 27200
    },
    {
      "epoch": 8.23262839879154,
      "grad_norm": 0.8102189898490906,
      "learning_rate": 5.887878714925386e-05,
      "loss": 1.4691,
      "step": 27250
    },
    {
      "epoch": 8.23262839879154,
      "eval_loss": 1.4903161525726318,
      "eval_runtime": 1510.4975,
      "eval_samples_per_second": 35.153,
      "eval_steps_per_second": 0.275,
      "step": 27250
    },
    {
      "epoch": 8.24773413897281,
      "grad_norm": 0.7300159931182861,
      "learning_rate": 5.8889355787209e-05,
      "loss": 1.4638,
      "step": 27300
    },
    {
      "epoch": 8.24773413897281,
      "eval_loss": 1.4929336309432983,
      "eval_runtime": 2106.9564,
      "eval_samples_per_second": 25.202,
      "eval_steps_per_second": 0.197,
      "step": 27300
    },
    {
      "epoch": 8.262839879154079,
      "grad_norm": 0.9193101525306702,
      "learning_rate": 5.889990508638305e-05,
      "loss": 1.4582,
      "step": 27350
    },
    {
      "epoch": 8.262839879154079,
      "eval_loss": 1.4920929670333862,
      "eval_runtime": 1591.2932,
      "eval_samples_per_second": 33.368,
      "eval_steps_per_second": 0.261,
      "step": 27350
    },
    {
      "epoch": 8.277945619335348,
      "grad_norm": 0.8338806629180908,
      "learning_rate": 5.8910435117420044e-05,
      "loss": 1.4492,
      "step": 27400
    },
    {
      "epoch": 8.277945619335348,
      "eval_loss": 1.4914064407348633,
      "eval_runtime": 1485.1324,
      "eval_samples_per_second": 35.754,
      "eval_steps_per_second": 0.279,
      "step": 27400
    },
    {
      "epoch": 8.293051359516616,
      "grad_norm": 1.003125548362732,
      "learning_rate": 5.892094595057759e-05,
      "loss": 1.4465,
      "step": 27450
    },
    {
      "epoch": 8.293051359516616,
      "eval_loss": 1.486607551574707,
      "eval_runtime": 1476.8818,
      "eval_samples_per_second": 35.953,
      "eval_steps_per_second": 0.281,
      "step": 27450
    },
    {
      "epoch": 8.308157099697885,
      "grad_norm": 0.6600865721702576,
      "learning_rate": 5.8931437655729734e-05,
      "loss": 1.4951,
      "step": 27500
    },
    {
      "epoch": 8.308157099697885,
      "eval_loss": 1.491239070892334,
      "eval_runtime": 1571.888,
      "eval_samples_per_second": 33.78,
      "eval_steps_per_second": 0.264,
      "step": 27500
    },
    {
      "epoch": 8.323262839879154,
      "grad_norm": 0.9227561354637146,
      "learning_rate": 5.8941910302369755e-05,
      "loss": 1.4845,
      "step": 27550
    },
    {
      "epoch": 8.323262839879154,
      "eval_loss": 1.4860070943832397,
      "eval_runtime": 1520.0034,
      "eval_samples_per_second": 34.933,
      "eval_steps_per_second": 0.273,
      "step": 27550
    },
    {
      "epoch": 8.338368580060424,
      "grad_norm": 0.8045327663421631,
      "learning_rate": 5.8952363959612876e-05,
      "loss": 1.4594,
      "step": 27600
    },
    {
      "epoch": 8.338368580060424,
      "eval_loss": 1.48704993724823,
      "eval_runtime": 1947.7388,
      "eval_samples_per_second": 27.262,
      "eval_steps_per_second": 0.213,
      "step": 27600
    },
    {
      "epoch": 8.353474320241691,
      "grad_norm": 0.7357081770896912,
      "learning_rate": 5.896279869619907e-05,
      "loss": 1.4668,
      "step": 27650
    },
    {
      "epoch": 8.353474320241691,
      "eval_loss": 1.489885926246643,
      "eval_runtime": 1458.5504,
      "eval_samples_per_second": 36.405,
      "eval_steps_per_second": 0.285,
      "step": 27650
    },
    {
      "epoch": 8.36858006042296,
      "grad_norm": 0.7989005446434021,
      "learning_rate": 5.897321458049571e-05,
      "loss": 1.4534,
      "step": 27700
    },
    {
      "epoch": 8.36858006042296,
      "eval_loss": 1.4922974109649658,
      "eval_runtime": 1543.0453,
      "eval_samples_per_second": 34.412,
      "eval_steps_per_second": 0.269,
      "step": 27700
    },
    {
      "epoch": 8.38368580060423,
      "grad_norm": 0.7968280911445618,
      "learning_rate": 5.89836116805003e-05,
      "loss": 1.4487,
      "step": 27750
    },
    {
      "epoch": 8.38368580060423,
      "eval_loss": 1.4898446798324585,
      "eval_runtime": 1548.7362,
      "eval_samples_per_second": 34.285,
      "eval_steps_per_second": 0.268,
      "step": 27750
    },
    {
      "epoch": 8.3987915407855,
      "grad_norm": 0.7611451148986816,
      "learning_rate": 5.8993990063843086e-05,
      "loss": 1.4535,
      "step": 27800
    },
    {
      "epoch": 8.3987915407855,
      "eval_loss": 1.4865481853485107,
      "eval_runtime": 1532.1038,
      "eval_samples_per_second": 34.658,
      "eval_steps_per_second": 0.271,
      "step": 27800
    },
    {
      "epoch": 8.413897280966767,
      "grad_norm": 0.7578529119491577,
      "learning_rate": 5.900434979778977e-05,
      "loss": 1.4513,
      "step": 27850
    },
    {
      "epoch": 8.413897280966767,
      "eval_loss": 1.4850295782089233,
      "eval_runtime": 1563.4681,
      "eval_samples_per_second": 33.962,
      "eval_steps_per_second": 0.265,
      "step": 27850
    },
    {
      "epoch": 8.429003021148036,
      "grad_norm": 0.8318649530410767,
      "learning_rate": 5.901469094924406e-05,
      "loss": 1.467,
      "step": 27900
    },
    {
      "epoch": 8.429003021148036,
      "eval_loss": 1.4891409873962402,
      "eval_runtime": 1485.5125,
      "eval_samples_per_second": 35.745,
      "eval_steps_per_second": 0.279,
      "step": 27900
    },
    {
      "epoch": 8.444108761329305,
      "grad_norm": 0.8811371922492981,
      "learning_rate": 5.902501358475031e-05,
      "loss": 1.4702,
      "step": 27950
    },
    {
      "epoch": 8.444108761329305,
      "eval_loss": 1.4873954057693481,
      "eval_runtime": 1595.3632,
      "eval_samples_per_second": 33.283,
      "eval_steps_per_second": 0.26,
      "step": 27950
    },
    {
      "epoch": 8.459214501510575,
      "grad_norm": 0.7634859085083008,
      "learning_rate": 5.9035317770496046e-05,
      "loss": 1.4472,
      "step": 28000
    },
    {
      "epoch": 8.459214501510575,
      "eval_loss": 1.4846845865249634,
      "eval_runtime": 1491.4218,
      "eval_samples_per_second": 35.603,
      "eval_steps_per_second": 0.278,
      "step": 28000
    },
    {
      "epoch": 8.474320241691842,
      "grad_norm": 0.775238037109375,
      "learning_rate": 5.904560357231454e-05,
      "loss": 1.4573,
      "step": 28050
    },
    {
      "epoch": 8.474320241691842,
      "eval_loss": 1.4866523742675781,
      "eval_runtime": 1854.8226,
      "eval_samples_per_second": 28.628,
      "eval_steps_per_second": 0.224,
      "step": 28050
    },
    {
      "epoch": 8.489425981873111,
      "grad_norm": 0.7931802868843079,
      "learning_rate": 5.905587105568733e-05,
      "loss": 1.4726,
      "step": 28100
    },
    {
      "epoch": 8.489425981873111,
      "eval_loss": 1.48541259765625,
      "eval_runtime": 2214.5811,
      "eval_samples_per_second": 23.977,
      "eval_steps_per_second": 0.187,
      "step": 28100
    },
    {
      "epoch": 8.50453172205438,
      "grad_norm": 0.8833373785018921,
      "learning_rate": 5.906612028574673e-05,
      "loss": 1.4785,
      "step": 28150
    },
    {
      "epoch": 8.50453172205438,
      "eval_loss": 1.48380446434021,
      "eval_runtime": 1976.3309,
      "eval_samples_per_second": 26.867,
      "eval_steps_per_second": 0.21,
      "step": 28150
    },
    {
      "epoch": 8.51963746223565,
      "grad_norm": 0.7297104001045227,
      "learning_rate": 5.907635132727828e-05,
      "loss": 1.4516,
      "step": 28200
    },
    {
      "epoch": 8.51963746223565,
      "eval_loss": 1.4853150844573975,
      "eval_runtime": 1520.1148,
      "eval_samples_per_second": 34.931,
      "eval_steps_per_second": 0.273,
      "step": 28200
    },
    {
      "epoch": 8.534743202416918,
      "grad_norm": 0.8306217193603516,
      "learning_rate": 5.908656424472321e-05,
      "loss": 1.4606,
      "step": 28250
    },
    {
      "epoch": 8.534743202416918,
      "eval_loss": 1.484437108039856,
      "eval_runtime": 1451.9466,
      "eval_samples_per_second": 36.571,
      "eval_steps_per_second": 0.286,
      "step": 28250
    },
    {
      "epoch": 8.549848942598187,
      "grad_norm": 0.6487260460853577,
      "learning_rate": 5.909675910218094e-05,
      "loss": 1.4573,
      "step": 28300
    },
    {
      "epoch": 8.549848942598187,
      "eval_loss": 1.48296320438385,
      "eval_runtime": 1491.8701,
      "eval_samples_per_second": 35.592,
      "eval_steps_per_second": 0.278,
      "step": 28300
    },
    {
      "epoch": 8.564954682779456,
      "grad_norm": 0.9298310279846191,
      "learning_rate": 5.910693596341138e-05,
      "loss": 1.4767,
      "step": 28350
    },
    {
      "epoch": 8.564954682779456,
      "eval_loss": 1.4829286336898804,
      "eval_runtime": 2048.1546,
      "eval_samples_per_second": 25.925,
      "eval_steps_per_second": 0.203,
      "step": 28350
    },
    {
      "epoch": 8.580060422960726,
      "grad_norm": 0.7131089568138123,
      "learning_rate": 5.9117094891837406e-05,
      "loss": 1.4652,
      "step": 28400
    },
    {
      "epoch": 8.580060422960726,
      "eval_loss": 1.4825352430343628,
      "eval_runtime": 1554.013,
      "eval_samples_per_second": 34.169,
      "eval_steps_per_second": 0.267,
      "step": 28400
    },
    {
      "epoch": 8.595166163141993,
      "grad_norm": 0.7792432308197021,
      "learning_rate": 5.912723595054722e-05,
      "loss": 1.4789,
      "step": 28450
    },
    {
      "epoch": 8.595166163141993,
      "eval_loss": 1.4839636087417603,
      "eval_runtime": 1498.32,
      "eval_samples_per_second": 35.439,
      "eval_steps_per_second": 0.277,
      "step": 28450
    },
    {
      "epoch": 8.610271903323262,
      "grad_norm": 0.8207442760467529,
      "learning_rate": 5.913735920229668e-05,
      "loss": 1.4755,
      "step": 28500
    },
    {
      "epoch": 8.610271903323262,
      "eval_loss": 1.4818089008331299,
      "eval_runtime": 1571.0339,
      "eval_samples_per_second": 33.799,
      "eval_steps_per_second": 0.264,
      "step": 28500
    },
    {
      "epoch": 8.625377643504532,
      "grad_norm": 0.7929608821868896,
      "learning_rate": 5.9147464709511616e-05,
      "loss": 1.4502,
      "step": 28550
    },
    {
      "epoch": 8.625377643504532,
      "eval_loss": 1.4826970100402832,
      "eval_runtime": 1590.3872,
      "eval_samples_per_second": 33.387,
      "eval_steps_per_second": 0.261,
      "step": 28550
    },
    {
      "epoch": 8.640483383685801,
      "grad_norm": 0.7009409666061401,
      "learning_rate": 5.915755253429021e-05,
      "loss": 1.4679,
      "step": 28600
    },
    {
      "epoch": 8.640483383685801,
      "eval_loss": 1.483843445777893,
      "eval_runtime": 1518.6458,
      "eval_samples_per_second": 34.965,
      "eval_steps_per_second": 0.273,
      "step": 28600
    },
    {
      "epoch": 8.65558912386707,
      "grad_norm": 0.7868331074714661,
      "learning_rate": 5.916762273840519e-05,
      "loss": 1.4576,
      "step": 28650
    },
    {
      "epoch": 8.65558912386707,
      "eval_loss": 1.4811053276062012,
      "eval_runtime": 1555.9173,
      "eval_samples_per_second": 34.127,
      "eval_steps_per_second": 0.267,
      "step": 28650
    },
    {
      "epoch": 8.670694864048338,
      "grad_norm": 0.7319183945655823,
      "learning_rate": 5.9177675383306186e-05,
      "loss": 1.4737,
      "step": 28700
    },
    {
      "epoch": 8.670694864048338,
      "eval_loss": 1.4788281917572021,
      "eval_runtime": 1533.2519,
      "eval_samples_per_second": 34.632,
      "eval_steps_per_second": 0.271,
      "step": 28700
    },
    {
      "epoch": 8.685800604229607,
      "grad_norm": 0.7227252721786499,
      "learning_rate": 5.918771053012193e-05,
      "loss": 1.4545,
      "step": 28750
    },
    {
      "epoch": 8.685800604229607,
      "eval_loss": 1.480721116065979,
      "eval_runtime": 1523.4457,
      "eval_samples_per_second": 34.855,
      "eval_steps_per_second": 0.272,
      "step": 28750
    },
    {
      "epoch": 8.700906344410877,
      "grad_norm": 0.982012152671814,
      "learning_rate": 5.919772823966248e-05,
      "loss": 1.4606,
      "step": 28800
    },
    {
      "epoch": 8.700906344410877,
      "eval_loss": 1.4814151525497437,
      "eval_runtime": 1608.5839,
      "eval_samples_per_second": 33.01,
      "eval_steps_per_second": 0.258,
      "step": 28800
    },
    {
      "epoch": 8.716012084592146,
      "grad_norm": 0.738176167011261,
      "learning_rate": 5.9207728572421466e-05,
      "loss": 1.4567,
      "step": 28850
    },
    {
      "epoch": 8.716012084592146,
      "eval_loss": 1.478501558303833,
      "eval_runtime": 1581.2749,
      "eval_samples_per_second": 33.58,
      "eval_steps_per_second": 0.262,
      "step": 28850
    },
    {
      "epoch": 8.731117824773413,
      "grad_norm": 0.7600139379501343,
      "learning_rate": 5.921771158857828e-05,
      "loss": 1.4499,
      "step": 28900
    },
    {
      "epoch": 8.731117824773413,
      "eval_loss": 1.480026364326477,
      "eval_runtime": 1581.9805,
      "eval_samples_per_second": 33.565,
      "eval_steps_per_second": 0.262,
      "step": 28900
    },
    {
      "epoch": 8.746223564954683,
      "grad_norm": 0.8608731031417847,
      "learning_rate": 5.922767734800019e-05,
      "loss": 1.4499,
      "step": 28950
    },
    {
      "epoch": 8.746223564954683,
      "eval_loss": 1.4784942865371704,
      "eval_runtime": 1520.8074,
      "eval_samples_per_second": 34.915,
      "eval_steps_per_second": 0.273,
      "step": 28950
    },
    {
      "epoch": 8.761329305135952,
      "grad_norm": 0.7987272143363953,
      "learning_rate": 5.92376259102446e-05,
      "loss": 1.4736,
      "step": 29000
    },
    {
      "epoch": 8.761329305135952,
      "eval_loss": 1.4753985404968262,
      "eval_runtime": 1549.8592,
      "eval_samples_per_second": 34.261,
      "eval_steps_per_second": 0.268,
      "step": 29000
    },
    {
      "epoch": 8.776435045317221,
      "grad_norm": 0.6334537863731384,
      "learning_rate": 5.924755733456107e-05,
      "loss": 1.4405,
      "step": 29050
    },
    {
      "epoch": 8.776435045317221,
      "eval_loss": 1.4777302742004395,
      "eval_runtime": 1491.77,
      "eval_samples_per_second": 35.595,
      "eval_steps_per_second": 0.278,
      "step": 29050
    },
    {
      "epoch": 8.791540785498489,
      "grad_norm": 0.8731252551078796,
      "learning_rate": 5.9257471679893486e-05,
      "loss": 1.4397,
      "step": 29100
    },
    {
      "epoch": 8.791540785498489,
      "eval_loss": 1.4792416095733643,
      "eval_runtime": 1539.6588,
      "eval_samples_per_second": 34.488,
      "eval_steps_per_second": 0.27,
      "step": 29100
    },
    {
      "epoch": 8.806646525679758,
      "grad_norm": 0.8467831015586853,
      "learning_rate": 5.9267369004882206e-05,
      "loss": 1.4495,
      "step": 29150
    },
    {
      "epoch": 8.806646525679758,
      "eval_loss": 1.4769647121429443,
      "eval_runtime": 1491.3403,
      "eval_samples_per_second": 35.605,
      "eval_steps_per_second": 0.278,
      "step": 29150
    },
    {
      "epoch": 8.821752265861027,
      "grad_norm": 0.650880753993988,
      "learning_rate": 5.927724936786608e-05,
      "loss": 1.4576,
      "step": 29200
    },
    {
      "epoch": 8.821752265861027,
      "eval_loss": 1.478593111038208,
      "eval_runtime": 1578.1136,
      "eval_samples_per_second": 33.647,
      "eval_steps_per_second": 0.263,
      "step": 29200
    },
    {
      "epoch": 8.836858006042297,
      "grad_norm": 0.6833228468894958,
      "learning_rate": 5.928711282688448e-05,
      "loss": 1.4521,
      "step": 29250
    },
    {
      "epoch": 8.836858006042297,
      "eval_loss": 1.4759345054626465,
      "eval_runtime": 1502.2711,
      "eval_samples_per_second": 35.346,
      "eval_steps_per_second": 0.276,
      "step": 29250
    },
    {
      "epoch": 8.851963746223564,
      "grad_norm": 0.6821826100349426,
      "learning_rate": 5.9296959439679454e-05,
      "loss": 1.441,
      "step": 29300
    },
    {
      "epoch": 8.851963746223564,
      "eval_loss": 1.4750429391860962,
      "eval_runtime": 1537.657,
      "eval_samples_per_second": 34.532,
      "eval_steps_per_second": 0.27,
      "step": 29300
    },
    {
      "epoch": 8.867069486404834,
      "grad_norm": 0.7980760931968689,
      "learning_rate": 5.930678926369768e-05,
      "loss": 1.4363,
      "step": 29350
    },
    {
      "epoch": 8.867069486404834,
      "eval_loss": 1.4765852689743042,
      "eval_runtime": 1460.8967,
      "eval_samples_per_second": 36.347,
      "eval_steps_per_second": 0.284,
      "step": 29350
    },
    {
      "epoch": 8.882175226586103,
      "grad_norm": 0.7577480673789978,
      "learning_rate": 5.931660235609246e-05,
      "loss": 1.4746,
      "step": 29400
    },
    {
      "epoch": 8.882175226586103,
      "eval_loss": 1.4750114679336548,
      "eval_runtime": 1565.7065,
      "eval_samples_per_second": 33.914,
      "eval_steps_per_second": 0.265,
      "step": 29400
    },
    {
      "epoch": 8.897280966767372,
      "grad_norm": 0.6255472898483276,
      "learning_rate": 5.932639877372577e-05,
      "loss": 1.4366,
      "step": 29450
    },
    {
      "epoch": 8.897280966767372,
      "eval_loss": 1.4767130613327026,
      "eval_runtime": 1499.8754,
      "eval_samples_per_second": 35.402,
      "eval_steps_per_second": 0.277,
      "step": 29450
    },
    {
      "epoch": 8.91238670694864,
      "grad_norm": 0.7147548794746399,
      "learning_rate": 5.933617857317023e-05,
      "loss": 1.4611,
      "step": 29500
    },
    {
      "epoch": 8.91238670694864,
      "eval_loss": 1.4766536951065063,
      "eval_runtime": 1540.4017,
      "eval_samples_per_second": 34.471,
      "eval_steps_per_second": 0.269,
      "step": 29500
    },
    {
      "epoch": 8.927492447129909,
      "grad_norm": 0.7926926612854004,
      "learning_rate": 5.9345941810711005e-05,
      "loss": 1.4545,
      "step": 29550
    },
    {
      "epoch": 8.927492447129909,
      "eval_loss": 1.474427580833435,
      "eval_runtime": 1487.8044,
      "eval_samples_per_second": 35.69,
      "eval_steps_per_second": 0.279,
      "step": 29550
    },
    {
      "epoch": 8.942598187311178,
      "grad_norm": 0.7858224511146545,
      "learning_rate": 5.935568854234781e-05,
      "loss": 1.442,
      "step": 29600
    },
    {
      "epoch": 8.942598187311178,
      "eval_loss": 1.4741489887237549,
      "eval_runtime": 1499.3695,
      "eval_samples_per_second": 35.414,
      "eval_steps_per_second": 0.277,
      "step": 29600
    },
    {
      "epoch": 8.957703927492448,
      "grad_norm": 0.7626060247421265,
      "learning_rate": 5.936541882379683e-05,
      "loss": 1.4341,
      "step": 29650
    },
    {
      "epoch": 8.957703927492448,
      "eval_loss": 1.4747635126113892,
      "eval_runtime": 1588.5646,
      "eval_samples_per_second": 33.426,
      "eval_steps_per_second": 0.261,
      "step": 29650
    },
    {
      "epoch": 8.972809667673715,
      "grad_norm": 0.6929795145988464,
      "learning_rate": 5.9375132710492586e-05,
      "loss": 1.4511,
      "step": 29700
    },
    {
      "epoch": 8.972809667673715,
      "eval_loss": 1.474945306777954,
      "eval_runtime": 1489.3102,
      "eval_samples_per_second": 35.653,
      "eval_steps_per_second": 0.279,
      "step": 29700
    },
    {
      "epoch": 8.987915407854985,
      "grad_norm": 0.8048384189605713,
      "learning_rate": 5.938483025758989e-05,
      "loss": 1.4295,
      "step": 29750
    },
    {
      "epoch": 8.987915407854985,
      "eval_loss": 1.472295880317688,
      "eval_runtime": 1515.9888,
      "eval_samples_per_second": 35.026,
      "eval_steps_per_second": 0.274,
      "step": 29750
    },
    {
      "epoch": 9.003021148036254,
      "grad_norm": 0.6411014795303345,
      "learning_rate": 5.939451151996569e-05,
      "loss": 1.4256,
      "step": 29800
    },
    {
      "epoch": 9.003021148036254,
      "eval_loss": 1.4736930131912231,
      "eval_runtime": 1485.2273,
      "eval_samples_per_second": 35.751,
      "eval_steps_per_second": 0.279,
      "step": 29800
    },
    {
      "epoch": 9.018126888217523,
      "grad_norm": 0.6732810139656067,
      "learning_rate": 5.940417655222092e-05,
      "loss": 1.4387,
      "step": 29850
    },
    {
      "epoch": 9.018126888217523,
      "eval_loss": 1.469618558883667,
      "eval_runtime": 1588.1195,
      "eval_samples_per_second": 33.435,
      "eval_steps_per_second": 0.261,
      "step": 29850
    },
    {
      "epoch": 9.03323262839879,
      "grad_norm": 0.7843582034111023,
      "learning_rate": 5.94138254086824e-05,
      "loss": 1.4459,
      "step": 29900
    },
    {
      "epoch": 9.03323262839879,
      "eval_loss": 1.4722175598144531,
      "eval_runtime": 1512.4663,
      "eval_samples_per_second": 35.108,
      "eval_steps_per_second": 0.274,
      "step": 29900
    },
    {
      "epoch": 9.04833836858006,
      "grad_norm": 0.7176902294158936,
      "learning_rate": 5.94234581434046e-05,
      "loss": 1.45,
      "step": 29950
    },
    {
      "epoch": 9.04833836858006,
      "eval_loss": 1.469732403755188,
      "eval_runtime": 1496.3003,
      "eval_samples_per_second": 35.487,
      "eval_steps_per_second": 0.277,
      "step": 29950
    },
    {
      "epoch": 9.06344410876133,
      "grad_norm": 0.6992211937904358,
      "learning_rate": 5.9433074810171524e-05,
      "loss": 1.4537,
      "step": 30000
    },
    {
      "epoch": 9.06344410876133,
      "eval_loss": 1.4737650156021118,
      "eval_runtime": 1640.9051,
      "eval_samples_per_second": 32.36,
      "eval_steps_per_second": 0.253,
      "step": 30000
    },
    {
      "epoch": 9.078549848942599,
      "grad_norm": 0.7221332788467407,
      "learning_rate": 5.944267546249845e-05,
      "loss": 1.4547,
      "step": 30050
    },
    {
      "epoch": 9.078549848942599,
      "eval_loss": 1.4705020189285278,
      "eval_runtime": 1526.1361,
      "eval_samples_per_second": 34.793,
      "eval_steps_per_second": 0.272,
      "step": 30050
    },
    {
      "epoch": 9.093655589123866,
      "grad_norm": 0.7793689966201782,
      "learning_rate": 5.945226015363376e-05,
      "loss": 1.4136,
      "step": 30100
    },
    {
      "epoch": 9.093655589123866,
      "eval_loss": 1.4722386598587036,
      "eval_runtime": 1497.1769,
      "eval_samples_per_second": 35.466,
      "eval_steps_per_second": 0.277,
      "step": 30100
    },
    {
      "epoch": 9.108761329305135,
      "grad_norm": 0.8123162984848022,
      "learning_rate": 5.946182893656072e-05,
      "loss": 1.4166,
      "step": 30150
    },
    {
      "epoch": 9.108761329305135,
      "eval_loss": 1.4719420671463013,
      "eval_runtime": 1564.7785,
      "eval_samples_per_second": 33.934,
      "eval_steps_per_second": 0.265,
      "step": 30150
    },
    {
      "epoch": 9.123867069486405,
      "grad_norm": 0.8008370995521545,
      "learning_rate": 5.947138186399917e-05,
      "loss": 1.4281,
      "step": 30200
    },
    {
      "epoch": 9.123867069486405,
      "eval_loss": 1.4726382493972778,
      "eval_runtime": 1563.5775,
      "eval_samples_per_second": 33.96,
      "eval_steps_per_second": 0.265,
      "step": 30200
    },
    {
      "epoch": 9.138972809667674,
      "grad_norm": 0.7831703424453735,
      "learning_rate": 5.948091898840735e-05,
      "loss": 1.4748,
      "step": 30250
    },
    {
      "epoch": 9.138972809667674,
      "eval_loss": 1.4689828157424927,
      "eval_runtime": 2030.8362,
      "eval_samples_per_second": 26.146,
      "eval_steps_per_second": 0.204,
      "step": 30250
    },
    {
      "epoch": 9.154078549848943,
      "grad_norm": 0.7981017827987671,
      "learning_rate": 5.949044036198358e-05,
      "loss": 1.4686,
      "step": 30300
    },
    {
      "epoch": 9.154078549848943,
      "eval_loss": 1.469900131225586,
      "eval_runtime": 1516.709,
      "eval_samples_per_second": 35.009,
      "eval_steps_per_second": 0.274,
      "step": 30300
    },
    {
      "epoch": 9.169184290030211,
      "grad_norm": 0.6734127402305603,
      "learning_rate": 5.9499946036667984e-05,
      "loss": 1.4639,
      "step": 30350
    },
    {
      "epoch": 9.169184290030211,
      "eval_loss": 1.4702035188674927,
      "eval_runtime": 1511.6217,
      "eval_samples_per_second": 35.127,
      "eval_steps_per_second": 0.275,
      "step": 30350
    },
    {
      "epoch": 9.18429003021148,
      "grad_norm": 0.8079190254211426,
      "learning_rate": 5.950943606414419e-05,
      "loss": 1.4481,
      "step": 30400
    },
    {
      "epoch": 9.18429003021148,
      "eval_loss": 1.4676817655563354,
      "eval_runtime": 1517.8282,
      "eval_samples_per_second": 34.984,
      "eval_steps_per_second": 0.273,
      "step": 30400
    },
    {
      "epoch": 9.19939577039275,
      "grad_norm": 0.7564939856529236,
      "learning_rate": 5.9518910495841016e-05,
      "loss": 1.4714,
      "step": 30450
    },
    {
      "epoch": 9.19939577039275,
      "eval_loss": 1.4675966501235962,
      "eval_runtime": 1556.7763,
      "eval_samples_per_second": 34.108,
      "eval_steps_per_second": 0.267,
      "step": 30450
    },
    {
      "epoch": 9.214501510574019,
      "grad_norm": 0.7367964386940002,
      "learning_rate": 5.952836938293415e-05,
      "loss": 1.4446,
      "step": 30500
    },
    {
      "epoch": 9.214501510574019,
      "eval_loss": 1.4669758081436157,
      "eval_runtime": 1584.844,
      "eval_samples_per_second": 33.504,
      "eval_steps_per_second": 0.262,
      "step": 30500
    },
    {
      "epoch": 9.229607250755286,
      "grad_norm": 0.8822395205497742,
      "learning_rate": 5.9537812776347794e-05,
      "loss": 1.4674,
      "step": 30550
    },
    {
      "epoch": 9.229607250755286,
      "eval_loss": 1.466902494430542,
      "eval_runtime": 1594.109,
      "eval_samples_per_second": 33.31,
      "eval_steps_per_second": 0.26,
      "step": 30550
    },
    {
      "epoch": 9.244712990936556,
      "grad_norm": 0.681732714176178,
      "learning_rate": 5.954724072675633e-05,
      "loss": 1.4303,
      "step": 30600
    },
    {
      "epoch": 9.244712990936556,
      "eval_loss": 1.467381477355957,
      "eval_runtime": 1526.1753,
      "eval_samples_per_second": 34.792,
      "eval_steps_per_second": 0.272,
      "step": 30600
    },
    {
      "epoch": 9.259818731117825,
      "grad_norm": 0.6757423877716064,
      "learning_rate": 5.9556653284585916e-05,
      "loss": 1.4625,
      "step": 30650
    },
    {
      "epoch": 9.259818731117825,
      "eval_loss": 1.4685429334640503,
      "eval_runtime": 1446.3939,
      "eval_samples_per_second": 36.711,
      "eval_steps_per_second": 0.287,
      "step": 30650
    },
    {
      "epoch": 9.274924471299094,
      "grad_norm": 0.8030160665512085,
      "learning_rate": 5.956605050001616e-05,
      "loss": 1.4291,
      "step": 30700
    },
    {
      "epoch": 9.274924471299094,
      "eval_loss": 1.4659894704818726,
      "eval_runtime": 1525.5687,
      "eval_samples_per_second": 34.806,
      "eval_steps_per_second": 0.272,
      "step": 30700
    },
    {
      "epoch": 9.290030211480362,
      "grad_norm": 0.6640319228172302,
      "learning_rate": 5.957543242298167e-05,
      "loss": 1.4327,
      "step": 30750
    },
    {
      "epoch": 9.290030211480362,
      "eval_loss": 1.4650462865829468,
      "eval_runtime": 1621.3911,
      "eval_samples_per_second": 32.749,
      "eval_steps_per_second": 0.256,
      "step": 30750
    },
    {
      "epoch": 9.305135951661631,
      "grad_norm": 0.847443699836731,
      "learning_rate": 5.9584799103173664e-05,
      "loss": 1.4521,
      "step": 30800
    },
    {
      "epoch": 9.305135951661631,
      "eval_loss": 1.46608567237854,
      "eval_runtime": 1501.6422,
      "eval_samples_per_second": 35.361,
      "eval_steps_per_second": 0.276,
      "step": 30800
    },
    {
      "epoch": 9.3202416918429,
      "grad_norm": 0.690744161605835,
      "learning_rate": 5.959415059004156e-05,
      "loss": 1.4518,
      "step": 30850
    },
    {
      "epoch": 9.3202416918429,
      "eval_loss": 1.4658355712890625,
      "eval_runtime": 1541.6482,
      "eval_samples_per_second": 34.443,
      "eval_steps_per_second": 0.269,
      "step": 30850
    },
    {
      "epoch": 9.33534743202417,
      "grad_norm": 0.861714780330658,
      "learning_rate": 5.960348693279456e-05,
      "loss": 1.4477,
      "step": 30900
    },
    {
      "epoch": 9.33534743202417,
      "eval_loss": 1.4649707078933716,
      "eval_runtime": 1718.1923,
      "eval_samples_per_second": 30.904,
      "eval_steps_per_second": 0.242,
      "step": 30900
    },
    {
      "epoch": 9.350453172205437,
      "grad_norm": 0.7911188006401062,
      "learning_rate": 5.9612808180403125e-05,
      "loss": 1.4373,
      "step": 30950
    },
    {
      "epoch": 9.350453172205437,
      "eval_loss": 1.4659916162490845,
      "eval_runtime": 1487.7392,
      "eval_samples_per_second": 35.691,
      "eval_steps_per_second": 0.279,
      "step": 30950
    },
    {
      "epoch": 9.365558912386707,
      "grad_norm": 0.6872831583023071,
      "learning_rate": 5.9622114381600626e-05,
      "loss": 1.4449,
      "step": 31000
    },
    {
      "epoch": 9.365558912386707,
      "eval_loss": 1.4642858505249023,
      "eval_runtime": 1537.0906,
      "eval_samples_per_second": 34.545,
      "eval_steps_per_second": 0.27,
      "step": 31000
    },
    {
      "epoch": 9.380664652567976,
      "grad_norm": 0.6572044491767883,
      "learning_rate": 5.963140558488478e-05,
      "loss": 1.4446,
      "step": 31050
    },
    {
      "epoch": 9.380664652567976,
      "eval_loss": 1.4660111665725708,
      "eval_runtime": 1549.1023,
      "eval_samples_per_second": 34.277,
      "eval_steps_per_second": 0.268,
      "step": 31050
    },
    {
      "epoch": 9.395770392749245,
      "grad_norm": 0.6269264817237854,
      "learning_rate": 5.964068183851921e-05,
      "loss": 1.4385,
      "step": 31100
    },
    {
      "epoch": 9.395770392749245,
      "eval_loss": 1.4639710187911987,
      "eval_runtime": 1480.9757,
      "eval_samples_per_second": 35.854,
      "eval_steps_per_second": 0.28,
      "step": 31100
    },
    {
      "epoch": 9.410876132930513,
      "grad_norm": 0.6808445453643799,
      "learning_rate": 5.964994319053498e-05,
      "loss": 1.4645,
      "step": 31150
    },
    {
      "epoch": 9.410876132930513,
      "eval_loss": 1.4651930332183838,
      "eval_runtime": 1539.1115,
      "eval_samples_per_second": 34.5,
      "eval_steps_per_second": 0.27,
      "step": 31150
    },
    {
      "epoch": 9.425981873111782,
      "grad_norm": 0.7704942226409912,
      "learning_rate": 5.965918968873199e-05,
      "loss": 1.4289,
      "step": 31200
    },
    {
      "epoch": 9.425981873111782,
      "eval_loss": 1.4627774953842163,
      "eval_runtime": 1474.0349,
      "eval_samples_per_second": 36.023,
      "eval_steps_per_second": 0.282,
      "step": 31200
    },
    {
      "epoch": 9.441087613293051,
      "grad_norm": 0.6453658938407898,
      "learning_rate": 5.966842138068057e-05,
      "loss": 1.4172,
      "step": 31250
    },
    {
      "epoch": 9.441087613293051,
      "eval_loss": 1.4642226696014404,
      "eval_runtime": 1481.3769,
      "eval_samples_per_second": 35.844,
      "eval_steps_per_second": 0.28,
      "step": 31250
    },
    {
      "epoch": 9.45619335347432,
      "grad_norm": 0.6727065443992615,
      "learning_rate": 5.9677638313722847e-05,
      "loss": 1.4551,
      "step": 31300
    },
    {
      "epoch": 9.45619335347432,
      "eval_loss": 1.4608606100082397,
      "eval_runtime": 1624.0158,
      "eval_samples_per_second": 32.696,
      "eval_steps_per_second": 0.256,
      "step": 31300
    },
    {
      "epoch": 9.471299093655588,
      "grad_norm": 0.7442569732666016,
      "learning_rate": 5.9686840534974295e-05,
      "loss": 1.4304,
      "step": 31350
    },
    {
      "epoch": 9.471299093655588,
      "eval_loss": 1.461451530456543,
      "eval_runtime": 1482.7584,
      "eval_samples_per_second": 35.811,
      "eval_steps_per_second": 0.28,
      "step": 31350
    },
    {
      "epoch": 9.486404833836858,
      "grad_norm": 0.7109950184822083,
      "learning_rate": 5.969602809132511e-05,
      "loss": 1.4158,
      "step": 31400
    },
    {
      "epoch": 9.486404833836858,
      "eval_loss": 1.4612497091293335,
      "eval_runtime": 1469.2847,
      "eval_samples_per_second": 36.139,
      "eval_steps_per_second": 0.282,
      "step": 31400
    },
    {
      "epoch": 9.501510574018127,
      "grad_norm": 0.7325189709663391,
      "learning_rate": 5.970520102944167e-05,
      "loss": 1.4468,
      "step": 31450
    },
    {
      "epoch": 9.501510574018127,
      "eval_loss": 1.4632172584533691,
      "eval_runtime": 1496.0921,
      "eval_samples_per_second": 35.492,
      "eval_steps_per_second": 0.277,
      "step": 31450
    },
    {
      "epoch": 9.516616314199396,
      "grad_norm": 0.7105164527893066,
      "learning_rate": 5.971435939576794e-05,
      "loss": 1.4212,
      "step": 31500
    },
    {
      "epoch": 9.516616314199396,
      "eval_loss": 1.4636597633361816,
      "eval_runtime": 1503.0856,
      "eval_samples_per_second": 35.327,
      "eval_steps_per_second": 0.276,
      "step": 31500
    },
    {
      "epoch": 9.531722054380666,
      "grad_norm": 0.774453341960907,
      "learning_rate": 5.9723503236526944e-05,
      "loss": 1.4051,
      "step": 31550
    },
    {
      "epoch": 9.531722054380666,
      "eval_loss": 1.4607983827590942,
      "eval_runtime": 1469.1943,
      "eval_samples_per_second": 36.142,
      "eval_steps_per_second": 0.282,
      "step": 31550
    },
    {
      "epoch": 9.546827794561933,
      "grad_norm": 0.7574877738952637,
      "learning_rate": 5.973263259772207e-05,
      "loss": 1.4115,
      "step": 31600
    },
    {
      "epoch": 9.546827794561933,
      "eval_loss": 1.4613388776779175,
      "eval_runtime": 1547.6658,
      "eval_samples_per_second": 34.309,
      "eval_steps_per_second": 0.268,
      "step": 31600
    },
    {
      "epoch": 9.561933534743202,
      "grad_norm": 0.5861889123916626,
      "learning_rate": 5.9741747525138546e-05,
      "loss": 1.442,
      "step": 31650
    },
    {
      "epoch": 9.561933534743202,
      "eval_loss": 1.4592317342758179,
      "eval_runtime": 1484.5413,
      "eval_samples_per_second": 35.768,
      "eval_steps_per_second": 0.28,
      "step": 31650
    },
    {
      "epoch": 9.577039274924472,
      "grad_norm": 0.663044273853302,
      "learning_rate": 5.9750848064344745e-05,
      "loss": 1.4273,
      "step": 31700
    },
    {
      "epoch": 9.577039274924472,
      "eval_loss": 1.4618101119995117,
      "eval_runtime": 1569.6525,
      "eval_samples_per_second": 33.829,
      "eval_steps_per_second": 0.264,
      "step": 31700
    },
    {
      "epoch": 9.59214501510574,
      "grad_norm": 0.7310140132904053,
      "learning_rate": 5.975993426069362e-05,
      "loss": 1.4546,
      "step": 31750
    },
    {
      "epoch": 9.59214501510574,
      "eval_loss": 1.4620949029922485,
      "eval_runtime": 1569.0102,
      "eval_samples_per_second": 33.842,
      "eval_steps_per_second": 0.264,
      "step": 31750
    },
    {
      "epoch": 9.607250755287009,
      "grad_norm": 0.745821475982666,
      "learning_rate": 5.9769006159324003e-05,
      "loss": 1.4496,
      "step": 31800
    },
    {
      "epoch": 9.607250755287009,
      "eval_loss": 1.458990216255188,
      "eval_runtime": 1603.2623,
      "eval_samples_per_second": 33.119,
      "eval_steps_per_second": 0.259,
      "step": 31800
    },
    {
      "epoch": 9.622356495468278,
      "grad_norm": 0.7674307823181152,
      "learning_rate": 5.977806380516198e-05,
      "loss": 1.4438,
      "step": 31850
    },
    {
      "epoch": 9.622356495468278,
      "eval_loss": 1.4620908498764038,
      "eval_runtime": 1477.7052,
      "eval_samples_per_second": 35.933,
      "eval_steps_per_second": 0.281,
      "step": 31850
    },
    {
      "epoch": 9.637462235649547,
      "grad_norm": 0.6926037669181824,
      "learning_rate": 5.9787107242922213e-05,
      "loss": 1.4397,
      "step": 31900
    },
    {
      "epoch": 9.637462235649547,
      "eval_loss": 1.4572445154190063,
      "eval_runtime": 1546.9723,
      "eval_samples_per_second": 34.324,
      "eval_steps_per_second": 0.268,
      "step": 31900
    },
    {
      "epoch": 9.652567975830816,
      "grad_norm": 0.7700081467628479,
      "learning_rate": 5.9796136517109305e-05,
      "loss": 1.4514,
      "step": 31950
    },
    {
      "epoch": 9.652567975830816,
      "eval_loss": 1.4598677158355713,
      "eval_runtime": 1478.6393,
      "eval_samples_per_second": 35.911,
      "eval_steps_per_second": 0.281,
      "step": 31950
    },
    {
      "epoch": 9.667673716012084,
      "grad_norm": 0.7401072382926941,
      "learning_rate": 5.9805151672019034e-05,
      "loss": 1.4291,
      "step": 32000
    },
    {
      "epoch": 9.667673716012084,
      "eval_loss": 1.461181402206421,
      "eval_runtime": 1532.1281,
      "eval_samples_per_second": 34.657,
      "eval_steps_per_second": 0.271,
      "step": 32000
    },
    {
      "epoch": 9.682779456193353,
      "grad_norm": 0.6314978003501892,
      "learning_rate": 5.9814152751739724e-05,
      "loss": 1.4304,
      "step": 32050
    },
    {
      "epoch": 9.682779456193353,
      "eval_loss": 1.458889365196228,
      "eval_runtime": 1506.3785,
      "eval_samples_per_second": 35.249,
      "eval_steps_per_second": 0.275,
      "step": 32050
    },
    {
      "epoch": 9.697885196374623,
      "grad_norm": 0.6534206867218018,
      "learning_rate": 5.982313980015354e-05,
      "loss": 1.428,
      "step": 32100
    },
    {
      "epoch": 9.697885196374623,
      "eval_loss": 1.4575942754745483,
      "eval_runtime": 1593.9717,
      "eval_samples_per_second": 33.312,
      "eval_steps_per_second": 0.26,
      "step": 32100
    },
    {
      "epoch": 9.712990936555892,
      "grad_norm": 0.6279093623161316,
      "learning_rate": 5.983211286093771e-05,
      "loss": 1.4443,
      "step": 32150
    },
    {
      "epoch": 9.712990936555892,
      "eval_loss": 1.458497405052185,
      "eval_runtime": 1535.4988,
      "eval_samples_per_second": 34.581,
      "eval_steps_per_second": 0.27,
      "step": 32150
    },
    {
      "epoch": 9.72809667673716,
      "grad_norm": 0.645253598690033,
      "learning_rate": 5.984107197756586e-05,
      "loss": 1.436,
      "step": 32200
    },
    {
      "epoch": 9.72809667673716,
      "eval_loss": 1.457378625869751,
      "eval_runtime": 1530.6081,
      "eval_samples_per_second": 34.691,
      "eval_steps_per_second": 0.271,
      "step": 32200
    },
    {
      "epoch": 9.743202416918429,
      "grad_norm": 0.7537388801574707,
      "learning_rate": 5.985001719330925e-05,
      "loss": 1.4354,
      "step": 32250
    },
    {
      "epoch": 9.743202416918429,
      "eval_loss": 1.4596318006515503,
      "eval_runtime": 1504.3493,
      "eval_samples_per_second": 35.297,
      "eval_steps_per_second": 0.276,
      "step": 32250
    },
    {
      "epoch": 9.758308157099698,
      "grad_norm": 0.6466118693351746,
      "learning_rate": 5.985894855123803e-05,
      "loss": 1.4391,
      "step": 32300
    },
    {
      "epoch": 9.758308157099698,
      "eval_loss": 1.4551990032196045,
      "eval_runtime": 1580.0195,
      "eval_samples_per_second": 33.607,
      "eval_steps_per_second": 0.263,
      "step": 32300
    },
    {
      "epoch": 9.773413897280967,
      "grad_norm": 0.655641496181488,
      "learning_rate": 5.9867866094222526e-05,
      "loss": 1.4043,
      "step": 32350
    },
    {
      "epoch": 9.773413897280967,
      "eval_loss": 1.4576438665390015,
      "eval_runtime": 1538.1964,
      "eval_samples_per_second": 34.52,
      "eval_steps_per_second": 0.27,
      "step": 32350
    },
    {
      "epoch": 9.788519637462235,
      "grad_norm": 0.7094830870628357,
      "learning_rate": 5.987676986493437e-05,
      "loss": 1.4394,
      "step": 32400
    },
    {
      "epoch": 9.788519637462235,
      "eval_loss": 1.4545221328735352,
      "eval_runtime": 1510.4333,
      "eval_samples_per_second": 35.155,
      "eval_steps_per_second": 0.275,
      "step": 32400
    },
    {
      "epoch": 9.803625377643504,
      "grad_norm": 0.6943615674972534,
      "learning_rate": 5.988565990584785e-05,
      "loss": 1.4289,
      "step": 32450
    },
    {
      "epoch": 9.803625377643504,
      "eval_loss": 1.45603346824646,
      "eval_runtime": 1519.2245,
      "eval_samples_per_second": 34.951,
      "eval_steps_per_second": 0.273,
      "step": 32450
    },
    {
      "epoch": 9.818731117824774,
      "grad_norm": 0.6761261820793152,
      "learning_rate": 5.989453625924104e-05,
      "loss": 1.4248,
      "step": 32500
    },
    {
      "epoch": 9.818731117824774,
      "eval_loss": 1.4560432434082031,
      "eval_runtime": 1549.8578,
      "eval_samples_per_second": 34.261,
      "eval_steps_per_second": 0.268,
      "step": 32500
    },
    {
      "epoch": 9.833836858006043,
      "grad_norm": 0.73700350522995,
      "learning_rate": 5.990339896719705e-05,
      "loss": 1.4245,
      "step": 32550
    },
    {
      "epoch": 9.833836858006043,
      "eval_loss": 1.456003189086914,
      "eval_runtime": 1546.1622,
      "eval_samples_per_second": 34.342,
      "eval_steps_per_second": 0.268,
      "step": 32550
    },
    {
      "epoch": 9.84894259818731,
      "grad_norm": 0.6558656692504883,
      "learning_rate": 5.991224807160516e-05,
      "loss": 1.455,
      "step": 32600
    },
    {
      "epoch": 9.84894259818731,
      "eval_loss": 1.4547945261001587,
      "eval_runtime": 1481.1395,
      "eval_samples_per_second": 35.85,
      "eval_steps_per_second": 0.28,
      "step": 32600
    },
    {
      "epoch": 9.86404833836858,
      "grad_norm": 0.6093393564224243,
      "learning_rate": 5.992108361416214e-05,
      "loss": 1.4331,
      "step": 32650
    },
    {
      "epoch": 9.86404833836858,
      "eval_loss": 1.4550080299377441,
      "eval_runtime": 1443.6758,
      "eval_samples_per_second": 36.78,
      "eval_steps_per_second": 0.287,
      "step": 32650
    },
    {
      "epoch": 9.879154078549849,
      "grad_norm": 0.6294627785682678,
      "learning_rate": 5.9929905636373276e-05,
      "loss": 1.4362,
      "step": 32700
    },
    {
      "epoch": 9.879154078549849,
      "eval_loss": 1.454916000366211,
      "eval_runtime": 1530.4023,
      "eval_samples_per_second": 34.696,
      "eval_steps_per_second": 0.271,
      "step": 32700
    },
    {
      "epoch": 9.894259818731118,
      "grad_norm": 0.6551443338394165,
      "learning_rate": 5.993871417955363e-05,
      "loss": 1.4303,
      "step": 32750
    },
    {
      "epoch": 9.894259818731118,
      "eval_loss": 1.4526315927505493,
      "eval_runtime": 1460.6432,
      "eval_samples_per_second": 36.353,
      "eval_steps_per_second": 0.284,
      "step": 32750
    },
    {
      "epoch": 9.909365558912386,
      "grad_norm": 0.7244375944137573,
      "learning_rate": 5.994750928482918e-05,
      "loss": 1.4076,
      "step": 32800
    },
    {
      "epoch": 9.909365558912386,
      "eval_loss": 1.4543112516403198,
      "eval_runtime": 1574.6284,
      "eval_samples_per_second": 33.722,
      "eval_steps_per_second": 0.264,
      "step": 32800
    },
    {
      "epoch": 9.924471299093655,
      "grad_norm": 0.6676394939422607,
      "learning_rate": 5.995629099313797e-05,
      "loss": 1.4322,
      "step": 32850
    },
    {
      "epoch": 9.924471299093655,
      "eval_loss": 1.4509323835372925,
      "eval_runtime": 1564.0527,
      "eval_samples_per_second": 33.95,
      "eval_steps_per_second": 0.265,
      "step": 32850
    },
    {
      "epoch": 9.939577039274925,
      "grad_norm": 0.6487152576446533,
      "learning_rate": 5.996505934523125e-05,
      "loss": 1.404,
      "step": 32900
    },
    {
      "epoch": 9.939577039274925,
      "eval_loss": 1.453568458557129,
      "eval_runtime": 1470.8813,
      "eval_samples_per_second": 36.1,
      "eval_steps_per_second": 0.282,
      "step": 32900
    },
    {
      "epoch": 9.954682779456194,
      "grad_norm": 0.7273639440536499,
      "learning_rate": 5.997381438167462e-05,
      "loss": 1.4261,
      "step": 32950
    },
    {
      "epoch": 9.954682779456194,
      "eval_loss": 1.4532098770141602,
      "eval_runtime": 1483.5907,
      "eval_samples_per_second": 35.791,
      "eval_steps_per_second": 0.28,
      "step": 32950
    },
    {
      "epoch": 9.969788519637461,
      "grad_norm": 0.6430342197418213,
      "learning_rate": 5.9982556142849135e-05,
      "loss": 1.412,
      "step": 33000
    },
    {
      "epoch": 9.969788519637461,
      "eval_loss": 1.4526437520980835,
      "eval_runtime": 1556.9283,
      "eval_samples_per_second": 34.105,
      "eval_steps_per_second": 0.267,
      "step": 33000
    },
    {
      "epoch": 9.98489425981873,
      "grad_norm": 0.6805771589279175,
      "learning_rate": 5.9991284668952495e-05,
      "loss": 1.4327,
      "step": 33050
    },
    {
      "epoch": 9.98489425981873,
      "eval_loss": 1.4510478973388672,
      "eval_runtime": 1502.9758,
      "eval_samples_per_second": 35.329,
      "eval_steps_per_second": 0.276,
      "step": 33050
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.6646634340286255,
      "learning_rate": 6e-05,
      "loss": 1.4416,
      "step": 33100
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.451181173324585,
      "eval_runtime": 1563.5301,
      "eval_samples_per_second": 33.961,
      "eval_steps_per_second": 0.265,
      "step": 33100
    },
    {
      "epoch": 10.01510574018127,
      "grad_norm": 0.8126400113105774,
      "learning_rate": 5.99901309164149e-05,
      "loss": 1.4289,
      "step": 33150
    },
    {
      "epoch": 10.01510574018127,
      "eval_loss": 1.4517157077789307,
      "eval_runtime": 1457.9336,
      "eval_samples_per_second": 36.421,
      "eval_steps_per_second": 0.285,
      "step": 33150
    },
    {
      "epoch": 10.030211480362539,
      "grad_norm": 0.6672797203063965,
      "learning_rate": 5.998006042296073e-05,
      "loss": 1.4457,
      "step": 33200
    },
    {
      "epoch": 10.030211480362539,
      "eval_loss": 1.4502379894256592,
      "eval_runtime": 1492.4385,
      "eval_samples_per_second": 35.579,
      "eval_steps_per_second": 0.278,
      "step": 33200
    },
    {
      "epoch": 10.045317220543806,
      "grad_norm": 0.6731664538383484,
      "learning_rate": 5.9969989929506546e-05,
      "loss": 1.4272,
      "step": 33250
    },
    {
      "epoch": 10.045317220543806,
      "eval_loss": 1.4491780996322632,
      "eval_runtime": 1493.4754,
      "eval_samples_per_second": 35.554,
      "eval_steps_per_second": 0.278,
      "step": 33250
    },
    {
      "epoch": 10.060422960725075,
      "grad_norm": 0.6217506527900696,
      "learning_rate": 5.9959919436052365e-05,
      "loss": 1.43,
      "step": 33300
    },
    {
      "epoch": 10.060422960725075,
      "eval_loss": 1.4498040676116943,
      "eval_runtime": 1536.6156,
      "eval_samples_per_second": 34.556,
      "eval_steps_per_second": 0.27,
      "step": 33300
    },
    {
      "epoch": 10.075528700906345,
      "grad_norm": 0.6397762894630432,
      "learning_rate": 5.9949848942598184e-05,
      "loss": 1.4186,
      "step": 33350
    },
    {
      "epoch": 10.075528700906345,
      "eval_loss": 1.4511686563491821,
      "eval_runtime": 1515.7024,
      "eval_samples_per_second": 35.033,
      "eval_steps_per_second": 0.274,
      "step": 33350
    },
    {
      "epoch": 10.090634441087614,
      "grad_norm": 0.618382453918457,
      "learning_rate": 5.993977844914401e-05,
      "loss": 1.4341,
      "step": 33400
    },
    {
      "epoch": 10.090634441087614,
      "eval_loss": 1.4510948657989502,
      "eval_runtime": 1565.4605,
      "eval_samples_per_second": 33.919,
      "eval_steps_per_second": 0.265,
      "step": 33400
    },
    {
      "epoch": 10.105740181268882,
      "grad_norm": 0.7561808228492737,
      "learning_rate": 5.992970795568983e-05,
      "loss": 1.4188,
      "step": 33450
    },
    {
      "epoch": 10.105740181268882,
      "eval_loss": 1.4491180181503296,
      "eval_runtime": 1575.6644,
      "eval_samples_per_second": 33.699,
      "eval_steps_per_second": 0.263,
      "step": 33450
    },
    {
      "epoch": 10.120845921450151,
      "grad_norm": 0.6538001894950867,
      "learning_rate": 5.9919637462235647e-05,
      "loss": 1.4105,
      "step": 33500
    },
    {
      "epoch": 10.120845921450151,
      "eval_loss": 1.4487665891647339,
      "eval_runtime": 1508.1846,
      "eval_samples_per_second": 35.207,
      "eval_steps_per_second": 0.275,
      "step": 33500
    },
    {
      "epoch": 10.13595166163142,
      "grad_norm": 0.7149539589881897,
      "learning_rate": 5.990956696878147e-05,
      "loss": 1.4041,
      "step": 33550
    },
    {
      "epoch": 10.13595166163142,
      "eval_loss": 1.448737621307373,
      "eval_runtime": 1520.305,
      "eval_samples_per_second": 34.927,
      "eval_steps_per_second": 0.273,
      "step": 33550
    },
    {
      "epoch": 10.15105740181269,
      "grad_norm": 0.6042513251304626,
      "learning_rate": 5.98994964753273e-05,
      "loss": 1.4129,
      "step": 33600
    },
    {
      "epoch": 10.15105740181269,
      "eval_loss": 1.4479771852493286,
      "eval_runtime": 2215.4987,
      "eval_samples_per_second": 23.967,
      "eval_steps_per_second": 0.187,
      "step": 33600
    },
    {
      "epoch": 10.166163141993957,
      "grad_norm": 0.7702732086181641,
      "learning_rate": 5.9889425981873116e-05,
      "loss": 1.4471,
      "step": 33650
    },
    {
      "epoch": 10.166163141993957,
      "eval_loss": 1.4497343301773071,
      "eval_runtime": 2285.1372,
      "eval_samples_per_second": 23.237,
      "eval_steps_per_second": 0.182,
      "step": 33650
    },
    {
      "epoch": 10.181268882175226,
      "grad_norm": 0.6309195160865784,
      "learning_rate": 5.9879355488418935e-05,
      "loss": 1.4255,
      "step": 33700
    },
    {
      "epoch": 10.181268882175226,
      "eval_loss": 1.4510207176208496,
      "eval_runtime": 1513.2259,
      "eval_samples_per_second": 35.09,
      "eval_steps_per_second": 0.274,
      "step": 33700
    },
    {
      "epoch": 10.196374622356496,
      "grad_norm": 0.8463542461395264,
      "learning_rate": 5.986928499496476e-05,
      "loss": 1.4176,
      "step": 33750
    },
    {
      "epoch": 10.196374622356496,
      "eval_loss": 1.448944330215454,
      "eval_runtime": 1574.5989,
      "eval_samples_per_second": 33.722,
      "eval_steps_per_second": 0.264,
      "step": 33750
    },
    {
      "epoch": 10.211480362537765,
      "grad_norm": 0.6514292359352112,
      "learning_rate": 5.985921450151058e-05,
      "loss": 1.4138,
      "step": 33800
    },
    {
      "epoch": 10.211480362537765,
      "eval_loss": 1.4481844902038574,
      "eval_runtime": 1516.3406,
      "eval_samples_per_second": 35.018,
      "eval_steps_per_second": 0.274,
      "step": 33800
    },
    {
      "epoch": 10.226586102719033,
      "grad_norm": 0.6185621619224548,
      "learning_rate": 5.98491440080564e-05,
      "loss": 1.4014,
      "step": 33850
    },
    {
      "epoch": 10.226586102719033,
      "eval_loss": 1.448412299156189,
      "eval_runtime": 1498.2134,
      "eval_samples_per_second": 35.442,
      "eval_steps_per_second": 0.277,
      "step": 33850
    },
    {
      "epoch": 10.241691842900302,
      "grad_norm": 0.6503190994262695,
      "learning_rate": 5.9839073514602216e-05,
      "loss": 1.4333,
      "step": 33900
    },
    {
      "epoch": 10.241691842900302,
      "eval_loss": 1.4468350410461426,
      "eval_runtime": 1563.8587,
      "eval_samples_per_second": 33.954,
      "eval_steps_per_second": 0.265,
      "step": 33900
    },
    {
      "epoch": 10.256797583081571,
      "grad_norm": 0.6504673957824707,
      "learning_rate": 5.982900302114804e-05,
      "loss": 1.4083,
      "step": 33950
    },
    {
      "epoch": 10.256797583081571,
      "eval_loss": 1.4486454725265503,
      "eval_runtime": 1642.1182,
      "eval_samples_per_second": 32.336,
      "eval_steps_per_second": 0.253,
      "step": 33950
    },
    {
      "epoch": 10.27190332326284,
      "grad_norm": 0.8272129893302917,
      "learning_rate": 5.981893252769386e-05,
      "loss": 1.4131,
      "step": 34000
    },
    {
      "epoch": 10.27190332326284,
      "eval_loss": 1.4436450004577637,
      "eval_runtime": 1492.9106,
      "eval_samples_per_second": 35.567,
      "eval_steps_per_second": 0.278,
      "step": 34000
    },
    {
      "epoch": 10.287009063444108,
      "grad_norm": 0.6750848889350891,
      "learning_rate": 5.980886203423968e-05,
      "loss": 1.4172,
      "step": 34050
    },
    {
      "epoch": 10.287009063444108,
      "eval_loss": 1.447332739830017,
      "eval_runtime": 1596.0939,
      "eval_samples_per_second": 33.268,
      "eval_steps_per_second": 0.26,
      "step": 34050
    },
    {
      "epoch": 10.302114803625377,
      "grad_norm": 0.6376634240150452,
      "learning_rate": 5.97987915407855e-05,
      "loss": 1.4402,
      "step": 34100
    },
    {
      "epoch": 10.302114803625377,
      "eval_loss": 1.4450782537460327,
      "eval_runtime": 1569.5776,
      "eval_samples_per_second": 33.83,
      "eval_steps_per_second": 0.264,
      "step": 34100
    },
    {
      "epoch": 10.317220543806647,
      "grad_norm": 0.9578709602355957,
      "learning_rate": 5.978872104733132e-05,
      "loss": 1.4309,
      "step": 34150
    },
    {
      "epoch": 10.317220543806647,
      "eval_loss": 1.4471995830535889,
      "eval_runtime": 1634.9133,
      "eval_samples_per_second": 32.478,
      "eval_steps_per_second": 0.254,
      "step": 34150
    },
    {
      "epoch": 10.332326283987916,
      "grad_norm": 0.6951043605804443,
      "learning_rate": 5.977865055387714e-05,
      "loss": 1.4081,
      "step": 34200
    },
    {
      "epoch": 10.332326283987916,
      "eval_loss": 1.4446736574172974,
      "eval_runtime": 1586.568,
      "eval_samples_per_second": 33.468,
      "eval_steps_per_second": 0.262,
      "step": 34200
    },
    {
      "epoch": 10.347432024169184,
      "grad_norm": 0.8831804394721985,
      "learning_rate": 5.976858006042296e-05,
      "loss": 1.4231,
      "step": 34250
    },
    {
      "epoch": 10.347432024169184,
      "eval_loss": 1.4467206001281738,
      "eval_runtime": 2522.5308,
      "eval_samples_per_second": 21.05,
      "eval_steps_per_second": 0.165,
      "step": 34250
    },
    {
      "epoch": 10.362537764350453,
      "grad_norm": 0.6876438856124878,
      "learning_rate": 5.975850956696878e-05,
      "loss": 1.4252,
      "step": 34300
    },
    {
      "epoch": 10.362537764350453,
      "eval_loss": 1.446834683418274,
      "eval_runtime": 7589.5729,
      "eval_samples_per_second": 6.996,
      "eval_steps_per_second": 0.055,
      "step": 34300
    },
    {
      "epoch": 10.377643504531722,
      "grad_norm": 0.6160025596618652,
      "learning_rate": 5.9748439073514605e-05,
      "loss": 1.3885,
      "step": 34350
    },
    {
      "epoch": 10.377643504531722,
      "eval_loss": 1.442542552947998,
      "eval_runtime": 1531.2998,
      "eval_samples_per_second": 34.676,
      "eval_steps_per_second": 0.271,
      "step": 34350
    },
    {
      "epoch": 10.392749244712991,
      "grad_norm": 0.8576580286026001,
      "learning_rate": 5.9738368580060424e-05,
      "loss": 1.4167,
      "step": 34400
    },
    {
      "epoch": 10.392749244712991,
      "eval_loss": 1.4444007873535156,
      "eval_runtime": 1541.3027,
      "eval_samples_per_second": 34.451,
      "eval_steps_per_second": 0.269,
      "step": 34400
    },
    {
      "epoch": 10.407854984894259,
      "grad_norm": 0.6244673132896423,
      "learning_rate": 5.972829808660624e-05,
      "loss": 1.416,
      "step": 34450
    },
    {
      "epoch": 10.407854984894259,
      "eval_loss": 1.4442453384399414,
      "eval_runtime": 1534.031,
      "eval_samples_per_second": 34.614,
      "eval_steps_per_second": 0.271,
      "step": 34450
    },
    {
      "epoch": 10.422960725075528,
      "grad_norm": 0.7148112058639526,
      "learning_rate": 5.971822759315206e-05,
      "loss": 1.4251,
      "step": 34500
    },
    {
      "epoch": 10.422960725075528,
      "eval_loss": 1.4452377557754517,
      "eval_runtime": 1556.7398,
      "eval_samples_per_second": 34.109,
      "eval_steps_per_second": 0.267,
      "step": 34500
    },
    {
      "epoch": 10.438066465256798,
      "grad_norm": 0.5658715963363647,
      "learning_rate": 5.9708157099697886e-05,
      "loss": 1.4057,
      "step": 34550
    },
    {
      "epoch": 10.438066465256798,
      "eval_loss": 1.4416300058364868,
      "eval_runtime": 1467.8138,
      "eval_samples_per_second": 36.176,
      "eval_steps_per_second": 0.283,
      "step": 34550
    },
    {
      "epoch": 10.453172205438067,
      "grad_norm": 0.8588746190071106,
      "learning_rate": 5.9698086606243705e-05,
      "loss": 1.4131,
      "step": 34600
    },
    {
      "epoch": 10.453172205438067,
      "eval_loss": 1.4424678087234497,
      "eval_runtime": 1743.4321,
      "eval_samples_per_second": 30.457,
      "eval_steps_per_second": 0.238,
      "step": 34600
    },
    {
      "epoch": 10.468277945619334,
      "grad_norm": 0.6804941892623901,
      "learning_rate": 5.9688016112789524e-05,
      "loss": 1.4499,
      "step": 34650
    },
    {
      "epoch": 10.468277945619334,
      "eval_loss": 1.4430174827575684,
      "eval_runtime": 1542.9542,
      "eval_samples_per_second": 34.414,
      "eval_steps_per_second": 0.269,
      "step": 34650
    },
    {
      "epoch": 10.483383685800604,
      "grad_norm": 0.7424218654632568,
      "learning_rate": 5.967794561933534e-05,
      "loss": 1.4227,
      "step": 34700
    },
    {
      "epoch": 10.483383685800604,
      "eval_loss": 1.4413704872131348,
      "eval_runtime": 4135.4505,
      "eval_samples_per_second": 12.84,
      "eval_steps_per_second": 0.1,
      "step": 34700
    },
    {
      "epoch": 10.498489425981873,
      "grad_norm": 0.6817479133605957,
      "learning_rate": 5.9667875125881175e-05,
      "loss": 1.4193,
      "step": 34750
    },
    {
      "epoch": 10.498489425981873,
      "eval_loss": 1.4436678886413574,
      "eval_runtime": 1495.8183,
      "eval_samples_per_second": 35.498,
      "eval_steps_per_second": 0.277,
      "step": 34750
    },
    {
      "epoch": 10.513595166163142,
      "grad_norm": 0.677594006061554,
      "learning_rate": 5.965780463242699e-05,
      "loss": 1.4127,
      "step": 34800
    },
    {
      "epoch": 10.513595166163142,
      "eval_loss": 1.4439822435379028,
      "eval_runtime": 1538.7702,
      "eval_samples_per_second": 34.507,
      "eval_steps_per_second": 0.27,
      "step": 34800
    },
    {
      "epoch": 10.528700906344412,
      "grad_norm": 0.6034581661224365,
      "learning_rate": 5.964773413897281e-05,
      "loss": 1.3965,
      "step": 34850
    },
    {
      "epoch": 10.528700906344412,
      "eval_loss": 1.4424980878829956,
      "eval_runtime": 1472.9975,
      "eval_samples_per_second": 36.048,
      "eval_steps_per_second": 0.282,
      "step": 34850
    },
    {
      "epoch": 10.54380664652568,
      "grad_norm": 0.697401762008667,
      "learning_rate": 5.963766364551864e-05,
      "loss": 1.422,
      "step": 34900
    },
    {
      "epoch": 10.54380664652568,
      "eval_loss": 1.4424160718917847,
      "eval_runtime": 1552.9538,
      "eval_samples_per_second": 34.192,
      "eval_steps_per_second": 0.267,
      "step": 34900
    },
    {
      "epoch": 10.558912386706949,
      "grad_norm": 0.650966465473175,
      "learning_rate": 5.9627593152064456e-05,
      "loss": 1.4228,
      "step": 34950
    },
    {
      "epoch": 10.558912386706949,
      "eval_loss": 1.4421055316925049,
      "eval_runtime": 1567.9029,
      "eval_samples_per_second": 33.866,
      "eval_steps_per_second": 0.265,
      "step": 34950
    },
    {
      "epoch": 10.574018126888218,
      "grad_norm": 0.6832713484764099,
      "learning_rate": 5.9617522658610275e-05,
      "loss": 1.4098,
      "step": 35000
    },
    {
      "epoch": 10.574018126888218,
      "eval_loss": 1.4419597387313843,
      "eval_runtime": 1573.1305,
      "eval_samples_per_second": 33.754,
      "eval_steps_per_second": 0.264,
      "step": 35000
    },
    {
      "epoch": 10.589123867069487,
      "grad_norm": 0.7233859896659851,
      "learning_rate": 5.9607452165156094e-05,
      "loss": 1.4195,
      "step": 35050
    },
    {
      "epoch": 10.589123867069487,
      "eval_loss": 1.4390064477920532,
      "eval_runtime": 1460.7799,
      "eval_samples_per_second": 36.35,
      "eval_steps_per_second": 0.284,
      "step": 35050
    },
    {
      "epoch": 10.604229607250755,
      "grad_norm": 0.6500203013420105,
      "learning_rate": 5.959738167170192e-05,
      "loss": 1.4406,
      "step": 35100
    },
    {
      "epoch": 10.604229607250755,
      "eval_loss": 1.4403924942016602,
      "eval_runtime": 1483.6774,
      "eval_samples_per_second": 35.789,
      "eval_steps_per_second": 0.28,
      "step": 35100
    },
    {
      "epoch": 10.619335347432024,
      "grad_norm": 0.6370648741722107,
      "learning_rate": 5.958731117824774e-05,
      "loss": 1.4132,
      "step": 35150
    },
    {
      "epoch": 10.619335347432024,
      "eval_loss": 1.4394190311431885,
      "eval_runtime": 1570.9753,
      "eval_samples_per_second": 33.8,
      "eval_steps_per_second": 0.264,
      "step": 35150
    },
    {
      "epoch": 10.634441087613293,
      "grad_norm": 0.7115036845207214,
      "learning_rate": 5.9577240684793556e-05,
      "loss": 1.3835,
      "step": 35200
    },
    {
      "epoch": 10.634441087613293,
      "eval_loss": 1.4415149688720703,
      "eval_runtime": 1489.486,
      "eval_samples_per_second": 35.649,
      "eval_steps_per_second": 0.279,
      "step": 35200
    },
    {
      "epoch": 10.649546827794563,
      "grad_norm": 0.6386028528213501,
      "learning_rate": 5.9567170191339375e-05,
      "loss": 1.4235,
      "step": 35250
    },
    {
      "epoch": 10.649546827794563,
      "eval_loss": 1.4411128759384155,
      "eval_runtime": 1486.4396,
      "eval_samples_per_second": 35.722,
      "eval_steps_per_second": 0.279,
      "step": 35250
    },
    {
      "epoch": 10.66465256797583,
      "grad_norm": 0.6242349743843079,
      "learning_rate": 5.95570996978852e-05,
      "loss": 1.4098,
      "step": 35300
    },
    {
      "epoch": 10.66465256797583,
      "eval_loss": 1.4376200437545776,
      "eval_runtime": 1548.7523,
      "eval_samples_per_second": 34.285,
      "eval_steps_per_second": 0.268,
      "step": 35300
    },
    {
      "epoch": 10.6797583081571,
      "grad_norm": 0.6177744269371033,
      "learning_rate": 5.954702920443102e-05,
      "loss": 1.4046,
      "step": 35350
    },
    {
      "epoch": 10.6797583081571,
      "eval_loss": 1.440769910812378,
      "eval_runtime": 1556.0738,
      "eval_samples_per_second": 34.124,
      "eval_steps_per_second": 0.267,
      "step": 35350
    },
    {
      "epoch": 10.694864048338369,
      "grad_norm": 0.6279183626174927,
      "learning_rate": 5.953695871097684e-05,
      "loss": 1.4259,
      "step": 35400
    },
    {
      "epoch": 10.694864048338369,
      "eval_loss": 1.438241958618164,
      "eval_runtime": 1517.505,
      "eval_samples_per_second": 34.991,
      "eval_steps_per_second": 0.273,
      "step": 35400
    },
    {
      "epoch": 10.709969788519638,
      "grad_norm": 0.5878473520278931,
      "learning_rate": 5.9526888217522657e-05,
      "loss": 1.403,
      "step": 35450
    },
    {
      "epoch": 10.709969788519638,
      "eval_loss": 1.4382432699203491,
      "eval_runtime": 1548.0765,
      "eval_samples_per_second": 34.3,
      "eval_steps_per_second": 0.268,
      "step": 35450
    },
    {
      "epoch": 10.725075528700906,
      "grad_norm": 0.6196269392967224,
      "learning_rate": 5.951681772406848e-05,
      "loss": 1.4354,
      "step": 35500
    },
    {
      "epoch": 10.725075528700906,
      "eval_loss": 1.440253496170044,
      "eval_runtime": 1492.861,
      "eval_samples_per_second": 35.569,
      "eval_steps_per_second": 0.278,
      "step": 35500
    },
    {
      "epoch": 10.740181268882175,
      "grad_norm": 0.5679284334182739,
      "learning_rate": 5.95067472306143e-05,
      "loss": 1.4464,
      "step": 35550
    },
    {
      "epoch": 10.740181268882175,
      "eval_loss": 1.4380199909210205,
      "eval_runtime": 1738.4297,
      "eval_samples_per_second": 30.544,
      "eval_steps_per_second": 0.239,
      "step": 35550
    },
    {
      "epoch": 10.755287009063444,
      "grad_norm": 0.6829946637153625,
      "learning_rate": 5.949667673716012e-05,
      "loss": 1.4287,
      "step": 35600
    },
    {
      "epoch": 10.755287009063444,
      "eval_loss": 1.436097502708435,
      "eval_runtime": 1524.291,
      "eval_samples_per_second": 34.835,
      "eval_steps_per_second": 0.272,
      "step": 35600
    },
    {
      "epoch": 10.770392749244714,
      "grad_norm": 0.653497576713562,
      "learning_rate": 5.948660624370594e-05,
      "loss": 1.4211,
      "step": 35650
    },
    {
      "epoch": 10.770392749244714,
      "eval_loss": 1.4390486478805542,
      "eval_runtime": 1490.2723,
      "eval_samples_per_second": 35.63,
      "eval_steps_per_second": 0.278,
      "step": 35650
    },
    {
      "epoch": 10.785498489425981,
      "grad_norm": 0.7199761867523193,
      "learning_rate": 5.9476535750251764e-05,
      "loss": 1.3952,
      "step": 35700
    },
    {
      "epoch": 10.785498489425981,
      "eval_loss": 1.4338480234146118,
      "eval_runtime": 1551.7383,
      "eval_samples_per_second": 34.219,
      "eval_steps_per_second": 0.267,
      "step": 35700
    },
    {
      "epoch": 10.80060422960725,
      "grad_norm": 0.7033522725105286,
      "learning_rate": 5.946646525679758e-05,
      "loss": 1.4031,
      "step": 35750
    },
    {
      "epoch": 10.80060422960725,
      "eval_loss": 1.4363288879394531,
      "eval_runtime": 1518.534,
      "eval_samples_per_second": 34.967,
      "eval_steps_per_second": 0.273,
      "step": 35750
    },
    {
      "epoch": 10.81570996978852,
      "grad_norm": 0.6711744666099548,
      "learning_rate": 5.94563947633434e-05,
      "loss": 1.4222,
      "step": 35800
    },
    {
      "epoch": 10.81570996978852,
      "eval_loss": 1.4376786947250366,
      "eval_runtime": 1482.4212,
      "eval_samples_per_second": 35.819,
      "eval_steps_per_second": 0.28,
      "step": 35800
    },
    {
      "epoch": 10.830815709969789,
      "grad_norm": 0.6135793328285217,
      "learning_rate": 5.944632426988922e-05,
      "loss": 1.4193,
      "step": 35850
    },
    {
      "epoch": 10.830815709969789,
      "eval_loss": 1.4358859062194824,
      "eval_runtime": 1513.1587,
      "eval_samples_per_second": 35.091,
      "eval_steps_per_second": 0.274,
      "step": 35850
    },
    {
      "epoch": 10.845921450151057,
      "grad_norm": 0.6200144290924072,
      "learning_rate": 5.943625377643505e-05,
      "loss": 1.4204,
      "step": 35900
    },
    {
      "epoch": 10.845921450151057,
      "eval_loss": 1.4364773035049438,
      "eval_runtime": 1530.5224,
      "eval_samples_per_second": 34.693,
      "eval_steps_per_second": 0.271,
      "step": 35900
    },
    {
      "epoch": 10.861027190332326,
      "grad_norm": 0.7276514768600464,
      "learning_rate": 5.942618328298087e-05,
      "loss": 1.3963,
      "step": 35950
    },
    {
      "epoch": 10.861027190332326,
      "eval_loss": 1.437056303024292,
      "eval_runtime": 1519.9405,
      "eval_samples_per_second": 34.935,
      "eval_steps_per_second": 0.273,
      "step": 35950
    },
    {
      "epoch": 10.876132930513595,
      "grad_norm": 0.6898419857025146,
      "learning_rate": 5.941611278952669e-05,
      "loss": 1.4077,
      "step": 36000
    },
    {
      "epoch": 10.876132930513595,
      "eval_loss": 1.4355041980743408,
      "eval_runtime": 1550.0264,
      "eval_samples_per_second": 34.257,
      "eval_steps_per_second": 0.268,
      "step": 36000
    },
    {
      "epoch": 10.891238670694865,
      "grad_norm": 0.6379905939102173,
      "learning_rate": 5.9406042296072515e-05,
      "loss": 1.3882,
      "step": 36050
    },
    {
      "epoch": 10.891238670694865,
      "eval_loss": 1.4363665580749512,
      "eval_runtime": 1472.716,
      "eval_samples_per_second": 36.055,
      "eval_steps_per_second": 0.282,
      "step": 36050
    },
    {
      "epoch": 10.906344410876134,
      "grad_norm": 0.6423574090003967,
      "learning_rate": 5.939597180261833e-05,
      "loss": 1.4226,
      "step": 36100
    },
    {
      "epoch": 10.906344410876134,
      "eval_loss": 1.4344619512557983,
      "eval_runtime": 1726.9537,
      "eval_samples_per_second": 30.747,
      "eval_steps_per_second": 0.24,
      "step": 36100
    },
    {
      "epoch": 10.921450151057401,
      "grad_norm": 0.5931873917579651,
      "learning_rate": 5.938590130916415e-05,
      "loss": 1.4208,
      "step": 36150
    },
    {
      "epoch": 10.921450151057401,
      "eval_loss": 1.4347280263900757,
      "eval_runtime": 1573.6214,
      "eval_samples_per_second": 33.743,
      "eval_steps_per_second": 0.264,
      "step": 36150
    },
    {
      "epoch": 10.93655589123867,
      "grad_norm": 0.5997322797775269,
      "learning_rate": 5.937583081570997e-05,
      "loss": 1.4273,
      "step": 36200
    },
    {
      "epoch": 10.93655589123867,
      "eval_loss": 1.4339802265167236,
      "eval_runtime": 1842.7635,
      "eval_samples_per_second": 28.815,
      "eval_steps_per_second": 0.225,
      "step": 36200
    },
    {
      "epoch": 10.95166163141994,
      "grad_norm": 0.7370365858078003,
      "learning_rate": 5.9365760322255796e-05,
      "loss": 1.4331,
      "step": 36250
    },
    {
      "epoch": 10.95166163141994,
      "eval_loss": 1.4352607727050781,
      "eval_runtime": 1788.1343,
      "eval_samples_per_second": 29.695,
      "eval_steps_per_second": 0.232,
      "step": 36250
    },
    {
      "epoch": 10.96676737160121,
      "grad_norm": 0.6606411933898926,
      "learning_rate": 5.9355689828801615e-05,
      "loss": 1.4251,
      "step": 36300
    },
    {
      "epoch": 10.96676737160121,
      "eval_loss": 1.4344167709350586,
      "eval_runtime": 1617.6319,
      "eval_samples_per_second": 32.825,
      "eval_steps_per_second": 0.257,
      "step": 36300
    },
    {
      "epoch": 10.981873111782477,
      "grad_norm": 0.6826127767562866,
      "learning_rate": 5.9345619335347434e-05,
      "loss": 1.4299,
      "step": 36350
    },
    {
      "epoch": 10.981873111782477,
      "eval_loss": 1.434647560119629,
      "eval_runtime": 1504.5497,
      "eval_samples_per_second": 35.292,
      "eval_steps_per_second": 0.276,
      "step": 36350
    },
    {
      "epoch": 10.996978851963746,
      "grad_norm": 0.5648223161697388,
      "learning_rate": 5.933554884189325e-05,
      "loss": 1.4178,
      "step": 36400
    },
    {
      "epoch": 10.996978851963746,
      "eval_loss": 1.4315016269683838,
      "eval_runtime": 1765.1761,
      "eval_samples_per_second": 30.081,
      "eval_steps_per_second": 0.235,
      "step": 36400
    },
    {
      "epoch": 11.012084592145015,
      "grad_norm": 0.7212138175964355,
      "learning_rate": 5.932547834843908e-05,
      "loss": 1.4102,
      "step": 36450
    },
    {
      "epoch": 11.012084592145015,
      "eval_loss": 1.4325562715530396,
      "eval_runtime": 1533.4529,
      "eval_samples_per_second": 34.627,
      "eval_steps_per_second": 0.271,
      "step": 36450
    },
    {
      "epoch": 11.027190332326285,
      "grad_norm": 0.6288532018661499,
      "learning_rate": 5.9315407854984896e-05,
      "loss": 1.4069,
      "step": 36500
    },
    {
      "epoch": 11.027190332326285,
      "eval_loss": 1.4335874319076538,
      "eval_runtime": 1948.6628,
      "eval_samples_per_second": 27.249,
      "eval_steps_per_second": 0.213,
      "step": 36500
    },
    {
      "epoch": 11.042296072507552,
      "grad_norm": 0.6901642084121704,
      "learning_rate": 5.9305337361530715e-05,
      "loss": 1.4064,
      "step": 36550
    },
    {
      "epoch": 11.042296072507552,
      "eval_loss": 1.4347350597381592,
      "eval_runtime": 1574.8341,
      "eval_samples_per_second": 33.717,
      "eval_steps_per_second": 0.264,
      "step": 36550
    },
    {
      "epoch": 11.057401812688822,
      "grad_norm": 0.5867125391960144,
      "learning_rate": 5.9295266868076534e-05,
      "loss": 1.3911,
      "step": 36600
    },
    {
      "epoch": 11.057401812688822,
      "eval_loss": 1.4311704635620117,
      "eval_runtime": 1464.6093,
      "eval_samples_per_second": 36.255,
      "eval_steps_per_second": 0.283,
      "step": 36600
    },
    {
      "epoch": 11.072507552870091,
      "grad_norm": 0.7160723209381104,
      "learning_rate": 5.928519637462236e-05,
      "loss": 1.4082,
      "step": 36650
    },
    {
      "epoch": 11.072507552870091,
      "eval_loss": 1.433308720588684,
      "eval_runtime": 2296.0115,
      "eval_samples_per_second": 23.127,
      "eval_steps_per_second": 0.181,
      "step": 36650
    },
    {
      "epoch": 11.08761329305136,
      "grad_norm": 0.6776326298713684,
      "learning_rate": 5.927512588116818e-05,
      "loss": 1.3752,
      "step": 36700
    },
    {
      "epoch": 11.08761329305136,
      "eval_loss": 1.4330222606658936,
      "eval_runtime": 1499.2123,
      "eval_samples_per_second": 35.418,
      "eval_steps_per_second": 0.277,
      "step": 36700
    },
    {
      "epoch": 11.102719033232628,
      "grad_norm": 0.6102674603462219,
      "learning_rate": 5.9265055387714e-05,
      "loss": 1.3923,
      "step": 36750
    },
    {
      "epoch": 11.102719033232628,
      "eval_loss": 1.4299201965332031,
      "eval_runtime": 1635.7192,
      "eval_samples_per_second": 32.462,
      "eval_steps_per_second": 0.254,
      "step": 36750
    },
    {
      "epoch": 11.117824773413897,
      "grad_norm": 0.5999743342399597,
      "learning_rate": 5.9254984894259815e-05,
      "loss": 1.3922,
      "step": 36800
    },
    {
      "epoch": 11.117824773413897,
      "eval_loss": 1.4320158958435059,
      "eval_runtime": 1498.0457,
      "eval_samples_per_second": 35.446,
      "eval_steps_per_second": 0.277,
      "step": 36800
    },
    {
      "epoch": 11.132930513595166,
      "grad_norm": 0.5791910290718079,
      "learning_rate": 5.924491440080564e-05,
      "loss": 1.4181,
      "step": 36850
    },
    {
      "epoch": 11.132930513595166,
      "eval_loss": 1.433193325996399,
      "eval_runtime": 2097.8622,
      "eval_samples_per_second": 25.311,
      "eval_steps_per_second": 0.198,
      "step": 36850
    },
    {
      "epoch": 11.148036253776436,
      "grad_norm": 0.7447454333305359,
      "learning_rate": 5.923484390735146e-05,
      "loss": 1.373,
      "step": 36900
    },
    {
      "epoch": 11.148036253776436,
      "eval_loss": 1.431430697441101,
      "eval_runtime": 1576.3271,
      "eval_samples_per_second": 33.685,
      "eval_steps_per_second": 0.263,
      "step": 36900
    },
    {
      "epoch": 11.163141993957703,
      "grad_norm": 0.8091233968734741,
      "learning_rate": 5.922477341389728e-05,
      "loss": 1.3964,
      "step": 36950
    },
    {
      "epoch": 11.163141993957703,
      "eval_loss": 1.43152916431427,
      "eval_runtime": 1731.4602,
      "eval_samples_per_second": 30.667,
      "eval_steps_per_second": 0.24,
      "step": 36950
    },
    {
      "epoch": 11.178247734138973,
      "grad_norm": 0.6816017627716064,
      "learning_rate": 5.92147029204431e-05,
      "loss": 1.4276,
      "step": 37000
    },
    {
      "epoch": 11.178247734138973,
      "eval_loss": 1.430628776550293,
      "eval_runtime": 1561.7767,
      "eval_samples_per_second": 33.999,
      "eval_steps_per_second": 0.266,
      "step": 37000
    },
    {
      "epoch": 11.193353474320242,
      "grad_norm": 0.6734932065010071,
      "learning_rate": 5.920463242698893e-05,
      "loss": 1.4221,
      "step": 37050
    },
    {
      "epoch": 11.193353474320242,
      "eval_loss": 1.4307315349578857,
      "eval_runtime": 1536.6632,
      "eval_samples_per_second": 34.555,
      "eval_steps_per_second": 0.27,
      "step": 37050
    },
    {
      "epoch": 11.208459214501511,
      "grad_norm": 0.5947619676589966,
      "learning_rate": 5.919456193353475e-05,
      "loss": 1.4062,
      "step": 37100
    },
    {
      "epoch": 11.208459214501511,
      "eval_loss": 1.4301533699035645,
      "eval_runtime": 1535.3705,
      "eval_samples_per_second": 34.584,
      "eval_steps_per_second": 0.27,
      "step": 37100
    },
    {
      "epoch": 11.223564954682779,
      "grad_norm": 0.6584747433662415,
      "learning_rate": 5.9184491440080566e-05,
      "loss": 1.4141,
      "step": 37150
    },
    {
      "epoch": 11.223564954682779,
      "eval_loss": 1.430139183998108,
      "eval_runtime": 1558.6121,
      "eval_samples_per_second": 34.068,
      "eval_steps_per_second": 0.266,
      "step": 37150
    },
    {
      "epoch": 11.238670694864048,
      "grad_norm": 0.6123700141906738,
      "learning_rate": 5.917442094662639e-05,
      "loss": 1.4052,
      "step": 37200
    },
    {
      "epoch": 11.238670694864048,
      "eval_loss": 1.4324074983596802,
      "eval_runtime": 1556.1101,
      "eval_samples_per_second": 34.123,
      "eval_steps_per_second": 0.267,
      "step": 37200
    },
    {
      "epoch": 11.253776435045317,
      "grad_norm": 0.6449901461601257,
      "learning_rate": 5.916435045317221e-05,
      "loss": 1.3987,
      "step": 37250
    },
    {
      "epoch": 11.253776435045317,
      "eval_loss": 1.4297739267349243,
      "eval_runtime": 1581.7577,
      "eval_samples_per_second": 33.57,
      "eval_steps_per_second": 0.262,
      "step": 37250
    },
    {
      "epoch": 11.268882175226587,
      "grad_norm": 0.5793278217315674,
      "learning_rate": 5.915427995971803e-05,
      "loss": 1.4058,
      "step": 37300
    },
    {
      "epoch": 11.268882175226587,
      "eval_loss": 1.428293228149414,
      "eval_runtime": 1562.7071,
      "eval_samples_per_second": 33.979,
      "eval_steps_per_second": 0.266,
      "step": 37300
    },
    {
      "epoch": 11.283987915407854,
      "grad_norm": 0.6922917366027832,
      "learning_rate": 5.914420946626385e-05,
      "loss": 1.4241,
      "step": 37350
    },
    {
      "epoch": 11.283987915407854,
      "eval_loss": 1.4299594163894653,
      "eval_runtime": 1559.0067,
      "eval_samples_per_second": 34.06,
      "eval_steps_per_second": 0.266,
      "step": 37350
    },
    {
      "epoch": 11.299093655589123,
      "grad_norm": 0.6420424580574036,
      "learning_rate": 5.9134138972809673e-05,
      "loss": 1.4268,
      "step": 37400
    },
    {
      "epoch": 11.299093655589123,
      "eval_loss": 1.4310152530670166,
      "eval_runtime": 1491.3773,
      "eval_samples_per_second": 35.604,
      "eval_steps_per_second": 0.278,
      "step": 37400
    },
    {
      "epoch": 11.314199395770393,
      "grad_norm": 0.6523287892341614,
      "learning_rate": 5.912406847935549e-05,
      "loss": 1.4111,
      "step": 37450
    },
    {
      "epoch": 11.314199395770393,
      "eval_loss": 1.4276484251022339,
      "eval_runtime": 1827.046,
      "eval_samples_per_second": 29.063,
      "eval_steps_per_second": 0.227,
      "step": 37450
    },
    {
      "epoch": 11.329305135951662,
      "grad_norm": 0.7355954051017761,
      "learning_rate": 5.911399798590131e-05,
      "loss": 1.3954,
      "step": 37500
    },
    {
      "epoch": 11.329305135951662,
      "eval_loss": 1.4281679391860962,
      "eval_runtime": 1583.5736,
      "eval_samples_per_second": 33.531,
      "eval_steps_per_second": 0.262,
      "step": 37500
    },
    {
      "epoch": 11.34441087613293,
      "grad_norm": 0.6585510969161987,
      "learning_rate": 5.910392749244713e-05,
      "loss": 1.4134,
      "step": 37550
    },
    {
      "epoch": 11.34441087613293,
      "eval_loss": 1.4297126531600952,
      "eval_runtime": 1551.9082,
      "eval_samples_per_second": 34.215,
      "eval_steps_per_second": 0.267,
      "step": 37550
    },
    {
      "epoch": 11.359516616314199,
      "grad_norm": 0.6973240971565247,
      "learning_rate": 5.9093856998992955e-05,
      "loss": 1.3985,
      "step": 37600
    },
    {
      "epoch": 11.359516616314199,
      "eval_loss": 1.4292017221450806,
      "eval_runtime": 1461.1814,
      "eval_samples_per_second": 36.34,
      "eval_steps_per_second": 0.284,
      "step": 37600
    },
    {
      "epoch": 11.374622356495468,
      "grad_norm": 0.6128041744232178,
      "learning_rate": 5.9083786505538774e-05,
      "loss": 1.4163,
      "step": 37650
    },
    {
      "epoch": 11.374622356495468,
      "eval_loss": 1.4284332990646362,
      "eval_runtime": 2333.2944,
      "eval_samples_per_second": 22.757,
      "eval_steps_per_second": 0.178,
      "step": 37650
    },
    {
      "epoch": 11.389728096676738,
      "grad_norm": 0.7130358219146729,
      "learning_rate": 5.907371601208459e-05,
      "loss": 1.4167,
      "step": 37700
    },
    {
      "epoch": 11.389728096676738,
      "eval_loss": 1.427838921546936,
      "eval_runtime": 1829.5623,
      "eval_samples_per_second": 29.023,
      "eval_steps_per_second": 0.227,
      "step": 37700
    },
    {
      "epoch": 11.404833836858007,
      "grad_norm": 0.5544151663780212,
      "learning_rate": 5.906364551863041e-05,
      "loss": 1.4011,
      "step": 37750
    },
    {
      "epoch": 11.404833836858007,
      "eval_loss": 1.4271537065505981,
      "eval_runtime": 1547.472,
      "eval_samples_per_second": 34.313,
      "eval_steps_per_second": 0.268,
      "step": 37750
    },
    {
      "epoch": 11.419939577039274,
      "grad_norm": 0.7047745585441589,
      "learning_rate": 5.9053575025176236e-05,
      "loss": 1.3793,
      "step": 37800
    },
    {
      "epoch": 11.419939577039274,
      "eval_loss": 1.4259324073791504,
      "eval_runtime": 1569.0529,
      "eval_samples_per_second": 33.841,
      "eval_steps_per_second": 0.264,
      "step": 37800
    },
    {
      "epoch": 11.435045317220544,
      "grad_norm": 0.6341607570648193,
      "learning_rate": 5.9043504531722055e-05,
      "loss": 1.3757,
      "step": 37850
    },
    {
      "epoch": 11.435045317220544,
      "eval_loss": 1.4258112907409668,
      "eval_runtime": 1556.5179,
      "eval_samples_per_second": 34.114,
      "eval_steps_per_second": 0.267,
      "step": 37850
    },
    {
      "epoch": 11.450151057401813,
      "grad_norm": 0.5790184140205383,
      "learning_rate": 5.9033434038267874e-05,
      "loss": 1.4013,
      "step": 37900
    },
    {
      "epoch": 11.450151057401813,
      "eval_loss": 1.424929141998291,
      "eval_runtime": 1503.9141,
      "eval_samples_per_second": 35.307,
      "eval_steps_per_second": 0.276,
      "step": 37900
    },
    {
      "epoch": 11.465256797583082,
      "grad_norm": 0.5754591822624207,
      "learning_rate": 5.902336354481369e-05,
      "loss": 1.4136,
      "step": 37950
    },
    {
      "epoch": 11.465256797583082,
      "eval_loss": 1.4285242557525635,
      "eval_runtime": 1563.9069,
      "eval_samples_per_second": 33.953,
      "eval_steps_per_second": 0.265,
      "step": 37950
    },
    {
      "epoch": 11.48036253776435,
      "grad_norm": 0.6368171572685242,
      "learning_rate": 5.901329305135952e-05,
      "loss": 1.4148,
      "step": 38000
    },
    {
      "epoch": 11.48036253776435,
      "eval_loss": 1.4251558780670166,
      "eval_runtime": 1566.7511,
      "eval_samples_per_second": 33.891,
      "eval_steps_per_second": 0.265,
      "step": 38000
    },
    {
      "epoch": 11.49546827794562,
      "grad_norm": 0.6124312877655029,
      "learning_rate": 5.900322255790534e-05,
      "loss": 1.3938,
      "step": 38050
    },
    {
      "epoch": 11.49546827794562,
      "eval_loss": 1.4241447448730469,
      "eval_runtime": 2542.8056,
      "eval_samples_per_second": 20.882,
      "eval_steps_per_second": 0.163,
      "step": 38050
    },
    {
      "epoch": 11.510574018126889,
      "grad_norm": 0.7248244881629944,
      "learning_rate": 5.8993152064451155e-05,
      "loss": 1.4157,
      "step": 38100
    },
    {
      "epoch": 11.510574018126889,
      "eval_loss": 1.4257938861846924,
      "eval_runtime": 1474.8911,
      "eval_samples_per_second": 36.002,
      "eval_steps_per_second": 0.281,
      "step": 38100
    },
    {
      "epoch": 11.525679758308158,
      "grad_norm": 0.6285499334335327,
      "learning_rate": 5.8983081570996974e-05,
      "loss": 1.3943,
      "step": 38150
    },
    {
      "epoch": 11.525679758308158,
      "eval_loss": 1.4255332946777344,
      "eval_runtime": 2802.345,
      "eval_samples_per_second": 18.948,
      "eval_steps_per_second": 0.148,
      "step": 38150
    },
    {
      "epoch": 11.540785498489425,
      "grad_norm": 0.5848469138145447,
      "learning_rate": 5.8973011077542806e-05,
      "loss": 1.4011,
      "step": 38200
    },
    {
      "epoch": 11.540785498489425,
      "eval_loss": 1.424750804901123,
      "eval_runtime": 1514.1277,
      "eval_samples_per_second": 35.069,
      "eval_steps_per_second": 0.274,
      "step": 38200
    },
    {
      "epoch": 11.555891238670695,
      "grad_norm": 0.5945606231689453,
      "learning_rate": 5.8962940584088625e-05,
      "loss": 1.39,
      "step": 38250
    },
    {
      "epoch": 11.555891238670695,
      "eval_loss": 1.427911400794983,
      "eval_runtime": 1506.297,
      "eval_samples_per_second": 35.251,
      "eval_steps_per_second": 0.276,
      "step": 38250
    },
    {
      "epoch": 11.570996978851964,
      "grad_norm": 0.5974770188331604,
      "learning_rate": 5.8952870090634444e-05,
      "loss": 1.3986,
      "step": 38300
    },
    {
      "epoch": 11.570996978851964,
      "eval_loss": 1.424296259880066,
      "eval_runtime": 1530.0397,
      "eval_samples_per_second": 34.704,
      "eval_steps_per_second": 0.271,
      "step": 38300
    },
    {
      "epoch": 11.586102719033233,
      "grad_norm": 0.5957794189453125,
      "learning_rate": 5.894279959718027e-05,
      "loss": 1.4014,
      "step": 38350
    },
    {
      "epoch": 11.586102719033233,
      "eval_loss": 1.4239875078201294,
      "eval_runtime": 1499.0135,
      "eval_samples_per_second": 35.423,
      "eval_steps_per_second": 0.277,
      "step": 38350
    },
    {
      "epoch": 11.6012084592145,
      "grad_norm": 0.5853845477104187,
      "learning_rate": 5.893272910372609e-05,
      "loss": 1.409,
      "step": 38400
    },
    {
      "epoch": 11.6012084592145,
      "eval_loss": 1.4248214960098267,
      "eval_runtime": 1568.0241,
      "eval_samples_per_second": 33.864,
      "eval_steps_per_second": 0.265,
      "step": 38400
    },
    {
      "epoch": 11.61631419939577,
      "grad_norm": 0.6024747490882874,
      "learning_rate": 5.8922658610271906e-05,
      "loss": 1.4319,
      "step": 38450
    },
    {
      "epoch": 11.61631419939577,
      "eval_loss": 1.4225153923034668,
      "eval_runtime": 1583.2388,
      "eval_samples_per_second": 33.538,
      "eval_steps_per_second": 0.262,
      "step": 38450
    },
    {
      "epoch": 11.63141993957704,
      "grad_norm": 0.5748002529144287,
      "learning_rate": 5.8912588116817725e-05,
      "loss": 1.411,
      "step": 38500
    },
    {
      "epoch": 11.63141993957704,
      "eval_loss": 1.4207655191421509,
      "eval_runtime": 1569.109,
      "eval_samples_per_second": 33.84,
      "eval_steps_per_second": 0.264,
      "step": 38500
    },
    {
      "epoch": 11.646525679758309,
      "grad_norm": 0.6206114888191223,
      "learning_rate": 5.890251762336355e-05,
      "loss": 1.3774,
      "step": 38550
    },
    {
      "epoch": 11.646525679758309,
      "eval_loss": 1.4220525026321411,
      "eval_runtime": 1566.9534,
      "eval_samples_per_second": 33.887,
      "eval_steps_per_second": 0.265,
      "step": 38550
    },
    {
      "epoch": 11.661631419939576,
      "grad_norm": 0.6231189966201782,
      "learning_rate": 5.889244712990937e-05,
      "loss": 1.3923,
      "step": 38600
    },
    {
      "epoch": 11.661631419939576,
      "eval_loss": 1.4232549667358398,
      "eval_runtime": 1515.1194,
      "eval_samples_per_second": 35.046,
      "eval_steps_per_second": 0.274,
      "step": 38600
    },
    {
      "epoch": 11.676737160120846,
      "grad_norm": 0.5701180696487427,
      "learning_rate": 5.888237663645519e-05,
      "loss": 1.3969,
      "step": 38650
    },
    {
      "epoch": 11.676737160120846,
      "eval_loss": 1.4238725900650024,
      "eval_runtime": 1676.2488,
      "eval_samples_per_second": 31.677,
      "eval_steps_per_second": 0.248,
      "step": 38650
    },
    {
      "epoch": 11.691842900302115,
      "grad_norm": 0.7069476842880249,
      "learning_rate": 5.887230614300101e-05,
      "loss": 1.4204,
      "step": 38700
    },
    {
      "epoch": 11.691842900302115,
      "eval_loss": 1.423920750617981,
      "eval_runtime": 1465.1336,
      "eval_samples_per_second": 36.242,
      "eval_steps_per_second": 0.283,
      "step": 38700
    },
    {
      "epoch": 11.706948640483384,
      "grad_norm": 0.590505838394165,
      "learning_rate": 5.886223564954683e-05,
      "loss": 1.3929,
      "step": 38750
    },
    {
      "epoch": 11.706948640483384,
      "eval_loss": 1.4226351976394653,
      "eval_runtime": 1586.3555,
      "eval_samples_per_second": 33.472,
      "eval_steps_per_second": 0.262,
      "step": 38750
    },
    {
      "epoch": 11.722054380664652,
      "grad_norm": 0.5474848747253418,
      "learning_rate": 5.885216515609265e-05,
      "loss": 1.3871,
      "step": 38800
    },
    {
      "epoch": 11.722054380664652,
      "eval_loss": 1.4224580526351929,
      "eval_runtime": 1489.5532,
      "eval_samples_per_second": 35.648,
      "eval_steps_per_second": 0.279,
      "step": 38800
    },
    {
      "epoch": 11.737160120845921,
      "grad_norm": 0.5590918660163879,
      "learning_rate": 5.884209466263847e-05,
      "loss": 1.3819,
      "step": 38850
    },
    {
      "epoch": 11.737160120845921,
      "eval_loss": 1.4235756397247314,
      "eval_runtime": 2068.009,
      "eval_samples_per_second": 25.676,
      "eval_steps_per_second": 0.201,
      "step": 38850
    },
    {
      "epoch": 11.75226586102719,
      "grad_norm": 0.5463442206382751,
      "learning_rate": 5.883202416918429e-05,
      "loss": 1.4146,
      "step": 38900
    },
    {
      "epoch": 11.75226586102719,
      "eval_loss": 1.4234157800674438,
      "eval_runtime": 1506.3611,
      "eval_samples_per_second": 35.25,
      "eval_steps_per_second": 0.275,
      "step": 38900
    },
    {
      "epoch": 11.76737160120846,
      "grad_norm": 0.7695345282554626,
      "learning_rate": 5.8821953675730114e-05,
      "loss": 1.4066,
      "step": 38950
    },
    {
      "epoch": 11.76737160120846,
      "eval_loss": 1.421822190284729,
      "eval_runtime": 1583.7068,
      "eval_samples_per_second": 33.528,
      "eval_steps_per_second": 0.262,
      "step": 38950
    },
    {
      "epoch": 11.782477341389729,
      "grad_norm": 0.5875406861305237,
      "learning_rate": 5.881188318227593e-05,
      "loss": 1.375,
      "step": 39000
    },
    {
      "epoch": 11.782477341389729,
      "eval_loss": 1.421111822128296,
      "eval_runtime": 1600.1847,
      "eval_samples_per_second": 33.183,
      "eval_steps_per_second": 0.259,
      "step": 39000
    },
    {
      "epoch": 11.797583081570997,
      "grad_norm": 0.5461638569831848,
      "learning_rate": 5.880181268882175e-05,
      "loss": 1.3938,
      "step": 39050
    },
    {
      "epoch": 11.797583081570997,
      "eval_loss": 1.4197663068771362,
      "eval_runtime": 1643.8337,
      "eval_samples_per_second": 32.302,
      "eval_steps_per_second": 0.252,
      "step": 39050
    },
    {
      "epoch": 11.812688821752266,
      "grad_norm": 0.5637790560722351,
      "learning_rate": 5.879174219536757e-05,
      "loss": 1.3848,
      "step": 39100
    },
    {
      "epoch": 11.812688821752266,
      "eval_loss": 1.4212526082992554,
      "eval_runtime": 1941.3028,
      "eval_samples_per_second": 27.352,
      "eval_steps_per_second": 0.214,
      "step": 39100
    },
    {
      "epoch": 11.827794561933535,
      "grad_norm": 0.6674908399581909,
      "learning_rate": 5.8781671701913395e-05,
      "loss": 1.3945,
      "step": 39150
    },
    {
      "epoch": 11.827794561933535,
      "eval_loss": 1.4210492372512817,
      "eval_runtime": 1473.0703,
      "eval_samples_per_second": 36.046,
      "eval_steps_per_second": 0.282,
      "step": 39150
    },
    {
      "epoch": 11.842900302114803,
      "grad_norm": 0.5618642568588257,
      "learning_rate": 5.8771601208459214e-05,
      "loss": 1.4049,
      "step": 39200
    },
    {
      "epoch": 11.842900302114803,
      "eval_loss": 1.4208605289459229,
      "eval_runtime": 1515.7691,
      "eval_samples_per_second": 35.031,
      "eval_steps_per_second": 0.274,
      "step": 39200
    },
    {
      "epoch": 11.858006042296072,
      "grad_norm": 0.5572999715805054,
      "learning_rate": 5.876153071500503e-05,
      "loss": 1.424,
      "step": 39250
    },
    {
      "epoch": 11.858006042296072,
      "eval_loss": 1.4189438819885254,
      "eval_runtime": 1604.2951,
      "eval_samples_per_second": 33.098,
      "eval_steps_per_second": 0.259,
      "step": 39250
    },
    {
      "epoch": 11.873111782477341,
      "grad_norm": 0.7309428453445435,
      "learning_rate": 5.875146022155085e-05,
      "loss": 1.3928,
      "step": 39300
    },
    {
      "epoch": 11.873111782477341,
      "eval_loss": 1.4193010330200195,
      "eval_runtime": 1736.6241,
      "eval_samples_per_second": 30.576,
      "eval_steps_per_second": 0.239,
      "step": 39300
    },
    {
      "epoch": 11.88821752265861,
      "grad_norm": 0.567708432674408,
      "learning_rate": 5.874138972809668e-05,
      "loss": 1.4142,
      "step": 39350
    },
    {
      "epoch": 11.88821752265861,
      "eval_loss": 1.419278860092163,
      "eval_runtime": 1545.1284,
      "eval_samples_per_second": 34.365,
      "eval_steps_per_second": 0.269,
      "step": 39350
    },
    {
      "epoch": 11.90332326283988,
      "grad_norm": 0.5344290733337402,
      "learning_rate": 5.87313192346425e-05,
      "loss": 1.3932,
      "step": 39400
    },
    {
      "epoch": 11.90332326283988,
      "eval_loss": 1.4194756746292114,
      "eval_runtime": 1552.2223,
      "eval_samples_per_second": 34.208,
      "eval_steps_per_second": 0.267,
      "step": 39400
    },
    {
      "epoch": 11.918429003021147,
      "grad_norm": 0.6055581569671631,
      "learning_rate": 5.872124874118832e-05,
      "loss": 1.3936,
      "step": 39450
    },
    {
      "epoch": 11.918429003021147,
      "eval_loss": 1.4202263355255127,
      "eval_runtime": 1494.0999,
      "eval_samples_per_second": 35.539,
      "eval_steps_per_second": 0.278,
      "step": 39450
    },
    {
      "epoch": 11.933534743202417,
      "grad_norm": 0.5609191060066223,
      "learning_rate": 5.8711178247734146e-05,
      "loss": 1.3991,
      "step": 39500
    },
    {
      "epoch": 11.933534743202417,
      "eval_loss": 1.417534351348877,
      "eval_runtime": 1557.6766,
      "eval_samples_per_second": 34.089,
      "eval_steps_per_second": 0.266,
      "step": 39500
    },
    {
      "epoch": 11.948640483383686,
      "grad_norm": 0.6073447465896606,
      "learning_rate": 5.8701107754279965e-05,
      "loss": 1.3906,
      "step": 39550
    },
    {
      "epoch": 11.948640483383686,
      "eval_loss": 1.4196559190750122,
      "eval_runtime": 1535.634,
      "eval_samples_per_second": 34.578,
      "eval_steps_per_second": 0.27,
      "step": 39550
    },
    {
      "epoch": 11.963746223564955,
      "grad_norm": 0.6252195835113525,
      "learning_rate": 5.8691037260825784e-05,
      "loss": 1.4091,
      "step": 39600
    },
    {
      "epoch": 11.963746223564955,
      "eval_loss": 1.4199930429458618,
      "eval_runtime": 2015.5353,
      "eval_samples_per_second": 26.345,
      "eval_steps_per_second": 0.206,
      "step": 39600
    },
    {
      "epoch": 11.978851963746223,
      "grad_norm": 0.6520158052444458,
      "learning_rate": 5.86809667673716e-05,
      "loss": 1.3901,
      "step": 39650
    },
    {
      "epoch": 11.978851963746223,
      "eval_loss": 1.4189873933792114,
      "eval_runtime": 1494.3929,
      "eval_samples_per_second": 35.532,
      "eval_steps_per_second": 0.278,
      "step": 39650
    },
    {
      "epoch": 11.993957703927492,
      "grad_norm": 0.6668535470962524,
      "learning_rate": 5.867089627391743e-05,
      "loss": 1.4097,
      "step": 39700
    },
    {
      "epoch": 11.993957703927492,
      "eval_loss": 1.4180532693862915,
      "eval_runtime": 1490.6683,
      "eval_samples_per_second": 35.621,
      "eval_steps_per_second": 0.278,
      "step": 39700
    },
    {
      "epoch": 12.009063444108762,
      "grad_norm": 0.6501492857933044,
      "learning_rate": 5.8660825780463246e-05,
      "loss": 1.4026,
      "step": 39750
    },
    {
      "epoch": 12.009063444108762,
      "eval_loss": 1.4191502332687378,
      "eval_runtime": 1511.4647,
      "eval_samples_per_second": 35.131,
      "eval_steps_per_second": 0.275,
      "step": 39750
    },
    {
      "epoch": 12.024169184290031,
      "grad_norm": 0.6277230978012085,
      "learning_rate": 5.8650755287009065e-05,
      "loss": 1.3891,
      "step": 39800
    },
    {
      "epoch": 12.024169184290031,
      "eval_loss": 1.4190515279769897,
      "eval_runtime": 1561.1517,
      "eval_samples_per_second": 34.013,
      "eval_steps_per_second": 0.266,
      "step": 39800
    },
    {
      "epoch": 12.039274924471298,
      "grad_norm": 0.7104089260101318,
      "learning_rate": 5.8640684793554884e-05,
      "loss": 1.4153,
      "step": 39850
    },
    {
      "epoch": 12.039274924471298,
      "eval_loss": 1.4190963506698608,
      "eval_runtime": 1675.5687,
      "eval_samples_per_second": 31.69,
      "eval_steps_per_second": 0.248,
      "step": 39850
    },
    {
      "epoch": 12.054380664652568,
      "grad_norm": 0.6778342723846436,
      "learning_rate": 5.863061430010071e-05,
      "loss": 1.3974,
      "step": 39900
    },
    {
      "epoch": 12.054380664652568,
      "eval_loss": 1.4182074069976807,
      "eval_runtime": 1550.3376,
      "eval_samples_per_second": 34.25,
      "eval_steps_per_second": 0.268,
      "step": 39900
    },
    {
      "epoch": 12.069486404833837,
      "grad_norm": 0.6361221671104431,
      "learning_rate": 5.862054380664653e-05,
      "loss": 1.395,
      "step": 39950
    },
    {
      "epoch": 12.069486404833837,
      "eval_loss": 1.4208563566207886,
      "eval_runtime": 1527.8713,
      "eval_samples_per_second": 34.754,
      "eval_steps_per_second": 0.272,
      "step": 39950
    },
    {
      "epoch": 12.084592145015106,
      "grad_norm": 0.5633265972137451,
      "learning_rate": 5.861047331319235e-05,
      "loss": 1.4136,
      "step": 40000
    },
    {
      "epoch": 12.084592145015106,
      "eval_loss": 1.4159255027770996,
      "eval_runtime": 1575.303,
      "eval_samples_per_second": 33.707,
      "eval_steps_per_second": 0.263,
      "step": 40000
    },
    {
      "epoch": 12.099697885196374,
      "grad_norm": 0.769153356552124,
      "learning_rate": 5.8600402819738165e-05,
      "loss": 1.4118,
      "step": 40050
    },
    {
      "epoch": 12.099697885196374,
      "eval_loss": 1.4179378747940063,
      "eval_runtime": 1484.5285,
      "eval_samples_per_second": 35.768,
      "eval_steps_per_second": 0.28,
      "step": 40050
    },
    {
      "epoch": 12.114803625377643,
      "grad_norm": 0.6592693328857422,
      "learning_rate": 5.859033232628399e-05,
      "loss": 1.3834,
      "step": 40100
    },
    {
      "epoch": 12.114803625377643,
      "eval_loss": 1.4153480529785156,
      "eval_runtime": 1557.434,
      "eval_samples_per_second": 34.094,
      "eval_steps_per_second": 0.266,
      "step": 40100
    },
    {
      "epoch": 12.129909365558913,
      "grad_norm": 0.622835636138916,
      "learning_rate": 5.858026183282981e-05,
      "loss": 1.3901,
      "step": 40150
    },
    {
      "epoch": 12.129909365558913,
      "eval_loss": 1.418436050415039,
      "eval_runtime": 1564.0756,
      "eval_samples_per_second": 33.949,
      "eval_steps_per_second": 0.265,
      "step": 40150
    },
    {
      "epoch": 12.145015105740182,
      "grad_norm": 0.6000571846961975,
      "learning_rate": 5.857019133937563e-05,
      "loss": 1.393,
      "step": 40200
    },
    {
      "epoch": 12.145015105740182,
      "eval_loss": 1.4151568412780762,
      "eval_runtime": 1469.1635,
      "eval_samples_per_second": 36.142,
      "eval_steps_per_second": 0.282,
      "step": 40200
    },
    {
      "epoch": 12.16012084592145,
      "grad_norm": 0.4934051036834717,
      "learning_rate": 5.856012084592145e-05,
      "loss": 1.389,
      "step": 40250
    },
    {
      "epoch": 12.16012084592145,
      "eval_loss": 1.413904070854187,
      "eval_runtime": 1490.2631,
      "eval_samples_per_second": 35.631,
      "eval_steps_per_second": 0.278,
      "step": 40250
    },
    {
      "epoch": 12.175226586102719,
      "grad_norm": 0.6511484384536743,
      "learning_rate": 5.855005035246727e-05,
      "loss": 1.4079,
      "step": 40300
    },
    {
      "epoch": 12.175226586102719,
      "eval_loss": 1.4154796600341797,
      "eval_runtime": 1467.0059,
      "eval_samples_per_second": 36.195,
      "eval_steps_per_second": 0.283,
      "step": 40300
    },
    {
      "epoch": 12.190332326283988,
      "grad_norm": 0.5987367630004883,
      "learning_rate": 5.853997985901309e-05,
      "loss": 1.3845,
      "step": 40350
    },
    {
      "epoch": 12.190332326283988,
      "eval_loss": 1.415597915649414,
      "eval_runtime": 1538.5026,
      "eval_samples_per_second": 34.513,
      "eval_steps_per_second": 0.27,
      "step": 40350
    },
    {
      "epoch": 12.205438066465257,
      "grad_norm": 0.6421720385551453,
      "learning_rate": 5.852990936555891e-05,
      "loss": 1.3882,
      "step": 40400
    },
    {
      "epoch": 12.205438066465257,
      "eval_loss": 1.4156938791275024,
      "eval_runtime": 1491.0559,
      "eval_samples_per_second": 35.612,
      "eval_steps_per_second": 0.278,
      "step": 40400
    },
    {
      "epoch": 12.220543806646525,
      "grad_norm": 0.7279514670372009,
      "learning_rate": 5.851983887210473e-05,
      "loss": 1.3855,
      "step": 40450
    },
    {
      "epoch": 12.220543806646525,
      "eval_loss": 1.4158508777618408,
      "eval_runtime": 1525.9057,
      "eval_samples_per_second": 34.798,
      "eval_steps_per_second": 0.272,
      "step": 40450
    },
    {
      "epoch": 12.235649546827794,
      "grad_norm": 0.5383117198944092,
      "learning_rate": 5.8509768378650554e-05,
      "loss": 1.3904,
      "step": 40500
    },
    {
      "epoch": 12.235649546827794,
      "eval_loss": 1.4137073755264282,
      "eval_runtime": 1516.0216,
      "eval_samples_per_second": 35.025,
      "eval_steps_per_second": 0.274,
      "step": 40500
    },
    {
      "epoch": 12.250755287009063,
      "grad_norm": 0.5818149447441101,
      "learning_rate": 5.849969788519638e-05,
      "loss": 1.4216,
      "step": 40550
    },
    {
      "epoch": 12.250755287009063,
      "eval_loss": 1.4167765378952026,
      "eval_runtime": 1498.2039,
      "eval_samples_per_second": 35.442,
      "eval_steps_per_second": 0.277,
      "step": 40550
    },
    {
      "epoch": 12.265861027190333,
      "grad_norm": 0.6300906538963318,
      "learning_rate": 5.84896273917422e-05,
      "loss": 1.3847,
      "step": 40600
    },
    {
      "epoch": 12.265861027190333,
      "eval_loss": 1.4144291877746582,
      "eval_runtime": 1561.2426,
      "eval_samples_per_second": 34.011,
      "eval_steps_per_second": 0.266,
      "step": 40600
    },
    {
      "epoch": 12.280966767371602,
      "grad_norm": 0.5496730804443359,
      "learning_rate": 5.8479556898288023e-05,
      "loss": 1.4017,
      "step": 40650
    },
    {
      "epoch": 12.280966767371602,
      "eval_loss": 1.4135106801986694,
      "eval_runtime": 1536.4503,
      "eval_samples_per_second": 34.56,
      "eval_steps_per_second": 0.27,
      "step": 40650
    },
    {
      "epoch": 12.29607250755287,
      "grad_norm": 0.668032705783844,
      "learning_rate": 5.846948640483384e-05,
      "loss": 1.3667,
      "step": 40700
    },
    {
      "epoch": 12.29607250755287,
      "eval_loss": 1.4146406650543213,
      "eval_runtime": 1474.3306,
      "eval_samples_per_second": 36.016,
      "eval_steps_per_second": 0.281,
      "step": 40700
    },
    {
      "epoch": 12.311178247734139,
      "grad_norm": 0.6072501540184021,
      "learning_rate": 5.845941591137966e-05,
      "loss": 1.3672,
      "step": 40750
    },
    {
      "epoch": 12.311178247734139,
      "eval_loss": 1.4153306484222412,
      "eval_runtime": 1569.9847,
      "eval_samples_per_second": 33.821,
      "eval_steps_per_second": 0.264,
      "step": 40750
    },
    {
      "epoch": 12.326283987915408,
      "grad_norm": 0.6153602600097656,
      "learning_rate": 5.844934541792548e-05,
      "loss": 1.3566,
      "step": 40800
    },
    {
      "epoch": 12.326283987915408,
      "eval_loss": 1.4159268140792847,
      "eval_runtime": 1517.3011,
      "eval_samples_per_second": 34.996,
      "eval_steps_per_second": 0.274,
      "step": 40800
    },
    {
      "epoch": 12.341389728096678,
      "grad_norm": 0.6270917057991028,
      "learning_rate": 5.8439274924471305e-05,
      "loss": 1.3669,
      "step": 40850
    },
    {
      "epoch": 12.341389728096678,
      "eval_loss": 1.4125046730041504,
      "eval_runtime": 1543.3854,
      "eval_samples_per_second": 34.404,
      "eval_steps_per_second": 0.269,
      "step": 40850
    },
    {
      "epoch": 12.356495468277945,
      "grad_norm": 0.645054280757904,
      "learning_rate": 5.8429204431017124e-05,
      "loss": 1.3515,
      "step": 40900
    },
    {
      "epoch": 12.356495468277945,
      "eval_loss": 1.4129301309585571,
      "eval_runtime": 1492.8836,
      "eval_samples_per_second": 35.568,
      "eval_steps_per_second": 0.278,
      "step": 40900
    },
    {
      "epoch": 12.371601208459214,
      "grad_norm": 0.5613044500350952,
      "learning_rate": 5.841913393756294e-05,
      "loss": 1.3703,
      "step": 40950
    },
    {
      "epoch": 12.371601208459214,
      "eval_loss": 1.412481427192688,
      "eval_runtime": 1532.2152,
      "eval_samples_per_second": 34.655,
      "eval_steps_per_second": 0.271,
      "step": 40950
    },
    {
      "epoch": 12.386706948640484,
      "grad_norm": 0.6035932898521423,
      "learning_rate": 5.840906344410876e-05,
      "loss": 1.388,
      "step": 41000
    },
    {
      "epoch": 12.386706948640484,
      "eval_loss": 1.4108887910842896,
      "eval_runtime": 1525.3982,
      "eval_samples_per_second": 34.81,
      "eval_steps_per_second": 0.272,
      "step": 41000
    },
    {
      "epoch": 12.401812688821753,
      "grad_norm": 0.5705187320709229,
      "learning_rate": 5.8398992950654587e-05,
      "loss": 1.3954,
      "step": 41050
    },
    {
      "epoch": 12.401812688821753,
      "eval_loss": 1.414640188217163,
      "eval_runtime": 1569.2299,
      "eval_samples_per_second": 33.838,
      "eval_steps_per_second": 0.264,
      "step": 41050
    },
    {
      "epoch": 12.41691842900302,
      "grad_norm": 0.5857031941413879,
      "learning_rate": 5.8388922457200405e-05,
      "loss": 1.4022,
      "step": 41100
    },
    {
      "epoch": 12.41691842900302,
      "eval_loss": 1.4137921333312988,
      "eval_runtime": 1510.498,
      "eval_samples_per_second": 35.153,
      "eval_steps_per_second": 0.275,
      "step": 41100
    },
    {
      "epoch": 12.43202416918429,
      "grad_norm": 0.5324504375457764,
      "learning_rate": 5.8378851963746224e-05,
      "loss": 1.398,
      "step": 41150
    },
    {
      "epoch": 12.43202416918429,
      "eval_loss": 1.411530613899231,
      "eval_runtime": 1484.3044,
      "eval_samples_per_second": 35.774,
      "eval_steps_per_second": 0.28,
      "step": 41150
    },
    {
      "epoch": 12.44712990936556,
      "grad_norm": 0.568031907081604,
      "learning_rate": 5.836878147029204e-05,
      "loss": 1.3818,
      "step": 41200
    },
    {
      "epoch": 12.44712990936556,
      "eval_loss": 1.4121158123016357,
      "eval_runtime": 1483.3869,
      "eval_samples_per_second": 35.796,
      "eval_steps_per_second": 0.28,
      "step": 41200
    },
    {
      "epoch": 12.462235649546828,
      "grad_norm": 0.6338077187538147,
      "learning_rate": 5.835871097683787e-05,
      "loss": 1.408,
      "step": 41250
    },
    {
      "epoch": 12.462235649546828,
      "eval_loss": 1.409891963005066,
      "eval_runtime": 1483.0093,
      "eval_samples_per_second": 35.805,
      "eval_steps_per_second": 0.28,
      "step": 41250
    },
    {
      "epoch": 12.477341389728096,
      "grad_norm": 0.6509496569633484,
      "learning_rate": 5.834864048338369e-05,
      "loss": 1.3618,
      "step": 41300
    },
    {
      "epoch": 12.477341389728096,
      "eval_loss": 1.4122662544250488,
      "eval_runtime": 1585.3442,
      "eval_samples_per_second": 33.494,
      "eval_steps_per_second": 0.262,
      "step": 41300
    },
    {
      "epoch": 12.492447129909365,
      "grad_norm": 0.7505311965942383,
      "learning_rate": 5.8338569989929505e-05,
      "loss": 1.3907,
      "step": 41350
    },
    {
      "epoch": 12.492447129909365,
      "eval_loss": 1.4113094806671143,
      "eval_runtime": 1499.0577,
      "eval_samples_per_second": 35.422,
      "eval_steps_per_second": 0.277,
      "step": 41350
    },
    {
      "epoch": 12.507552870090635,
      "grad_norm": 0.6150670647621155,
      "learning_rate": 5.8328499496475324e-05,
      "loss": 1.3874,
      "step": 41400
    },
    {
      "epoch": 12.507552870090635,
      "eval_loss": 1.4105312824249268,
      "eval_runtime": 1471.8022,
      "eval_samples_per_second": 36.078,
      "eval_steps_per_second": 0.282,
      "step": 41400
    },
    {
      "epoch": 12.522658610271904,
      "grad_norm": 0.5883982181549072,
      "learning_rate": 5.831842900302115e-05,
      "loss": 1.393,
      "step": 41450
    },
    {
      "epoch": 12.522658610271904,
      "eval_loss": 1.4123598337173462,
      "eval_runtime": 1524.273,
      "eval_samples_per_second": 34.836,
      "eval_steps_per_second": 0.272,
      "step": 41450
    },
    {
      "epoch": 12.537764350453172,
      "grad_norm": 0.8196191787719727,
      "learning_rate": 5.830835850956697e-05,
      "loss": 1.3933,
      "step": 41500
    },
    {
      "epoch": 12.537764350453172,
      "eval_loss": 1.4078551530838013,
      "eval_runtime": 1546.7931,
      "eval_samples_per_second": 34.328,
      "eval_steps_per_second": 0.268,
      "step": 41500
    },
    {
      "epoch": 12.55287009063444,
      "grad_norm": 0.5475345253944397,
      "learning_rate": 5.829828801611279e-05,
      "loss": 1.3759,
      "step": 41550
    },
    {
      "epoch": 12.55287009063444,
      "eval_loss": 1.4080044031143188,
      "eval_runtime": 1472.9755,
      "eval_samples_per_second": 36.049,
      "eval_steps_per_second": 0.282,
      "step": 41550
    },
    {
      "epoch": 12.56797583081571,
      "grad_norm": 0.6154534220695496,
      "learning_rate": 5.8288217522658606e-05,
      "loss": 1.3913,
      "step": 41600
    },
    {
      "epoch": 12.56797583081571,
      "eval_loss": 1.4102716445922852,
      "eval_runtime": 1578.302,
      "eval_samples_per_second": 33.643,
      "eval_steps_per_second": 0.263,
      "step": 41600
    },
    {
      "epoch": 12.58308157099698,
      "grad_norm": 0.5769264101982117,
      "learning_rate": 5.827814702920443e-05,
      "loss": 1.3904,
      "step": 41650
    },
    {
      "epoch": 12.58308157099698,
      "eval_loss": 1.4121567010879517,
      "eval_runtime": 1490.4145,
      "eval_samples_per_second": 35.627,
      "eval_steps_per_second": 0.278,
      "step": 41650
    },
    {
      "epoch": 12.598187311178247,
      "grad_norm": 0.6605812311172485,
      "learning_rate": 5.8268076535750257e-05,
      "loss": 1.3713,
      "step": 41700
    },
    {
      "epoch": 12.598187311178247,
      "eval_loss": 1.4094487428665161,
      "eval_runtime": 1551.0631,
      "eval_samples_per_second": 34.234,
      "eval_steps_per_second": 0.268,
      "step": 41700
    },
    {
      "epoch": 12.613293051359516,
      "grad_norm": 0.5568344593048096,
      "learning_rate": 5.8258006042296075e-05,
      "loss": 1.3968,
      "step": 41750
    },
    {
      "epoch": 12.613293051359516,
      "eval_loss": 1.4087148904800415,
      "eval_runtime": 1511.0274,
      "eval_samples_per_second": 35.141,
      "eval_steps_per_second": 0.275,
      "step": 41750
    },
    {
      "epoch": 12.628398791540786,
      "grad_norm": 0.6435456275939941,
      "learning_rate": 5.82479355488419e-05,
      "loss": 1.3839,
      "step": 41800
    },
    {
      "epoch": 12.628398791540786,
      "eval_loss": 1.4116872549057007,
      "eval_runtime": 1541.0029,
      "eval_samples_per_second": 34.457,
      "eval_steps_per_second": 0.269,
      "step": 41800
    },
    {
      "epoch": 12.643504531722055,
      "grad_norm": 0.7645115256309509,
      "learning_rate": 5.823786505538772e-05,
      "loss": 1.4043,
      "step": 41850
    },
    {
      "epoch": 12.643504531722055,
      "eval_loss": 1.4107136726379395,
      "eval_runtime": 1478.8613,
      "eval_samples_per_second": 35.905,
      "eval_steps_per_second": 0.281,
      "step": 41850
    },
    {
      "epoch": 12.658610271903322,
      "grad_norm": 0.5408714413642883,
      "learning_rate": 5.822779456193354e-05,
      "loss": 1.3635,
      "step": 41900
    },
    {
      "epoch": 12.658610271903322,
      "eval_loss": 1.4072836637496948,
      "eval_runtime": 1573.2807,
      "eval_samples_per_second": 33.75,
      "eval_steps_per_second": 0.264,
      "step": 41900
    },
    {
      "epoch": 12.673716012084592,
      "grad_norm": 0.5642234086990356,
      "learning_rate": 5.821772406847936e-05,
      "loss": 1.3951,
      "step": 41950
    },
    {
      "epoch": 12.673716012084592,
      "eval_loss": 1.409816026687622,
      "eval_runtime": 1554.716,
      "eval_samples_per_second": 34.154,
      "eval_steps_per_second": 0.267,
      "step": 41950
    },
    {
      "epoch": 12.688821752265861,
      "grad_norm": 0.5946542620658875,
      "learning_rate": 5.820765357502518e-05,
      "loss": 1.384,
      "step": 42000
    },
    {
      "epoch": 12.688821752265861,
      "eval_loss": 1.4079478979110718,
      "eval_runtime": 1583.3923,
      "eval_samples_per_second": 33.535,
      "eval_steps_per_second": 0.262,
      "step": 42000
    },
    {
      "epoch": 12.70392749244713,
      "grad_norm": 0.6071217060089111,
      "learning_rate": 5.8197583081571e-05,
      "loss": 1.3926,
      "step": 42050
    },
    {
      "epoch": 12.70392749244713,
      "eval_loss": 1.407069206237793,
      "eval_runtime": 1547.0927,
      "eval_samples_per_second": 34.322,
      "eval_steps_per_second": 0.268,
      "step": 42050
    },
    {
      "epoch": 12.719033232628398,
      "grad_norm": 0.6072923541069031,
      "learning_rate": 5.818751258811682e-05,
      "loss": 1.3804,
      "step": 42100
    },
    {
      "epoch": 12.719033232628398,
      "eval_loss": 1.4094069004058838,
      "eval_runtime": 1566.262,
      "eval_samples_per_second": 33.902,
      "eval_steps_per_second": 0.265,
      "step": 42100
    },
    {
      "epoch": 12.734138972809667,
      "grad_norm": 0.6094747185707092,
      "learning_rate": 5.817744209466264e-05,
      "loss": 1.3943,
      "step": 42150
    },
    {
      "epoch": 12.734138972809667,
      "eval_loss": 1.4080049991607666,
      "eval_runtime": 1549.4789,
      "eval_samples_per_second": 34.269,
      "eval_steps_per_second": 0.268,
      "step": 42150
    },
    {
      "epoch": 12.749244712990937,
      "grad_norm": 0.6307992935180664,
      "learning_rate": 5.8167371601208464e-05,
      "loss": 1.3761,
      "step": 42200
    },
    {
      "epoch": 12.749244712990937,
      "eval_loss": 1.408982276916504,
      "eval_runtime": 1471.3798,
      "eval_samples_per_second": 36.088,
      "eval_steps_per_second": 0.282,
      "step": 42200
    },
    {
      "epoch": 12.764350453172206,
      "grad_norm": 0.5851343870162964,
      "learning_rate": 5.815730110775428e-05,
      "loss": 1.3964,
      "step": 42250
    },
    {
      "epoch": 12.764350453172206,
      "eval_loss": 1.4083753824234009,
      "eval_runtime": 1571.5582,
      "eval_samples_per_second": 33.787,
      "eval_steps_per_second": 0.264,
      "step": 42250
    },
    {
      "epoch": 12.779456193353475,
      "grad_norm": 0.642608106136322,
      "learning_rate": 5.81472306143001e-05,
      "loss": 1.4025,
      "step": 42300
    },
    {
      "epoch": 12.779456193353475,
      "eval_loss": 1.4076237678527832,
      "eval_runtime": 1479.7571,
      "eval_samples_per_second": 35.884,
      "eval_steps_per_second": 0.28,
      "step": 42300
    },
    {
      "epoch": 12.794561933534743,
      "grad_norm": 0.6075584292411804,
      "learning_rate": 5.813716012084592e-05,
      "loss": 1.39,
      "step": 42350
    },
    {
      "epoch": 12.794561933534743,
      "eval_loss": 1.4087255001068115,
      "eval_runtime": 1540.0371,
      "eval_samples_per_second": 34.479,
      "eval_steps_per_second": 0.269,
      "step": 42350
    },
    {
      "epoch": 12.809667673716012,
      "grad_norm": 0.5675721168518066,
      "learning_rate": 5.8127089627391745e-05,
      "loss": 1.3774,
      "step": 42400
    },
    {
      "epoch": 12.809667673716012,
      "eval_loss": 1.4069297313690186,
      "eval_runtime": 1523.5329,
      "eval_samples_per_second": 34.853,
      "eval_steps_per_second": 0.272,
      "step": 42400
    },
    {
      "epoch": 12.824773413897281,
      "grad_norm": 0.6109246015548706,
      "learning_rate": 5.8117019133937564e-05,
      "loss": 1.3779,
      "step": 42450
    },
    {
      "epoch": 12.824773413897281,
      "eval_loss": 1.405488133430481,
      "eval_runtime": 1455.893,
      "eval_samples_per_second": 36.472,
      "eval_steps_per_second": 0.285,
      "step": 42450
    },
    {
      "epoch": 12.83987915407855,
      "grad_norm": 0.5771641135215759,
      "learning_rate": 5.810694864048338e-05,
      "loss": 1.3794,
      "step": 42500
    },
    {
      "epoch": 12.83987915407855,
      "eval_loss": 1.4061862230300903,
      "eval_runtime": 1474.9123,
      "eval_samples_per_second": 36.001,
      "eval_steps_per_second": 0.281,
      "step": 42500
    },
    {
      "epoch": 12.854984894259818,
      "grad_norm": 0.5598164200782776,
      "learning_rate": 5.80968781470292e-05,
      "loss": 1.3912,
      "step": 42550
    },
    {
      "epoch": 12.854984894259818,
      "eval_loss": 1.4049853086471558,
      "eval_runtime": 1505.2581,
      "eval_samples_per_second": 35.276,
      "eval_steps_per_second": 0.276,
      "step": 42550
    },
    {
      "epoch": 12.870090634441087,
      "grad_norm": 0.5383325815200806,
      "learning_rate": 5.808680765357503e-05,
      "loss": 1.3871,
      "step": 42600
    },
    {
      "epoch": 12.870090634441087,
      "eval_loss": 1.4074550867080688,
      "eval_runtime": 1516.6195,
      "eval_samples_per_second": 35.011,
      "eval_steps_per_second": 0.274,
      "step": 42600
    },
    {
      "epoch": 12.885196374622357,
      "grad_norm": 0.5866584181785583,
      "learning_rate": 5.8076737160120845e-05,
      "loss": 1.3667,
      "step": 42650
    },
    {
      "epoch": 12.885196374622357,
      "eval_loss": 1.4079421758651733,
      "eval_runtime": 1504.9317,
      "eval_samples_per_second": 35.283,
      "eval_steps_per_second": 0.276,
      "step": 42650
    },
    {
      "epoch": 12.900302114803626,
      "grad_norm": 0.5895225405693054,
      "learning_rate": 5.8066666666666664e-05,
      "loss": 1.3891,
      "step": 42700
    },
    {
      "epoch": 12.900302114803626,
      "eval_loss": 1.404680848121643,
      "eval_runtime": 1539.4573,
      "eval_samples_per_second": 34.492,
      "eval_steps_per_second": 0.27,
      "step": 42700
    },
    {
      "epoch": 12.915407854984894,
      "grad_norm": 0.632752001285553,
      "learning_rate": 5.805659617321248e-05,
      "loss": 1.3637,
      "step": 42750
    },
    {
      "epoch": 12.915407854984894,
      "eval_loss": 1.4067866802215576,
      "eval_runtime": 1595.5564,
      "eval_samples_per_second": 33.279,
      "eval_steps_per_second": 0.26,
      "step": 42750
    },
    {
      "epoch": 12.930513595166163,
      "grad_norm": 0.529937207698822,
      "learning_rate": 5.804652567975831e-05,
      "loss": 1.3506,
      "step": 42800
    },
    {
      "epoch": 12.930513595166163,
      "eval_loss": 1.4052776098251343,
      "eval_runtime": 1514.899,
      "eval_samples_per_second": 35.051,
      "eval_steps_per_second": 0.274,
      "step": 42800
    },
    {
      "epoch": 12.945619335347432,
      "grad_norm": 0.49684426188468933,
      "learning_rate": 5.803645518630413e-05,
      "loss": 1.3732,
      "step": 42850
    },
    {
      "epoch": 12.945619335347432,
      "eval_loss": 1.4064363241195679,
      "eval_runtime": 1595.7076,
      "eval_samples_per_second": 33.276,
      "eval_steps_per_second": 0.26,
      "step": 42850
    },
    {
      "epoch": 12.960725075528702,
      "grad_norm": 0.6175812482833862,
      "learning_rate": 5.802638469284995e-05,
      "loss": 1.4063,
      "step": 42900
    },
    {
      "epoch": 12.960725075528702,
      "eval_loss": 1.4062436819076538,
      "eval_runtime": 1572.4069,
      "eval_samples_per_second": 33.769,
      "eval_steps_per_second": 0.264,
      "step": 42900
    },
    {
      "epoch": 12.975830815709969,
      "grad_norm": 0.5710799694061279,
      "learning_rate": 5.801631419939578e-05,
      "loss": 1.3913,
      "step": 42950
    },
    {
      "epoch": 12.975830815709969,
      "eval_loss": 1.4017013311386108,
      "eval_runtime": 1577.2889,
      "eval_samples_per_second": 33.665,
      "eval_steps_per_second": 0.263,
      "step": 42950
    },
    {
      "epoch": 12.990936555891238,
      "grad_norm": 0.5806480050086975,
      "learning_rate": 5.8006243705941597e-05,
      "loss": 1.3973,
      "step": 43000
    },
    {
      "epoch": 12.990936555891238,
      "eval_loss": 1.4021406173706055,
      "eval_runtime": 1470.3609,
      "eval_samples_per_second": 36.113,
      "eval_steps_per_second": 0.282,
      "step": 43000
    },
    {
      "epoch": 13.006042296072508,
      "grad_norm": 0.5879541039466858,
      "learning_rate": 5.7996173212487415e-05,
      "loss": 1.3854,
      "step": 43050
    },
    {
      "epoch": 13.006042296072508,
      "eval_loss": 1.4040597677230835,
      "eval_runtime": 1491.7821,
      "eval_samples_per_second": 35.594,
      "eval_steps_per_second": 0.278,
      "step": 43050
    },
    {
      "epoch": 13.021148036253777,
      "grad_norm": 0.5595449805259705,
      "learning_rate": 5.7986102719033234e-05,
      "loss": 1.3566,
      "step": 43100
    },
    {
      "epoch": 13.021148036253777,
      "eval_loss": 1.4029006958007812,
      "eval_runtime": 1498.9103,
      "eval_samples_per_second": 35.425,
      "eval_steps_per_second": 0.277,
      "step": 43100
    },
    {
      "epoch": 13.036253776435045,
      "grad_norm": 0.6652155518531799,
      "learning_rate": 5.797603222557906e-05,
      "loss": 1.359,
      "step": 43150
    },
    {
      "epoch": 13.036253776435045,
      "eval_loss": 1.4043875932693481,
      "eval_runtime": 1534.8215,
      "eval_samples_per_second": 34.596,
      "eval_steps_per_second": 0.27,
      "step": 43150
    },
    {
      "epoch": 13.051359516616314,
      "grad_norm": 0.5632046461105347,
      "learning_rate": 5.796596173212488e-05,
      "loss": 1.3636,
      "step": 43200
    },
    {
      "epoch": 13.051359516616314,
      "eval_loss": 1.404819369316101,
      "eval_runtime": 1465.6205,
      "eval_samples_per_second": 36.23,
      "eval_steps_per_second": 0.283,
      "step": 43200
    },
    {
      "epoch": 13.066465256797583,
      "grad_norm": 0.5371897220611572,
      "learning_rate": 5.79558912386707e-05,
      "loss": 1.3709,
      "step": 43250
    },
    {
      "epoch": 13.066465256797583,
      "eval_loss": 1.4020899534225464,
      "eval_runtime": 1566.2936,
      "eval_samples_per_second": 33.901,
      "eval_steps_per_second": 0.265,
      "step": 43250
    },
    {
      "epoch": 13.081570996978853,
      "grad_norm": 0.5814716815948486,
      "learning_rate": 5.7945820745216515e-05,
      "loss": 1.343,
      "step": 43300
    },
    {
      "epoch": 13.081570996978853,
      "eval_loss": 1.4029346704483032,
      "eval_runtime": 1500.9626,
      "eval_samples_per_second": 35.377,
      "eval_steps_per_second": 0.276,
      "step": 43300
    },
    {
      "epoch": 13.09667673716012,
      "grad_norm": 0.5804418921470642,
      "learning_rate": 5.793575025176234e-05,
      "loss": 1.3636,
      "step": 43350
    },
    {
      "epoch": 13.09667673716012,
      "eval_loss": 1.403686285018921,
      "eval_runtime": 1563.9545,
      "eval_samples_per_second": 33.952,
      "eval_steps_per_second": 0.265,
      "step": 43350
    },
    {
      "epoch": 13.11178247734139,
      "grad_norm": 0.577390730381012,
      "learning_rate": 5.792567975830816e-05,
      "loss": 1.373,
      "step": 43400
    },
    {
      "epoch": 13.11178247734139,
      "eval_loss": 1.4033931493759155,
      "eval_runtime": 1670.9215,
      "eval_samples_per_second": 31.778,
      "eval_steps_per_second": 0.248,
      "step": 43400
    },
    {
      "epoch": 13.126888217522659,
      "grad_norm": 0.5257072448730469,
      "learning_rate": 5.791560926485398e-05,
      "loss": 1.3796,
      "step": 43450
    },
    {
      "epoch": 13.126888217522659,
      "eval_loss": 1.4016237258911133,
      "eval_runtime": 1521.9135,
      "eval_samples_per_second": 34.89,
      "eval_steps_per_second": 0.273,
      "step": 43450
    },
    {
      "epoch": 13.141993957703928,
      "grad_norm": 0.5383739471435547,
      "learning_rate": 5.79055387713998e-05,
      "loss": 1.3655,
      "step": 43500
    },
    {
      "epoch": 13.141993957703928,
      "eval_loss": 1.4016010761260986,
      "eval_runtime": 1523.2471,
      "eval_samples_per_second": 34.859,
      "eval_steps_per_second": 0.272,
      "step": 43500
    },
    {
      "epoch": 13.157099697885196,
      "grad_norm": 0.5563644170761108,
      "learning_rate": 5.789546827794562e-05,
      "loss": 1.3858,
      "step": 43550
    },
    {
      "epoch": 13.157099697885196,
      "eval_loss": 1.401145577430725,
      "eval_runtime": 1683.9161,
      "eval_samples_per_second": 31.533,
      "eval_steps_per_second": 0.246,
      "step": 43550
    },
    {
      "epoch": 13.172205438066465,
      "grad_norm": 0.5881613492965698,
      "learning_rate": 5.788539778449144e-05,
      "loss": 1.3829,
      "step": 43600
    },
    {
      "epoch": 13.172205438066465,
      "eval_loss": 1.4046096801757812,
      "eval_runtime": 1555.4042,
      "eval_samples_per_second": 34.138,
      "eval_steps_per_second": 0.267,
      "step": 43600
    },
    {
      "epoch": 13.187311178247734,
      "grad_norm": 0.5429680347442627,
      "learning_rate": 5.787532729103726e-05,
      "loss": 1.392,
      "step": 43650
    },
    {
      "epoch": 13.187311178247734,
      "eval_loss": 1.4019975662231445,
      "eval_runtime": 1522.2346,
      "eval_samples_per_second": 34.882,
      "eval_steps_per_second": 0.273,
      "step": 43650
    },
    {
      "epoch": 13.202416918429003,
      "grad_norm": 0.5209929347038269,
      "learning_rate": 5.786525679758308e-05,
      "loss": 1.3573,
      "step": 43700
    },
    {
      "epoch": 13.202416918429003,
      "eval_loss": 1.4037657976150513,
      "eval_runtime": 1520.3577,
      "eval_samples_per_second": 34.925,
      "eval_steps_per_second": 0.273,
      "step": 43700
    },
    {
      "epoch": 13.217522658610273,
      "grad_norm": 0.6964015960693359,
      "learning_rate": 5.7855186304128904e-05,
      "loss": 1.3603,
      "step": 43750
    },
    {
      "epoch": 13.217522658610273,
      "eval_loss": 1.4029083251953125,
      "eval_runtime": 1495.3091,
      "eval_samples_per_second": 35.51,
      "eval_steps_per_second": 0.278,
      "step": 43750
    },
    {
      "epoch": 13.23262839879154,
      "grad_norm": 0.6669768691062927,
      "learning_rate": 5.784511581067472e-05,
      "loss": 1.3924,
      "step": 43800
    },
    {
      "epoch": 13.23262839879154,
      "eval_loss": 1.4027533531188965,
      "eval_runtime": 1565.4667,
      "eval_samples_per_second": 33.919,
      "eval_steps_per_second": 0.265,
      "step": 43800
    },
    {
      "epoch": 13.24773413897281,
      "grad_norm": 0.5658168792724609,
      "learning_rate": 5.783504531722054e-05,
      "loss": 1.3909,
      "step": 43850
    },
    {
      "epoch": 13.24773413897281,
      "eval_loss": 1.4009191989898682,
      "eval_runtime": 1566.6282,
      "eval_samples_per_second": 33.894,
      "eval_steps_per_second": 0.265,
      "step": 43850
    },
    {
      "epoch": 13.262839879154079,
      "grad_norm": 0.5149337649345398,
      "learning_rate": 5.782497482376636e-05,
      "loss": 1.4069,
      "step": 43900
    },
    {
      "epoch": 13.262839879154079,
      "eval_loss": 1.3995118141174316,
      "eval_runtime": 1500.3124,
      "eval_samples_per_second": 35.392,
      "eval_steps_per_second": 0.277,
      "step": 43900
    },
    {
      "epoch": 13.277945619335348,
      "grad_norm": 0.5484784245491028,
      "learning_rate": 5.7814904330312185e-05,
      "loss": 1.3689,
      "step": 43950
    },
    {
      "epoch": 13.277945619335348,
      "eval_loss": 1.4018607139587402,
      "eval_runtime": 1542.2336,
      "eval_samples_per_second": 34.43,
      "eval_steps_per_second": 0.269,
      "step": 43950
    },
    {
      "epoch": 13.293051359516616,
      "grad_norm": 0.5225099325180054,
      "learning_rate": 5.7804833836858004e-05,
      "loss": 1.3713,
      "step": 44000
    },
    {
      "epoch": 13.293051359516616,
      "eval_loss": 1.3995139598846436,
      "eval_runtime": 1568.9985,
      "eval_samples_per_second": 33.843,
      "eval_steps_per_second": 0.264,
      "step": 44000
    },
    {
      "epoch": 13.308157099697885,
      "grad_norm": 0.5168834924697876,
      "learning_rate": 5.779476334340383e-05,
      "loss": 1.3812,
      "step": 44050
    },
    {
      "epoch": 13.308157099697885,
      "eval_loss": 1.3992855548858643,
      "eval_runtime": 1475.5343,
      "eval_samples_per_second": 35.986,
      "eval_steps_per_second": 0.281,
      "step": 44050
    },
    {
      "epoch": 13.323262839879154,
      "grad_norm": 0.7834631204605103,
      "learning_rate": 5.7784692849949655e-05,
      "loss": 1.4011,
      "step": 44100
    },
    {
      "epoch": 13.323262839879154,
      "eval_loss": 1.3992937803268433,
      "eval_runtime": 1556.642,
      "eval_samples_per_second": 34.111,
      "eval_steps_per_second": 0.267,
      "step": 44100
    },
    {
      "epoch": 13.338368580060424,
      "grad_norm": 0.5340818762779236,
      "learning_rate": 5.7774622356495474e-05,
      "loss": 1.3891,
      "step": 44150
    },
    {
      "epoch": 13.338368580060424,
      "eval_loss": 1.4002114534378052,
      "eval_runtime": 1518.7249,
      "eval_samples_per_second": 34.963,
      "eval_steps_per_second": 0.273,
      "step": 44150
    },
    {
      "epoch": 13.353474320241691,
      "grad_norm": 0.4972155690193176,
      "learning_rate": 5.776455186304129e-05,
      "loss": 1.3704,
      "step": 44200
    },
    {
      "epoch": 13.353474320241691,
      "eval_loss": 1.4011880159378052,
      "eval_runtime": 1536.6222,
      "eval_samples_per_second": 34.556,
      "eval_steps_per_second": 0.27,
      "step": 44200
    },
    {
      "epoch": 13.36858006042296,
      "grad_norm": 0.5929043292999268,
      "learning_rate": 5.775448136958711e-05,
      "loss": 1.3868,
      "step": 44250
    },
    {
      "epoch": 13.36858006042296,
      "eval_loss": 1.4005329608917236,
      "eval_runtime": 1582.6883,
      "eval_samples_per_second": 33.55,
      "eval_steps_per_second": 0.262,
      "step": 44250
    },
    {
      "epoch": 13.38368580060423,
      "grad_norm": 0.6748528480529785,
      "learning_rate": 5.7744410876132937e-05,
      "loss": 1.3885,
      "step": 44300
    },
    {
      "epoch": 13.38368580060423,
      "eval_loss": 1.400958776473999,
      "eval_runtime": 1470.518,
      "eval_samples_per_second": 36.109,
      "eval_steps_per_second": 0.282,
      "step": 44300
    },
    {
      "epoch": 13.3987915407855,
      "grad_norm": 0.5472017526626587,
      "learning_rate": 5.7734340382678755e-05,
      "loss": 1.3776,
      "step": 44350
    },
    {
      "epoch": 13.3987915407855,
      "eval_loss": 1.3979859352111816,
      "eval_runtime": 1502.1168,
      "eval_samples_per_second": 35.349,
      "eval_steps_per_second": 0.276,
      "step": 44350
    },
    {
      "epoch": 13.413897280966767,
      "grad_norm": 0.5431060791015625,
      "learning_rate": 5.7724269889224574e-05,
      "loss": 1.3763,
      "step": 44400
    },
    {
      "epoch": 13.413897280966767,
      "eval_loss": 1.3995341062545776,
      "eval_runtime": 1485.4991,
      "eval_samples_per_second": 35.745,
      "eval_steps_per_second": 0.279,
      "step": 44400
    },
    {
      "epoch": 13.429003021148036,
      "grad_norm": 0.5681546926498413,
      "learning_rate": 5.771419939577039e-05,
      "loss": 1.3663,
      "step": 44450
    },
    {
      "epoch": 13.429003021148036,
      "eval_loss": 1.3993477821350098,
      "eval_runtime": 1559.5971,
      "eval_samples_per_second": 34.047,
      "eval_steps_per_second": 0.266,
      "step": 44450
    },
    {
      "epoch": 13.444108761329305,
      "grad_norm": 0.6939182877540588,
      "learning_rate": 5.770412890231622e-05,
      "loss": 1.364,
      "step": 44500
    },
    {
      "epoch": 13.444108761329305,
      "eval_loss": 1.4004430770874023,
      "eval_runtime": 1512.7402,
      "eval_samples_per_second": 35.101,
      "eval_steps_per_second": 0.274,
      "step": 44500
    },
    {
      "epoch": 13.459214501510575,
      "grad_norm": 0.5611580610275269,
      "learning_rate": 5.769405840886204e-05,
      "loss": 1.3772,
      "step": 44550
    },
    {
      "epoch": 13.459214501510575,
      "eval_loss": 1.3992228507995605,
      "eval_runtime": 1567.8136,
      "eval_samples_per_second": 33.868,
      "eval_steps_per_second": 0.265,
      "step": 44550
    },
    {
      "epoch": 13.474320241691842,
      "grad_norm": 0.5577418208122253,
      "learning_rate": 5.7683987915407855e-05,
      "loss": 1.384,
      "step": 44600
    },
    {
      "epoch": 13.474320241691842,
      "eval_loss": 1.4015108346939087,
      "eval_runtime": 1586.6124,
      "eval_samples_per_second": 33.467,
      "eval_steps_per_second": 0.262,
      "step": 44600
    },
    {
      "epoch": 13.489425981873111,
      "grad_norm": 0.5957871079444885,
      "learning_rate": 5.7673917421953674e-05,
      "loss": 1.3877,
      "step": 44650
    },
    {
      "epoch": 13.489425981873111,
      "eval_loss": 1.3971140384674072,
      "eval_runtime": 1499.4903,
      "eval_samples_per_second": 35.411,
      "eval_steps_per_second": 0.277,
      "step": 44650
    },
    {
      "epoch": 13.50453172205438,
      "grad_norm": 0.5866619944572449,
      "learning_rate": 5.76638469284995e-05,
      "loss": 1.3484,
      "step": 44700
    },
    {
      "epoch": 13.50453172205438,
      "eval_loss": 1.3973705768585205,
      "eval_runtime": 1519.6704,
      "eval_samples_per_second": 34.941,
      "eval_steps_per_second": 0.273,
      "step": 44700
    },
    {
      "epoch": 13.51963746223565,
      "grad_norm": 0.5456629395484924,
      "learning_rate": 5.765377643504532e-05,
      "loss": 1.348,
      "step": 44750
    },
    {
      "epoch": 13.51963746223565,
      "eval_loss": 1.399842619895935,
      "eval_runtime": 1543.4126,
      "eval_samples_per_second": 34.404,
      "eval_steps_per_second": 0.269,
      "step": 44750
    },
    {
      "epoch": 13.534743202416918,
      "grad_norm": 0.5397294163703918,
      "learning_rate": 5.764370594159114e-05,
      "loss": 1.3814,
      "step": 44800
    },
    {
      "epoch": 13.534743202416918,
      "eval_loss": 1.3967230319976807,
      "eval_runtime": 1548.9037,
      "eval_samples_per_second": 34.282,
      "eval_steps_per_second": 0.268,
      "step": 44800
    },
    {
      "epoch": 13.549848942598187,
      "grad_norm": 0.6169509291648865,
      "learning_rate": 5.7633635448136956e-05,
      "loss": 1.3462,
      "step": 44850
    },
    {
      "epoch": 13.549848942598187,
      "eval_loss": 1.3970381021499634,
      "eval_runtime": 1548.6171,
      "eval_samples_per_second": 34.288,
      "eval_steps_per_second": 0.268,
      "step": 44850
    },
    {
      "epoch": 13.564954682779456,
      "grad_norm": 0.5861954689025879,
      "learning_rate": 5.762356495468278e-05,
      "loss": 1.3678,
      "step": 44900
    },
    {
      "epoch": 13.564954682779456,
      "eval_loss": 1.3969749212265015,
      "eval_runtime": 1511.4918,
      "eval_samples_per_second": 35.13,
      "eval_steps_per_second": 0.275,
      "step": 44900
    },
    {
      "epoch": 13.580060422960726,
      "grad_norm": 0.592410683631897,
      "learning_rate": 5.76134944612286e-05,
      "loss": 1.3857,
      "step": 44950
    },
    {
      "epoch": 13.580060422960726,
      "eval_loss": 1.3980129957199097,
      "eval_runtime": 1615.2199,
      "eval_samples_per_second": 32.874,
      "eval_steps_per_second": 0.257,
      "step": 44950
    },
    {
      "epoch": 13.595166163141993,
      "grad_norm": 0.539483904838562,
      "learning_rate": 5.760342396777442e-05,
      "loss": 1.3752,
      "step": 45000
    },
    {
      "epoch": 13.595166163141993,
      "eval_loss": 1.3956702947616577,
      "eval_runtime": 1587.0728,
      "eval_samples_per_second": 33.457,
      "eval_steps_per_second": 0.261,
      "step": 45000
    },
    {
      "epoch": 13.610271903323262,
      "grad_norm": 0.5853093266487122,
      "learning_rate": 5.759335347432024e-05,
      "loss": 1.3868,
      "step": 45050
    },
    {
      "epoch": 13.610271903323262,
      "eval_loss": 1.3969242572784424,
      "eval_runtime": 1486.4502,
      "eval_samples_per_second": 35.722,
      "eval_steps_per_second": 0.279,
      "step": 45050
    },
    {
      "epoch": 13.625377643504532,
      "grad_norm": 0.5944021940231323,
      "learning_rate": 5.758328298086606e-05,
      "loss": 1.366,
      "step": 45100
    },
    {
      "epoch": 13.625377643504532,
      "eval_loss": 1.3981837034225464,
      "eval_runtime": 1580.2433,
      "eval_samples_per_second": 33.602,
      "eval_steps_per_second": 0.263,
      "step": 45100
    },
    {
      "epoch": 13.640483383685801,
      "grad_norm": 0.6486613750457764,
      "learning_rate": 5.757321248741188e-05,
      "loss": 1.3513,
      "step": 45150
    },
    {
      "epoch": 13.640483383685801,
      "eval_loss": 1.3967950344085693,
      "eval_runtime": 1498.2038,
      "eval_samples_per_second": 35.442,
      "eval_steps_per_second": 0.277,
      "step": 45150
    },
    {
      "epoch": 13.65558912386707,
      "grad_norm": 0.6924705505371094,
      "learning_rate": 5.756314199395771e-05,
      "loss": 1.4,
      "step": 45200
    },
    {
      "epoch": 13.65558912386707,
      "eval_loss": 1.3976709842681885,
      "eval_runtime": 1566.9388,
      "eval_samples_per_second": 33.887,
      "eval_steps_per_second": 0.265,
      "step": 45200
    },
    {
      "epoch": 13.670694864048338,
      "grad_norm": 0.6031945943832397,
      "learning_rate": 5.755307150050353e-05,
      "loss": 1.3673,
      "step": 45250
    },
    {
      "epoch": 13.670694864048338,
      "eval_loss": 1.3963335752487183,
      "eval_runtime": 1514.0711,
      "eval_samples_per_second": 35.07,
      "eval_steps_per_second": 0.274,
      "step": 45250
    },
    {
      "epoch": 13.685800604229607,
      "grad_norm": 0.6061331629753113,
      "learning_rate": 5.754300100704935e-05,
      "loss": 1.3724,
      "step": 45300
    },
    {
      "epoch": 13.685800604229607,
      "eval_loss": 1.3948708772659302,
      "eval_runtime": 1470.4821,
      "eval_samples_per_second": 36.11,
      "eval_steps_per_second": 0.282,
      "step": 45300
    },
    {
      "epoch": 13.700906344410877,
      "grad_norm": 0.6399690508842468,
      "learning_rate": 5.753293051359517e-05,
      "loss": 1.3787,
      "step": 45350
    },
    {
      "epoch": 13.700906344410877,
      "eval_loss": 1.4005365371704102,
      "eval_runtime": 1577.1868,
      "eval_samples_per_second": 33.667,
      "eval_steps_per_second": 0.263,
      "step": 45350
    },
    {
      "epoch": 13.716012084592146,
      "grad_norm": 0.5815733075141907,
      "learning_rate": 5.752286002014099e-05,
      "loss": 1.386,
      "step": 45400
    },
    {
      "epoch": 13.716012084592146,
      "eval_loss": 1.3964728116989136,
      "eval_runtime": 1549.5174,
      "eval_samples_per_second": 34.268,
      "eval_steps_per_second": 0.268,
      "step": 45400
    },
    {
      "epoch": 13.731117824773413,
      "grad_norm": 0.601840615272522,
      "learning_rate": 5.7512789526686814e-05,
      "loss": 1.3548,
      "step": 45450
    },
    {
      "epoch": 13.731117824773413,
      "eval_loss": 1.3947068452835083,
      "eval_runtime": 1514.9661,
      "eval_samples_per_second": 35.05,
      "eval_steps_per_second": 0.274,
      "step": 45450
    },
    {
      "epoch": 13.746223564954683,
      "grad_norm": 0.6387118101119995,
      "learning_rate": 5.750271903323263e-05,
      "loss": 1.3726,
      "step": 45500
    },
    {
      "epoch": 13.746223564954683,
      "eval_loss": 1.3961284160614014,
      "eval_runtime": 1492.0243,
      "eval_samples_per_second": 35.589,
      "eval_steps_per_second": 0.278,
      "step": 45500
    },
    {
      "epoch": 13.761329305135952,
      "grad_norm": 0.5624803304672241,
      "learning_rate": 5.749264853977845e-05,
      "loss": 1.3553,
      "step": 45550
    },
    {
      "epoch": 13.761329305135952,
      "eval_loss": 1.393221139907837,
      "eval_runtime": 1483.9576,
      "eval_samples_per_second": 35.782,
      "eval_steps_per_second": 0.28,
      "step": 45550
    },
    {
      "epoch": 13.776435045317221,
      "grad_norm": 0.6153302192687988,
      "learning_rate": 5.748257804632427e-05,
      "loss": 1.3996,
      "step": 45600
    },
    {
      "epoch": 13.776435045317221,
      "eval_loss": 1.3960380554199219,
      "eval_runtime": 1574.9084,
      "eval_samples_per_second": 33.716,
      "eval_steps_per_second": 0.264,
      "step": 45600
    },
    {
      "epoch": 13.791540785498489,
      "grad_norm": 0.5763387680053711,
      "learning_rate": 5.7472507552870095e-05,
      "loss": 1.378,
      "step": 45650
    },
    {
      "epoch": 13.791540785498489,
      "eval_loss": 1.3944127559661865,
      "eval_runtime": 1535.1734,
      "eval_samples_per_second": 34.588,
      "eval_steps_per_second": 0.27,
      "step": 45650
    },
    {
      "epoch": 13.806646525679758,
      "grad_norm": 0.5764722228050232,
      "learning_rate": 5.7462437059415914e-05,
      "loss": 1.3666,
      "step": 45700
    },
    {
      "epoch": 13.806646525679758,
      "eval_loss": 1.3942021131515503,
      "eval_runtime": 1503.0179,
      "eval_samples_per_second": 35.328,
      "eval_steps_per_second": 0.276,
      "step": 45700
    },
    {
      "epoch": 13.821752265861027,
      "grad_norm": 0.6815654039382935,
      "learning_rate": 5.745236656596173e-05,
      "loss": 1.3852,
      "step": 45750
    },
    {
      "epoch": 13.821752265861027,
      "eval_loss": 1.3926607370376587,
      "eval_runtime": 1524.5807,
      "eval_samples_per_second": 34.829,
      "eval_steps_per_second": 0.272,
      "step": 45750
    },
    {
      "epoch": 13.836858006042297,
      "grad_norm": 0.604233980178833,
      "learning_rate": 5.744229607250755e-05,
      "loss": 1.3644,
      "step": 45800
    },
    {
      "epoch": 13.836858006042297,
      "eval_loss": 1.3946688175201416,
      "eval_runtime": 1670.9362,
      "eval_samples_per_second": 31.778,
      "eval_steps_per_second": 0.248,
      "step": 45800
    },
    {
      "epoch": 13.851963746223564,
      "grad_norm": 0.5841574668884277,
      "learning_rate": 5.743222557905338e-05,
      "loss": 1.3673,
      "step": 45850
    },
    {
      "epoch": 13.851963746223564,
      "eval_loss": 1.3942042589187622,
      "eval_runtime": 1538.1601,
      "eval_samples_per_second": 34.521,
      "eval_steps_per_second": 0.27,
      "step": 45850
    },
    {
      "epoch": 13.867069486404834,
      "grad_norm": 0.6547210216522217,
      "learning_rate": 5.7422155085599195e-05,
      "loss": 1.375,
      "step": 45900
    },
    {
      "epoch": 13.867069486404834,
      "eval_loss": 1.391941785812378,
      "eval_runtime": 1500.2935,
      "eval_samples_per_second": 35.392,
      "eval_steps_per_second": 0.277,
      "step": 45900
    },
    {
      "epoch": 13.882175226586103,
      "grad_norm": 0.7161016464233398,
      "learning_rate": 5.7412084592145014e-05,
      "loss": 1.3711,
      "step": 45950
    },
    {
      "epoch": 13.882175226586103,
      "eval_loss": 1.392634630203247,
      "eval_runtime": 1501.4015,
      "eval_samples_per_second": 35.366,
      "eval_steps_per_second": 0.276,
      "step": 45950
    },
    {
      "epoch": 13.897280966767372,
      "grad_norm": 0.5929995179176331,
      "learning_rate": 5.740201409869083e-05,
      "loss": 1.3751,
      "step": 46000
    },
    {
      "epoch": 13.897280966767372,
      "eval_loss": 1.3928285837173462,
      "eval_runtime": 1696.358,
      "eval_samples_per_second": 31.302,
      "eval_steps_per_second": 0.245,
      "step": 46000
    },
    {
      "epoch": 13.91238670694864,
      "grad_norm": 0.6211075186729431,
      "learning_rate": 5.739194360523666e-05,
      "loss": 1.3509,
      "step": 46050
    },
    {
      "epoch": 13.91238670694864,
      "eval_loss": 1.394071340560913,
      "eval_runtime": 1559.5589,
      "eval_samples_per_second": 34.047,
      "eval_steps_per_second": 0.266,
      "step": 46050
    },
    {
      "epoch": 13.927492447129909,
      "grad_norm": 0.58050936460495,
      "learning_rate": 5.738187311178248e-05,
      "loss": 1.3668,
      "step": 46100
    },
    {
      "epoch": 13.927492447129909,
      "eval_loss": 1.393052577972412,
      "eval_runtime": 1622.4352,
      "eval_samples_per_second": 32.728,
      "eval_steps_per_second": 0.256,
      "step": 46100
    },
    {
      "epoch": 13.942598187311178,
      "grad_norm": 0.6002784371376038,
      "learning_rate": 5.7371802618328296e-05,
      "loss": 1.3882,
      "step": 46150
    },
    {
      "epoch": 13.942598187311178,
      "eval_loss": 1.3916966915130615,
      "eval_runtime": 1752.4667,
      "eval_samples_per_second": 30.3,
      "eval_steps_per_second": 0.237,
      "step": 46150
    },
    {
      "epoch": 13.957703927492448,
      "grad_norm": 0.6055322289466858,
      "learning_rate": 5.736173212487412e-05,
      "loss": 1.3976,
      "step": 46200
    },
    {
      "epoch": 13.957703927492448,
      "eval_loss": 1.3928228616714478,
      "eval_runtime": 1517.4688,
      "eval_samples_per_second": 34.992,
      "eval_steps_per_second": 0.273,
      "step": 46200
    },
    {
      "epoch": 13.972809667673715,
      "grad_norm": 0.5733835101127625,
      "learning_rate": 5.735166163141994e-05,
      "loss": 1.3924,
      "step": 46250
    },
    {
      "epoch": 13.972809667673715,
      "eval_loss": 1.3932138681411743,
      "eval_runtime": 1507.6428,
      "eval_samples_per_second": 35.22,
      "eval_steps_per_second": 0.275,
      "step": 46250
    },
    {
      "epoch": 13.987915407854985,
      "grad_norm": 0.5276346802711487,
      "learning_rate": 5.734159113796576e-05,
      "loss": 1.3555,
      "step": 46300
    },
    {
      "epoch": 13.987915407854985,
      "eval_loss": 1.3940232992172241,
      "eval_runtime": 1692.8444,
      "eval_samples_per_second": 31.367,
      "eval_steps_per_second": 0.245,
      "step": 46300
    },
    {
      "epoch": 14.003021148036254,
      "grad_norm": 0.5355077385902405,
      "learning_rate": 5.7331520644511584e-05,
      "loss": 1.3741,
      "step": 46350
    },
    {
      "epoch": 14.003021148036254,
      "eval_loss": 1.3896114826202393,
      "eval_runtime": 1465.4872,
      "eval_samples_per_second": 36.233,
      "eval_steps_per_second": 0.283,
      "step": 46350
    },
    {
      "epoch": 14.018126888217523,
      "grad_norm": 0.6153223514556885,
      "learning_rate": 5.732145015105741e-05,
      "loss": 1.3258,
      "step": 46400
    },
    {
      "epoch": 14.018126888217523,
      "eval_loss": 1.392286777496338,
      "eval_runtime": 1505.9346,
      "eval_samples_per_second": 35.26,
      "eval_steps_per_second": 0.276,
      "step": 46400
    },
    {
      "epoch": 14.03323262839879,
      "grad_norm": 0.5160367488861084,
      "learning_rate": 5.731137965760323e-05,
      "loss": 1.3906,
      "step": 46450
    },
    {
      "epoch": 14.03323262839879,
      "eval_loss": 1.3940770626068115,
      "eval_runtime": 1500.0805,
      "eval_samples_per_second": 35.397,
      "eval_steps_per_second": 0.277,
      "step": 46450
    },
    {
      "epoch": 14.04833836858006,
      "grad_norm": 0.6102373003959656,
      "learning_rate": 5.730130916414905e-05,
      "loss": 1.3827,
      "step": 46500
    },
    {
      "epoch": 14.04833836858006,
      "eval_loss": 1.3943649530410767,
      "eval_runtime": 1552.2858,
      "eval_samples_per_second": 34.207,
      "eval_steps_per_second": 0.267,
      "step": 46500
    },
    {
      "epoch": 14.06344410876133,
      "grad_norm": 0.6891878843307495,
      "learning_rate": 5.7291238670694866e-05,
      "loss": 1.383,
      "step": 46550
    },
    {
      "epoch": 14.06344410876133,
      "eval_loss": 1.3900055885314941,
      "eval_runtime": 1498.6167,
      "eval_samples_per_second": 35.432,
      "eval_steps_per_second": 0.277,
      "step": 46550
    },
    {
      "epoch": 14.078549848942599,
      "grad_norm": 0.5578047037124634,
      "learning_rate": 5.728116817724069e-05,
      "loss": 1.3561,
      "step": 46600
    },
    {
      "epoch": 14.078549848942599,
      "eval_loss": 1.3933576345443726,
      "eval_runtime": 1577.7462,
      "eval_samples_per_second": 33.655,
      "eval_steps_per_second": 0.263,
      "step": 46600
    },
    {
      "epoch": 14.093655589123866,
      "grad_norm": 0.6033040285110474,
      "learning_rate": 5.727109768378651e-05,
      "loss": 1.338,
      "step": 46650
    },
    {
      "epoch": 14.093655589123866,
      "eval_loss": 1.3901236057281494,
      "eval_runtime": 1655.3492,
      "eval_samples_per_second": 32.077,
      "eval_steps_per_second": 0.251,
      "step": 46650
    },
    {
      "epoch": 14.108761329305135,
      "grad_norm": 0.5554432272911072,
      "learning_rate": 5.726102719033233e-05,
      "loss": 1.3723,
      "step": 46700
    },
    {
      "epoch": 14.108761329305135,
      "eval_loss": 1.391386866569519,
      "eval_runtime": 1514.2839,
      "eval_samples_per_second": 35.065,
      "eval_steps_per_second": 0.274,
      "step": 46700
    },
    {
      "epoch": 14.123867069486405,
      "grad_norm": 0.5467498302459717,
      "learning_rate": 5.725095669687815e-05,
      "loss": 1.3814,
      "step": 46750
    },
    {
      "epoch": 14.123867069486405,
      "eval_loss": 1.391072392463684,
      "eval_runtime": 1527.1247,
      "eval_samples_per_second": 34.771,
      "eval_steps_per_second": 0.272,
      "step": 46750
    },
    {
      "epoch": 14.138972809667674,
      "grad_norm": 0.5374352335929871,
      "learning_rate": 5.724088620342397e-05,
      "loss": 1.3497,
      "step": 46800
    },
    {
      "epoch": 14.138972809667674,
      "eval_loss": 1.3936043977737427,
      "eval_runtime": 1580.7827,
      "eval_samples_per_second": 33.59,
      "eval_steps_per_second": 0.263,
      "step": 46800
    },
    {
      "epoch": 14.154078549848943,
      "grad_norm": 0.533883273601532,
      "learning_rate": 5.723081570996979e-05,
      "loss": 1.3681,
      "step": 46850
    },
    {
      "epoch": 14.154078549848943,
      "eval_loss": 1.390084981918335,
      "eval_runtime": 1519.9776,
      "eval_samples_per_second": 34.934,
      "eval_steps_per_second": 0.273,
      "step": 46850
    },
    {
      "epoch": 14.169184290030211,
      "grad_norm": 0.48672762513160706,
      "learning_rate": 5.722074521651561e-05,
      "loss": 1.369,
      "step": 46900
    },
    {
      "epoch": 14.169184290030211,
      "eval_loss": 1.3885021209716797,
      "eval_runtime": 1572.5258,
      "eval_samples_per_second": 33.767,
      "eval_steps_per_second": 0.264,
      "step": 46900
    },
    {
      "epoch": 14.18429003021148,
      "grad_norm": 0.5375825762748718,
      "learning_rate": 5.721067472306143e-05,
      "loss": 1.3496,
      "step": 46950
    },
    {
      "epoch": 14.18429003021148,
      "eval_loss": 1.3906584978103638,
      "eval_runtime": 1562.4486,
      "eval_samples_per_second": 33.984,
      "eval_steps_per_second": 0.266,
      "step": 46950
    },
    {
      "epoch": 14.19939577039275,
      "grad_norm": 0.5787410140037537,
      "learning_rate": 5.7200604229607254e-05,
      "loss": 1.3788,
      "step": 47000
    },
    {
      "epoch": 14.19939577039275,
      "eval_loss": 1.3930583000183105,
      "eval_runtime": 1571.5041,
      "eval_samples_per_second": 33.789,
      "eval_steps_per_second": 0.264,
      "step": 47000
    },
    {
      "epoch": 14.214501510574019,
      "grad_norm": 0.5620562434196472,
      "learning_rate": 5.719053373615307e-05,
      "loss": 1.3659,
      "step": 47050
    },
    {
      "epoch": 14.214501510574019,
      "eval_loss": 1.3903133869171143,
      "eval_runtime": 1515.4668,
      "eval_samples_per_second": 35.038,
      "eval_steps_per_second": 0.274,
      "step": 47050
    },
    {
      "epoch": 14.229607250755286,
      "grad_norm": 0.5434920191764832,
      "learning_rate": 5.718046324269889e-05,
      "loss": 1.3831,
      "step": 47100
    },
    {
      "epoch": 14.229607250755286,
      "eval_loss": 1.3911842107772827,
      "eval_runtime": 1532.7962,
      "eval_samples_per_second": 34.642,
      "eval_steps_per_second": 0.271,
      "step": 47100
    },
    {
      "epoch": 14.244712990936556,
      "grad_norm": 0.556407630443573,
      "learning_rate": 5.717039274924471e-05,
      "loss": 1.3682,
      "step": 47150
    },
    {
      "epoch": 14.244712990936556,
      "eval_loss": 1.3898327350616455,
      "eval_runtime": 1497.3813,
      "eval_samples_per_second": 35.461,
      "eval_steps_per_second": 0.277,
      "step": 47150
    },
    {
      "epoch": 14.259818731117825,
      "grad_norm": 0.5277171730995178,
      "learning_rate": 5.7160322255790536e-05,
      "loss": 1.3719,
      "step": 47200
    },
    {
      "epoch": 14.259818731117825,
      "eval_loss": 1.3907973766326904,
      "eval_runtime": 1521.4602,
      "eval_samples_per_second": 34.9,
      "eval_steps_per_second": 0.273,
      "step": 47200
    },
    {
      "epoch": 14.274924471299094,
      "grad_norm": 0.5781939625740051,
      "learning_rate": 5.7150251762336354e-05,
      "loss": 1.338,
      "step": 47250
    },
    {
      "epoch": 14.274924471299094,
      "eval_loss": 1.3882986307144165,
      "eval_runtime": 2029.7779,
      "eval_samples_per_second": 26.16,
      "eval_steps_per_second": 0.204,
      "step": 47250
    },
    {
      "epoch": 14.290030211480362,
      "grad_norm": 0.604358434677124,
      "learning_rate": 5.714018126888217e-05,
      "loss": 1.383,
      "step": 47300
    },
    {
      "epoch": 14.290030211480362,
      "eval_loss": 1.3881109952926636,
      "eval_runtime": 2011.6918,
      "eval_samples_per_second": 26.395,
      "eval_steps_per_second": 0.206,
      "step": 47300
    },
    {
      "epoch": 14.305135951661631,
      "grad_norm": 0.5209693312644958,
      "learning_rate": 5.7130110775428e-05,
      "loss": 1.3505,
      "step": 47350
    },
    {
      "epoch": 14.305135951661631,
      "eval_loss": 1.3868844509124756,
      "eval_runtime": 1684.4756,
      "eval_samples_per_second": 31.523,
      "eval_steps_per_second": 0.246,
      "step": 47350
    },
    {
      "epoch": 14.3202416918429,
      "grad_norm": 0.5657762885093689,
      "learning_rate": 5.712004028197382e-05,
      "loss": 1.3683,
      "step": 47400
    },
    {
      "epoch": 14.3202416918429,
      "eval_loss": 1.3870848417282104,
      "eval_runtime": 1930.4188,
      "eval_samples_per_second": 27.506,
      "eval_steps_per_second": 0.215,
      "step": 47400
    },
    {
      "epoch": 14.33534743202417,
      "grad_norm": 0.5637296438217163,
      "learning_rate": 5.7109969788519636e-05,
      "loss": 1.3511,
      "step": 47450
    },
    {
      "epoch": 14.33534743202417,
      "eval_loss": 1.3882917165756226,
      "eval_runtime": 1498.8979,
      "eval_samples_per_second": 35.425,
      "eval_steps_per_second": 0.277,
      "step": 47450
    },
    {
      "epoch": 14.350453172205437,
      "grad_norm": 0.6201141476631165,
      "learning_rate": 5.7099899295065454e-05,
      "loss": 1.3833,
      "step": 47500
    },
    {
      "epoch": 14.350453172205437,
      "eval_loss": 1.3894457817077637,
      "eval_runtime": 1599.2075,
      "eval_samples_per_second": 33.203,
      "eval_steps_per_second": 0.26,
      "step": 47500
    },
    {
      "epoch": 14.365558912386707,
      "grad_norm": 0.5870910882949829,
      "learning_rate": 5.708982880161129e-05,
      "loss": 1.3799,
      "step": 47550
    },
    {
      "epoch": 14.365558912386707,
      "eval_loss": 1.3899340629577637,
      "eval_runtime": 1535.8171,
      "eval_samples_per_second": 34.574,
      "eval_steps_per_second": 0.27,
      "step": 47550
    },
    {
      "epoch": 14.380664652567976,
      "grad_norm": 0.5204420685768127,
      "learning_rate": 5.7079758308157105e-05,
      "loss": 1.3751,
      "step": 47600
    },
    {
      "epoch": 14.380664652567976,
      "eval_loss": 1.3901152610778809,
      "eval_runtime": 1524.7557,
      "eval_samples_per_second": 34.825,
      "eval_steps_per_second": 0.272,
      "step": 47600
    },
    {
      "epoch": 14.395770392749245,
      "grad_norm": 0.5363486409187317,
      "learning_rate": 5.7069687814702924e-05,
      "loss": 1.3705,
      "step": 47650
    },
    {
      "epoch": 14.395770392749245,
      "eval_loss": 1.3879847526550293,
      "eval_runtime": 1946.8669,
      "eval_samples_per_second": 27.274,
      "eval_steps_per_second": 0.213,
      "step": 47650
    },
    {
      "epoch": 14.410876132930513,
      "grad_norm": 0.606777012348175,
      "learning_rate": 5.705961732124874e-05,
      "loss": 1.3677,
      "step": 47700
    },
    {
      "epoch": 14.410876132930513,
      "eval_loss": 1.387853980064392,
      "eval_runtime": 1531.2709,
      "eval_samples_per_second": 34.676,
      "eval_steps_per_second": 0.271,
      "step": 47700
    },
    {
      "epoch": 14.425981873111782,
      "grad_norm": 0.5702624917030334,
      "learning_rate": 5.704954682779457e-05,
      "loss": 1.3584,
      "step": 47750
    },
    {
      "epoch": 14.425981873111782,
      "eval_loss": 1.3889241218566895,
      "eval_runtime": 1537.7431,
      "eval_samples_per_second": 34.53,
      "eval_steps_per_second": 0.27,
      "step": 47750
    },
    {
      "epoch": 14.441087613293051,
      "grad_norm": 0.5179279446601868,
      "learning_rate": 5.703947633434039e-05,
      "loss": 1.3866,
      "step": 47800
    },
    {
      "epoch": 14.441087613293051,
      "eval_loss": 1.3873579502105713,
      "eval_runtime": 2128.5052,
      "eval_samples_per_second": 24.947,
      "eval_steps_per_second": 0.195,
      "step": 47800
    },
    {
      "epoch": 14.45619335347432,
      "grad_norm": 0.52354496717453,
      "learning_rate": 5.7029405840886206e-05,
      "loss": 1.3562,
      "step": 47850
    },
    {
      "epoch": 14.45619335347432,
      "eval_loss": 1.3887327909469604,
      "eval_runtime": 1529.8155,
      "eval_samples_per_second": 34.709,
      "eval_steps_per_second": 0.271,
      "step": 47850
    },
    {
      "epoch": 14.471299093655588,
      "grad_norm": 0.5514571666717529,
      "learning_rate": 5.7019335347432024e-05,
      "loss": 1.3556,
      "step": 47900
    },
    {
      "epoch": 14.471299093655588,
      "eval_loss": 1.3885271549224854,
      "eval_runtime": 1705.8291,
      "eval_samples_per_second": 31.128,
      "eval_steps_per_second": 0.243,
      "step": 47900
    },
    {
      "epoch": 14.486404833836858,
      "grad_norm": 0.49099165201187134,
      "learning_rate": 5.700926485397785e-05,
      "loss": 1.3603,
      "step": 47950
    },
    {
      "epoch": 14.486404833836858,
      "eval_loss": 1.3846416473388672,
      "eval_runtime": 1515.4302,
      "eval_samples_per_second": 35.039,
      "eval_steps_per_second": 0.274,
      "step": 47950
    },
    {
      "epoch": 14.501510574018127,
      "grad_norm": 0.5966735482215881,
      "learning_rate": 5.699919436052367e-05,
      "loss": 1.3677,
      "step": 48000
    },
    {
      "epoch": 14.501510574018127,
      "eval_loss": 1.3856316804885864,
      "eval_runtime": 1574.7409,
      "eval_samples_per_second": 33.719,
      "eval_steps_per_second": 0.264,
      "step": 48000
    },
    {
      "epoch": 14.516616314199396,
      "grad_norm": 0.5021581649780273,
      "learning_rate": 5.698912386706949e-05,
      "loss": 1.3407,
      "step": 48050
    },
    {
      "epoch": 14.516616314199396,
      "eval_loss": 1.3879389762878418,
      "eval_runtime": 1530.3633,
      "eval_samples_per_second": 34.697,
      "eval_steps_per_second": 0.271,
      "step": 48050
    },
    {
      "epoch": 14.531722054380666,
      "grad_norm": 0.57292640209198,
      "learning_rate": 5.6979053373615306e-05,
      "loss": 1.3625,
      "step": 48100
    },
    {
      "epoch": 14.531722054380666,
      "eval_loss": 1.386364459991455,
      "eval_runtime": 1546.3785,
      "eval_samples_per_second": 34.338,
      "eval_steps_per_second": 0.268,
      "step": 48100
    },
    {
      "epoch": 14.546827794561933,
      "grad_norm": 0.587098240852356,
      "learning_rate": 5.696898288016113e-05,
      "loss": 1.3464,
      "step": 48150
    },
    {
      "epoch": 14.546827794561933,
      "eval_loss": 1.3870843648910522,
      "eval_runtime": 1493.2956,
      "eval_samples_per_second": 35.558,
      "eval_steps_per_second": 0.278,
      "step": 48150
    },
    {
      "epoch": 14.561933534743202,
      "grad_norm": 0.6023491621017456,
      "learning_rate": 5.695891238670695e-05,
      "loss": 1.3677,
      "step": 48200
    },
    {
      "epoch": 14.561933534743202,
      "eval_loss": 1.385825753211975,
      "eval_runtime": 1605.8189,
      "eval_samples_per_second": 33.067,
      "eval_steps_per_second": 0.258,
      "step": 48200
    },
    {
      "epoch": 14.577039274924472,
      "grad_norm": 0.6233184337615967,
      "learning_rate": 5.694884189325277e-05,
      "loss": 1.3677,
      "step": 48250
    },
    {
      "epoch": 14.577039274924472,
      "eval_loss": 1.3880068063735962,
      "eval_runtime": 1615.7441,
      "eval_samples_per_second": 32.863,
      "eval_steps_per_second": 0.257,
      "step": 48250
    },
    {
      "epoch": 14.59214501510574,
      "grad_norm": 0.529735267162323,
      "learning_rate": 5.693877139979859e-05,
      "loss": 1.3429,
      "step": 48300
    },
    {
      "epoch": 14.59214501510574,
      "eval_loss": 1.3884239196777344,
      "eval_runtime": 1601.0133,
      "eval_samples_per_second": 33.166,
      "eval_steps_per_second": 0.259,
      "step": 48300
    },
    {
      "epoch": 14.607250755287009,
      "grad_norm": 0.6030406951904297,
      "learning_rate": 5.692870090634441e-05,
      "loss": 1.3462,
      "step": 48350
    },
    {
      "epoch": 14.607250755287009,
      "eval_loss": 1.3824281692504883,
      "eval_runtime": 1492.6797,
      "eval_samples_per_second": 35.573,
      "eval_steps_per_second": 0.278,
      "step": 48350
    },
    {
      "epoch": 14.622356495468278,
      "grad_norm": 0.5060774683952332,
      "learning_rate": 5.691863041289023e-05,
      "loss": 1.3618,
      "step": 48400
    },
    {
      "epoch": 14.622356495468278,
      "eval_loss": 1.3865457773208618,
      "eval_runtime": 1578.9656,
      "eval_samples_per_second": 33.629,
      "eval_steps_per_second": 0.263,
      "step": 48400
    },
    {
      "epoch": 14.637462235649547,
      "grad_norm": 0.5145888924598694,
      "learning_rate": 5.690855991943605e-05,
      "loss": 1.3773,
      "step": 48450
    },
    {
      "epoch": 14.637462235649547,
      "eval_loss": 1.3873145580291748,
      "eval_runtime": 1467.8568,
      "eval_samples_per_second": 36.175,
      "eval_steps_per_second": 0.283,
      "step": 48450
    },
    {
      "epoch": 14.652567975830816,
      "grad_norm": 0.5471309423446655,
      "learning_rate": 5.6898489425981876e-05,
      "loss": 1.3518,
      "step": 48500
    },
    {
      "epoch": 14.652567975830816,
      "eval_loss": 1.3861390352249146,
      "eval_runtime": 1532.749,
      "eval_samples_per_second": 34.643,
      "eval_steps_per_second": 0.271,
      "step": 48500
    },
    {
      "epoch": 14.667673716012084,
      "grad_norm": 0.5711308717727661,
      "learning_rate": 5.6888418932527694e-05,
      "loss": 1.3644,
      "step": 48550
    },
    {
      "epoch": 14.667673716012084,
      "eval_loss": 1.3851412534713745,
      "eval_runtime": 1561.9462,
      "eval_samples_per_second": 33.995,
      "eval_steps_per_second": 0.266,
      "step": 48550
    },
    {
      "epoch": 14.682779456193353,
      "grad_norm": 0.5498450994491577,
      "learning_rate": 5.687834843907351e-05,
      "loss": 1.3831,
      "step": 48600
    },
    {
      "epoch": 14.682779456193353,
      "eval_loss": 1.3850971460342407,
      "eval_runtime": 1675.5309,
      "eval_samples_per_second": 31.691,
      "eval_steps_per_second": 0.248,
      "step": 48600
    },
    {
      "epoch": 14.697885196374623,
      "grad_norm": 0.6010122895240784,
      "learning_rate": 5.686827794561933e-05,
      "loss": 1.3778,
      "step": 48650
    },
    {
      "epoch": 14.697885196374623,
      "eval_loss": 1.3835530281066895,
      "eval_runtime": 1542.318,
      "eval_samples_per_second": 34.428,
      "eval_steps_per_second": 0.269,
      "step": 48650
    },
    {
      "epoch": 14.712990936555892,
      "grad_norm": 0.5248005390167236,
      "learning_rate": 5.6858207452165164e-05,
      "loss": 1.3679,
      "step": 48700
    },
    {
      "epoch": 14.712990936555892,
      "eval_loss": 1.3863368034362793,
      "eval_runtime": 1478.4751,
      "eval_samples_per_second": 35.915,
      "eval_steps_per_second": 0.281,
      "step": 48700
    },
    {
      "epoch": 14.72809667673716,
      "grad_norm": 0.6067065596580505,
      "learning_rate": 5.684813695871098e-05,
      "loss": 1.3632,
      "step": 48750
    },
    {
      "epoch": 14.72809667673716,
      "eval_loss": 1.3854436874389648,
      "eval_runtime": 2939.872,
      "eval_samples_per_second": 18.062,
      "eval_steps_per_second": 0.141,
      "step": 48750
    },
    {
      "epoch": 14.743202416918429,
      "grad_norm": 0.6191179752349854,
      "learning_rate": 5.68380664652568e-05,
      "loss": 1.3802,
      "step": 48800
    },
    {
      "epoch": 14.743202416918429,
      "eval_loss": 1.3846242427825928,
      "eval_runtime": 1699.1559,
      "eval_samples_per_second": 31.25,
      "eval_steps_per_second": 0.244,
      "step": 48800
    },
    {
      "epoch": 14.758308157099698,
      "grad_norm": 0.5931519865989685,
      "learning_rate": 5.682799597180262e-05,
      "loss": 1.3607,
      "step": 48850
    },
    {
      "epoch": 14.758308157099698,
      "eval_loss": 1.383469581604004,
      "eval_runtime": 1565.7087,
      "eval_samples_per_second": 33.914,
      "eval_steps_per_second": 0.265,
      "step": 48850
    },
    {
      "epoch": 14.773413897280967,
      "grad_norm": 0.5412018895149231,
      "learning_rate": 5.6817925478348445e-05,
      "loss": 1.3544,
      "step": 48900
    },
    {
      "epoch": 14.773413897280967,
      "eval_loss": 1.3845223188400269,
      "eval_runtime": 1553.7284,
      "eval_samples_per_second": 34.175,
      "eval_steps_per_second": 0.267,
      "step": 48900
    },
    {
      "epoch": 14.788519637462235,
      "grad_norm": 0.5954903364181519,
      "learning_rate": 5.6807854984894264e-05,
      "loss": 1.3445,
      "step": 48950
    },
    {
      "epoch": 14.788519637462235,
      "eval_loss": 1.3861117362976074,
      "eval_runtime": 1514.8019,
      "eval_samples_per_second": 35.053,
      "eval_steps_per_second": 0.274,
      "step": 48950
    },
    {
      "epoch": 14.803625377643504,
      "grad_norm": 0.5884648561477661,
      "learning_rate": 5.679778449144008e-05,
      "loss": 1.3775,
      "step": 49000
    },
    {
      "epoch": 14.803625377643504,
      "eval_loss": 1.3854138851165771,
      "eval_runtime": 1504.8388,
      "eval_samples_per_second": 35.286,
      "eval_steps_per_second": 0.276,
      "step": 49000
    },
    {
      "epoch": 14.818731117824774,
      "grad_norm": 0.5269038677215576,
      "learning_rate": 5.67877139979859e-05,
      "loss": 1.3848,
      "step": 49050
    },
    {
      "epoch": 14.818731117824774,
      "eval_loss": 1.3827829360961914,
      "eval_runtime": 1599.9649,
      "eval_samples_per_second": 33.188,
      "eval_steps_per_second": 0.259,
      "step": 49050
    },
    {
      "epoch": 14.833836858006043,
      "grad_norm": 0.5337154269218445,
      "learning_rate": 5.677764350453173e-05,
      "loss": 1.3539,
      "step": 49100
    },
    {
      "epoch": 14.833836858006043,
      "eval_loss": 1.3827669620513916,
      "eval_runtime": 1514.0434,
      "eval_samples_per_second": 35.071,
      "eval_steps_per_second": 0.274,
      "step": 49100
    },
    {
      "epoch": 14.84894259818731,
      "grad_norm": 0.5625326633453369,
      "learning_rate": 5.6767573011077546e-05,
      "loss": 1.3595,
      "step": 49150
    },
    {
      "epoch": 14.84894259818731,
      "eval_loss": 1.382725477218628,
      "eval_runtime": 1616.2609,
      "eval_samples_per_second": 32.853,
      "eval_steps_per_second": 0.257,
      "step": 49150
    },
    {
      "epoch": 14.86404833836858,
      "grad_norm": 0.5364956259727478,
      "learning_rate": 5.6757502517623364e-05,
      "loss": 1.3585,
      "step": 49200
    },
    {
      "epoch": 14.86404833836858,
      "eval_loss": 1.383605718612671,
      "eval_runtime": 1564.5714,
      "eval_samples_per_second": 33.938,
      "eval_steps_per_second": 0.265,
      "step": 49200
    },
    {
      "epoch": 14.879154078549849,
      "grad_norm": 0.5772152543067932,
      "learning_rate": 5.674743202416918e-05,
      "loss": 1.3571,
      "step": 49250
    },
    {
      "epoch": 14.879154078549849,
      "eval_loss": 1.3826920986175537,
      "eval_runtime": 2156.5444,
      "eval_samples_per_second": 24.622,
      "eval_steps_per_second": 0.192,
      "step": 49250
    },
    {
      "epoch": 14.894259818731118,
      "grad_norm": 0.5076730251312256,
      "learning_rate": 5.673736153071501e-05,
      "loss": 1.3706,
      "step": 49300
    },
    {
      "epoch": 14.894259818731118,
      "eval_loss": 1.3823692798614502,
      "eval_runtime": 1529.4391,
      "eval_samples_per_second": 34.718,
      "eval_steps_per_second": 0.271,
      "step": 49300
    },
    {
      "epoch": 14.909365558912386,
      "grad_norm": 0.5434141755104065,
      "learning_rate": 5.672729103726083e-05,
      "loss": 1.3476,
      "step": 49350
    },
    {
      "epoch": 14.909365558912386,
      "eval_loss": 1.3838744163513184,
      "eval_runtime": 1573.1311,
      "eval_samples_per_second": 33.754,
      "eval_steps_per_second": 0.264,
      "step": 49350
    },
    {
      "epoch": 14.924471299093655,
      "grad_norm": 0.5556861162185669,
      "learning_rate": 5.6717220543806646e-05,
      "loss": 1.3568,
      "step": 49400
    },
    {
      "epoch": 14.924471299093655,
      "eval_loss": 1.3820769786834717,
      "eval_runtime": 1540.0141,
      "eval_samples_per_second": 34.48,
      "eval_steps_per_second": 0.269,
      "step": 49400
    },
    {
      "epoch": 14.939577039274925,
      "grad_norm": 0.5378739237785339,
      "learning_rate": 5.6707150050352464e-05,
      "loss": 1.3499,
      "step": 49450
    },
    {
      "epoch": 14.939577039274925,
      "eval_loss": 1.3801205158233643,
      "eval_runtime": 1485.0133,
      "eval_samples_per_second": 35.757,
      "eval_steps_per_second": 0.279,
      "step": 49450
    },
    {
      "epoch": 14.954682779456194,
      "grad_norm": 0.531771719455719,
      "learning_rate": 5.669707955689829e-05,
      "loss": 1.3641,
      "step": 49500
    },
    {
      "epoch": 14.954682779456194,
      "eval_loss": 1.3814969062805176,
      "eval_runtime": 1542.1552,
      "eval_samples_per_second": 34.432,
      "eval_steps_per_second": 0.269,
      "step": 49500
    },
    {
      "epoch": 14.969788519637461,
      "grad_norm": 0.5376490950584412,
      "learning_rate": 5.668700906344411e-05,
      "loss": 1.3576,
      "step": 49550
    },
    {
      "epoch": 14.969788519637461,
      "eval_loss": 1.3811825513839722,
      "eval_runtime": 1612.26,
      "eval_samples_per_second": 32.935,
      "eval_steps_per_second": 0.257,
      "step": 49550
    },
    {
      "epoch": 14.98489425981873,
      "grad_norm": 0.5820741057395935,
      "learning_rate": 5.667693856998993e-05,
      "loss": 1.3474,
      "step": 49600
    },
    {
      "epoch": 14.98489425981873,
      "eval_loss": 1.3807107210159302,
      "eval_runtime": 1478.8546,
      "eval_samples_per_second": 35.905,
      "eval_steps_per_second": 0.281,
      "step": 49600
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.5892369747161865,
      "learning_rate": 5.666686807653575e-05,
      "loss": 1.3467,
      "step": 49650
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.3811980485916138,
      "eval_runtime": 1633.0045,
      "eval_samples_per_second": 32.516,
      "eval_steps_per_second": 0.254,
      "step": 49650
    },
    {
      "epoch": 15.01510574018127,
      "grad_norm": 0.49185627698898315,
      "learning_rate": 5.665679758308157e-05,
      "loss": 1.3399,
      "step": 49700
    },
    {
      "epoch": 15.01510574018127,
      "eval_loss": 1.3819403648376465,
      "eval_runtime": 1517.0338,
      "eval_samples_per_second": 35.002,
      "eval_steps_per_second": 0.274,
      "step": 49700
    },
    {
      "epoch": 15.030211480362539,
      "grad_norm": 0.581073522567749,
      "learning_rate": 5.664672708962739e-05,
      "loss": 1.3516,
      "step": 49750
    },
    {
      "epoch": 15.030211480362539,
      "eval_loss": 1.3797481060028076,
      "eval_runtime": 1539.1287,
      "eval_samples_per_second": 34.499,
      "eval_steps_per_second": 0.27,
      "step": 49750
    },
    {
      "epoch": 15.045317220543806,
      "grad_norm": 0.498614639043808,
      "learning_rate": 5.663665659617321e-05,
      "loss": 1.3578,
      "step": 49800
    },
    {
      "epoch": 15.045317220543806,
      "eval_loss": 1.3795216083526611,
      "eval_runtime": 1662.7948,
      "eval_samples_per_second": 31.934,
      "eval_steps_per_second": 0.25,
      "step": 49800
    },
    {
      "epoch": 15.060422960725075,
      "grad_norm": 0.4996922016143799,
      "learning_rate": 5.662658610271904e-05,
      "loss": 1.3618,
      "step": 49850
    },
    {
      "epoch": 15.060422960725075,
      "eval_loss": 1.3788981437683105,
      "eval_runtime": 1595.2445,
      "eval_samples_per_second": 33.286,
      "eval_steps_per_second": 0.26,
      "step": 49850
    },
    {
      "epoch": 15.075528700906345,
      "grad_norm": 0.5410614609718323,
      "learning_rate": 5.661651560926486e-05,
      "loss": 1.3481,
      "step": 49900
    },
    {
      "epoch": 15.075528700906345,
      "eval_loss": 1.3824630975723267,
      "eval_runtime": 1517.7328,
      "eval_samples_per_second": 34.986,
      "eval_steps_per_second": 0.273,
      "step": 49900
    },
    {
      "epoch": 15.090634441087614,
      "grad_norm": 0.510749101638794,
      "learning_rate": 5.660644511581068e-05,
      "loss": 1.3485,
      "step": 49950
    },
    {
      "epoch": 15.090634441087614,
      "eval_loss": 1.380532145500183,
      "eval_runtime": 1569.19,
      "eval_samples_per_second": 33.838,
      "eval_steps_per_second": 0.264,
      "step": 49950
    },
    {
      "epoch": 15.105740181268882,
      "grad_norm": 0.5680515170097351,
      "learning_rate": 5.65963746223565e-05,
      "loss": 1.3655,
      "step": 50000
    },
    {
      "epoch": 15.105740181268882,
      "eval_loss": 1.3794084787368774,
      "eval_runtime": 1671.0201,
      "eval_samples_per_second": 31.776,
      "eval_steps_per_second": 0.248,
      "step": 50000
    },
    {
      "epoch": 15.120845921450151,
      "grad_norm": 0.4828715920448303,
      "learning_rate": 5.658630412890232e-05,
      "loss": 1.3493,
      "step": 50050
    },
    {
      "epoch": 15.120845921450151,
      "eval_loss": 1.3834978342056274,
      "eval_runtime": 1480.8131,
      "eval_samples_per_second": 35.858,
      "eval_steps_per_second": 0.28,
      "step": 50050
    },
    {
      "epoch": 15.13595166163142,
      "grad_norm": 0.579380452632904,
      "learning_rate": 5.657623363544814e-05,
      "loss": 1.3768,
      "step": 50100
    },
    {
      "epoch": 15.13595166163142,
      "eval_loss": 1.3796296119689941,
      "eval_runtime": 1581.844,
      "eval_samples_per_second": 33.568,
      "eval_steps_per_second": 0.262,
      "step": 50100
    },
    {
      "epoch": 15.15105740181269,
      "grad_norm": 0.5702747702598572,
      "learning_rate": 5.656616314199396e-05,
      "loss": 1.3746,
      "step": 50150
    },
    {
      "epoch": 15.15105740181269,
      "eval_loss": 1.3804144859313965,
      "eval_runtime": 1545.5626,
      "eval_samples_per_second": 34.356,
      "eval_steps_per_second": 0.269,
      "step": 50150
    },
    {
      "epoch": 15.166163141993957,
      "grad_norm": 0.5343189239501953,
      "learning_rate": 5.655609264853978e-05,
      "loss": 1.3615,
      "step": 50200
    },
    {
      "epoch": 15.166163141993957,
      "eval_loss": 1.381568431854248,
      "eval_runtime": 1830.5008,
      "eval_samples_per_second": 29.008,
      "eval_steps_per_second": 0.227,
      "step": 50200
    },
    {
      "epoch": 15.181268882175226,
      "grad_norm": 0.5245643854141235,
      "learning_rate": 5.6546022155085604e-05,
      "loss": 1.3576,
      "step": 50250
    },
    {
      "epoch": 15.181268882175226,
      "eval_loss": 1.3805354833602905,
      "eval_runtime": 1658.5541,
      "eval_samples_per_second": 32.015,
      "eval_steps_per_second": 0.25,
      "step": 50250
    },
    {
      "epoch": 15.196374622356496,
      "grad_norm": 0.6302180886268616,
      "learning_rate": 5.653595166163142e-05,
      "loss": 1.3322,
      "step": 50300
    },
    {
      "epoch": 15.196374622356496,
      "eval_loss": 1.3799763917922974,
      "eval_runtime": 1563.9281,
      "eval_samples_per_second": 33.952,
      "eval_steps_per_second": 0.265,
      "step": 50300
    },
    {
      "epoch": 15.211480362537765,
      "grad_norm": 0.5305684804916382,
      "learning_rate": 5.652588116817724e-05,
      "loss": 1.3401,
      "step": 50350
    },
    {
      "epoch": 15.211480362537765,
      "eval_loss": 1.3801616430282593,
      "eval_runtime": 1455.9442,
      "eval_samples_per_second": 36.47,
      "eval_steps_per_second": 0.285,
      "step": 50350
    },
    {
      "epoch": 15.226586102719033,
      "grad_norm": 0.5539216995239258,
      "learning_rate": 5.651581067472306e-05,
      "loss": 1.3728,
      "step": 50400
    },
    {
      "epoch": 15.226586102719033,
      "eval_loss": 1.3789219856262207,
      "eval_runtime": 1509.2392,
      "eval_samples_per_second": 35.183,
      "eval_steps_per_second": 0.275,
      "step": 50400
    },
    {
      "epoch": 15.241691842900302,
      "grad_norm": 0.5350661873817444,
      "learning_rate": 5.6505740181268886e-05,
      "loss": 1.3615,
      "step": 50450
    },
    {
      "epoch": 15.241691842900302,
      "eval_loss": 1.3806977272033691,
      "eval_runtime": 1528.9745,
      "eval_samples_per_second": 34.729,
      "eval_steps_per_second": 0.271,
      "step": 50450
    },
    {
      "epoch": 15.256797583081571,
      "grad_norm": 0.6050390005111694,
      "learning_rate": 5.6495669687814704e-05,
      "loss": 1.364,
      "step": 50500
    },
    {
      "epoch": 15.256797583081571,
      "eval_loss": 1.3774679899215698,
      "eval_runtime": 1504.559,
      "eval_samples_per_second": 35.292,
      "eval_steps_per_second": 0.276,
      "step": 50500
    },
    {
      "epoch": 15.27190332326284,
      "grad_norm": 0.5881174206733704,
      "learning_rate": 5.648559919436052e-05,
      "loss": 1.3721,
      "step": 50550
    },
    {
      "epoch": 15.27190332326284,
      "eval_loss": 1.3764921426773071,
      "eval_runtime": 1563.2738,
      "eval_samples_per_second": 33.967,
      "eval_steps_per_second": 0.265,
      "step": 50550
    },
    {
      "epoch": 15.287009063444108,
      "grad_norm": 0.4914150536060333,
      "learning_rate": 5.647552870090634e-05,
      "loss": 1.3569,
      "step": 50600
    },
    {
      "epoch": 15.287009063444108,
      "eval_loss": 1.3778728246688843,
      "eval_runtime": 1566.7508,
      "eval_samples_per_second": 33.891,
      "eval_steps_per_second": 0.265,
      "step": 50600
    },
    {
      "epoch": 15.302114803625377,
      "grad_norm": 0.5096219778060913,
      "learning_rate": 5.646545820745217e-05,
      "loss": 1.3637,
      "step": 50650
    },
    {
      "epoch": 15.302114803625377,
      "eval_loss": 1.3772437572479248,
      "eval_runtime": 1533.6884,
      "eval_samples_per_second": 34.622,
      "eval_steps_per_second": 0.271,
      "step": 50650
    },
    {
      "epoch": 15.317220543806647,
      "grad_norm": 0.5605212450027466,
      "learning_rate": 5.6455387713997986e-05,
      "loss": 1.3594,
      "step": 50700
    },
    {
      "epoch": 15.317220543806647,
      "eval_loss": 1.3776124715805054,
      "eval_runtime": 1499.2646,
      "eval_samples_per_second": 35.417,
      "eval_steps_per_second": 0.277,
      "step": 50700
    },
    {
      "epoch": 15.332326283987916,
      "grad_norm": 0.5529459118843079,
      "learning_rate": 5.6445317220543804e-05,
      "loss": 1.3578,
      "step": 50750
    },
    {
      "epoch": 15.332326283987916,
      "eval_loss": 1.3802775144577026,
      "eval_runtime": 1589.4553,
      "eval_samples_per_second": 33.407,
      "eval_steps_per_second": 0.261,
      "step": 50750
    },
    {
      "epoch": 15.347432024169184,
      "grad_norm": 0.5114065408706665,
      "learning_rate": 5.643524672708963e-05,
      "loss": 1.3484,
      "step": 50800
    },
    {
      "epoch": 15.347432024169184,
      "eval_loss": 1.3796626329421997,
      "eval_runtime": 1546.8921,
      "eval_samples_per_second": 34.326,
      "eval_steps_per_second": 0.268,
      "step": 50800
    },
    {
      "epoch": 15.362537764350453,
      "grad_norm": 0.537864625453949,
      "learning_rate": 5.642517623363545e-05,
      "loss": 1.3237,
      "step": 50850
    },
    {
      "epoch": 15.362537764350453,
      "eval_loss": 1.380536437034607,
      "eval_runtime": 1593.2401,
      "eval_samples_per_second": 33.328,
      "eval_steps_per_second": 0.26,
      "step": 50850
    },
    {
      "epoch": 15.377643504531722,
      "grad_norm": 0.5423424243927002,
      "learning_rate": 5.641510574018127e-05,
      "loss": 1.3721,
      "step": 50900
    },
    {
      "epoch": 15.377643504531722,
      "eval_loss": 1.3773092031478882,
      "eval_runtime": 1502.178,
      "eval_samples_per_second": 35.348,
      "eval_steps_per_second": 0.276,
      "step": 50900
    },
    {
      "epoch": 15.392749244712991,
      "grad_norm": 0.5060034394264221,
      "learning_rate": 5.6405035246727086e-05,
      "loss": 1.3553,
      "step": 50950
    },
    {
      "epoch": 15.392749244712991,
      "eval_loss": 1.3787641525268555,
      "eval_runtime": 1551.1692,
      "eval_samples_per_second": 34.232,
      "eval_steps_per_second": 0.268,
      "step": 50950
    },
    {
      "epoch": 15.407854984894259,
      "grad_norm": 0.5859330892562866,
      "learning_rate": 5.639496475327292e-05,
      "loss": 1.3553,
      "step": 51000
    },
    {
      "epoch": 15.407854984894259,
      "eval_loss": 1.3798367977142334,
      "eval_runtime": 1519.2165,
      "eval_samples_per_second": 34.952,
      "eval_steps_per_second": 0.273,
      "step": 51000
    },
    {
      "epoch": 15.422960725075528,
      "grad_norm": 0.5282493829727173,
      "learning_rate": 5.638489425981874e-05,
      "loss": 1.3786,
      "step": 51050
    },
    {
      "epoch": 15.422960725075528,
      "eval_loss": 1.3761917352676392,
      "eval_runtime": 1569.208,
      "eval_samples_per_second": 33.838,
      "eval_steps_per_second": 0.264,
      "step": 51050
    },
    {
      "epoch": 15.438066465256798,
      "grad_norm": 0.566554605960846,
      "learning_rate": 5.6374823766364556e-05,
      "loss": 1.3415,
      "step": 51100
    },
    {
      "epoch": 15.438066465256798,
      "eval_loss": 1.3751587867736816,
      "eval_runtime": 1549.6288,
      "eval_samples_per_second": 34.266,
      "eval_steps_per_second": 0.268,
      "step": 51100
    },
    {
      "epoch": 15.453172205438067,
      "grad_norm": 0.5818085670471191,
      "learning_rate": 5.6364753272910374e-05,
      "loss": 1.3499,
      "step": 51150
    },
    {
      "epoch": 15.453172205438067,
      "eval_loss": 1.375824213027954,
      "eval_runtime": 1510.0351,
      "eval_samples_per_second": 35.164,
      "eval_steps_per_second": 0.275,
      "step": 51150
    },
    {
      "epoch": 15.468277945619334,
      "grad_norm": 0.5111041069030762,
      "learning_rate": 5.63546827794562e-05,
      "loss": 1.3455,
      "step": 51200
    },
    {
      "epoch": 15.468277945619334,
      "eval_loss": 1.3761558532714844,
      "eval_runtime": 1499.3257,
      "eval_samples_per_second": 35.415,
      "eval_steps_per_second": 0.277,
      "step": 51200
    },
    {
      "epoch": 15.483383685800604,
      "grad_norm": 0.5780200958251953,
      "learning_rate": 5.634461228600202e-05,
      "loss": 1.3544,
      "step": 51250
    },
    {
      "epoch": 15.483383685800604,
      "eval_loss": 1.3782252073287964,
      "eval_runtime": 1510.7389,
      "eval_samples_per_second": 35.148,
      "eval_steps_per_second": 0.275,
      "step": 51250
    },
    {
      "epoch": 15.498489425981873,
      "grad_norm": 0.5347203612327576,
      "learning_rate": 5.633454179254784e-05,
      "loss": 1.3671,
      "step": 51300
    },
    {
      "epoch": 15.498489425981873,
      "eval_loss": 1.3752232789993286,
      "eval_runtime": 1535.588,
      "eval_samples_per_second": 34.579,
      "eval_steps_per_second": 0.27,
      "step": 51300
    },
    {
      "epoch": 15.513595166163142,
      "grad_norm": 0.5326416492462158,
      "learning_rate": 5.6324471299093656e-05,
      "loss": 1.3263,
      "step": 51350
    },
    {
      "epoch": 15.513595166163142,
      "eval_loss": 1.3763474225997925,
      "eval_runtime": 1879.482,
      "eval_samples_per_second": 28.252,
      "eval_steps_per_second": 0.221,
      "step": 51350
    },
    {
      "epoch": 15.528700906344412,
      "grad_norm": 0.5504317283630371,
      "learning_rate": 5.631440080563948e-05,
      "loss": 1.3774,
      "step": 51400
    },
    {
      "epoch": 15.528700906344412,
      "eval_loss": 1.3760449886322021,
      "eval_runtime": 1591.5675,
      "eval_samples_per_second": 33.363,
      "eval_steps_per_second": 0.261,
      "step": 51400
    },
    {
      "epoch": 15.54380664652568,
      "grad_norm": 0.5019095540046692,
      "learning_rate": 5.63043303121853e-05,
      "loss": 1.3569,
      "step": 51450
    },
    {
      "epoch": 15.54380664652568,
      "eval_loss": 1.3740700483322144,
      "eval_runtime": 1530.1538,
      "eval_samples_per_second": 34.702,
      "eval_steps_per_second": 0.271,
      "step": 51450
    },
    {
      "epoch": 15.558912386706949,
      "grad_norm": 0.6623796224594116,
      "learning_rate": 5.629425981873112e-05,
      "loss": 1.3567,
      "step": 51500
    },
    {
      "epoch": 15.558912386706949,
      "eval_loss": 1.376361608505249,
      "eval_runtime": 1509.4712,
      "eval_samples_per_second": 35.177,
      "eval_steps_per_second": 0.275,
      "step": 51500
    },
    {
      "epoch": 15.574018126888218,
      "grad_norm": 0.48400917649269104,
      "learning_rate": 5.628418932527694e-05,
      "loss": 1.3597,
      "step": 51550
    },
    {
      "epoch": 15.574018126888218,
      "eval_loss": 1.3768197298049927,
      "eval_runtime": 1570.1806,
      "eval_samples_per_second": 33.817,
      "eval_steps_per_second": 0.264,
      "step": 51550
    },
    {
      "epoch": 15.589123867069487,
      "grad_norm": 0.5676271319389343,
      "learning_rate": 5.627411883182276e-05,
      "loss": 1.3524,
      "step": 51600
    },
    {
      "epoch": 15.589123867069487,
      "eval_loss": 1.37757408618927,
      "eval_runtime": 1474.9039,
      "eval_samples_per_second": 36.002,
      "eval_steps_per_second": 0.281,
      "step": 51600
    },
    {
      "epoch": 15.604229607250755,
      "grad_norm": 0.4803467392921448,
      "learning_rate": 5.626404833836858e-05,
      "loss": 1.348,
      "step": 51650
    },
    {
      "epoch": 15.604229607250755,
      "eval_loss": 1.3773508071899414,
      "eval_runtime": 1474.0027,
      "eval_samples_per_second": 36.024,
      "eval_steps_per_second": 0.282,
      "step": 51650
    },
    {
      "epoch": 15.619335347432024,
      "grad_norm": 0.5160859823226929,
      "learning_rate": 5.62539778449144e-05,
      "loss": 1.3459,
      "step": 51700
    },
    {
      "epoch": 15.619335347432024,
      "eval_loss": 1.3761420249938965,
      "eval_runtime": 1453.3897,
      "eval_samples_per_second": 36.535,
      "eval_steps_per_second": 0.286,
      "step": 51700
    },
    {
      "epoch": 15.634441087613293,
      "grad_norm": 0.4967907667160034,
      "learning_rate": 5.624390735146022e-05,
      "loss": 1.3387,
      "step": 51750
    },
    {
      "epoch": 15.634441087613293,
      "eval_loss": 1.3738386631011963,
      "eval_runtime": 1507.7888,
      "eval_samples_per_second": 35.216,
      "eval_steps_per_second": 0.275,
      "step": 51750
    },
    {
      "epoch": 15.649546827794563,
      "grad_norm": 0.5238662362098694,
      "learning_rate": 5.6233836858006044e-05,
      "loss": 1.3589,
      "step": 51800
    },
    {
      "epoch": 15.649546827794563,
      "eval_loss": 1.3762340545654297,
      "eval_runtime": 1569.3843,
      "eval_samples_per_second": 33.834,
      "eval_steps_per_second": 0.264,
      "step": 51800
    },
    {
      "epoch": 15.66465256797583,
      "grad_norm": 0.5400018095970154,
      "learning_rate": 5.622376636455186e-05,
      "loss": 1.3408,
      "step": 51850
    },
    {
      "epoch": 15.66465256797583,
      "eval_loss": 1.3755701780319214,
      "eval_runtime": 1492.7226,
      "eval_samples_per_second": 35.572,
      "eval_steps_per_second": 0.278,
      "step": 51850
    },
    {
      "epoch": 15.6797583081571,
      "grad_norm": 0.49274757504463196,
      "learning_rate": 5.621369587109768e-05,
      "loss": 1.35,
      "step": 51900
    },
    {
      "epoch": 15.6797583081571,
      "eval_loss": 1.375187635421753,
      "eval_runtime": 1531.4688,
      "eval_samples_per_second": 34.672,
      "eval_steps_per_second": 0.271,
      "step": 51900
    },
    {
      "epoch": 15.694864048338369,
      "grad_norm": 0.621638834476471,
      "learning_rate": 5.620362537764351e-05,
      "loss": 1.3526,
      "step": 51950
    },
    {
      "epoch": 15.694864048338369,
      "eval_loss": 1.3761796951293945,
      "eval_runtime": 1543.2443,
      "eval_samples_per_second": 34.407,
      "eval_steps_per_second": 0.269,
      "step": 51950
    },
    {
      "epoch": 15.709969788519638,
      "grad_norm": 0.5920258164405823,
      "learning_rate": 5.6193554884189326e-05,
      "loss": 1.3758,
      "step": 52000
    },
    {
      "epoch": 15.709969788519638,
      "eval_loss": 1.3752435445785522,
      "eval_runtime": 1620.011,
      "eval_samples_per_second": 32.777,
      "eval_steps_per_second": 0.256,
      "step": 52000
    },
    {
      "epoch": 15.725075528700906,
      "grad_norm": 0.5635077953338623,
      "learning_rate": 5.6183484390735144e-05,
      "loss": 1.346,
      "step": 52050
    },
    {
      "epoch": 15.725075528700906,
      "eval_loss": 1.3759187459945679,
      "eval_runtime": 1525.7981,
      "eval_samples_per_second": 34.801,
      "eval_steps_per_second": 0.272,
      "step": 52050
    },
    {
      "epoch": 15.740181268882175,
      "grad_norm": 0.6198443174362183,
      "learning_rate": 5.617341389728096e-05,
      "loss": 1.3435,
      "step": 52100
    },
    {
      "epoch": 15.740181268882175,
      "eval_loss": 1.3731191158294678,
      "eval_runtime": 1519.5377,
      "eval_samples_per_second": 34.944,
      "eval_steps_per_second": 0.273,
      "step": 52100
    },
    {
      "epoch": 15.755287009063444,
      "grad_norm": 0.48331931233406067,
      "learning_rate": 5.616334340382679e-05,
      "loss": 1.3451,
      "step": 52150
    },
    {
      "epoch": 15.755287009063444,
      "eval_loss": 1.3743793964385986,
      "eval_runtime": 1507.67,
      "eval_samples_per_second": 35.219,
      "eval_steps_per_second": 0.275,
      "step": 52150
    },
    {
      "epoch": 15.770392749244714,
      "grad_norm": 0.541533350944519,
      "learning_rate": 5.6153272910372614e-05,
      "loss": 1.3693,
      "step": 52200
    },
    {
      "epoch": 15.770392749244714,
      "eval_loss": 1.3750776052474976,
      "eval_runtime": 1567.3311,
      "eval_samples_per_second": 33.879,
      "eval_steps_per_second": 0.265,
      "step": 52200
    },
    {
      "epoch": 15.785498489425981,
      "grad_norm": 0.5963336825370789,
      "learning_rate": 5.614320241691843e-05,
      "loss": 1.3392,
      "step": 52250
    },
    {
      "epoch": 15.785498489425981,
      "eval_loss": 1.3772621154785156,
      "eval_runtime": 1522.023,
      "eval_samples_per_second": 34.887,
      "eval_steps_per_second": 0.273,
      "step": 52250
    },
    {
      "epoch": 15.80060422960725,
      "grad_norm": 0.45709437131881714,
      "learning_rate": 5.613313192346425e-05,
      "loss": 1.3344,
      "step": 52300
    },
    {
      "epoch": 15.80060422960725,
      "eval_loss": 1.3743926286697388,
      "eval_runtime": 1490.6256,
      "eval_samples_per_second": 35.622,
      "eval_steps_per_second": 0.278,
      "step": 52300
    },
    {
      "epoch": 15.81570996978852,
      "grad_norm": 0.5546799898147583,
      "learning_rate": 5.612306143001008e-05,
      "loss": 1.3611,
      "step": 52350
    },
    {
      "epoch": 15.81570996978852,
      "eval_loss": 1.374294400215149,
      "eval_runtime": 1523.501,
      "eval_samples_per_second": 34.853,
      "eval_steps_per_second": 0.272,
      "step": 52350
    },
    {
      "epoch": 15.830815709969789,
      "grad_norm": 0.5360093116760254,
      "learning_rate": 5.6112990936555896e-05,
      "loss": 1.3389,
      "step": 52400
    },
    {
      "epoch": 15.830815709969789,
      "eval_loss": 1.3738031387329102,
      "eval_runtime": 1550.7823,
      "eval_samples_per_second": 34.24,
      "eval_steps_per_second": 0.268,
      "step": 52400
    },
    {
      "epoch": 15.845921450151057,
      "grad_norm": 0.5891736745834351,
      "learning_rate": 5.6102920443101714e-05,
      "loss": 1.3779,
      "step": 52450
    },
    {
      "epoch": 15.845921450151057,
      "eval_loss": 1.3727887868881226,
      "eval_runtime": 1551.452,
      "eval_samples_per_second": 34.225,
      "eval_steps_per_second": 0.267,
      "step": 52450
    },
    {
      "epoch": 15.861027190332326,
      "grad_norm": 0.49296265840530396,
      "learning_rate": 5.609284994964753e-05,
      "loss": 1.3425,
      "step": 52500
    },
    {
      "epoch": 15.861027190332326,
      "eval_loss": 1.3744539022445679,
      "eval_runtime": 1571.0042,
      "eval_samples_per_second": 33.799,
      "eval_steps_per_second": 0.264,
      "step": 52500
    },
    {
      "epoch": 15.876132930513595,
      "grad_norm": 0.5332037210464478,
      "learning_rate": 5.608277945619336e-05,
      "loss": 1.3407,
      "step": 52550
    },
    {
      "epoch": 15.876132930513595,
      "eval_loss": 1.3722116947174072,
      "eval_runtime": 1482.1046,
      "eval_samples_per_second": 35.827,
      "eval_steps_per_second": 0.28,
      "step": 52550
    },
    {
      "epoch": 15.891238670694865,
      "grad_norm": 0.5513148903846741,
      "learning_rate": 5.607270896273918e-05,
      "loss": 1.3299,
      "step": 52600
    },
    {
      "epoch": 15.891238670694865,
      "eval_loss": 1.3749209642410278,
      "eval_runtime": 1571.7902,
      "eval_samples_per_second": 33.782,
      "eval_steps_per_second": 0.264,
      "step": 52600
    },
    {
      "epoch": 15.906344410876134,
      "grad_norm": 0.5782269835472107,
      "learning_rate": 5.6062638469284996e-05,
      "loss": 1.3638,
      "step": 52650
    },
    {
      "epoch": 15.906344410876134,
      "eval_loss": 1.3731844425201416,
      "eval_runtime": 1568.6572,
      "eval_samples_per_second": 33.85,
      "eval_steps_per_second": 0.265,
      "step": 52650
    },
    {
      "epoch": 15.921450151057401,
      "grad_norm": 0.4894973039627075,
      "learning_rate": 5.6052567975830815e-05,
      "loss": 1.3858,
      "step": 52700
    },
    {
      "epoch": 15.921450151057401,
      "eval_loss": 1.3750126361846924,
      "eval_runtime": 1499.0001,
      "eval_samples_per_second": 35.423,
      "eval_steps_per_second": 0.277,
      "step": 52700
    },
    {
      "epoch": 15.93655589123867,
      "grad_norm": 0.5599584579467773,
      "learning_rate": 5.604249748237664e-05,
      "loss": 1.323,
      "step": 52750
    },
    {
      "epoch": 15.93655589123867,
      "eval_loss": 1.3718996047973633,
      "eval_runtime": 1505.7962,
      "eval_samples_per_second": 35.263,
      "eval_steps_per_second": 0.276,
      "step": 52750
    },
    {
      "epoch": 15.95166163141994,
      "grad_norm": 0.5045821666717529,
      "learning_rate": 5.603242698892246e-05,
      "loss": 1.3509,
      "step": 52800
    },
    {
      "epoch": 15.95166163141994,
      "eval_loss": 1.3709051609039307,
      "eval_runtime": 1578.3233,
      "eval_samples_per_second": 33.643,
      "eval_steps_per_second": 0.263,
      "step": 52800
    },
    {
      "epoch": 15.96676737160121,
      "grad_norm": 0.5724356770515442,
      "learning_rate": 5.602235649546828e-05,
      "loss": 1.3362,
      "step": 52850
    },
    {
      "epoch": 15.96676737160121,
      "eval_loss": 1.3701658248901367,
      "eval_runtime": 1601.848,
      "eval_samples_per_second": 33.149,
      "eval_steps_per_second": 0.259,
      "step": 52850
    },
    {
      "epoch": 15.981873111782477,
      "grad_norm": 0.5933526158332825,
      "learning_rate": 5.6012286002014096e-05,
      "loss": 1.3396,
      "step": 52900
    },
    {
      "epoch": 15.981873111782477,
      "eval_loss": 1.3713867664337158,
      "eval_runtime": 1515.8719,
      "eval_samples_per_second": 35.029,
      "eval_steps_per_second": 0.274,
      "step": 52900
    },
    {
      "epoch": 15.996978851963746,
      "grad_norm": 0.5937522053718567,
      "learning_rate": 5.600221550855992e-05,
      "loss": 1.3377,
      "step": 52950
    },
    {
      "epoch": 15.996978851963746,
      "eval_loss": 1.3736830949783325,
      "eval_runtime": 1606.1226,
      "eval_samples_per_second": 33.06,
      "eval_steps_per_second": 0.258,
      "step": 52950
    },
    {
      "epoch": 16.012084592145015,
      "grad_norm": 0.5499695539474487,
      "learning_rate": 5.599214501510574e-05,
      "loss": 1.3398,
      "step": 53000
    },
    {
      "epoch": 16.012084592145015,
      "eval_loss": 1.372615098953247,
      "eval_runtime": 1580.5313,
      "eval_samples_per_second": 33.596,
      "eval_steps_per_second": 0.263,
      "step": 53000
    },
    {
      "epoch": 16.027190332326285,
      "grad_norm": 0.47714877128601074,
      "learning_rate": 5.598207452165156e-05,
      "loss": 1.3402,
      "step": 53050
    },
    {
      "epoch": 16.027190332326285,
      "eval_loss": 1.3724786043167114,
      "eval_runtime": 1598.0269,
      "eval_samples_per_second": 33.228,
      "eval_steps_per_second": 0.26,
      "step": 53050
    },
    {
      "epoch": 16.042296072507554,
      "grad_norm": 0.5772601962089539,
      "learning_rate": 5.5972004028197384e-05,
      "loss": 1.3495,
      "step": 53100
    },
    {
      "epoch": 16.042296072507554,
      "eval_loss": 1.371221661567688,
      "eval_runtime": 1533.336,
      "eval_samples_per_second": 34.63,
      "eval_steps_per_second": 0.271,
      "step": 53100
    },
    {
      "epoch": 16.057401812688823,
      "grad_norm": 0.4987989366054535,
      "learning_rate": 5.59619335347432e-05,
      "loss": 1.3385,
      "step": 53150
    },
    {
      "epoch": 16.057401812688823,
      "eval_loss": 1.371743083000183,
      "eval_runtime": 1538.6363,
      "eval_samples_per_second": 34.51,
      "eval_steps_per_second": 0.27,
      "step": 53150
    },
    {
      "epoch": 16.07250755287009,
      "grad_norm": 0.5248287916183472,
      "learning_rate": 5.595186304128902e-05,
      "loss": 1.3668,
      "step": 53200
    },
    {
      "epoch": 16.07250755287009,
      "eval_loss": 1.3707932233810425,
      "eval_runtime": 1549.557,
      "eval_samples_per_second": 34.267,
      "eval_steps_per_second": 0.268,
      "step": 53200
    },
    {
      "epoch": 16.08761329305136,
      "grad_norm": 0.4848731756210327,
      "learning_rate": 5.594179254783484e-05,
      "loss": 1.3459,
      "step": 53250
    },
    {
      "epoch": 16.08761329305136,
      "eval_loss": 1.3699251413345337,
      "eval_runtime": 1603.566,
      "eval_samples_per_second": 33.113,
      "eval_steps_per_second": 0.259,
      "step": 53250
    },
    {
      "epoch": 16.102719033232628,
      "grad_norm": 0.5105554461479187,
      "learning_rate": 5.5931722054380666e-05,
      "loss": 1.351,
      "step": 53300
    },
    {
      "epoch": 16.102719033232628,
      "eval_loss": 1.3726259469985962,
      "eval_runtime": 1672.4919,
      "eval_samples_per_second": 31.748,
      "eval_steps_per_second": 0.248,
      "step": 53300
    },
    {
      "epoch": 16.117824773413897,
      "grad_norm": 0.5560063123703003,
      "learning_rate": 5.592165156092649e-05,
      "loss": 1.3437,
      "step": 53350
    },
    {
      "epoch": 16.117824773413897,
      "eval_loss": 1.370367407798767,
      "eval_runtime": 1547.735,
      "eval_samples_per_second": 34.308,
      "eval_steps_per_second": 0.268,
      "step": 53350
    },
    {
      "epoch": 16.132930513595166,
      "grad_norm": 0.5026819109916687,
      "learning_rate": 5.591158106747231e-05,
      "loss": 1.3503,
      "step": 53400
    },
    {
      "epoch": 16.132930513595166,
      "eval_loss": 1.3717193603515625,
      "eval_runtime": 1601.661,
      "eval_samples_per_second": 33.152,
      "eval_steps_per_second": 0.259,
      "step": 53400
    },
    {
      "epoch": 16.148036253776436,
      "grad_norm": 0.4933640956878662,
      "learning_rate": 5.590151057401813e-05,
      "loss": 1.3327,
      "step": 53450
    },
    {
      "epoch": 16.148036253776436,
      "eval_loss": 1.370052456855774,
      "eval_runtime": 1520.8799,
      "eval_samples_per_second": 34.913,
      "eval_steps_per_second": 0.273,
      "step": 53450
    },
    {
      "epoch": 16.163141993957705,
      "grad_norm": 0.49912229180336,
      "learning_rate": 5.5891440080563954e-05,
      "loss": 1.3409,
      "step": 53500
    },
    {
      "epoch": 16.163141993957705,
      "eval_loss": 1.3723325729370117,
      "eval_runtime": 1479.5445,
      "eval_samples_per_second": 35.889,
      "eval_steps_per_second": 0.28,
      "step": 53500
    },
    {
      "epoch": 16.178247734138974,
      "grad_norm": 0.4646875858306885,
      "learning_rate": 5.588136958710977e-05,
      "loss": 1.3404,
      "step": 53550
    },
    {
      "epoch": 16.178247734138974,
      "eval_loss": 1.3707879781723022,
      "eval_runtime": 654.7302,
      "eval_samples_per_second": 81.101,
      "eval_steps_per_second": 0.634,
      "step": 53550
    },
    {
      "epoch": 16.19335347432024,
      "grad_norm": 0.5570998787879944,
      "learning_rate": 5.587129909365559e-05,
      "loss": 1.3581,
      "step": 53600
    },
    {
      "epoch": 16.19335347432024,
      "eval_loss": 1.3706954717636108,
      "eval_runtime": 850.7001,
      "eval_samples_per_second": 62.418,
      "eval_steps_per_second": 0.488,
      "step": 53600
    },
    {
      "epoch": 16.20845921450151,
      "grad_norm": 0.5551944971084595,
      "learning_rate": 5.586122860020141e-05,
      "loss": 1.353,
      "step": 53650
    },
    {
      "epoch": 16.20845921450151,
      "eval_loss": 1.3701236248016357,
      "eval_runtime": 569.5849,
      "eval_samples_per_second": 93.224,
      "eval_steps_per_second": 0.729,
      "step": 53650
    },
    {
      "epoch": 16.22356495468278,
      "grad_norm": 0.5004580616950989,
      "learning_rate": 5.5851158106747236e-05,
      "loss": 1.3302,
      "step": 53700
    },
    {
      "epoch": 16.22356495468278,
      "eval_loss": 1.371325969696045,
      "eval_runtime": 600.8631,
      "eval_samples_per_second": 88.371,
      "eval_steps_per_second": 0.691,
      "step": 53700
    },
    {
      "epoch": 16.238670694864048,
      "grad_norm": 0.5132049322128296,
      "learning_rate": 5.5841087613293054e-05,
      "loss": 1.3301,
      "step": 53750
    },
    {
      "epoch": 16.238670694864048,
      "eval_loss": 1.3700720071792603,
      "eval_runtime": 830.8895,
      "eval_samples_per_second": 63.906,
      "eval_steps_per_second": 0.499,
      "step": 53750
    },
    {
      "epoch": 16.253776435045317,
      "grad_norm": 0.584566593170166,
      "learning_rate": 5.583101711983887e-05,
      "loss": 1.3423,
      "step": 53800
    },
    {
      "epoch": 16.253776435045317,
      "eval_loss": 1.3698750734329224,
      "eval_runtime": 553.4969,
      "eval_samples_per_second": 95.934,
      "eval_steps_per_second": 0.75,
      "step": 53800
    },
    {
      "epoch": 16.268882175226587,
      "grad_norm": 0.514745831489563,
      "learning_rate": 5.582094662638469e-05,
      "loss": 1.3487,
      "step": 53850
    },
    {
      "epoch": 16.268882175226587,
      "eval_loss": 1.371221661567688,
      "eval_runtime": 618.0112,
      "eval_samples_per_second": 85.919,
      "eval_steps_per_second": 0.672,
      "step": 53850
    },
    {
      "epoch": 16.283987915407856,
      "grad_norm": 0.5241430401802063,
      "learning_rate": 5.581087613293052e-05,
      "loss": 1.3357,
      "step": 53900
    },
    {
      "epoch": 16.283987915407856,
      "eval_loss": 1.3717889785766602,
      "eval_runtime": 560.3626,
      "eval_samples_per_second": 94.758,
      "eval_steps_per_second": 0.741,
      "step": 53900
    },
    {
      "epoch": 16.299093655589125,
      "grad_norm": 0.5019649863243103,
      "learning_rate": 5.5800805639476336e-05,
      "loss": 1.34,
      "step": 53950
    },
    {
      "epoch": 16.299093655589125,
      "eval_loss": 1.3724116086959839,
      "eval_runtime": 584.8547,
      "eval_samples_per_second": 90.79,
      "eval_steps_per_second": 0.71,
      "step": 53950
    },
    {
      "epoch": 16.31419939577039,
      "grad_norm": 0.5579741597175598,
      "learning_rate": 5.5790735146022155e-05,
      "loss": 1.3547,
      "step": 54000
    },
    {
      "epoch": 16.31419939577039,
      "eval_loss": 1.3664588928222656,
      "eval_runtime": 582.6798,
      "eval_samples_per_second": 91.129,
      "eval_steps_per_second": 0.712,
      "step": 54000
    },
    {
      "epoch": 16.32930513595166,
      "grad_norm": 0.5696942806243896,
      "learning_rate": 5.578066465256797e-05,
      "loss": 1.3394,
      "step": 54050
    },
    {
      "epoch": 16.32930513595166,
      "eval_loss": 1.36994469165802,
      "eval_runtime": 682.8227,
      "eval_samples_per_second": 77.764,
      "eval_steps_per_second": 0.608,
      "step": 54050
    },
    {
      "epoch": 16.34441087613293,
      "grad_norm": 0.5129740238189697,
      "learning_rate": 5.57705941591138e-05,
      "loss": 1.3387,
      "step": 54100
    },
    {
      "epoch": 16.34441087613293,
      "eval_loss": 1.3689719438552856,
      "eval_runtime": 626.8622,
      "eval_samples_per_second": 84.706,
      "eval_steps_per_second": 0.662,
      "step": 54100
    },
    {
      "epoch": 16.3595166163142,
      "grad_norm": 0.5437852144241333,
      "learning_rate": 5.576052366565962e-05,
      "loss": 1.3595,
      "step": 54150
    },
    {
      "epoch": 16.3595166163142,
      "eval_loss": 1.3695653676986694,
      "eval_runtime": 838.6519,
      "eval_samples_per_second": 63.315,
      "eval_steps_per_second": 0.495,
      "step": 54150
    },
    {
      "epoch": 16.37462235649547,
      "grad_norm": 0.6123802661895752,
      "learning_rate": 5.5750453172205436e-05,
      "loss": 1.3582,
      "step": 54200
    },
    {
      "epoch": 16.37462235649547,
      "eval_loss": 1.37043297290802,
      "eval_runtime": 640.9898,
      "eval_samples_per_second": 82.839,
      "eval_steps_per_second": 0.647,
      "step": 54200
    },
    {
      "epoch": 16.389728096676738,
      "grad_norm": 0.5209549069404602,
      "learning_rate": 5.574038267875126e-05,
      "loss": 1.3273,
      "step": 54250
    },
    {
      "epoch": 16.389728096676738,
      "eval_loss": 1.368133306503296,
      "eval_runtime": 623.7606,
      "eval_samples_per_second": 85.127,
      "eval_steps_per_second": 0.665,
      "step": 54250
    },
    {
      "epoch": 16.404833836858007,
      "grad_norm": 0.5348086357116699,
      "learning_rate": 5.573031218529708e-05,
      "loss": 1.3523,
      "step": 54300
    },
    {
      "epoch": 16.404833836858007,
      "eval_loss": 1.3702876567840576,
      "eval_runtime": 642.6652,
      "eval_samples_per_second": 82.623,
      "eval_steps_per_second": 0.646,
      "step": 54300
    },
    {
      "epoch": 16.419939577039276,
      "grad_norm": 0.537539541721344,
      "learning_rate": 5.57202416918429e-05,
      "loss": 1.3306,
      "step": 54350
    },
    {
      "epoch": 16.419939577039276,
      "eval_loss": 1.3680325746536255,
      "eval_runtime": 700.3653,
      "eval_samples_per_second": 75.816,
      "eval_steps_per_second": 0.593,
      "step": 54350
    },
    {
      "epoch": 16.435045317220546,
      "grad_norm": 0.5067332983016968,
      "learning_rate": 5.571017119838872e-05,
      "loss": 1.3613,
      "step": 54400
    },
    {
      "epoch": 16.435045317220546,
      "eval_loss": 1.368173360824585,
      "eval_runtime": 618.8178,
      "eval_samples_per_second": 85.807,
      "eval_steps_per_second": 0.671,
      "step": 54400
    },
    {
      "epoch": 16.45015105740181,
      "grad_norm": 0.6248213052749634,
      "learning_rate": 5.570010070493454e-05,
      "loss": 1.3294,
      "step": 54450
    },
    {
      "epoch": 16.45015105740181,
      "eval_loss": 1.3680495023727417,
      "eval_runtime": 614.2429,
      "eval_samples_per_second": 86.446,
      "eval_steps_per_second": 0.676,
      "step": 54450
    },
    {
      "epoch": 16.46525679758308,
      "grad_norm": 0.5377839803695679,
      "learning_rate": 5.569003021148037e-05,
      "loss": 1.3166,
      "step": 54500
    },
    {
      "epoch": 16.46525679758308,
      "eval_loss": 1.3697705268859863,
      "eval_runtime": 628.9094,
      "eval_samples_per_second": 84.43,
      "eval_steps_per_second": 0.66,
      "step": 54500
    },
    {
      "epoch": 16.48036253776435,
      "grad_norm": 0.5717898011207581,
      "learning_rate": 5.567995971802619e-05,
      "loss": 1.3461,
      "step": 54550
    },
    {
      "epoch": 16.48036253776435,
      "eval_loss": 1.3660277128219604,
      "eval_runtime": 593.8862,
      "eval_samples_per_second": 89.409,
      "eval_steps_per_second": 0.699,
      "step": 54550
    },
    {
      "epoch": 16.49546827794562,
      "grad_norm": 0.6185166835784912,
      "learning_rate": 5.5669889224572006e-05,
      "loss": 1.3512,
      "step": 54600
    },
    {
      "epoch": 16.49546827794562,
      "eval_loss": 1.367431879043579,
      "eval_runtime": 659.878,
      "eval_samples_per_second": 80.468,
      "eval_steps_per_second": 0.629,
      "step": 54600
    },
    {
      "epoch": 16.51057401812689,
      "grad_norm": 0.5282122492790222,
      "learning_rate": 5.565981873111783e-05,
      "loss": 1.3485,
      "step": 54650
    },
    {
      "epoch": 16.51057401812689,
      "eval_loss": 1.3676645755767822,
      "eval_runtime": 672.8181,
      "eval_samples_per_second": 78.92,
      "eval_steps_per_second": 0.617,
      "step": 54650
    },
    {
      "epoch": 16.525679758308158,
      "grad_norm": 0.5956951975822449,
      "learning_rate": 5.564974823766365e-05,
      "loss": 1.354,
      "step": 54700
    },
    {
      "epoch": 16.525679758308158,
      "eval_loss": 1.3681825399398804,
      "eval_runtime": 650.1664,
      "eval_samples_per_second": 81.67,
      "eval_steps_per_second": 0.638,
      "step": 54700
    },
    {
      "epoch": 16.540785498489427,
      "grad_norm": 0.5292063355445862,
      "learning_rate": 5.563967774420947e-05,
      "loss": 1.3376,
      "step": 54750
    },
    {
      "epoch": 16.540785498489427,
      "eval_loss": 1.3682408332824707,
      "eval_runtime": 633.758,
      "eval_samples_per_second": 83.784,
      "eval_steps_per_second": 0.655,
      "step": 54750
    },
    {
      "epoch": 16.555891238670696,
      "grad_norm": 0.5111120939254761,
      "learning_rate": 5.562960725075529e-05,
      "loss": 1.3336,
      "step": 54800
    },
    {
      "epoch": 16.555891238670696,
      "eval_loss": 1.369211196899414,
      "eval_runtime": 687.948,
      "eval_samples_per_second": 77.185,
      "eval_steps_per_second": 0.603,
      "step": 54800
    },
    {
      "epoch": 16.570996978851962,
      "grad_norm": 0.5104734301567078,
      "learning_rate": 5.561953675730111e-05,
      "loss": 1.3444,
      "step": 54850
    },
    {
      "epoch": 16.570996978851962,
      "eval_loss": 1.3680025339126587,
      "eval_runtime": 677.6178,
      "eval_samples_per_second": 78.361,
      "eval_steps_per_second": 0.612,
      "step": 54850
    },
    {
      "epoch": 16.58610271903323,
      "grad_norm": 0.5248856544494629,
      "learning_rate": 5.560946626384693e-05,
      "loss": 1.3504,
      "step": 54900
    },
    {
      "epoch": 16.58610271903323,
      "eval_loss": 1.3669898509979248,
      "eval_runtime": 632.1566,
      "eval_samples_per_second": 83.997,
      "eval_steps_per_second": 0.656,
      "step": 54900
    },
    {
      "epoch": 16.6012084592145,
      "grad_norm": 0.5420593619346619,
      "learning_rate": 5.559939577039275e-05,
      "loss": 1.323,
      "step": 54950
    },
    {
      "epoch": 16.6012084592145,
      "eval_loss": 1.3684237003326416,
      "eval_runtime": 607.8269,
      "eval_samples_per_second": 87.359,
      "eval_steps_per_second": 0.683,
      "step": 54950
    },
    {
      "epoch": 16.61631419939577,
      "grad_norm": 0.5642802715301514,
      "learning_rate": 5.558932527693857e-05,
      "loss": 1.356,
      "step": 55000
    },
    {
      "epoch": 16.61631419939577,
      "eval_loss": 1.3691232204437256,
      "eval_runtime": 664.4057,
      "eval_samples_per_second": 79.92,
      "eval_steps_per_second": 0.625,
      "step": 55000
    },
    {
      "epoch": 16.63141993957704,
      "grad_norm": 0.5293298959732056,
      "learning_rate": 5.5579254783484394e-05,
      "loss": 1.3292,
      "step": 55050
    },
    {
      "epoch": 16.63141993957704,
      "eval_loss": 1.369969129562378,
      "eval_runtime": 651.5217,
      "eval_samples_per_second": 81.5,
      "eval_steps_per_second": 0.637,
      "step": 55050
    },
    {
      "epoch": 16.64652567975831,
      "grad_norm": 0.4955792725086212,
      "learning_rate": 5.556918429003021e-05,
      "loss": 1.3281,
      "step": 55100
    },
    {
      "epoch": 16.64652567975831,
      "eval_loss": 1.3672949075698853,
      "eval_runtime": 623.62,
      "eval_samples_per_second": 85.146,
      "eval_steps_per_second": 0.665,
      "step": 55100
    },
    {
      "epoch": 16.661631419939578,
      "grad_norm": 0.5251079201698303,
      "learning_rate": 5.555911379657603e-05,
      "loss": 1.3588,
      "step": 55150
    },
    {
      "epoch": 16.661631419939578,
      "eval_loss": 1.3653898239135742,
      "eval_runtime": 666.6343,
      "eval_samples_per_second": 79.652,
      "eval_steps_per_second": 0.623,
      "step": 55150
    },
    {
      "epoch": 16.676737160120847,
      "grad_norm": 0.5804842710494995,
      "learning_rate": 5.554904330312185e-05,
      "loss": 1.3456,
      "step": 55200
    },
    {
      "epoch": 16.676737160120847,
      "eval_loss": 1.3652795553207397,
      "eval_runtime": 648.1149,
      "eval_samples_per_second": 81.928,
      "eval_steps_per_second": 0.64,
      "step": 55200
    },
    {
      "epoch": 16.691842900302113,
      "grad_norm": 0.4897204637527466,
      "learning_rate": 5.5538972809667676e-05,
      "loss": 1.3491,
      "step": 55250
    },
    {
      "epoch": 16.691842900302113,
      "eval_loss": 1.3674471378326416,
      "eval_runtime": 666.3715,
      "eval_samples_per_second": 79.684,
      "eval_steps_per_second": 0.623,
      "step": 55250
    },
    {
      "epoch": 16.706948640483382,
      "grad_norm": 0.5286354422569275,
      "learning_rate": 5.5528902316213495e-05,
      "loss": 1.347,
      "step": 55300
    },
    {
      "epoch": 16.706948640483382,
      "eval_loss": 1.3642598390579224,
      "eval_runtime": 626.8098,
      "eval_samples_per_second": 84.713,
      "eval_steps_per_second": 0.662,
      "step": 55300
    },
    {
      "epoch": 16.72205438066465,
      "grad_norm": 0.578708827495575,
      "learning_rate": 5.551883182275931e-05,
      "loss": 1.3354,
      "step": 55350
    },
    {
      "epoch": 16.72205438066465,
      "eval_loss": 1.3628802299499512,
      "eval_runtime": 696.4608,
      "eval_samples_per_second": 76.241,
      "eval_steps_per_second": 0.596,
      "step": 55350
    },
    {
      "epoch": 16.73716012084592,
      "grad_norm": 0.601195752620697,
      "learning_rate": 5.550876132930514e-05,
      "loss": 1.3362,
      "step": 55400
    },
    {
      "epoch": 16.73716012084592,
      "eval_loss": 1.3655846118927002,
      "eval_runtime": 655.9821,
      "eval_samples_per_second": 80.946,
      "eval_steps_per_second": 0.633,
      "step": 55400
    },
    {
      "epoch": 16.75226586102719,
      "grad_norm": 0.49002736806869507,
      "learning_rate": 5.549869083585096e-05,
      "loss": 1.3402,
      "step": 55450
    },
    {
      "epoch": 16.75226586102719,
      "eval_loss": 1.3659824132919312,
      "eval_runtime": 646.1136,
      "eval_samples_per_second": 82.182,
      "eval_steps_per_second": 0.642,
      "step": 55450
    },
    {
      "epoch": 16.76737160120846,
      "grad_norm": 0.4862501323223114,
      "learning_rate": 5.5488620342396776e-05,
      "loss": 1.3326,
      "step": 55500
    },
    {
      "epoch": 16.76737160120846,
      "eval_loss": 1.3638715744018555,
      "eval_runtime": 645.374,
      "eval_samples_per_second": 82.276,
      "eval_steps_per_second": 0.643,
      "step": 55500
    },
    {
      "epoch": 16.78247734138973,
      "grad_norm": 0.48809370398521423,
      "learning_rate": 5.5478549848942595e-05,
      "loss": 1.362,
      "step": 55550
    },
    {
      "epoch": 16.78247734138973,
      "eval_loss": 1.3638992309570312,
      "eval_runtime": 767.6306,
      "eval_samples_per_second": 69.173,
      "eval_steps_per_second": 0.541,
      "step": 55550
    },
    {
      "epoch": 16.797583081571,
      "grad_norm": 0.4721750020980835,
      "learning_rate": 5.546847935548842e-05,
      "loss": 1.3583,
      "step": 55600
    },
    {
      "epoch": 16.797583081571,
      "eval_loss": 1.3655211925506592,
      "eval_runtime": 642.081,
      "eval_samples_per_second": 82.698,
      "eval_steps_per_second": 0.646,
      "step": 55600
    },
    {
      "epoch": 16.812688821752268,
      "grad_norm": 0.47653108835220337,
      "learning_rate": 5.545840886203424e-05,
      "loss": 1.3549,
      "step": 55650
    },
    {
      "epoch": 16.812688821752268,
      "eval_loss": 1.3648334741592407,
      "eval_runtime": 616.0934,
      "eval_samples_per_second": 86.187,
      "eval_steps_per_second": 0.674,
      "step": 55650
    },
    {
      "epoch": 16.827794561933533,
      "grad_norm": 0.5588006377220154,
      "learning_rate": 5.5448338368580064e-05,
      "loss": 1.3375,
      "step": 55700
    },
    {
      "epoch": 16.827794561933533,
      "eval_loss": 1.3646353483200073,
      "eval_runtime": 1096.1353,
      "eval_samples_per_second": 48.442,
      "eval_steps_per_second": 0.379,
      "step": 55700
    },
    {
      "epoch": 16.842900302114803,
      "grad_norm": 0.5336201786994934,
      "learning_rate": 5.543826787512588e-05,
      "loss": 1.3475,
      "step": 55750
    },
    {
      "epoch": 16.842900302114803,
      "eval_loss": 1.36443293094635,
      "eval_runtime": 599.235,
      "eval_samples_per_second": 88.611,
      "eval_steps_per_second": 0.693,
      "step": 55750
    },
    {
      "epoch": 16.858006042296072,
      "grad_norm": 0.4525313079357147,
      "learning_rate": 5.542819738167171e-05,
      "loss": 1.3255,
      "step": 55800
    },
    {
      "epoch": 16.858006042296072,
      "eval_loss": 1.3668590784072876,
      "eval_runtime": 699.4855,
      "eval_samples_per_second": 75.912,
      "eval_steps_per_second": 0.593,
      "step": 55800
    },
    {
      "epoch": 16.87311178247734,
      "grad_norm": 0.5015347599983215,
      "learning_rate": 5.541812688821753e-05,
      "loss": 1.338,
      "step": 55850
    },
    {
      "epoch": 16.87311178247734,
      "eval_loss": 1.363668441772461,
      "eval_runtime": 676.2898,
      "eval_samples_per_second": 78.515,
      "eval_steps_per_second": 0.614,
      "step": 55850
    },
    {
      "epoch": 16.88821752265861,
      "grad_norm": 0.6519224643707275,
      "learning_rate": 5.5408056394763346e-05,
      "loss": 1.3409,
      "step": 55900
    },
    {
      "epoch": 16.88821752265861,
      "eval_loss": 1.3641186952590942,
      "eval_runtime": 652.2589,
      "eval_samples_per_second": 81.408,
      "eval_steps_per_second": 0.636,
      "step": 55900
    },
    {
      "epoch": 16.90332326283988,
      "grad_norm": 0.5421741008758545,
      "learning_rate": 5.5397985901309165e-05,
      "loss": 1.3338,
      "step": 55950
    },
    {
      "epoch": 16.90332326283988,
      "eval_loss": 1.366811990737915,
      "eval_runtime": 689.5986,
      "eval_samples_per_second": 77.0,
      "eval_steps_per_second": 0.602,
      "step": 55950
    },
    {
      "epoch": 16.91842900302115,
      "grad_norm": 0.5105981230735779,
      "learning_rate": 5.538791540785499e-05,
      "loss": 1.3513,
      "step": 56000
    },
    {
      "epoch": 16.91842900302115,
      "eval_loss": 1.3649072647094727,
      "eval_runtime": 696.6689,
      "eval_samples_per_second": 76.218,
      "eval_steps_per_second": 0.596,
      "step": 56000
    },
    {
      "epoch": 16.93353474320242,
      "grad_norm": 0.5237328410148621,
      "learning_rate": 5.537784491440081e-05,
      "loss": 1.3428,
      "step": 56050
    },
    {
      "epoch": 16.93353474320242,
      "eval_loss": 1.3621704578399658,
      "eval_runtime": 691.971,
      "eval_samples_per_second": 76.736,
      "eval_steps_per_second": 0.6,
      "step": 56050
    },
    {
      "epoch": 16.948640483383684,
      "grad_norm": 0.5015336871147156,
      "learning_rate": 5.536777442094663e-05,
      "loss": 1.3423,
      "step": 56100
    },
    {
      "epoch": 16.948640483383684,
      "eval_loss": 1.3641836643218994,
      "eval_runtime": 662.0631,
      "eval_samples_per_second": 80.202,
      "eval_steps_per_second": 0.627,
      "step": 56100
    },
    {
      "epoch": 16.963746223564954,
      "grad_norm": 0.4731326699256897,
      "learning_rate": 5.5357703927492446e-05,
      "loss": 1.3561,
      "step": 56150
    },
    {
      "epoch": 16.963746223564954,
      "eval_loss": 1.3639830350875854,
      "eval_runtime": 731.1446,
      "eval_samples_per_second": 72.624,
      "eval_steps_per_second": 0.568,
      "step": 56150
    },
    {
      "epoch": 16.978851963746223,
      "grad_norm": 0.5477480888366699,
      "learning_rate": 5.534763343403827e-05,
      "loss": 1.3541,
      "step": 56200
    },
    {
      "epoch": 16.978851963746223,
      "eval_loss": 1.3627080917358398,
      "eval_runtime": 681.0072,
      "eval_samples_per_second": 77.971,
      "eval_steps_per_second": 0.609,
      "step": 56200
    },
    {
      "epoch": 16.993957703927492,
      "grad_norm": 0.636360228061676,
      "learning_rate": 5.533756294058409e-05,
      "loss": 1.3379,
      "step": 56250
    },
    {
      "epoch": 16.993957703927492,
      "eval_loss": 1.3634939193725586,
      "eval_runtime": 685.5843,
      "eval_samples_per_second": 77.451,
      "eval_steps_per_second": 0.605,
      "step": 56250
    },
    {
      "epoch": 17.00906344410876,
      "grad_norm": 0.575941264629364,
      "learning_rate": 5.532749244712991e-05,
      "loss": 1.3341,
      "step": 56300
    },
    {
      "epoch": 17.00906344410876,
      "eval_loss": 1.3631523847579956,
      "eval_runtime": 692.8982,
      "eval_samples_per_second": 76.633,
      "eval_steps_per_second": 0.599,
      "step": 56300
    },
    {
      "epoch": 17.02416918429003,
      "grad_norm": 0.5483881831169128,
      "learning_rate": 5.531742195367573e-05,
      "loss": 1.3433,
      "step": 56350
    },
    {
      "epoch": 17.02416918429003,
      "eval_loss": 1.3636391162872314,
      "eval_runtime": 702.5723,
      "eval_samples_per_second": 75.578,
      "eval_steps_per_second": 0.591,
      "step": 56350
    },
    {
      "epoch": 17.0392749244713,
      "grad_norm": 0.6086419820785522,
      "learning_rate": 5.530735146022155e-05,
      "loss": 1.3362,
      "step": 56400
    },
    {
      "epoch": 17.0392749244713,
      "eval_loss": 1.3642024993896484,
      "eval_runtime": 645.7925,
      "eval_samples_per_second": 82.223,
      "eval_steps_per_second": 0.643,
      "step": 56400
    },
    {
      "epoch": 17.05438066465257,
      "grad_norm": 0.5759154558181763,
      "learning_rate": 5.529728096676737e-05,
      "loss": 1.3346,
      "step": 56450
    },
    {
      "epoch": 17.05438066465257,
      "eval_loss": 1.3638970851898193,
      "eval_runtime": 694.1672,
      "eval_samples_per_second": 76.493,
      "eval_steps_per_second": 0.598,
      "step": 56450
    },
    {
      "epoch": 17.069486404833835,
      "grad_norm": 0.5295670032501221,
      "learning_rate": 5.528721047331319e-05,
      "loss": 1.3173,
      "step": 56500
    },
    {
      "epoch": 17.069486404833835,
      "eval_loss": 1.3651471138000488,
      "eval_runtime": 705.8358,
      "eval_samples_per_second": 75.229,
      "eval_steps_per_second": 0.588,
      "step": 56500
    },
    {
      "epoch": 17.084592145015105,
      "grad_norm": 0.49663034081459045,
      "learning_rate": 5.5277139979859016e-05,
      "loss": 1.3659,
      "step": 56550
    },
    {
      "epoch": 17.084592145015105,
      "eval_loss": 1.362815022468567,
      "eval_runtime": 612.4521,
      "eval_samples_per_second": 86.699,
      "eval_steps_per_second": 0.678,
      "step": 56550
    },
    {
      "epoch": 17.099697885196374,
      "grad_norm": 0.5029022097587585,
      "learning_rate": 5.5267069486404835e-05,
      "loss": 1.3389,
      "step": 56600
    },
    {
      "epoch": 17.099697885196374,
      "eval_loss": 1.362217664718628,
      "eval_runtime": 653.6807,
      "eval_samples_per_second": 81.231,
      "eval_steps_per_second": 0.635,
      "step": 56600
    },
    {
      "epoch": 17.114803625377643,
      "grad_norm": 0.5179957747459412,
      "learning_rate": 5.525699899295065e-05,
      "loss": 1.3371,
      "step": 56650
    },
    {
      "epoch": 17.114803625377643,
      "eval_loss": 1.3627371788024902,
      "eval_runtime": 687.2038,
      "eval_samples_per_second": 77.268,
      "eval_steps_per_second": 0.604,
      "step": 56650
    },
    {
      "epoch": 17.129909365558913,
      "grad_norm": 0.5007076263427734,
      "learning_rate": 5.524692849949647e-05,
      "loss": 1.3144,
      "step": 56700
    },
    {
      "epoch": 17.129909365558913,
      "eval_loss": 1.3609980344772339,
      "eval_runtime": 645.7222,
      "eval_samples_per_second": 82.232,
      "eval_steps_per_second": 0.643,
      "step": 56700
    },
    {
      "epoch": 17.145015105740182,
      "grad_norm": 0.540650486946106,
      "learning_rate": 5.52368580060423e-05,
      "loss": 1.3276,
      "step": 56750
    },
    {
      "epoch": 17.145015105740182,
      "eval_loss": 1.3626400232315063,
      "eval_runtime": 623.0236,
      "eval_samples_per_second": 85.228,
      "eval_steps_per_second": 0.666,
      "step": 56750
    },
    {
      "epoch": 17.16012084592145,
      "grad_norm": 0.4677518904209137,
      "learning_rate": 5.5226787512588116e-05,
      "loss": 1.3452,
      "step": 56800
    },
    {
      "epoch": 17.16012084592145,
      "eval_loss": 1.3621236085891724,
      "eval_runtime": 666.549,
      "eval_samples_per_second": 79.663,
      "eval_steps_per_second": 0.623,
      "step": 56800
    },
    {
      "epoch": 17.17522658610272,
      "grad_norm": 0.5547200441360474,
      "learning_rate": 5.521671701913394e-05,
      "loss": 1.3505,
      "step": 56850
    },
    {
      "epoch": 17.17522658610272,
      "eval_loss": 1.3635934591293335,
      "eval_runtime": 700.0231,
      "eval_samples_per_second": 75.853,
      "eval_steps_per_second": 0.593,
      "step": 56850
    },
    {
      "epoch": 17.190332326283986,
      "grad_norm": 0.5709131956100464,
      "learning_rate": 5.520664652567976e-05,
      "loss": 1.3386,
      "step": 56900
    },
    {
      "epoch": 17.190332326283986,
      "eval_loss": 1.3590551614761353,
      "eval_runtime": 789.264,
      "eval_samples_per_second": 67.277,
      "eval_steps_per_second": 0.526,
      "step": 56900
    },
    {
      "epoch": 17.205438066465256,
      "grad_norm": 0.5425175428390503,
      "learning_rate": 5.5196576032225586e-05,
      "loss": 1.3354,
      "step": 56950
    },
    {
      "epoch": 17.205438066465256,
      "eval_loss": 1.3614753484725952,
      "eval_runtime": 698.8717,
      "eval_samples_per_second": 75.978,
      "eval_steps_per_second": 0.594,
      "step": 56950
    },
    {
      "epoch": 17.220543806646525,
      "grad_norm": 0.509783923625946,
      "learning_rate": 5.5186505538771404e-05,
      "loss": 1.3527,
      "step": 57000
    },
    {
      "epoch": 17.220543806646525,
      "eval_loss": 1.3594586849212646,
      "eval_runtime": 625.3414,
      "eval_samples_per_second": 84.912,
      "eval_steps_per_second": 0.664,
      "step": 57000
    },
    {
      "epoch": 17.235649546827794,
      "grad_norm": 0.5055949091911316,
      "learning_rate": 5.517643504531722e-05,
      "loss": 1.3456,
      "step": 57050
    },
    {
      "epoch": 17.235649546827794,
      "eval_loss": 1.3586654663085938,
      "eval_runtime": 623.8589,
      "eval_samples_per_second": 85.114,
      "eval_steps_per_second": 0.665,
      "step": 57050
    },
    {
      "epoch": 17.250755287009063,
      "grad_norm": 0.5103828310966492,
      "learning_rate": 5.516636455186304e-05,
      "loss": 1.3328,
      "step": 57100
    },
    {
      "epoch": 17.250755287009063,
      "eval_loss": 1.3616337776184082,
      "eval_runtime": 706.0886,
      "eval_samples_per_second": 75.202,
      "eval_steps_per_second": 0.588,
      "step": 57100
    },
    {
      "epoch": 17.265861027190333,
      "grad_norm": 0.5235001444816589,
      "learning_rate": 5.515629405840887e-05,
      "loss": 1.314,
      "step": 57150
    },
    {
      "epoch": 17.265861027190333,
      "eval_loss": 1.3622454404830933,
      "eval_runtime": 634.0628,
      "eval_samples_per_second": 83.744,
      "eval_steps_per_second": 0.655,
      "step": 57150
    },
    {
      "epoch": 17.280966767371602,
      "grad_norm": 0.5167179703712463,
      "learning_rate": 5.5146223564954686e-05,
      "loss": 1.3443,
      "step": 57200
    },
    {
      "epoch": 17.280966767371602,
      "eval_loss": 1.3609769344329834,
      "eval_runtime": 691.4398,
      "eval_samples_per_second": 76.795,
      "eval_steps_per_second": 0.6,
      "step": 57200
    },
    {
      "epoch": 17.29607250755287,
      "grad_norm": 0.5274014472961426,
      "learning_rate": 5.5136153071500505e-05,
      "loss": 1.3435,
      "step": 57250
    },
    {
      "epoch": 17.29607250755287,
      "eval_loss": 1.3612501621246338,
      "eval_runtime": 680.075,
      "eval_samples_per_second": 78.078,
      "eval_steps_per_second": 0.61,
      "step": 57250
    },
    {
      "epoch": 17.31117824773414,
      "grad_norm": 0.5456421971321106,
      "learning_rate": 5.512608257804632e-05,
      "loss": 1.3286,
      "step": 57300
    },
    {
      "epoch": 17.31117824773414,
      "eval_loss": 1.3589611053466797,
      "eval_runtime": 675.5742,
      "eval_samples_per_second": 78.598,
      "eval_steps_per_second": 0.614,
      "step": 57300
    },
    {
      "epoch": 17.326283987915406,
      "grad_norm": 0.4888179898262024,
      "learning_rate": 5.511601208459215e-05,
      "loss": 1.3375,
      "step": 57350
    },
    {
      "epoch": 17.326283987915406,
      "eval_loss": 1.3609356880187988,
      "eval_runtime": 686.4352,
      "eval_samples_per_second": 77.355,
      "eval_steps_per_second": 0.605,
      "step": 57350
    },
    {
      "epoch": 17.341389728096676,
      "grad_norm": 0.4953087568283081,
      "learning_rate": 5.510594159113797e-05,
      "loss": 1.3279,
      "step": 57400
    },
    {
      "epoch": 17.341389728096676,
      "eval_loss": 1.360220193862915,
      "eval_runtime": 675.5585,
      "eval_samples_per_second": 78.6,
      "eval_steps_per_second": 0.614,
      "step": 57400
    },
    {
      "epoch": 17.356495468277945,
      "grad_norm": 0.48630353808403015,
      "learning_rate": 5.5095871097683786e-05,
      "loss": 1.3502,
      "step": 57450
    },
    {
      "epoch": 17.356495468277945,
      "eval_loss": 1.3609105348587036,
      "eval_runtime": 622.3816,
      "eval_samples_per_second": 85.316,
      "eval_steps_per_second": 0.667,
      "step": 57450
    },
    {
      "epoch": 17.371601208459214,
      "grad_norm": 0.5323360562324524,
      "learning_rate": 5.5085800604229605e-05,
      "loss": 1.3607,
      "step": 57500
    },
    {
      "epoch": 17.371601208459214,
      "eval_loss": 1.3601495027542114,
      "eval_runtime": 617.5031,
      "eval_samples_per_second": 85.99,
      "eval_steps_per_second": 0.672,
      "step": 57500
    },
    {
      "epoch": 17.386706948640484,
      "grad_norm": 0.4974187910556793,
      "learning_rate": 5.507573011077543e-05,
      "loss": 1.3458,
      "step": 57550
    },
    {
      "epoch": 17.386706948640484,
      "eval_loss": 1.359140157699585,
      "eval_runtime": 660.0949,
      "eval_samples_per_second": 80.441,
      "eval_steps_per_second": 0.629,
      "step": 57550
    },
    {
      "epoch": 17.401812688821753,
      "grad_norm": 0.48310625553131104,
      "learning_rate": 5.506565961732125e-05,
      "loss": 1.3476,
      "step": 57600
    },
    {
      "epoch": 17.401812688821753,
      "eval_loss": 1.3604143857955933,
      "eval_runtime": 643.9434,
      "eval_samples_per_second": 82.459,
      "eval_steps_per_second": 0.644,
      "step": 57600
    },
    {
      "epoch": 17.416918429003022,
      "grad_norm": 0.5044103860855103,
      "learning_rate": 5.505558912386707e-05,
      "loss": 1.3329,
      "step": 57650
    },
    {
      "epoch": 17.416918429003022,
      "eval_loss": 1.3597488403320312,
      "eval_runtime": 672.9981,
      "eval_samples_per_second": 78.899,
      "eval_steps_per_second": 0.617,
      "step": 57650
    },
    {
      "epoch": 17.43202416918429,
      "grad_norm": 0.5012694001197815,
      "learning_rate": 5.504551863041289e-05,
      "loss": 1.3659,
      "step": 57700
    },
    {
      "epoch": 17.43202416918429,
      "eval_loss": 1.361063003540039,
      "eval_runtime": 617.7528,
      "eval_samples_per_second": 85.955,
      "eval_steps_per_second": 0.672,
      "step": 57700
    },
    {
      "epoch": 17.447129909365557,
      "grad_norm": 0.5291391015052795,
      "learning_rate": 5.503544813695871e-05,
      "loss": 1.335,
      "step": 57750
    },
    {
      "epoch": 17.447129909365557,
      "eval_loss": 1.3586457967758179,
      "eval_runtime": 701.1851,
      "eval_samples_per_second": 75.728,
      "eval_steps_per_second": 0.592,
      "step": 57750
    },
    {
      "epoch": 17.462235649546827,
      "grad_norm": 0.5181128978729248,
      "learning_rate": 5.502537764350453e-05,
      "loss": 1.351,
      "step": 57800
    },
    {
      "epoch": 17.462235649546827,
      "eval_loss": 1.3615554571151733,
      "eval_runtime": 649.1376,
      "eval_samples_per_second": 81.799,
      "eval_steps_per_second": 0.639,
      "step": 57800
    },
    {
      "epoch": 17.477341389728096,
      "grad_norm": 0.5319236516952515,
      "learning_rate": 5.501530715005035e-05,
      "loss": 1.3536,
      "step": 57850
    },
    {
      "epoch": 17.477341389728096,
      "eval_loss": 1.360313892364502,
      "eval_runtime": 647.6753,
      "eval_samples_per_second": 81.984,
      "eval_steps_per_second": 0.641,
      "step": 57850
    },
    {
      "epoch": 17.492447129909365,
      "grad_norm": 0.5352767705917358,
      "learning_rate": 5.5005236656596175e-05,
      "loss": 1.3268,
      "step": 57900
    },
    {
      "epoch": 17.492447129909365,
      "eval_loss": 1.3586978912353516,
      "eval_runtime": 711.3597,
      "eval_samples_per_second": 74.644,
      "eval_steps_per_second": 0.583,
      "step": 57900
    },
    {
      "epoch": 17.507552870090635,
      "grad_norm": 0.5587167739868164,
      "learning_rate": 5.499516616314199e-05,
      "loss": 1.3376,
      "step": 57950
    },
    {
      "epoch": 17.507552870090635,
      "eval_loss": 1.3615314960479736,
      "eval_runtime": 696.716,
      "eval_samples_per_second": 76.213,
      "eval_steps_per_second": 0.596,
      "step": 57950
    },
    {
      "epoch": 17.522658610271904,
      "grad_norm": 0.5965714454650879,
      "learning_rate": 5.498509566968782e-05,
      "loss": 1.3224,
      "step": 58000
    },
    {
      "epoch": 17.522658610271904,
      "eval_loss": 1.3600565195083618,
      "eval_runtime": 636.6958,
      "eval_samples_per_second": 83.398,
      "eval_steps_per_second": 0.652,
      "step": 58000
    },
    {
      "epoch": 17.537764350453173,
      "grad_norm": 0.5037333965301514,
      "learning_rate": 5.497502517623364e-05,
      "loss": 1.342,
      "step": 58050
    },
    {
      "epoch": 17.537764350453173,
      "eval_loss": 1.3616896867752075,
      "eval_runtime": 662.1172,
      "eval_samples_per_second": 80.196,
      "eval_steps_per_second": 0.627,
      "step": 58050
    },
    {
      "epoch": 17.552870090634443,
      "grad_norm": 0.5272897481918335,
      "learning_rate": 5.496495468277946e-05,
      "loss": 1.3353,
      "step": 58100
    },
    {
      "epoch": 17.552870090634443,
      "eval_loss": 1.360203742980957,
      "eval_runtime": 711.0127,
      "eval_samples_per_second": 74.681,
      "eval_steps_per_second": 0.584,
      "step": 58100
    },
    {
      "epoch": 17.56797583081571,
      "grad_norm": 0.5316163301467896,
      "learning_rate": 5.495488418932528e-05,
      "loss": 1.3282,
      "step": 58150
    },
    {
      "epoch": 17.56797583081571,
      "eval_loss": 1.358261227607727,
      "eval_runtime": 696.5956,
      "eval_samples_per_second": 76.226,
      "eval_steps_per_second": 0.596,
      "step": 58150
    },
    {
      "epoch": 17.583081570996978,
      "grad_norm": 0.5142291188240051,
      "learning_rate": 5.49448136958711e-05,
      "loss": 1.3444,
      "step": 58200
    },
    {
      "epoch": 17.583081570996978,
      "eval_loss": 1.3600497245788574,
      "eval_runtime": 643.438,
      "eval_samples_per_second": 82.524,
      "eval_steps_per_second": 0.645,
      "step": 58200
    },
    {
      "epoch": 17.598187311178247,
      "grad_norm": 0.5194198489189148,
      "learning_rate": 5.493474320241692e-05,
      "loss": 1.3287,
      "step": 58250
    },
    {
      "epoch": 17.598187311178247,
      "eval_loss": 1.3605866432189941,
      "eval_runtime": 622.9856,
      "eval_samples_per_second": 85.233,
      "eval_steps_per_second": 0.666,
      "step": 58250
    },
    {
      "epoch": 17.613293051359516,
      "grad_norm": 0.4817735254764557,
      "learning_rate": 5.4924672708962744e-05,
      "loss": 1.3285,
      "step": 58300
    },
    {
      "epoch": 17.613293051359516,
      "eval_loss": 1.35809326171875,
      "eval_runtime": 744.0677,
      "eval_samples_per_second": 71.363,
      "eval_steps_per_second": 0.558,
      "step": 58300
    },
    {
      "epoch": 17.628398791540786,
      "grad_norm": 0.5188039541244507,
      "learning_rate": 5.491460221550856e-05,
      "loss": 1.3336,
      "step": 58350
    },
    {
      "epoch": 17.628398791540786,
      "eval_loss": 1.3584883213043213,
      "eval_runtime": 607.5038,
      "eval_samples_per_second": 87.405,
      "eval_steps_per_second": 0.683,
      "step": 58350
    },
    {
      "epoch": 17.643504531722055,
      "grad_norm": 0.5064590573310852,
      "learning_rate": 5.490453172205438e-05,
      "loss": 1.341,
      "step": 58400
    },
    {
      "epoch": 17.643504531722055,
      "eval_loss": 1.358957290649414,
      "eval_runtime": 698.1056,
      "eval_samples_per_second": 76.062,
      "eval_steps_per_second": 0.594,
      "step": 58400
    },
    {
      "epoch": 17.658610271903324,
      "grad_norm": 0.5468868613243103,
      "learning_rate": 5.48944612286002e-05,
      "loss": 1.335,
      "step": 58450
    },
    {
      "epoch": 17.658610271903324,
      "eval_loss": 1.3587260246276855,
      "eval_runtime": 690.8615,
      "eval_samples_per_second": 76.859,
      "eval_steps_per_second": 0.601,
      "step": 58450
    },
    {
      "epoch": 17.673716012084594,
      "grad_norm": 0.5139057040214539,
      "learning_rate": 5.4884390735146026e-05,
      "loss": 1.3382,
      "step": 58500
    },
    {
      "epoch": 17.673716012084594,
      "eval_loss": 1.3579397201538086,
      "eval_runtime": 696.3444,
      "eval_samples_per_second": 76.254,
      "eval_steps_per_second": 0.596,
      "step": 58500
    },
    {
      "epoch": 17.68882175226586,
      "grad_norm": 0.5130036473274231,
      "learning_rate": 5.4874320241691845e-05,
      "loss": 1.3224,
      "step": 58550
    },
    {
      "epoch": 17.68882175226586,
      "eval_loss": 1.3539496660232544,
      "eval_runtime": 711.1379,
      "eval_samples_per_second": 74.668,
      "eval_steps_per_second": 0.584,
      "step": 58550
    },
    {
      "epoch": 17.70392749244713,
      "grad_norm": 0.5176281929016113,
      "learning_rate": 5.486424974823766e-05,
      "loss": 1.3417,
      "step": 58600
    },
    {
      "epoch": 17.70392749244713,
      "eval_loss": 1.358025074005127,
      "eval_runtime": 710.8333,
      "eval_samples_per_second": 74.7,
      "eval_steps_per_second": 0.584,
      "step": 58600
    },
    {
      "epoch": 17.719033232628398,
      "grad_norm": 0.5594184994697571,
      "learning_rate": 5.485417925478348e-05,
      "loss": 1.3228,
      "step": 58650
    },
    {
      "epoch": 17.719033232628398,
      "eval_loss": 1.355748176574707,
      "eval_runtime": 710.1562,
      "eval_samples_per_second": 74.771,
      "eval_steps_per_second": 0.584,
      "step": 58650
    },
    {
      "epoch": 17.734138972809667,
      "grad_norm": 0.4598894417285919,
      "learning_rate": 5.484410876132931e-05,
      "loss": 1.3318,
      "step": 58700
    },
    {
      "epoch": 17.734138972809667,
      "eval_loss": 1.3572607040405273,
      "eval_runtime": 619.0421,
      "eval_samples_per_second": 85.776,
      "eval_steps_per_second": 0.67,
      "step": 58700
    },
    {
      "epoch": 17.749244712990937,
      "grad_norm": 0.4673003852367401,
      "learning_rate": 5.4834038267875126e-05,
      "loss": 1.3327,
      "step": 58750
    },
    {
      "epoch": 17.749244712990937,
      "eval_loss": 1.35663902759552,
      "eval_runtime": 1411.984,
      "eval_samples_per_second": 37.606,
      "eval_steps_per_second": 0.294,
      "step": 58750
    },
    {
      "epoch": 17.764350453172206,
      "grad_norm": 0.5114690661430359,
      "learning_rate": 5.4823967774420945e-05,
      "loss": 1.3273,
      "step": 58800
    },
    {
      "epoch": 17.764350453172206,
      "eval_loss": 1.3575029373168945,
      "eval_runtime": 763.2245,
      "eval_samples_per_second": 69.572,
      "eval_steps_per_second": 0.544,
      "step": 58800
    },
    {
      "epoch": 17.779456193353475,
      "grad_norm": 0.5231975317001343,
      "learning_rate": 5.481389728096677e-05,
      "loss": 1.3172,
      "step": 58850
    },
    {
      "epoch": 17.779456193353475,
      "eval_loss": 1.3569737672805786,
      "eval_runtime": 689.6491,
      "eval_samples_per_second": 76.994,
      "eval_steps_per_second": 0.602,
      "step": 58850
    },
    {
      "epoch": 17.794561933534744,
      "grad_norm": 0.5101891160011292,
      "learning_rate": 5.480382678751259e-05,
      "loss": 1.3172,
      "step": 58900
    },
    {
      "epoch": 17.794561933534744,
      "eval_loss": 1.3561062812805176,
      "eval_runtime": 715.7942,
      "eval_samples_per_second": 74.182,
      "eval_steps_per_second": 0.58,
      "step": 58900
    },
    {
      "epoch": 17.809667673716014,
      "grad_norm": 0.5426963567733765,
      "learning_rate": 5.479375629405841e-05,
      "loss": 1.3292,
      "step": 58950
    },
    {
      "epoch": 17.809667673716014,
      "eval_loss": 1.355408787727356,
      "eval_runtime": 693.7187,
      "eval_samples_per_second": 76.543,
      "eval_steps_per_second": 0.598,
      "step": 58950
    },
    {
      "epoch": 17.82477341389728,
      "grad_norm": 0.5421400666236877,
      "learning_rate": 5.4783685800604226e-05,
      "loss": 1.3253,
      "step": 59000
    },
    {
      "epoch": 17.82477341389728,
      "eval_loss": 1.3559675216674805,
      "eval_runtime": 645.031,
      "eval_samples_per_second": 82.32,
      "eval_steps_per_second": 0.643,
      "step": 59000
    },
    {
      "epoch": 17.83987915407855,
      "grad_norm": 0.5282860994338989,
      "learning_rate": 5.477361530715005e-05,
      "loss": 1.341,
      "step": 59050
    },
    {
      "epoch": 17.83987915407855,
      "eval_loss": 1.3559584617614746,
      "eval_runtime": 669.3138,
      "eval_samples_per_second": 79.333,
      "eval_steps_per_second": 0.62,
      "step": 59050
    },
    {
      "epoch": 17.854984894259818,
      "grad_norm": 0.46678200364112854,
      "learning_rate": 5.476354481369587e-05,
      "loss": 1.3477,
      "step": 59100
    },
    {
      "epoch": 17.854984894259818,
      "eval_loss": 1.3563400506973267,
      "eval_runtime": 698.0615,
      "eval_samples_per_second": 76.066,
      "eval_steps_per_second": 0.595,
      "step": 59100
    },
    {
      "epoch": 17.870090634441087,
      "grad_norm": 0.5366848707199097,
      "learning_rate": 5.4753474320241696e-05,
      "loss": 1.3027,
      "step": 59150
    },
    {
      "epoch": 17.870090634441087,
      "eval_loss": 1.3542877435684204,
      "eval_runtime": 590.1876,
      "eval_samples_per_second": 89.97,
      "eval_steps_per_second": 0.703,
      "step": 59150
    },
    {
      "epoch": 17.885196374622357,
      "grad_norm": 0.5154303312301636,
      "learning_rate": 5.4743403826787515e-05,
      "loss": 1.3385,
      "step": 59200
    },
    {
      "epoch": 17.885196374622357,
      "eval_loss": 1.3542839288711548,
      "eval_runtime": 693.1338,
      "eval_samples_per_second": 76.607,
      "eval_steps_per_second": 0.599,
      "step": 59200
    },
    {
      "epoch": 17.900302114803626,
      "grad_norm": 0.5649290084838867,
      "learning_rate": 5.473333333333334e-05,
      "loss": 1.3326,
      "step": 59250
    },
    {
      "epoch": 17.900302114803626,
      "eval_loss": 1.3548362255096436,
      "eval_runtime": 711.4926,
      "eval_samples_per_second": 74.63,
      "eval_steps_per_second": 0.583,
      "step": 59250
    },
    {
      "epoch": 17.915407854984895,
      "grad_norm": 0.5272582173347473,
      "learning_rate": 5.472326283987916e-05,
      "loss": 1.344,
      "step": 59300
    },
    {
      "epoch": 17.915407854984895,
      "eval_loss": 1.3532841205596924,
      "eval_runtime": 650.664,
      "eval_samples_per_second": 81.607,
      "eval_steps_per_second": 0.638,
      "step": 59300
    },
    {
      "epoch": 17.930513595166165,
      "grad_norm": 0.4683024287223816,
      "learning_rate": 5.471319234642498e-05,
      "loss": 1.3243,
      "step": 59350
    },
    {
      "epoch": 17.930513595166165,
      "eval_loss": 1.3557313680648804,
      "eval_runtime": 589.2528,
      "eval_samples_per_second": 90.112,
      "eval_steps_per_second": 0.704,
      "step": 59350
    },
    {
      "epoch": 17.94561933534743,
      "grad_norm": 0.5183467864990234,
      "learning_rate": 5.4703121852970796e-05,
      "loss": 1.3321,
      "step": 59400
    },
    {
      "epoch": 17.94561933534743,
      "eval_loss": 1.3566474914550781,
      "eval_runtime": 632.5741,
      "eval_samples_per_second": 83.941,
      "eval_steps_per_second": 0.656,
      "step": 59400
    },
    {
      "epoch": 17.9607250755287,
      "grad_norm": 0.5045500993728638,
      "learning_rate": 5.469305135951662e-05,
      "loss": 1.3331,
      "step": 59450
    },
    {
      "epoch": 17.9607250755287,
      "eval_loss": 1.3536754846572876,
      "eval_runtime": 667.0241,
      "eval_samples_per_second": 79.606,
      "eval_steps_per_second": 0.622,
      "step": 59450
    },
    {
      "epoch": 17.97583081570997,
      "grad_norm": 0.5787469148635864,
      "learning_rate": 5.468298086606244e-05,
      "loss": 1.3229,
      "step": 59500
    },
    {
      "epoch": 17.97583081570997,
      "eval_loss": 1.3570750951766968,
      "eval_runtime": 633.4747,
      "eval_samples_per_second": 83.822,
      "eval_steps_per_second": 0.655,
      "step": 59500
    },
    {
      "epoch": 17.99093655589124,
      "grad_norm": 0.4411330223083496,
      "learning_rate": 5.467291037260826e-05,
      "loss": 1.3299,
      "step": 59550
    },
    {
      "epoch": 17.99093655589124,
      "eval_loss": 1.3537534475326538,
      "eval_runtime": 651.9851,
      "eval_samples_per_second": 81.442,
      "eval_steps_per_second": 0.637,
      "step": 59550
    },
    {
      "epoch": 18.006042296072508,
      "grad_norm": 0.5120583772659302,
      "learning_rate": 5.466283987915408e-05,
      "loss": 1.3476,
      "step": 59600
    },
    {
      "epoch": 18.006042296072508,
      "eval_loss": 1.3544576168060303,
      "eval_runtime": 685.8845,
      "eval_samples_per_second": 77.417,
      "eval_steps_per_second": 0.605,
      "step": 59600
    },
    {
      "epoch": 18.021148036253777,
      "grad_norm": 0.5782233476638794,
      "learning_rate": 5.46527693856999e-05,
      "loss": 1.3221,
      "step": 59650
    },
    {
      "epoch": 18.021148036253777,
      "eval_loss": 1.3571759462356567,
      "eval_runtime": 657.9333,
      "eval_samples_per_second": 80.706,
      "eval_steps_per_second": 0.631,
      "step": 59650
    },
    {
      "epoch": 18.036253776435046,
      "grad_norm": 0.49760714173316956,
      "learning_rate": 5.464269889224572e-05,
      "loss": 1.3268,
      "step": 59700
    },
    {
      "epoch": 18.036253776435046,
      "eval_loss": 1.3520845174789429,
      "eval_runtime": 692.8699,
      "eval_samples_per_second": 76.636,
      "eval_steps_per_second": 0.599,
      "step": 59700
    },
    {
      "epoch": 18.051359516616316,
      "grad_norm": 0.495246559381485,
      "learning_rate": 5.463262839879154e-05,
      "loss": 1.3115,
      "step": 59750
    },
    {
      "epoch": 18.051359516616316,
      "eval_loss": 1.3558233976364136,
      "eval_runtime": 689.489,
      "eval_samples_per_second": 77.012,
      "eval_steps_per_second": 0.602,
      "step": 59750
    },
    {
      "epoch": 18.06646525679758,
      "grad_norm": 0.4731508195400238,
      "learning_rate": 5.462255790533736e-05,
      "loss": 1.3432,
      "step": 59800
    },
    {
      "epoch": 18.06646525679758,
      "eval_loss": 1.3552623987197876,
      "eval_runtime": 681.277,
      "eval_samples_per_second": 77.94,
      "eval_steps_per_second": 0.609,
      "step": 59800
    },
    {
      "epoch": 18.08157099697885,
      "grad_norm": 0.5140150189399719,
      "learning_rate": 5.4612487411883185e-05,
      "loss": 1.3439,
      "step": 59850
    },
    {
      "epoch": 18.08157099697885,
      "eval_loss": 1.3542323112487793,
      "eval_runtime": 682.7835,
      "eval_samples_per_second": 77.768,
      "eval_steps_per_second": 0.608,
      "step": 59850
    },
    {
      "epoch": 18.09667673716012,
      "grad_norm": 0.4672185182571411,
      "learning_rate": 5.4602416918429e-05,
      "loss": 1.3245,
      "step": 59900
    },
    {
      "epoch": 18.09667673716012,
      "eval_loss": 1.355834722518921,
      "eval_runtime": 652.2023,
      "eval_samples_per_second": 81.415,
      "eval_steps_per_second": 0.636,
      "step": 59900
    },
    {
      "epoch": 18.11178247734139,
      "grad_norm": 0.5509049296379089,
      "learning_rate": 5.459234642497482e-05,
      "loss": 1.3528,
      "step": 59950
    },
    {
      "epoch": 18.11178247734139,
      "eval_loss": 1.3555316925048828,
      "eval_runtime": 609.5278,
      "eval_samples_per_second": 87.115,
      "eval_steps_per_second": 0.681,
      "step": 59950
    },
    {
      "epoch": 18.12688821752266,
      "grad_norm": 0.49646395444869995,
      "learning_rate": 5.458227593152065e-05,
      "loss": 1.3257,
      "step": 60000
    },
    {
      "epoch": 18.12688821752266,
      "eval_loss": 1.3536627292633057,
      "eval_runtime": 629.3631,
      "eval_samples_per_second": 84.369,
      "eval_steps_per_second": 0.659,
      "step": 60000
    },
    {
      "epoch": 18.141993957703928,
      "grad_norm": 0.4578133821487427,
      "learning_rate": 5.4572205438066466e-05,
      "loss": 1.3338,
      "step": 60050
    },
    {
      "epoch": 18.141993957703928,
      "eval_loss": 1.3570051193237305,
      "eval_runtime": 716.0912,
      "eval_samples_per_second": 74.151,
      "eval_steps_per_second": 0.58,
      "step": 60050
    },
    {
      "epoch": 18.157099697885197,
      "grad_norm": 0.581471860408783,
      "learning_rate": 5.4562134944612285e-05,
      "loss": 1.3081,
      "step": 60100
    },
    {
      "epoch": 18.157099697885197,
      "eval_loss": 1.3544098138809204,
      "eval_runtime": 627.0099,
      "eval_samples_per_second": 84.686,
      "eval_steps_per_second": 0.662,
      "step": 60100
    },
    {
      "epoch": 18.172205438066467,
      "grad_norm": 0.5379969477653503,
      "learning_rate": 5.4552064451158104e-05,
      "loss": 1.317,
      "step": 60150
    },
    {
      "epoch": 18.172205438066467,
      "eval_loss": 1.3521368503570557,
      "eval_runtime": 658.1387,
      "eval_samples_per_second": 80.681,
      "eval_steps_per_second": 0.631,
      "step": 60150
    },
    {
      "epoch": 18.187311178247732,
      "grad_norm": 0.5691713690757751,
      "learning_rate": 5.454199395770393e-05,
      "loss": 1.3447,
      "step": 60200
    },
    {
      "epoch": 18.187311178247732,
      "eval_loss": 1.3535112142562866,
      "eval_runtime": 647.3015,
      "eval_samples_per_second": 82.031,
      "eval_steps_per_second": 0.641,
      "step": 60200
    },
    {
      "epoch": 18.202416918429,
      "grad_norm": 0.533970832824707,
      "learning_rate": 5.453192346424975e-05,
      "loss": 1.3351,
      "step": 60250
    },
    {
      "epoch": 18.202416918429,
      "eval_loss": 1.3538081645965576,
      "eval_runtime": 674.9979,
      "eval_samples_per_second": 78.665,
      "eval_steps_per_second": 0.615,
      "step": 60250
    },
    {
      "epoch": 18.21752265861027,
      "grad_norm": 0.5133771896362305,
      "learning_rate": 5.4521852970795566e-05,
      "loss": 1.3279,
      "step": 60300
    },
    {
      "epoch": 18.21752265861027,
      "eval_loss": 1.3539674282073975,
      "eval_runtime": 662.1723,
      "eval_samples_per_second": 80.189,
      "eval_steps_per_second": 0.627,
      "step": 60300
    },
    {
      "epoch": 18.23262839879154,
      "grad_norm": 0.5694714188575745,
      "learning_rate": 5.451178247734139e-05,
      "loss": 1.3282,
      "step": 60350
    },
    {
      "epoch": 18.23262839879154,
      "eval_loss": 1.3539133071899414,
      "eval_runtime": 682.0417,
      "eval_samples_per_second": 77.853,
      "eval_steps_per_second": 0.608,
      "step": 60350
    },
    {
      "epoch": 18.24773413897281,
      "grad_norm": 0.5293237566947937,
      "learning_rate": 5.450171198388722e-05,
      "loss": 1.3363,
      "step": 60400
    },
    {
      "epoch": 18.24773413897281,
      "eval_loss": 1.3515065908432007,
      "eval_runtime": 624.4171,
      "eval_samples_per_second": 85.038,
      "eval_steps_per_second": 0.665,
      "step": 60400
    },
    {
      "epoch": 18.26283987915408,
      "grad_norm": 0.5716665387153625,
      "learning_rate": 5.4491641490433036e-05,
      "loss": 1.3283,
      "step": 60450
    },
    {
      "epoch": 18.26283987915408,
      "eval_loss": 1.3526899814605713,
      "eval_runtime": 637.6864,
      "eval_samples_per_second": 83.268,
      "eval_steps_per_second": 0.651,
      "step": 60450
    },
    {
      "epoch": 18.27794561933535,
      "grad_norm": 0.4763275384902954,
      "learning_rate": 5.4481570996978855e-05,
      "loss": 1.3268,
      "step": 60500
    },
    {
      "epoch": 18.27794561933535,
      "eval_loss": 1.3511637449264526,
      "eval_runtime": 1023.3206,
      "eval_samples_per_second": 51.889,
      "eval_steps_per_second": 0.406,
      "step": 60500
    },
    {
      "epoch": 18.293051359516618,
      "grad_norm": 0.4562079906463623,
      "learning_rate": 5.447150050352467e-05,
      "loss": 1.3141,
      "step": 60550
    },
    {
      "epoch": 18.293051359516618,
      "eval_loss": 1.3547735214233398,
      "eval_runtime": 704.8503,
      "eval_samples_per_second": 75.334,
      "eval_steps_per_second": 0.589,
      "step": 60550
    },
    {
      "epoch": 18.308157099697887,
      "grad_norm": 0.534509003162384,
      "learning_rate": 5.44614300100705e-05,
      "loss": 1.3225,
      "step": 60600
    },
    {
      "epoch": 18.308157099697887,
      "eval_loss": 1.3535089492797852,
      "eval_runtime": 616.8869,
      "eval_samples_per_second": 86.076,
      "eval_steps_per_second": 0.673,
      "step": 60600
    },
    {
      "epoch": 18.323262839879153,
      "grad_norm": 0.5520313382148743,
      "learning_rate": 5.445135951661632e-05,
      "loss": 1.3094,
      "step": 60650
    },
    {
      "epoch": 18.323262839879153,
      "eval_loss": 1.35321044921875,
      "eval_runtime": 649.7149,
      "eval_samples_per_second": 81.727,
      "eval_steps_per_second": 0.639,
      "step": 60650
    },
    {
      "epoch": 18.338368580060422,
      "grad_norm": 0.5339381694793701,
      "learning_rate": 5.4441289023162136e-05,
      "loss": 1.3278,
      "step": 60700
    },
    {
      "epoch": 18.338368580060422,
      "eval_loss": 1.3555537462234497,
      "eval_runtime": 648.8304,
      "eval_samples_per_second": 81.838,
      "eval_steps_per_second": 0.64,
      "step": 60700
    },
    {
      "epoch": 18.35347432024169,
      "grad_norm": 0.48347195982933044,
      "learning_rate": 5.4431218529707955e-05,
      "loss": 1.3171,
      "step": 60750
    },
    {
      "epoch": 18.35347432024169,
      "eval_loss": 1.3522030115127563,
      "eval_runtime": 715.6171,
      "eval_samples_per_second": 74.2,
      "eval_steps_per_second": 0.58,
      "step": 60750
    },
    {
      "epoch": 18.36858006042296,
      "grad_norm": 0.5383223295211792,
      "learning_rate": 5.442114803625378e-05,
      "loss": 1.3184,
      "step": 60800
    },
    {
      "epoch": 18.36858006042296,
      "eval_loss": 1.3517564535140991,
      "eval_runtime": 677.4189,
      "eval_samples_per_second": 78.384,
      "eval_steps_per_second": 0.613,
      "step": 60800
    },
    {
      "epoch": 18.38368580060423,
      "grad_norm": 0.4876514673233032,
      "learning_rate": 5.44110775427996e-05,
      "loss": 1.3194,
      "step": 60850
    },
    {
      "epoch": 18.38368580060423,
      "eval_loss": 1.3521872758865356,
      "eval_runtime": 645.6163,
      "eval_samples_per_second": 82.245,
      "eval_steps_per_second": 0.643,
      "step": 60850
    },
    {
      "epoch": 18.3987915407855,
      "grad_norm": 0.46411392092704773,
      "learning_rate": 5.440100704934542e-05,
      "loss": 1.3469,
      "step": 60900
    },
    {
      "epoch": 18.3987915407855,
      "eval_loss": 1.351249098777771,
      "eval_runtime": 703.3128,
      "eval_samples_per_second": 75.498,
      "eval_steps_per_second": 0.59,
      "step": 60900
    },
    {
      "epoch": 18.41389728096677,
      "grad_norm": 0.49956899881362915,
      "learning_rate": 5.4390936555891236e-05,
      "loss": 1.3294,
      "step": 60950
    },
    {
      "epoch": 18.41389728096677,
      "eval_loss": 1.3534828424453735,
      "eval_runtime": 674.9816,
      "eval_samples_per_second": 78.667,
      "eval_steps_per_second": 0.615,
      "step": 60950
    },
    {
      "epoch": 18.429003021148038,
      "grad_norm": 0.5518670082092285,
      "learning_rate": 5.438086606243706e-05,
      "loss": 1.3121,
      "step": 61000
    },
    {
      "epoch": 18.429003021148038,
      "eval_loss": 1.354343295097351,
      "eval_runtime": 678.8529,
      "eval_samples_per_second": 78.219,
      "eval_steps_per_second": 0.611,
      "step": 61000
    },
    {
      "epoch": 18.444108761329304,
      "grad_norm": 0.5162932872772217,
      "learning_rate": 5.437079556898288e-05,
      "loss": 1.3191,
      "step": 61050
    },
    {
      "epoch": 18.444108761329304,
      "eval_loss": 1.351804256439209,
      "eval_runtime": 686.3487,
      "eval_samples_per_second": 77.364,
      "eval_steps_per_second": 0.605,
      "step": 61050
    },
    {
      "epoch": 18.459214501510573,
      "grad_norm": 0.516524612903595,
      "learning_rate": 5.43607250755287e-05,
      "loss": 1.3048,
      "step": 61100
    },
    {
      "epoch": 18.459214501510573,
      "eval_loss": 1.3522672653198242,
      "eval_runtime": 679.5673,
      "eval_samples_per_second": 78.136,
      "eval_steps_per_second": 0.611,
      "step": 61100
    },
    {
      "epoch": 18.474320241691842,
      "grad_norm": 0.4863668978214264,
      "learning_rate": 5.4350654582074525e-05,
      "loss": 1.3312,
      "step": 61150
    },
    {
      "epoch": 18.474320241691842,
      "eval_loss": 1.3506437540054321,
      "eval_runtime": 658.5485,
      "eval_samples_per_second": 80.63,
      "eval_steps_per_second": 0.63,
      "step": 61150
    },
    {
      "epoch": 18.48942598187311,
      "grad_norm": 0.5702614784240723,
      "learning_rate": 5.434058408862034e-05,
      "loss": 1.3446,
      "step": 61200
    },
    {
      "epoch": 18.48942598187311,
      "eval_loss": 1.3525161743164062,
      "eval_runtime": 632.6657,
      "eval_samples_per_second": 83.929,
      "eval_steps_per_second": 0.656,
      "step": 61200
    },
    {
      "epoch": 18.50453172205438,
      "grad_norm": 0.46487247943878174,
      "learning_rate": 5.433051359516616e-05,
      "loss": 1.316,
      "step": 61250
    },
    {
      "epoch": 18.50453172205438,
      "eval_loss": 1.352852463722229,
      "eval_runtime": 692.7063,
      "eval_samples_per_second": 76.654,
      "eval_steps_per_second": 0.599,
      "step": 61250
    },
    {
      "epoch": 18.51963746223565,
      "grad_norm": 0.5060528516769409,
      "learning_rate": 5.432044310171198e-05,
      "loss": 1.3117,
      "step": 61300
    },
    {
      "epoch": 18.51963746223565,
      "eval_loss": 1.352744221687317,
      "eval_runtime": 717.3429,
      "eval_samples_per_second": 74.022,
      "eval_steps_per_second": 0.579,
      "step": 61300
    },
    {
      "epoch": 18.53474320241692,
      "grad_norm": 0.5177628993988037,
      "learning_rate": 5.4310372608257806e-05,
      "loss": 1.3527,
      "step": 61350
    },
    {
      "epoch": 18.53474320241692,
      "eval_loss": 1.3535850048065186,
      "eval_runtime": 651.322,
      "eval_samples_per_second": 81.525,
      "eval_steps_per_second": 0.637,
      "step": 61350
    },
    {
      "epoch": 18.54984894259819,
      "grad_norm": 0.5161418914794922,
      "learning_rate": 5.4300302114803625e-05,
      "loss": 1.3231,
      "step": 61400
    },
    {
      "epoch": 18.54984894259819,
      "eval_loss": 1.3515015840530396,
      "eval_runtime": 612.7348,
      "eval_samples_per_second": 86.659,
      "eval_steps_per_second": 0.677,
      "step": 61400
    },
    {
      "epoch": 18.564954682779454,
      "grad_norm": 0.4709491431713104,
      "learning_rate": 5.4290231621349444e-05,
      "loss": 1.3062,
      "step": 61450
    },
    {
      "epoch": 18.564954682779454,
      "eval_loss": 1.3508760929107666,
      "eval_runtime": 634.145,
      "eval_samples_per_second": 83.733,
      "eval_steps_per_second": 0.654,
      "step": 61450
    },
    {
      "epoch": 18.580060422960724,
      "grad_norm": 0.4971238374710083,
      "learning_rate": 5.428016112789527e-05,
      "loss": 1.3244,
      "step": 61500
    },
    {
      "epoch": 18.580060422960724,
      "eval_loss": 1.350226879119873,
      "eval_runtime": 713.6659,
      "eval_samples_per_second": 74.403,
      "eval_steps_per_second": 0.582,
      "step": 61500
    },
    {
      "epoch": 18.595166163141993,
      "grad_norm": 0.4770379662513733,
      "learning_rate": 5.4270090634441094e-05,
      "loss": 1.3267,
      "step": 61550
    },
    {
      "epoch": 18.595166163141993,
      "eval_loss": 1.3498731851577759,
      "eval_runtime": 662.7624,
      "eval_samples_per_second": 80.118,
      "eval_steps_per_second": 0.626,
      "step": 61550
    },
    {
      "epoch": 18.610271903323262,
      "grad_norm": 0.47990682721138,
      "learning_rate": 5.426002014098691e-05,
      "loss": 1.3426,
      "step": 61600
    },
    {
      "epoch": 18.610271903323262,
      "eval_loss": 1.3510711193084717,
      "eval_runtime": 642.2489,
      "eval_samples_per_second": 82.677,
      "eval_steps_per_second": 0.646,
      "step": 61600
    },
    {
      "epoch": 18.62537764350453,
      "grad_norm": 0.5023549795150757,
      "learning_rate": 5.424994964753273e-05,
      "loss": 1.3392,
      "step": 61650
    },
    {
      "epoch": 18.62537764350453,
      "eval_loss": 1.3498849868774414,
      "eval_runtime": 708.398,
      "eval_samples_per_second": 74.956,
      "eval_steps_per_second": 0.586,
      "step": 61650
    },
    {
      "epoch": 18.6404833836858,
      "grad_norm": 0.5273448824882507,
      "learning_rate": 5.423987915407855e-05,
      "loss": 1.3141,
      "step": 61700
    },
    {
      "epoch": 18.6404833836858,
      "eval_loss": 1.3525943756103516,
      "eval_runtime": 621.3979,
      "eval_samples_per_second": 85.451,
      "eval_steps_per_second": 0.668,
      "step": 61700
    },
    {
      "epoch": 18.65558912386707,
      "grad_norm": 0.4868473708629608,
      "learning_rate": 5.4229808660624376e-05,
      "loss": 1.3254,
      "step": 61750
    },
    {
      "epoch": 18.65558912386707,
      "eval_loss": 1.3534091711044312,
      "eval_runtime": 711.2438,
      "eval_samples_per_second": 74.657,
      "eval_steps_per_second": 0.583,
      "step": 61750
    },
    {
      "epoch": 18.67069486404834,
      "grad_norm": 0.4775843620300293,
      "learning_rate": 5.4219738167170195e-05,
      "loss": 1.3284,
      "step": 61800
    },
    {
      "epoch": 18.67069486404834,
      "eval_loss": 1.3509503602981567,
      "eval_runtime": 706.0309,
      "eval_samples_per_second": 75.208,
      "eval_steps_per_second": 0.588,
      "step": 61800
    },
    {
      "epoch": 18.685800604229605,
      "grad_norm": 0.5668249130249023,
      "learning_rate": 5.420966767371601e-05,
      "loss": 1.3488,
      "step": 61850
    },
    {
      "epoch": 18.685800604229605,
      "eval_loss": 1.3496702909469604,
      "eval_runtime": 701.887,
      "eval_samples_per_second": 75.652,
      "eval_steps_per_second": 0.591,
      "step": 61850
    },
    {
      "epoch": 18.700906344410875,
      "grad_norm": 0.4993915557861328,
      "learning_rate": 5.419959718026183e-05,
      "loss": 1.3173,
      "step": 61900
    },
    {
      "epoch": 18.700906344410875,
      "eval_loss": 1.351616382598877,
      "eval_runtime": 667.4657,
      "eval_samples_per_second": 79.553,
      "eval_steps_per_second": 0.622,
      "step": 61900
    },
    {
      "epoch": 18.716012084592144,
      "grad_norm": 0.5152052640914917,
      "learning_rate": 5.418952668680766e-05,
      "loss": 1.3231,
      "step": 61950
    },
    {
      "epoch": 18.716012084592144,
      "eval_loss": 1.3505909442901611,
      "eval_runtime": 762.7745,
      "eval_samples_per_second": 69.613,
      "eval_steps_per_second": 0.544,
      "step": 61950
    },
    {
      "epoch": 18.731117824773413,
      "grad_norm": 0.48348143696784973,
      "learning_rate": 5.4179456193353476e-05,
      "loss": 1.3167,
      "step": 62000
    },
    {
      "epoch": 18.731117824773413,
      "eval_loss": 1.3511823415756226,
      "eval_runtime": 704.5147,
      "eval_samples_per_second": 75.37,
      "eval_steps_per_second": 0.589,
      "step": 62000
    },
    {
      "epoch": 18.746223564954683,
      "grad_norm": 0.5134595632553101,
      "learning_rate": 5.4169385699899295e-05,
      "loss": 1.3309,
      "step": 62050
    },
    {
      "epoch": 18.746223564954683,
      "eval_loss": 1.3487468957901,
      "eval_runtime": 628.6039,
      "eval_samples_per_second": 84.471,
      "eval_steps_per_second": 0.66,
      "step": 62050
    },
    {
      "epoch": 18.761329305135952,
      "grad_norm": 0.49551141262054443,
      "learning_rate": 5.4159315206445114e-05,
      "loss": 1.3449,
      "step": 62100
    },
    {
      "epoch": 18.761329305135952,
      "eval_loss": 1.3512399196624756,
      "eval_runtime": 620.8751,
      "eval_samples_per_second": 85.523,
      "eval_steps_per_second": 0.668,
      "step": 62100
    },
    {
      "epoch": 18.77643504531722,
      "grad_norm": 0.5265377759933472,
      "learning_rate": 5.414924471299094e-05,
      "loss": 1.3357,
      "step": 62150
    },
    {
      "epoch": 18.77643504531722,
      "eval_loss": 1.3496137857437134,
      "eval_runtime": 651.5296,
      "eval_samples_per_second": 81.499,
      "eval_steps_per_second": 0.637,
      "step": 62150
    },
    {
      "epoch": 18.79154078549849,
      "grad_norm": 0.5426825284957886,
      "learning_rate": 5.413917421953676e-05,
      "loss": 1.346,
      "step": 62200
    },
    {
      "epoch": 18.79154078549849,
      "eval_loss": 1.347683310508728,
      "eval_runtime": 619.9856,
      "eval_samples_per_second": 85.646,
      "eval_steps_per_second": 0.669,
      "step": 62200
    },
    {
      "epoch": 18.80664652567976,
      "grad_norm": 0.5187966227531433,
      "learning_rate": 5.4129103726082576e-05,
      "loss": 1.3245,
      "step": 62250
    },
    {
      "epoch": 18.80664652567976,
      "eval_loss": 1.34971022605896,
      "eval_runtime": 694.4338,
      "eval_samples_per_second": 76.464,
      "eval_steps_per_second": 0.598,
      "step": 62250
    },
    {
      "epoch": 18.821752265861026,
      "grad_norm": 0.488587886095047,
      "learning_rate": 5.41190332326284e-05,
      "loss": 1.3263,
      "step": 62300
    },
    {
      "epoch": 18.821752265861026,
      "eval_loss": 1.3506580591201782,
      "eval_runtime": 721.8223,
      "eval_samples_per_second": 73.562,
      "eval_steps_per_second": 0.575,
      "step": 62300
    },
    {
      "epoch": 18.836858006042295,
      "grad_norm": 0.48326560854911804,
      "learning_rate": 5.410896273917422e-05,
      "loss": 1.3445,
      "step": 62350
    },
    {
      "epoch": 18.836858006042295,
      "eval_loss": 1.348482370376587,
      "eval_runtime": 662.9097,
      "eval_samples_per_second": 80.1,
      "eval_steps_per_second": 0.626,
      "step": 62350
    },
    {
      "epoch": 18.851963746223564,
      "grad_norm": 0.533197283744812,
      "learning_rate": 5.409889224572004e-05,
      "loss": 1.3523,
      "step": 62400
    },
    {
      "epoch": 18.851963746223564,
      "eval_loss": 1.3484828472137451,
      "eval_runtime": 635.9425,
      "eval_samples_per_second": 83.497,
      "eval_steps_per_second": 0.653,
      "step": 62400
    },
    {
      "epoch": 18.867069486404834,
      "grad_norm": 0.5282161831855774,
      "learning_rate": 5.408882175226586e-05,
      "loss": 1.3494,
      "step": 62450
    },
    {
      "epoch": 18.867069486404834,
      "eval_loss": 1.3490657806396484,
      "eval_runtime": 621.3238,
      "eval_samples_per_second": 85.461,
      "eval_steps_per_second": 0.668,
      "step": 62450
    },
    {
      "epoch": 18.882175226586103,
      "grad_norm": 0.4974813759326935,
      "learning_rate": 5.4078751258811683e-05,
      "loss": 1.341,
      "step": 62500
    },
    {
      "epoch": 18.882175226586103,
      "eval_loss": 1.3496928215026855,
      "eval_runtime": 635.2426,
      "eval_samples_per_second": 83.589,
      "eval_steps_per_second": 0.653,
      "step": 62500
    },
    {
      "epoch": 18.897280966767372,
      "grad_norm": 0.5070651769638062,
      "learning_rate": 5.40686807653575e-05,
      "loss": 1.2952,
      "step": 62550
    },
    {
      "epoch": 18.897280966767372,
      "eval_loss": 1.3474795818328857,
      "eval_runtime": 637.3044,
      "eval_samples_per_second": 83.318,
      "eval_steps_per_second": 0.651,
      "step": 62550
    },
    {
      "epoch": 18.91238670694864,
      "grad_norm": 0.5539134740829468,
      "learning_rate": 5.405861027190332e-05,
      "loss": 1.3156,
      "step": 62600
    },
    {
      "epoch": 18.91238670694864,
      "eval_loss": 1.3452914953231812,
      "eval_runtime": 650.8041,
      "eval_samples_per_second": 81.59,
      "eval_steps_per_second": 0.638,
      "step": 62600
    },
    {
      "epoch": 18.92749244712991,
      "grad_norm": 0.4876008629798889,
      "learning_rate": 5.4048539778449146e-05,
      "loss": 1.3069,
      "step": 62650
    },
    {
      "epoch": 18.92749244712991,
      "eval_loss": 1.3465991020202637,
      "eval_runtime": 814.642,
      "eval_samples_per_second": 65.181,
      "eval_steps_per_second": 0.509,
      "step": 62650
    },
    {
      "epoch": 18.942598187311177,
      "grad_norm": 0.5160836577415466,
      "learning_rate": 5.403846928499497e-05,
      "loss": 1.3169,
      "step": 62700
    },
    {
      "epoch": 18.942598187311177,
      "eval_loss": 1.3495533466339111,
      "eval_runtime": 692.7198,
      "eval_samples_per_second": 76.653,
      "eval_steps_per_second": 0.599,
      "step": 62700
    },
    {
      "epoch": 18.957703927492446,
      "grad_norm": 0.5025117993354797,
      "learning_rate": 5.402839879154079e-05,
      "loss": 1.3162,
      "step": 62750
    },
    {
      "epoch": 18.957703927492446,
      "eval_loss": 1.3499177694320679,
      "eval_runtime": 701.6577,
      "eval_samples_per_second": 75.677,
      "eval_steps_per_second": 0.591,
      "step": 62750
    },
    {
      "epoch": 18.972809667673715,
      "grad_norm": 0.44800323247909546,
      "learning_rate": 5.401832829808661e-05,
      "loss": 1.3397,
      "step": 62800
    },
    {
      "epoch": 18.972809667673715,
      "eval_loss": 1.3484504222869873,
      "eval_runtime": 665.3633,
      "eval_samples_per_second": 79.805,
      "eval_steps_per_second": 0.624,
      "step": 62800
    },
    {
      "epoch": 18.987915407854985,
      "grad_norm": 0.6262120604515076,
      "learning_rate": 5.400825780463243e-05,
      "loss": 1.305,
      "step": 62850
    },
    {
      "epoch": 18.987915407854985,
      "eval_loss": 1.347152829170227,
      "eval_runtime": 703.3152,
      "eval_samples_per_second": 75.498,
      "eval_steps_per_second": 0.59,
      "step": 62850
    },
    {
      "epoch": 19.003021148036254,
      "grad_norm": 0.48598483204841614,
      "learning_rate": 5.399818731117825e-05,
      "loss": 1.3269,
      "step": 62900
    },
    {
      "epoch": 19.003021148036254,
      "eval_loss": 1.3476979732513428,
      "eval_runtime": 652.1842,
      "eval_samples_per_second": 81.417,
      "eval_steps_per_second": 0.636,
      "step": 62900
    },
    {
      "epoch": 19.018126888217523,
      "grad_norm": 0.48555853962898254,
      "learning_rate": 5.398811681772407e-05,
      "loss": 1.3313,
      "step": 62950
    },
    {
      "epoch": 19.018126888217523,
      "eval_loss": 1.34776771068573,
      "eval_runtime": 615.7084,
      "eval_samples_per_second": 86.241,
      "eval_steps_per_second": 0.674,
      "step": 62950
    },
    {
      "epoch": 19.033232628398792,
      "grad_norm": 0.43671613931655884,
      "learning_rate": 5.397804632426989e-05,
      "loss": 1.3108,
      "step": 63000
    },
    {
      "epoch": 19.033232628398792,
      "eval_loss": 1.346346378326416,
      "eval_runtime": 679.4212,
      "eval_samples_per_second": 78.153,
      "eval_steps_per_second": 0.611,
      "step": 63000
    },
    {
      "epoch": 19.048338368580062,
      "grad_norm": 0.4742732048034668,
      "learning_rate": 5.396797583081571e-05,
      "loss": 1.2983,
      "step": 63050
    },
    {
      "epoch": 19.048338368580062,
      "eval_loss": 1.3483264446258545,
      "eval_runtime": 604.6866,
      "eval_samples_per_second": 87.812,
      "eval_steps_per_second": 0.686,
      "step": 63050
    },
    {
      "epoch": 19.063444108761328,
      "grad_norm": 0.45864731073379517,
      "learning_rate": 5.3957905337361535e-05,
      "loss": 1.3189,
      "step": 63100
    },
    {
      "epoch": 19.063444108761328,
      "eval_loss": 1.3496962785720825,
      "eval_runtime": 686.299,
      "eval_samples_per_second": 77.37,
      "eval_steps_per_second": 0.605,
      "step": 63100
    },
    {
      "epoch": 19.078549848942597,
      "grad_norm": 0.5120567083358765,
      "learning_rate": 5.3947834843907353e-05,
      "loss": 1.3641,
      "step": 63150
    },
    {
      "epoch": 19.078549848942597,
      "eval_loss": 1.3468793630599976,
      "eval_runtime": 680.6468,
      "eval_samples_per_second": 78.013,
      "eval_steps_per_second": 0.61,
      "step": 63150
    },
    {
      "epoch": 19.093655589123866,
      "grad_norm": 0.4713807702064514,
      "learning_rate": 5.393776435045317e-05,
      "loss": 1.3392,
      "step": 63200
    },
    {
      "epoch": 19.093655589123866,
      "eval_loss": 1.3496195077896118,
      "eval_runtime": 650.0547,
      "eval_samples_per_second": 81.684,
      "eval_steps_per_second": 0.638,
      "step": 63200
    },
    {
      "epoch": 19.108761329305135,
      "grad_norm": 0.4932421147823334,
      "learning_rate": 5.392769385699899e-05,
      "loss": 1.3308,
      "step": 63250
    },
    {
      "epoch": 19.108761329305135,
      "eval_loss": 1.346778392791748,
      "eval_runtime": 613.8889,
      "eval_samples_per_second": 86.496,
      "eval_steps_per_second": 0.676,
      "step": 63250
    },
    {
      "epoch": 19.123867069486405,
      "grad_norm": 0.46444886922836304,
      "learning_rate": 5.3917623363544816e-05,
      "loss": 1.3366,
      "step": 63300
    },
    {
      "epoch": 19.123867069486405,
      "eval_loss": 1.3495657444000244,
      "eval_runtime": 706.2106,
      "eval_samples_per_second": 75.189,
      "eval_steps_per_second": 0.588,
      "step": 63300
    },
    {
      "epoch": 19.138972809667674,
      "grad_norm": 0.5011460185050964,
      "learning_rate": 5.3907552870090635e-05,
      "loss": 1.3068,
      "step": 63350
    },
    {
      "epoch": 19.138972809667674,
      "eval_loss": 1.3481515645980835,
      "eval_runtime": 647.3053,
      "eval_samples_per_second": 82.031,
      "eval_steps_per_second": 0.641,
      "step": 63350
    },
    {
      "epoch": 19.154078549848943,
      "grad_norm": 0.4819689393043518,
      "learning_rate": 5.3897482376636454e-05,
      "loss": 1.33,
      "step": 63400
    },
    {
      "epoch": 19.154078549848943,
      "eval_loss": 1.3481590747833252,
      "eval_runtime": 630.8444,
      "eval_samples_per_second": 84.171,
      "eval_steps_per_second": 0.658,
      "step": 63400
    },
    {
      "epoch": 19.169184290030213,
      "grad_norm": 0.48830801248550415,
      "learning_rate": 5.388741188318228e-05,
      "loss": 1.3354,
      "step": 63450
    },
    {
      "epoch": 19.169184290030213,
      "eval_loss": 1.3459527492523193,
      "eval_runtime": 627.4994,
      "eval_samples_per_second": 84.62,
      "eval_steps_per_second": 0.661,
      "step": 63450
    },
    {
      "epoch": 19.184290030211482,
      "grad_norm": 0.4969002902507782,
      "learning_rate": 5.38773413897281e-05,
      "loss": 1.3185,
      "step": 63500
    },
    {
      "epoch": 19.184290030211482,
      "eval_loss": 1.3462905883789062,
      "eval_runtime": 662.6806,
      "eval_samples_per_second": 80.128,
      "eval_steps_per_second": 0.626,
      "step": 63500
    },
    {
      "epoch": 19.199395770392748,
      "grad_norm": 0.5371991395950317,
      "learning_rate": 5.3867270896273916e-05,
      "loss": 1.3223,
      "step": 63550
    },
    {
      "epoch": 19.199395770392748,
      "eval_loss": 1.3476067781448364,
      "eval_runtime": 624.7613,
      "eval_samples_per_second": 84.991,
      "eval_steps_per_second": 0.664,
      "step": 63550
    },
    {
      "epoch": 19.214501510574017,
      "grad_norm": 0.5374041199684143,
      "learning_rate": 5.3857200402819735e-05,
      "loss": 1.3234,
      "step": 63600
    },
    {
      "epoch": 19.214501510574017,
      "eval_loss": 1.347290277481079,
      "eval_runtime": 691.3006,
      "eval_samples_per_second": 76.81,
      "eval_steps_per_second": 0.6,
      "step": 63600
    },
    {
      "epoch": 19.229607250755286,
      "grad_norm": 0.4859744608402252,
      "learning_rate": 5.384712990936556e-05,
      "loss": 1.3267,
      "step": 63650
    },
    {
      "epoch": 19.229607250755286,
      "eval_loss": 1.3466956615447998,
      "eval_runtime": 695.2407,
      "eval_samples_per_second": 76.375,
      "eval_steps_per_second": 0.597,
      "step": 63650
    },
    {
      "epoch": 19.244712990936556,
      "grad_norm": 0.5409610867500305,
      "learning_rate": 5.383705941591138e-05,
      "loss": 1.3206,
      "step": 63700
    },
    {
      "epoch": 19.244712990936556,
      "eval_loss": 1.3468726873397827,
      "eval_runtime": 620.1271,
      "eval_samples_per_second": 85.626,
      "eval_steps_per_second": 0.669,
      "step": 63700
    },
    {
      "epoch": 19.259818731117825,
      "grad_norm": 0.5039141774177551,
      "learning_rate": 5.38269889224572e-05,
      "loss": 1.3464,
      "step": 63750
    },
    {
      "epoch": 19.259818731117825,
      "eval_loss": 1.3479700088500977,
      "eval_runtime": 681.6038,
      "eval_samples_per_second": 77.903,
      "eval_steps_per_second": 0.609,
      "step": 63750
    },
    {
      "epoch": 19.274924471299094,
      "grad_norm": 0.48244085907936096,
      "learning_rate": 5.3816918429003023e-05,
      "loss": 1.3315,
      "step": 63800
    },
    {
      "epoch": 19.274924471299094,
      "eval_loss": 1.348023772239685,
      "eval_runtime": 628.3715,
      "eval_samples_per_second": 84.503,
      "eval_steps_per_second": 0.66,
      "step": 63800
    },
    {
      "epoch": 19.290030211480364,
      "grad_norm": 0.5284452438354492,
      "learning_rate": 5.380684793554885e-05,
      "loss": 1.3314,
      "step": 63850
    },
    {
      "epoch": 19.290030211480364,
      "eval_loss": 1.3460158109664917,
      "eval_runtime": 672.2492,
      "eval_samples_per_second": 78.987,
      "eval_steps_per_second": 0.617,
      "step": 63850
    },
    {
      "epoch": 19.305135951661633,
      "grad_norm": 0.5258666276931763,
      "learning_rate": 5.379677744209467e-05,
      "loss": 1.3329,
      "step": 63900
    },
    {
      "epoch": 19.305135951661633,
      "eval_loss": 1.344983458518982,
      "eval_runtime": 794.0609,
      "eval_samples_per_second": 66.87,
      "eval_steps_per_second": 0.523,
      "step": 63900
    },
    {
      "epoch": 19.3202416918429,
      "grad_norm": 0.49951353669166565,
      "learning_rate": 5.3786706948640486e-05,
      "loss": 1.3377,
      "step": 63950
    },
    {
      "epoch": 19.3202416918429,
      "eval_loss": 1.3460209369659424,
      "eval_runtime": 659.9358,
      "eval_samples_per_second": 80.461,
      "eval_steps_per_second": 0.629,
      "step": 63950
    },
    {
      "epoch": 19.335347432024168,
      "grad_norm": 0.5227755904197693,
      "learning_rate": 5.3776636455186305e-05,
      "loss": 1.3153,
      "step": 64000
    },
    {
      "epoch": 19.335347432024168,
      "eval_loss": 1.3475059270858765,
      "eval_runtime": 645.9396,
      "eval_samples_per_second": 82.204,
      "eval_steps_per_second": 0.642,
      "step": 64000
    },
    {
      "epoch": 19.350453172205437,
      "grad_norm": 0.5711994767189026,
      "learning_rate": 5.376656596173213e-05,
      "loss": 1.3219,
      "step": 64050
    },
    {
      "epoch": 19.350453172205437,
      "eval_loss": 1.3444887399673462,
      "eval_runtime": 684.2051,
      "eval_samples_per_second": 77.607,
      "eval_steps_per_second": 0.607,
      "step": 64050
    },
    {
      "epoch": 19.365558912386707,
      "grad_norm": 0.5365167856216431,
      "learning_rate": 5.375649546827795e-05,
      "loss": 1.3227,
      "step": 64100
    },
    {
      "epoch": 19.365558912386707,
      "eval_loss": 1.3459694385528564,
      "eval_runtime": 685.9162,
      "eval_samples_per_second": 77.413,
      "eval_steps_per_second": 0.605,
      "step": 64100
    },
    {
      "epoch": 19.380664652567976,
      "grad_norm": 0.5051136016845703,
      "learning_rate": 5.374642497482377e-05,
      "loss": 1.3055,
      "step": 64150
    },
    {
      "epoch": 19.380664652567976,
      "eval_loss": 1.343931794166565,
      "eval_runtime": 642.1777,
      "eval_samples_per_second": 82.686,
      "eval_steps_per_second": 0.646,
      "step": 64150
    },
    {
      "epoch": 19.395770392749245,
      "grad_norm": 0.5417635440826416,
      "learning_rate": 5.3736354481369586e-05,
      "loss": 1.31,
      "step": 64200
    },
    {
      "epoch": 19.395770392749245,
      "eval_loss": 1.3414809703826904,
      "eval_runtime": 671.749,
      "eval_samples_per_second": 79.046,
      "eval_steps_per_second": 0.618,
      "step": 64200
    },
    {
      "epoch": 19.410876132930515,
      "grad_norm": 0.4941923916339874,
      "learning_rate": 5.372628398791541e-05,
      "loss": 1.285,
      "step": 64250
    },
    {
      "epoch": 19.410876132930515,
      "eval_loss": 1.3448377847671509,
      "eval_runtime": 691.1836,
      "eval_samples_per_second": 76.823,
      "eval_steps_per_second": 0.6,
      "step": 64250
    },
    {
      "epoch": 19.425981873111784,
      "grad_norm": 0.5422788858413696,
      "learning_rate": 5.371621349446123e-05,
      "loss": 1.3186,
      "step": 64300
    },
    {
      "epoch": 19.425981873111784,
      "eval_loss": 1.343986988067627,
      "eval_runtime": 641.9027,
      "eval_samples_per_second": 82.721,
      "eval_steps_per_second": 0.647,
      "step": 64300
    },
    {
      "epoch": 19.44108761329305,
      "grad_norm": 0.5362288355827332,
      "learning_rate": 5.370614300100705e-05,
      "loss": 1.3277,
      "step": 64350
    },
    {
      "epoch": 19.44108761329305,
      "eval_loss": 1.3455214500427246,
      "eval_runtime": 702.9685,
      "eval_samples_per_second": 75.535,
      "eval_steps_per_second": 0.59,
      "step": 64350
    },
    {
      "epoch": 19.45619335347432,
      "grad_norm": 0.527600884437561,
      "learning_rate": 5.369607250755287e-05,
      "loss": 1.3398,
      "step": 64400
    },
    {
      "epoch": 19.45619335347432,
      "eval_loss": 1.3470866680145264,
      "eval_runtime": 677.5362,
      "eval_samples_per_second": 78.371,
      "eval_steps_per_second": 0.613,
      "step": 64400
    },
    {
      "epoch": 19.47129909365559,
      "grad_norm": 0.4521428644657135,
      "learning_rate": 5.3686002014098693e-05,
      "loss": 1.3359,
      "step": 64450
    },
    {
      "epoch": 19.47129909365559,
      "eval_loss": 1.345218539237976,
      "eval_runtime": 656.2269,
      "eval_samples_per_second": 80.916,
      "eval_steps_per_second": 0.632,
      "step": 64450
    },
    {
      "epoch": 19.486404833836858,
      "grad_norm": 0.5474592447280884,
      "learning_rate": 5.367593152064451e-05,
      "loss": 1.3225,
      "step": 64500
    },
    {
      "epoch": 19.486404833836858,
      "eval_loss": 1.3438677787780762,
      "eval_runtime": 677.7132,
      "eval_samples_per_second": 78.35,
      "eval_steps_per_second": 0.612,
      "step": 64500
    },
    {
      "epoch": 19.501510574018127,
      "grad_norm": 0.4491107165813446,
      "learning_rate": 5.366586102719033e-05,
      "loss": 1.3099,
      "step": 64550
    },
    {
      "epoch": 19.501510574018127,
      "eval_loss": 1.3463770151138306,
      "eval_runtime": 699.9597,
      "eval_samples_per_second": 75.86,
      "eval_steps_per_second": 0.593,
      "step": 64550
    },
    {
      "epoch": 19.516616314199396,
      "grad_norm": 0.6800017952919006,
      "learning_rate": 5.3655790533736156e-05,
      "loss": 1.3236,
      "step": 64600
    },
    {
      "epoch": 19.516616314199396,
      "eval_loss": 1.3438562154769897,
      "eval_runtime": 642.8066,
      "eval_samples_per_second": 82.605,
      "eval_steps_per_second": 0.646,
      "step": 64600
    },
    {
      "epoch": 19.531722054380666,
      "grad_norm": 0.4957701563835144,
      "learning_rate": 5.3645720040281975e-05,
      "loss": 1.3397,
      "step": 64650
    },
    {
      "epoch": 19.531722054380666,
      "eval_loss": 1.3463709354400635,
      "eval_runtime": 666.4529,
      "eval_samples_per_second": 79.674,
      "eval_steps_per_second": 0.623,
      "step": 64650
    },
    {
      "epoch": 19.546827794561935,
      "grad_norm": 0.4976804554462433,
      "learning_rate": 5.3635649546827794e-05,
      "loss": 1.3033,
      "step": 64700
    },
    {
      "epoch": 19.546827794561935,
      "eval_loss": 1.3446329832077026,
      "eval_runtime": 645.591,
      "eval_samples_per_second": 82.249,
      "eval_steps_per_second": 0.643,
      "step": 64700
    },
    {
      "epoch": 19.561933534743204,
      "grad_norm": 0.5536131858825684,
      "learning_rate": 5.362557905337361e-05,
      "loss": 1.3379,
      "step": 64750
    },
    {
      "epoch": 19.561933534743204,
      "eval_loss": 1.3431131839752197,
      "eval_runtime": 695.6169,
      "eval_samples_per_second": 76.334,
      "eval_steps_per_second": 0.597,
      "step": 64750
    },
    {
      "epoch": 19.57703927492447,
      "grad_norm": 0.5209552645683289,
      "learning_rate": 5.361550855991944e-05,
      "loss": 1.326,
      "step": 64800
    },
    {
      "epoch": 19.57703927492447,
      "eval_loss": 1.344774603843689,
      "eval_runtime": 684.6976,
      "eval_samples_per_second": 77.551,
      "eval_steps_per_second": 0.606,
      "step": 64800
    },
    {
      "epoch": 19.59214501510574,
      "grad_norm": 0.5020827651023865,
      "learning_rate": 5.3605438066465256e-05,
      "loss": 1.3119,
      "step": 64850
    },
    {
      "epoch": 19.59214501510574,
      "eval_loss": 1.3463853597640991,
      "eval_runtime": 715.6202,
      "eval_samples_per_second": 74.2,
      "eval_steps_per_second": 0.58,
      "step": 64850
    },
    {
      "epoch": 19.60725075528701,
      "grad_norm": 0.5152894258499146,
      "learning_rate": 5.3595367573011075e-05,
      "loss": 1.3202,
      "step": 64900
    },
    {
      "epoch": 19.60725075528701,
      "eval_loss": 1.3443772792816162,
      "eval_runtime": 708.6413,
      "eval_samples_per_second": 74.931,
      "eval_steps_per_second": 0.586,
      "step": 64900
    },
    {
      "epoch": 19.622356495468278,
      "grad_norm": 0.5354976058006287,
      "learning_rate": 5.3585297079556894e-05,
      "loss": 1.3092,
      "step": 64950
    },
    {
      "epoch": 19.622356495468278,
      "eval_loss": 1.343683123588562,
      "eval_runtime": 694.6758,
      "eval_samples_per_second": 76.437,
      "eval_steps_per_second": 0.597,
      "step": 64950
    },
    {
      "epoch": 19.637462235649547,
      "grad_norm": 0.5460193157196045,
      "learning_rate": 5.3575226586102726e-05,
      "loss": 1.3193,
      "step": 65000
    },
    {
      "epoch": 19.637462235649547,
      "eval_loss": 1.3424941301345825,
      "eval_runtime": 671.5872,
      "eval_samples_per_second": 79.065,
      "eval_steps_per_second": 0.618,
      "step": 65000
    },
    {
      "epoch": 19.652567975830816,
      "grad_norm": 0.5044828653335571,
      "learning_rate": 5.3565156092648545e-05,
      "loss": 1.3178,
      "step": 65050
    },
    {
      "epoch": 19.652567975830816,
      "eval_loss": 1.344894528388977,
      "eval_runtime": 755.5888,
      "eval_samples_per_second": 70.275,
      "eval_steps_per_second": 0.549,
      "step": 65050
    },
    {
      "epoch": 19.667673716012086,
      "grad_norm": 0.46503692865371704,
      "learning_rate": 5.3555085599194363e-05,
      "loss": 1.3183,
      "step": 65100
    },
    {
      "epoch": 19.667673716012086,
      "eval_loss": 1.3454338312149048,
      "eval_runtime": 632.3848,
      "eval_samples_per_second": 83.966,
      "eval_steps_per_second": 0.656,
      "step": 65100
    },
    {
      "epoch": 19.682779456193355,
      "grad_norm": 0.49778273701667786,
      "learning_rate": 5.354501510574018e-05,
      "loss": 1.3175,
      "step": 65150
    },
    {
      "epoch": 19.682779456193355,
      "eval_loss": 1.343688726425171,
      "eval_runtime": 708.8715,
      "eval_samples_per_second": 74.906,
      "eval_steps_per_second": 0.585,
      "step": 65150
    },
    {
      "epoch": 19.69788519637462,
      "grad_norm": 0.5467755198478699,
      "learning_rate": 5.353494461228601e-05,
      "loss": 1.3029,
      "step": 65200
    },
    {
      "epoch": 19.69788519637462,
      "eval_loss": 1.3443458080291748,
      "eval_runtime": 628.2071,
      "eval_samples_per_second": 84.525,
      "eval_steps_per_second": 0.661,
      "step": 65200
    },
    {
      "epoch": 19.71299093655589,
      "grad_norm": 0.5347175002098083,
      "learning_rate": 5.3524874118831826e-05,
      "loss": 1.3416,
      "step": 65250
    },
    {
      "epoch": 19.71299093655589,
      "eval_loss": 1.341852068901062,
      "eval_runtime": 974.135,
      "eval_samples_per_second": 54.509,
      "eval_steps_per_second": 0.426,
      "step": 65250
    },
    {
      "epoch": 19.72809667673716,
      "grad_norm": 0.4925382137298584,
      "learning_rate": 5.3514803625377645e-05,
      "loss": 1.3178,
      "step": 65300
    },
    {
      "epoch": 19.72809667673716,
      "eval_loss": 1.3438376188278198,
      "eval_runtime": 711.3924,
      "eval_samples_per_second": 74.641,
      "eval_steps_per_second": 0.583,
      "step": 65300
    },
    {
      "epoch": 19.74320241691843,
      "grad_norm": 0.5181942582130432,
      "learning_rate": 5.3504733131923464e-05,
      "loss": 1.3042,
      "step": 65350
    },
    {
      "epoch": 19.74320241691843,
      "eval_loss": 1.3426737785339355,
      "eval_runtime": 750.5888,
      "eval_samples_per_second": 70.743,
      "eval_steps_per_second": 0.553,
      "step": 65350
    },
    {
      "epoch": 19.758308157099698,
      "grad_norm": 0.4843793213367462,
      "learning_rate": 5.349466263846929e-05,
      "loss": 1.3305,
      "step": 65400
    },
    {
      "epoch": 19.758308157099698,
      "eval_loss": 1.344681739807129,
      "eval_runtime": 671.9092,
      "eval_samples_per_second": 79.027,
      "eval_steps_per_second": 0.618,
      "step": 65400
    },
    {
      "epoch": 19.773413897280967,
      "grad_norm": 0.4795028567314148,
      "learning_rate": 5.348459214501511e-05,
      "loss": 1.3301,
      "step": 65450
    },
    {
      "epoch": 19.773413897280967,
      "eval_loss": 1.3432536125183105,
      "eval_runtime": 664.3683,
      "eval_samples_per_second": 79.924,
      "eval_steps_per_second": 0.625,
      "step": 65450
    },
    {
      "epoch": 19.788519637462237,
      "grad_norm": 0.4800523817539215,
      "learning_rate": 5.3474521651560926e-05,
      "loss": 1.3208,
      "step": 65500
    },
    {
      "epoch": 19.788519637462237,
      "eval_loss": 1.3422105312347412,
      "eval_runtime": 615.8139,
      "eval_samples_per_second": 86.226,
      "eval_steps_per_second": 0.674,
      "step": 65500
    },
    {
      "epoch": 19.803625377643506,
      "grad_norm": 0.47174397110939026,
      "learning_rate": 5.3464451158106745e-05,
      "loss": 1.3183,
      "step": 65550
    },
    {
      "epoch": 19.803625377643506,
      "eval_loss": 1.343703031539917,
      "eval_runtime": 691.1935,
      "eval_samples_per_second": 76.822,
      "eval_steps_per_second": 0.6,
      "step": 65550
    },
    {
      "epoch": 19.818731117824772,
      "grad_norm": 0.5010992288589478,
      "learning_rate": 5.345438066465257e-05,
      "loss": 1.3071,
      "step": 65600
    },
    {
      "epoch": 19.818731117824772,
      "eval_loss": 1.3412505388259888,
      "eval_runtime": 633.3945,
      "eval_samples_per_second": 83.832,
      "eval_steps_per_second": 0.655,
      "step": 65600
    },
    {
      "epoch": 19.83383685800604,
      "grad_norm": 0.49504587054252625,
      "learning_rate": 5.344431017119839e-05,
      "loss": 1.3297,
      "step": 65650
    },
    {
      "epoch": 19.83383685800604,
      "eval_loss": 1.344683051109314,
      "eval_runtime": 674.8153,
      "eval_samples_per_second": 78.687,
      "eval_steps_per_second": 0.615,
      "step": 65650
    },
    {
      "epoch": 19.84894259818731,
      "grad_norm": 0.5027015805244446,
      "learning_rate": 5.343423967774421e-05,
      "loss": 1.3238,
      "step": 65700
    },
    {
      "epoch": 19.84894259818731,
      "eval_loss": 1.3424148559570312,
      "eval_runtime": 687.4454,
      "eval_samples_per_second": 77.241,
      "eval_steps_per_second": 0.604,
      "step": 65700
    },
    {
      "epoch": 19.86404833836858,
      "grad_norm": 0.4495459198951721,
      "learning_rate": 5.3424169184290033e-05,
      "loss": 1.3182,
      "step": 65750
    },
    {
      "epoch": 19.86404833836858,
      "eval_loss": 1.3411548137664795,
      "eval_runtime": 728.7645,
      "eval_samples_per_second": 72.862,
      "eval_steps_per_second": 0.569,
      "step": 65750
    },
    {
      "epoch": 19.87915407854985,
      "grad_norm": 0.443149209022522,
      "learning_rate": 5.341409869083585e-05,
      "loss": 1.2817,
      "step": 65800
    },
    {
      "epoch": 19.87915407854985,
      "eval_loss": 1.3426318168640137,
      "eval_runtime": 631.8381,
      "eval_samples_per_second": 84.039,
      "eval_steps_per_second": 0.657,
      "step": 65800
    },
    {
      "epoch": 19.89425981873112,
      "grad_norm": 0.5231761336326599,
      "learning_rate": 5.340402819738167e-05,
      "loss": 1.3254,
      "step": 65850
    },
    {
      "epoch": 19.89425981873112,
      "eval_loss": 1.341268539428711,
      "eval_runtime": 664.3695,
      "eval_samples_per_second": 79.924,
      "eval_steps_per_second": 0.625,
      "step": 65850
    },
    {
      "epoch": 19.909365558912388,
      "grad_norm": 0.492288202047348,
      "learning_rate": 5.339395770392749e-05,
      "loss": 1.3039,
      "step": 65900
    },
    {
      "epoch": 19.909365558912388,
      "eval_loss": 1.341660976409912,
      "eval_runtime": 697.9321,
      "eval_samples_per_second": 76.08,
      "eval_steps_per_second": 0.595,
      "step": 65900
    },
    {
      "epoch": 19.924471299093657,
      "grad_norm": 0.46199044585227966,
      "learning_rate": 5.3383887210473315e-05,
      "loss": 1.3382,
      "step": 65950
    },
    {
      "epoch": 19.924471299093657,
      "eval_loss": 1.3408889770507812,
      "eval_runtime": 613.6178,
      "eval_samples_per_second": 86.534,
      "eval_steps_per_second": 0.676,
      "step": 65950
    },
    {
      "epoch": 19.939577039274923,
      "grad_norm": 0.48878195881843567,
      "learning_rate": 5.3373816717019134e-05,
      "loss": 1.3084,
      "step": 66000
    },
    {
      "epoch": 19.939577039274923,
      "eval_loss": 1.3432421684265137,
      "eval_runtime": 719.258,
      "eval_samples_per_second": 73.825,
      "eval_steps_per_second": 0.577,
      "step": 66000
    },
    {
      "epoch": 19.954682779456192,
      "grad_norm": 0.5590002536773682,
      "learning_rate": 5.336374622356495e-05,
      "loss": 1.3139,
      "step": 66050
    },
    {
      "epoch": 19.954682779456192,
      "eval_loss": 1.3396228551864624,
      "eval_runtime": 612.9612,
      "eval_samples_per_second": 86.627,
      "eval_steps_per_second": 0.677,
      "step": 66050
    },
    {
      "epoch": 19.96978851963746,
      "grad_norm": 0.4509779214859009,
      "learning_rate": 5.335367573011077e-05,
      "loss": 1.3077,
      "step": 66100
    },
    {
      "epoch": 19.96978851963746,
      "eval_loss": 1.3412940502166748,
      "eval_runtime": 622.2868,
      "eval_samples_per_second": 85.329,
      "eval_steps_per_second": 0.667,
      "step": 66100
    },
    {
      "epoch": 19.98489425981873,
      "grad_norm": 0.4888402223587036,
      "learning_rate": 5.33436052366566e-05,
      "loss": 1.3108,
      "step": 66150
    },
    {
      "epoch": 19.98489425981873,
      "eval_loss": 1.3418158292770386,
      "eval_runtime": 659.5809,
      "eval_samples_per_second": 80.504,
      "eval_steps_per_second": 0.629,
      "step": 66150
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.4974716901779175,
      "learning_rate": 5.333353474320242e-05,
      "loss": 1.3311,
      "step": 66200
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.343595266342163,
      "eval_runtime": 681.9197,
      "eval_samples_per_second": 77.867,
      "eval_steps_per_second": 0.609,
      "step": 66200
    },
    {
      "epoch": 20.01510574018127,
      "grad_norm": 0.5626916289329529,
      "learning_rate": 5.332346424974824e-05,
      "loss": 1.3259,
      "step": 66250
    },
    {
      "epoch": 20.01510574018127,
      "eval_loss": 1.340628981590271,
      "eval_runtime": 683.6594,
      "eval_samples_per_second": 77.669,
      "eval_steps_per_second": 0.607,
      "step": 66250
    },
    {
      "epoch": 20.03021148036254,
      "grad_norm": 0.47495248913764954,
      "learning_rate": 5.331339375629406e-05,
      "loss": 1.3261,
      "step": 66300
    },
    {
      "epoch": 20.03021148036254,
      "eval_loss": 1.342148780822754,
      "eval_runtime": 595.3057,
      "eval_samples_per_second": 89.196,
      "eval_steps_per_second": 0.697,
      "step": 66300
    },
    {
      "epoch": 20.045317220543808,
      "grad_norm": 0.5400357246398926,
      "learning_rate": 5.3303323262839885e-05,
      "loss": 1.3083,
      "step": 66350
    },
    {
      "epoch": 20.045317220543808,
      "eval_loss": 1.339923620223999,
      "eval_runtime": 624.9785,
      "eval_samples_per_second": 84.961,
      "eval_steps_per_second": 0.664,
      "step": 66350
    },
    {
      "epoch": 20.060422960725077,
      "grad_norm": 0.5189738869667053,
      "learning_rate": 5.3293252769385703e-05,
      "loss": 1.3158,
      "step": 66400
    },
    {
      "epoch": 20.060422960725077,
      "eval_loss": 1.342514157295227,
      "eval_runtime": 611.4119,
      "eval_samples_per_second": 86.847,
      "eval_steps_per_second": 0.679,
      "step": 66400
    },
    {
      "epoch": 20.075528700906343,
      "grad_norm": 0.5539981126785278,
      "learning_rate": 5.328318227593152e-05,
      "loss": 1.3057,
      "step": 66450
    },
    {
      "epoch": 20.075528700906343,
      "eval_loss": 1.3404922485351562,
      "eval_runtime": 698.0684,
      "eval_samples_per_second": 76.066,
      "eval_steps_per_second": 0.594,
      "step": 66450
    },
    {
      "epoch": 20.090634441087612,
      "grad_norm": 0.5002562999725342,
      "learning_rate": 5.327311178247734e-05,
      "loss": 1.3305,
      "step": 66500
    },
    {
      "epoch": 20.090634441087612,
      "eval_loss": 1.3402727842330933,
      "eval_runtime": 668.8309,
      "eval_samples_per_second": 79.391,
      "eval_steps_per_second": 0.62,
      "step": 66500
    },
    {
      "epoch": 20.10574018126888,
      "grad_norm": 0.5572805404663086,
      "learning_rate": 5.3263041289023166e-05,
      "loss": 1.3246,
      "step": 66550
    },
    {
      "epoch": 20.10574018126888,
      "eval_loss": 1.3395425081253052,
      "eval_runtime": 612.6154,
      "eval_samples_per_second": 86.676,
      "eval_steps_per_second": 0.677,
      "step": 66550
    },
    {
      "epoch": 20.12084592145015,
      "grad_norm": 0.5413634181022644,
      "learning_rate": 5.3252970795568985e-05,
      "loss": 1.3273,
      "step": 66600
    },
    {
      "epoch": 20.12084592145015,
      "eval_loss": 1.3416130542755127,
      "eval_runtime": 604.914,
      "eval_samples_per_second": 87.779,
      "eval_steps_per_second": 0.686,
      "step": 66600
    },
    {
      "epoch": 20.13595166163142,
      "grad_norm": 0.4878172278404236,
      "learning_rate": 5.3242900302114804e-05,
      "loss": 1.3284,
      "step": 66650
    },
    {
      "epoch": 20.13595166163142,
      "eval_loss": 1.3400005102157593,
      "eval_runtime": 671.7266,
      "eval_samples_per_second": 79.049,
      "eval_steps_per_second": 0.618,
      "step": 66650
    },
    {
      "epoch": 20.15105740181269,
      "grad_norm": 0.5871115922927856,
      "learning_rate": 5.323282980866063e-05,
      "loss": 1.317,
      "step": 66700
    },
    {
      "epoch": 20.15105740181269,
      "eval_loss": 1.3417370319366455,
      "eval_runtime": 661.0176,
      "eval_samples_per_second": 80.329,
      "eval_steps_per_second": 0.628,
      "step": 66700
    },
    {
      "epoch": 20.16616314199396,
      "grad_norm": 0.5529077649116516,
      "learning_rate": 5.322275931520645e-05,
      "loss": 1.3238,
      "step": 66750
    },
    {
      "epoch": 20.16616314199396,
      "eval_loss": 1.3427997827529907,
      "eval_runtime": 691.8826,
      "eval_samples_per_second": 76.746,
      "eval_steps_per_second": 0.6,
      "step": 66750
    },
    {
      "epoch": 20.181268882175228,
      "grad_norm": 0.48811739683151245,
      "learning_rate": 5.3212688821752267e-05,
      "loss": 1.326,
      "step": 66800
    },
    {
      "epoch": 20.181268882175228,
      "eval_loss": 1.3384041786193848,
      "eval_runtime": 642.4411,
      "eval_samples_per_second": 82.652,
      "eval_steps_per_second": 0.646,
      "step": 66800
    },
    {
      "epoch": 20.196374622356494,
      "grad_norm": 0.5000355243682861,
      "learning_rate": 5.3202618328298085e-05,
      "loss": 1.3108,
      "step": 66850
    },
    {
      "epoch": 20.196374622356494,
      "eval_loss": 1.3430641889572144,
      "eval_runtime": 674.528,
      "eval_samples_per_second": 78.72,
      "eval_steps_per_second": 0.615,
      "step": 66850
    },
    {
      "epoch": 20.211480362537763,
      "grad_norm": 0.5403585433959961,
      "learning_rate": 5.319254783484391e-05,
      "loss": 1.3436,
      "step": 66900
    },
    {
      "epoch": 20.211480362537763,
      "eval_loss": 1.340522050857544,
      "eval_runtime": 606.9148,
      "eval_samples_per_second": 87.49,
      "eval_steps_per_second": 0.684,
      "step": 66900
    },
    {
      "epoch": 20.226586102719033,
      "grad_norm": 0.5224751830101013,
      "learning_rate": 5.318247734138973e-05,
      "loss": 1.306,
      "step": 66950
    },
    {
      "epoch": 20.226586102719033,
      "eval_loss": 1.3415534496307373,
      "eval_runtime": 620.8652,
      "eval_samples_per_second": 85.524,
      "eval_steps_per_second": 0.668,
      "step": 66950
    },
    {
      "epoch": 20.241691842900302,
      "grad_norm": 0.4724048674106598,
      "learning_rate": 5.317240684793555e-05,
      "loss": 1.3105,
      "step": 67000
    },
    {
      "epoch": 20.241691842900302,
      "eval_loss": 1.3400212526321411,
      "eval_runtime": 626.4282,
      "eval_samples_per_second": 84.765,
      "eval_steps_per_second": 0.662,
      "step": 67000
    },
    {
      "epoch": 20.25679758308157,
      "grad_norm": 0.4794454574584961,
      "learning_rate": 5.316233635448137e-05,
      "loss": 1.316,
      "step": 67050
    },
    {
      "epoch": 20.25679758308157,
      "eval_loss": 1.3380707502365112,
      "eval_runtime": 610.8962,
      "eval_samples_per_second": 86.92,
      "eval_steps_per_second": 0.679,
      "step": 67050
    },
    {
      "epoch": 20.27190332326284,
      "grad_norm": 0.49397581815719604,
      "learning_rate": 5.315226586102719e-05,
      "loss": 1.3183,
      "step": 67100
    },
    {
      "epoch": 20.27190332326284,
      "eval_loss": 1.3381544351577759,
      "eval_runtime": 673.4136,
      "eval_samples_per_second": 78.851,
      "eval_steps_per_second": 0.616,
      "step": 67100
    },
    {
      "epoch": 20.28700906344411,
      "grad_norm": 0.49478471279144287,
      "learning_rate": 5.314219536757301e-05,
      "loss": 1.3067,
      "step": 67150
    },
    {
      "epoch": 20.28700906344411,
      "eval_loss": 1.3407468795776367,
      "eval_runtime": 631.3891,
      "eval_samples_per_second": 84.099,
      "eval_steps_per_second": 0.657,
      "step": 67150
    },
    {
      "epoch": 20.30211480362538,
      "grad_norm": 0.5112154483795166,
      "learning_rate": 5.313212487411883e-05,
      "loss": 1.3184,
      "step": 67200
    },
    {
      "epoch": 20.30211480362538,
      "eval_loss": 1.341658353805542,
      "eval_runtime": 621.6608,
      "eval_samples_per_second": 85.415,
      "eval_steps_per_second": 0.668,
      "step": 67200
    },
    {
      "epoch": 20.317220543806645,
      "grad_norm": 0.525073230266571,
      "learning_rate": 5.312205438066465e-05,
      "loss": 1.3112,
      "step": 67250
    },
    {
      "epoch": 20.317220543806645,
      "eval_loss": 1.3389250040054321,
      "eval_runtime": 647.4066,
      "eval_samples_per_second": 82.018,
      "eval_steps_per_second": 0.641,
      "step": 67250
    },
    {
      "epoch": 20.332326283987914,
      "grad_norm": 0.5139686465263367,
      "learning_rate": 5.311198388721048e-05,
      "loss": 1.2925,
      "step": 67300
    },
    {
      "epoch": 20.332326283987914,
      "eval_loss": 1.3408482074737549,
      "eval_runtime": 686.3388,
      "eval_samples_per_second": 77.366,
      "eval_steps_per_second": 0.605,
      "step": 67300
    },
    {
      "epoch": 20.347432024169184,
      "grad_norm": 0.5462926030158997,
      "learning_rate": 5.31019133937563e-05,
      "loss": 1.3034,
      "step": 67350
    },
    {
      "epoch": 20.347432024169184,
      "eval_loss": 1.3391377925872803,
      "eval_runtime": 685.9145,
      "eval_samples_per_second": 77.413,
      "eval_steps_per_second": 0.605,
      "step": 67350
    },
    {
      "epoch": 20.362537764350453,
      "grad_norm": 0.4935046136379242,
      "learning_rate": 5.309184290030212e-05,
      "loss": 1.3133,
      "step": 67400
    },
    {
      "epoch": 20.362537764350453,
      "eval_loss": 1.3398171663284302,
      "eval_runtime": 620.6028,
      "eval_samples_per_second": 85.56,
      "eval_steps_per_second": 0.669,
      "step": 67400
    },
    {
      "epoch": 20.377643504531722,
      "grad_norm": 0.4933932423591614,
      "learning_rate": 5.3081772406847937e-05,
      "loss": 1.333,
      "step": 67450
    },
    {
      "epoch": 20.377643504531722,
      "eval_loss": 1.3410922288894653,
      "eval_runtime": 671.0159,
      "eval_samples_per_second": 79.132,
      "eval_steps_per_second": 0.618,
      "step": 67450
    },
    {
      "epoch": 20.39274924471299,
      "grad_norm": 0.4844164252281189,
      "learning_rate": 5.307170191339376e-05,
      "loss": 1.3205,
      "step": 67500
    },
    {
      "epoch": 20.39274924471299,
      "eval_loss": 1.3381524085998535,
      "eval_runtime": 667.5304,
      "eval_samples_per_second": 79.545,
      "eval_steps_per_second": 0.622,
      "step": 67500
    },
    {
      "epoch": 20.40785498489426,
      "grad_norm": 0.49612438678741455,
      "learning_rate": 5.306163141993958e-05,
      "loss": 1.301,
      "step": 67550
    },
    {
      "epoch": 20.40785498489426,
      "eval_loss": 1.3390889167785645,
      "eval_runtime": 641.2015,
      "eval_samples_per_second": 82.812,
      "eval_steps_per_second": 0.647,
      "step": 67550
    },
    {
      "epoch": 20.42296072507553,
      "grad_norm": 0.47036293148994446,
      "learning_rate": 5.30515609264854e-05,
      "loss": 1.2983,
      "step": 67600
    },
    {
      "epoch": 20.42296072507553,
      "eval_loss": 1.339375615119934,
      "eval_runtime": 707.3861,
      "eval_samples_per_second": 75.064,
      "eval_steps_per_second": 0.587,
      "step": 67600
    },
    {
      "epoch": 20.438066465256796,
      "grad_norm": 0.4575091600418091,
      "learning_rate": 5.304149043303122e-05,
      "loss": 1.3071,
      "step": 67650
    },
    {
      "epoch": 20.438066465256796,
      "eval_loss": 1.340767502784729,
      "eval_runtime": 618.3816,
      "eval_samples_per_second": 85.868,
      "eval_steps_per_second": 0.671,
      "step": 67650
    },
    {
      "epoch": 20.453172205438065,
      "grad_norm": 0.4763048589229584,
      "learning_rate": 5.3031419939577043e-05,
      "loss": 1.3175,
      "step": 67700
    },
    {
      "epoch": 20.453172205438065,
      "eval_loss": 1.3361979722976685,
      "eval_runtime": 629.8762,
      "eval_samples_per_second": 84.301,
      "eval_steps_per_second": 0.659,
      "step": 67700
    },
    {
      "epoch": 20.468277945619334,
      "grad_norm": 0.4857925474643707,
      "learning_rate": 5.302134944612286e-05,
      "loss": 1.301,
      "step": 67750
    },
    {
      "epoch": 20.468277945619334,
      "eval_loss": 1.3387348651885986,
      "eval_runtime": 668.634,
      "eval_samples_per_second": 79.414,
      "eval_steps_per_second": 0.621,
      "step": 67750
    },
    {
      "epoch": 20.483383685800604,
      "grad_norm": 0.4670795500278473,
      "learning_rate": 5.301127895266868e-05,
      "loss": 1.3254,
      "step": 67800
    },
    {
      "epoch": 20.483383685800604,
      "eval_loss": 1.3398267030715942,
      "eval_runtime": 632.9124,
      "eval_samples_per_second": 83.896,
      "eval_steps_per_second": 0.656,
      "step": 67800
    },
    {
      "epoch": 20.498489425981873,
      "grad_norm": 0.5015237927436829,
      "learning_rate": 5.3001208459214506e-05,
      "loss": 1.3208,
      "step": 67850
    },
    {
      "epoch": 20.498489425981873,
      "eval_loss": 1.338419795036316,
      "eval_runtime": 631.1214,
      "eval_samples_per_second": 84.134,
      "eval_steps_per_second": 0.658,
      "step": 67850
    },
    {
      "epoch": 20.513595166163142,
      "grad_norm": 0.4830264449119568,
      "learning_rate": 5.2991137965760325e-05,
      "loss": 1.301,
      "step": 67900
    },
    {
      "epoch": 20.513595166163142,
      "eval_loss": 1.3373509645462036,
      "eval_runtime": 623.7883,
      "eval_samples_per_second": 85.123,
      "eval_steps_per_second": 0.665,
      "step": 67900
    },
    {
      "epoch": 20.52870090634441,
      "grad_norm": 0.4832850992679596,
      "learning_rate": 5.2981067472306144e-05,
      "loss": 1.3258,
      "step": 67950
    },
    {
      "epoch": 20.52870090634441,
      "eval_loss": 1.3377230167388916,
      "eval_runtime": 638.3012,
      "eval_samples_per_second": 83.188,
      "eval_steps_per_second": 0.65,
      "step": 67950
    },
    {
      "epoch": 20.54380664652568,
      "grad_norm": 0.48068171739578247,
      "learning_rate": 5.297099697885196e-05,
      "loss": 1.308,
      "step": 68000
    },
    {
      "epoch": 20.54380664652568,
      "eval_loss": 1.337164282798767,
      "eval_runtime": 662.9464,
      "eval_samples_per_second": 80.095,
      "eval_steps_per_second": 0.626,
      "step": 68000
    },
    {
      "epoch": 20.55891238670695,
      "grad_norm": 0.4408913254737854,
      "learning_rate": 5.296092648539779e-05,
      "loss": 1.3279,
      "step": 68050
    },
    {
      "epoch": 20.55891238670695,
      "eval_loss": 1.3393586874008179,
      "eval_runtime": 643.8617,
      "eval_samples_per_second": 82.47,
      "eval_steps_per_second": 0.645,
      "step": 68050
    },
    {
      "epoch": 20.574018126888216,
      "grad_norm": 0.47069865465164185,
      "learning_rate": 5.2950855991943607e-05,
      "loss": 1.3084,
      "step": 68100
    },
    {
      "epoch": 20.574018126888216,
      "eval_loss": 1.3359135389328003,
      "eval_runtime": 685.9077,
      "eval_samples_per_second": 77.414,
      "eval_steps_per_second": 0.605,
      "step": 68100
    },
    {
      "epoch": 20.589123867069485,
      "grad_norm": 0.5326268076896667,
      "learning_rate": 5.2940785498489425e-05,
      "loss": 1.3069,
      "step": 68150
    },
    {
      "epoch": 20.589123867069485,
      "eval_loss": 1.3395347595214844,
      "eval_runtime": 642.7824,
      "eval_samples_per_second": 82.608,
      "eval_steps_per_second": 0.646,
      "step": 68150
    },
    {
      "epoch": 20.604229607250755,
      "grad_norm": 0.4718950092792511,
      "learning_rate": 5.2930715005035244e-05,
      "loss": 1.2953,
      "step": 68200
    },
    {
      "epoch": 20.604229607250755,
      "eval_loss": 1.3368781805038452,
      "eval_runtime": 675.8118,
      "eval_samples_per_second": 78.571,
      "eval_steps_per_second": 0.614,
      "step": 68200
    },
    {
      "epoch": 20.619335347432024,
      "grad_norm": 0.5516763925552368,
      "learning_rate": 5.292064451158107e-05,
      "loss": 1.3228,
      "step": 68250
    },
    {
      "epoch": 20.619335347432024,
      "eval_loss": 1.3366174697875977,
      "eval_runtime": 635.5722,
      "eval_samples_per_second": 83.545,
      "eval_steps_per_second": 0.653,
      "step": 68250
    },
    {
      "epoch": 20.634441087613293,
      "grad_norm": 0.461183100938797,
      "learning_rate": 5.291057401812689e-05,
      "loss": 1.3165,
      "step": 68300
    },
    {
      "epoch": 20.634441087613293,
      "eval_loss": 1.3402135372161865,
      "eval_runtime": 651.6864,
      "eval_samples_per_second": 81.479,
      "eval_steps_per_second": 0.637,
      "step": 68300
    },
    {
      "epoch": 20.649546827794563,
      "grad_norm": 0.4682932198047638,
      "learning_rate": 5.290050352467271e-05,
      "loss": 1.2998,
      "step": 68350
    },
    {
      "epoch": 20.649546827794563,
      "eval_loss": 1.3356101512908936,
      "eval_runtime": 625.5446,
      "eval_samples_per_second": 84.884,
      "eval_steps_per_second": 0.663,
      "step": 68350
    },
    {
      "epoch": 20.664652567975832,
      "grad_norm": 0.5204065442085266,
      "learning_rate": 5.2890433031218525e-05,
      "loss": 1.3096,
      "step": 68400
    },
    {
      "epoch": 20.664652567975832,
      "eval_loss": 1.3355090618133545,
      "eval_runtime": 631.9166,
      "eval_samples_per_second": 84.028,
      "eval_steps_per_second": 0.657,
      "step": 68400
    },
    {
      "epoch": 20.6797583081571,
      "grad_norm": 0.5018268823623657,
      "learning_rate": 5.288036253776435e-05,
      "loss": 1.3342,
      "step": 68450
    },
    {
      "epoch": 20.6797583081571,
      "eval_loss": 1.3391882181167603,
      "eval_runtime": 646.6965,
      "eval_samples_per_second": 82.108,
      "eval_steps_per_second": 0.642,
      "step": 68450
    },
    {
      "epoch": 20.694864048338367,
      "grad_norm": 0.5578904747962952,
      "learning_rate": 5.2870292044310176e-05,
      "loss": 1.2816,
      "step": 68500
    },
    {
      "epoch": 20.694864048338367,
      "eval_loss": 1.3399733304977417,
      "eval_runtime": 642.9321,
      "eval_samples_per_second": 82.589,
      "eval_steps_per_second": 0.645,
      "step": 68500
    },
    {
      "epoch": 20.709969788519636,
      "grad_norm": 0.4924595355987549,
      "learning_rate": 5.2860221550855995e-05,
      "loss": 1.3123,
      "step": 68550
    },
    {
      "epoch": 20.709969788519636,
      "eval_loss": 1.335528016090393,
      "eval_runtime": 706.1032,
      "eval_samples_per_second": 75.2,
      "eval_steps_per_second": 0.588,
      "step": 68550
    },
    {
      "epoch": 20.725075528700906,
      "grad_norm": 0.5352769494056702,
      "learning_rate": 5.2850151057401814e-05,
      "loss": 1.3103,
      "step": 68600
    },
    {
      "epoch": 20.725075528700906,
      "eval_loss": 1.3357023000717163,
      "eval_runtime": 606.5882,
      "eval_samples_per_second": 87.537,
      "eval_steps_per_second": 0.684,
      "step": 68600
    },
    {
      "epoch": 20.740181268882175,
      "grad_norm": 0.519766092300415,
      "learning_rate": 5.284008056394764e-05,
      "loss": 1.3243,
      "step": 68650
    },
    {
      "epoch": 20.740181268882175,
      "eval_loss": 1.3376318216323853,
      "eval_runtime": 706.7538,
      "eval_samples_per_second": 75.131,
      "eval_steps_per_second": 0.587,
      "step": 68650
    },
    {
      "epoch": 20.755287009063444,
      "grad_norm": 0.5086255073547363,
      "learning_rate": 5.283001007049346e-05,
      "loss": 1.2916,
      "step": 68700
    },
    {
      "epoch": 20.755287009063444,
      "eval_loss": 1.3376713991165161,
      "eval_runtime": 675.3566,
      "eval_samples_per_second": 78.624,
      "eval_steps_per_second": 0.614,
      "step": 68700
    },
    {
      "epoch": 20.770392749244714,
      "grad_norm": 0.4791909456253052,
      "learning_rate": 5.2819939577039277e-05,
      "loss": 1.3153,
      "step": 68750
    },
    {
      "epoch": 20.770392749244714,
      "eval_loss": 1.3355658054351807,
      "eval_runtime": 687.4756,
      "eval_samples_per_second": 77.238,
      "eval_steps_per_second": 0.604,
      "step": 68750
    },
    {
      "epoch": 20.785498489425983,
      "grad_norm": 0.524446964263916,
      "learning_rate": 5.2809869083585095e-05,
      "loss": 1.3103,
      "step": 68800
    },
    {
      "epoch": 20.785498489425983,
      "eval_loss": 1.3379663228988647,
      "eval_runtime": 646.847,
      "eval_samples_per_second": 82.089,
      "eval_steps_per_second": 0.642,
      "step": 68800
    },
    {
      "epoch": 20.800604229607252,
      "grad_norm": 0.43096351623535156,
      "learning_rate": 5.279979859013092e-05,
      "loss": 1.314,
      "step": 68850
    },
    {
      "epoch": 20.800604229607252,
      "eval_loss": 1.3363758325576782,
      "eval_runtime": 687.0578,
      "eval_samples_per_second": 77.285,
      "eval_steps_per_second": 0.604,
      "step": 68850
    },
    {
      "epoch": 20.815709969788518,
      "grad_norm": 0.5556179881095886,
      "learning_rate": 5.278972809667674e-05,
      "loss": 1.3132,
      "step": 68900
    },
    {
      "epoch": 20.815709969788518,
      "eval_loss": 1.334190845489502,
      "eval_runtime": 629.2975,
      "eval_samples_per_second": 84.378,
      "eval_steps_per_second": 0.659,
      "step": 68900
    },
    {
      "epoch": 20.830815709969787,
      "grad_norm": 0.4970934987068176,
      "learning_rate": 5.277965760322256e-05,
      "loss": 1.3158,
      "step": 68950
    },
    {
      "epoch": 20.830815709969787,
      "eval_loss": 1.3356995582580566,
      "eval_runtime": 672.1175,
      "eval_samples_per_second": 79.003,
      "eval_steps_per_second": 0.617,
      "step": 68950
    },
    {
      "epoch": 20.845921450151057,
      "grad_norm": 0.4790904223918915,
      "learning_rate": 5.2769587109768384e-05,
      "loss": 1.3055,
      "step": 69000
    },
    {
      "epoch": 20.845921450151057,
      "eval_loss": 1.3360949754714966,
      "eval_runtime": 708.9207,
      "eval_samples_per_second": 74.901,
      "eval_steps_per_second": 0.585,
      "step": 69000
    },
    {
      "epoch": 20.861027190332326,
      "grad_norm": 0.4995339810848236,
      "learning_rate": 5.27595166163142e-05,
      "loss": 1.3172,
      "step": 69050
    },
    {
      "epoch": 20.861027190332326,
      "eval_loss": 1.339627981185913,
      "eval_runtime": 655.4866,
      "eval_samples_per_second": 81.007,
      "eval_steps_per_second": 0.633,
      "step": 69050
    },
    {
      "epoch": 20.876132930513595,
      "grad_norm": 0.5224643349647522,
      "learning_rate": 5.274944612286002e-05,
      "loss": 1.3253,
      "step": 69100
    },
    {
      "epoch": 20.876132930513595,
      "eval_loss": 1.3344203233718872,
      "eval_runtime": 645.2048,
      "eval_samples_per_second": 82.298,
      "eval_steps_per_second": 0.643,
      "step": 69100
    },
    {
      "epoch": 20.891238670694865,
      "grad_norm": 0.4868065118789673,
      "learning_rate": 5.273937562940584e-05,
      "loss": 1.3068,
      "step": 69150
    },
    {
      "epoch": 20.891238670694865,
      "eval_loss": 1.3363358974456787,
      "eval_runtime": 701.1764,
      "eval_samples_per_second": 75.728,
      "eval_steps_per_second": 0.592,
      "step": 69150
    },
    {
      "epoch": 20.906344410876134,
      "grad_norm": 0.41571035981178284,
      "learning_rate": 5.2729305135951665e-05,
      "loss": 1.318,
      "step": 69200
    },
    {
      "epoch": 20.906344410876134,
      "eval_loss": 1.3363314867019653,
      "eval_runtime": 610.1398,
      "eval_samples_per_second": 87.028,
      "eval_steps_per_second": 0.68,
      "step": 69200
    },
    {
      "epoch": 20.921450151057403,
      "grad_norm": 0.5199667811393738,
      "learning_rate": 5.2719234642497484e-05,
      "loss": 1.309,
      "step": 69250
    },
    {
      "epoch": 20.921450151057403,
      "eval_loss": 1.3353749513626099,
      "eval_runtime": 691.1116,
      "eval_samples_per_second": 76.831,
      "eval_steps_per_second": 0.6,
      "step": 69250
    },
    {
      "epoch": 20.93655589123867,
      "grad_norm": 0.49859708547592163,
      "learning_rate": 5.27091641490433e-05,
      "loss": 1.3167,
      "step": 69300
    },
    {
      "epoch": 20.93655589123867,
      "eval_loss": 1.3354713916778564,
      "eval_runtime": 638.4951,
      "eval_samples_per_second": 83.163,
      "eval_steps_per_second": 0.65,
      "step": 69300
    },
    {
      "epoch": 20.951661631419938,
      "grad_norm": 0.4967023432254791,
      "learning_rate": 5.269909365558912e-05,
      "loss": 1.3162,
      "step": 69350
    },
    {
      "epoch": 20.951661631419938,
      "eval_loss": 1.3335593938827515,
      "eval_runtime": 696.5662,
      "eval_samples_per_second": 76.23,
      "eval_steps_per_second": 0.596,
      "step": 69350
    },
    {
      "epoch": 20.966767371601208,
      "grad_norm": 0.4954341650009155,
      "learning_rate": 5.2689023162134947e-05,
      "loss": 1.3283,
      "step": 69400
    },
    {
      "epoch": 20.966767371601208,
      "eval_loss": 1.3332206010818481,
      "eval_runtime": 649.5659,
      "eval_samples_per_second": 81.745,
      "eval_steps_per_second": 0.639,
      "step": 69400
    },
    {
      "epoch": 20.981873111782477,
      "grad_norm": 0.4656049311161041,
      "learning_rate": 5.2678952668680765e-05,
      "loss": 1.299,
      "step": 69450
    },
    {
      "epoch": 20.981873111782477,
      "eval_loss": 1.3364869356155396,
      "eval_runtime": 715.3531,
      "eval_samples_per_second": 74.228,
      "eval_steps_per_second": 0.58,
      "step": 69450
    },
    {
      "epoch": 20.996978851963746,
      "grad_norm": 0.46723267436027527,
      "learning_rate": 5.2668882175226584e-05,
      "loss": 1.3047,
      "step": 69500
    },
    {
      "epoch": 20.996978851963746,
      "eval_loss": 1.3357990980148315,
      "eval_runtime": 633.6099,
      "eval_samples_per_second": 83.804,
      "eval_steps_per_second": 0.655,
      "step": 69500
    },
    {
      "epoch": 21.012084592145015,
      "grad_norm": 0.4755236804485321,
      "learning_rate": 5.26588116817724e-05,
      "loss": 1.3011,
      "step": 69550
    },
    {
      "epoch": 21.012084592145015,
      "eval_loss": 1.3385682106018066,
      "eval_runtime": 593.9769,
      "eval_samples_per_second": 89.396,
      "eval_steps_per_second": 0.699,
      "step": 69550
    },
    {
      "epoch": 21.027190332326285,
      "grad_norm": 0.5326620936393738,
      "learning_rate": 5.264874118831823e-05,
      "loss": 1.2899,
      "step": 69600
    },
    {
      "epoch": 21.027190332326285,
      "eval_loss": 1.3372942209243774,
      "eval_runtime": 699.0558,
      "eval_samples_per_second": 75.958,
      "eval_steps_per_second": 0.594,
      "step": 69600
    },
    {
      "epoch": 21.042296072507554,
      "grad_norm": 0.4937785863876343,
      "learning_rate": 5.2638670694864054e-05,
      "loss": 1.2994,
      "step": 69650
    },
    {
      "epoch": 21.042296072507554,
      "eval_loss": 1.3355419635772705,
      "eval_runtime": 653.0971,
      "eval_samples_per_second": 81.303,
      "eval_steps_per_second": 0.635,
      "step": 69650
    },
    {
      "epoch": 21.057401812688823,
      "grad_norm": 0.4974781274795532,
      "learning_rate": 5.262860020140987e-05,
      "loss": 1.3061,
      "step": 69700
    },
    {
      "epoch": 21.057401812688823,
      "eval_loss": 1.3352736234664917,
      "eval_runtime": 660.057,
      "eval_samples_per_second": 80.446,
      "eval_steps_per_second": 0.629,
      "step": 69700
    },
    {
      "epoch": 21.07250755287009,
      "grad_norm": 0.5171361565589905,
      "learning_rate": 5.261852970795569e-05,
      "loss": 1.3113,
      "step": 69750
    },
    {
      "epoch": 21.07250755287009,
      "eval_loss": 1.3364918231964111,
      "eval_runtime": 624.974,
      "eval_samples_per_second": 84.962,
      "eval_steps_per_second": 0.664,
      "step": 69750
    },
    {
      "epoch": 21.08761329305136,
      "grad_norm": 0.48955345153808594,
      "learning_rate": 5.2608459214501516e-05,
      "loss": 1.2898,
      "step": 69800
    },
    {
      "epoch": 21.08761329305136,
      "eval_loss": 1.3350331783294678,
      "eval_runtime": 704.4015,
      "eval_samples_per_second": 75.382,
      "eval_steps_per_second": 0.589,
      "step": 69800
    },
    {
      "epoch": 21.102719033232628,
      "grad_norm": 0.47809353470802307,
      "learning_rate": 5.2598388721047335e-05,
      "loss": 1.3006,
      "step": 69850
    },
    {
      "epoch": 21.102719033232628,
      "eval_loss": 1.3350129127502441,
      "eval_runtime": 611.2545,
      "eval_samples_per_second": 86.869,
      "eval_steps_per_second": 0.679,
      "step": 69850
    },
    {
      "epoch": 21.117824773413897,
      "grad_norm": 0.4930874705314636,
      "learning_rate": 5.2588318227593154e-05,
      "loss": 1.3002,
      "step": 69900
    },
    {
      "epoch": 21.117824773413897,
      "eval_loss": 1.3381189107894897,
      "eval_runtime": 607.3906,
      "eval_samples_per_second": 87.422,
      "eval_steps_per_second": 0.683,
      "step": 69900
    },
    {
      "epoch": 21.132930513595166,
      "grad_norm": 0.49834173917770386,
      "learning_rate": 5.257824773413897e-05,
      "loss": 1.3234,
      "step": 69950
    },
    {
      "epoch": 21.132930513595166,
      "eval_loss": 1.3359938859939575,
      "eval_runtime": 600.7441,
      "eval_samples_per_second": 88.389,
      "eval_steps_per_second": 0.691,
      "step": 69950
    },
    {
      "epoch": 21.148036253776436,
      "grad_norm": 0.512037456035614,
      "learning_rate": 5.25681772406848e-05,
      "loss": 1.2971,
      "step": 70000
    },
    {
      "epoch": 21.148036253776436,
      "eval_loss": 1.335018277168274,
      "eval_runtime": 647.9714,
      "eval_samples_per_second": 81.947,
      "eval_steps_per_second": 0.64,
      "step": 70000
    },
    {
      "epoch": 21.163141993957705,
      "grad_norm": 0.5125743746757507,
      "learning_rate": 5.2558106747230617e-05,
      "loss": 1.299,
      "step": 70050
    },
    {
      "epoch": 21.163141993957705,
      "eval_loss": 1.33477783203125,
      "eval_runtime": 671.355,
      "eval_samples_per_second": 79.092,
      "eval_steps_per_second": 0.618,
      "step": 70050
    },
    {
      "epoch": 21.178247734138974,
      "grad_norm": 0.47162118554115295,
      "learning_rate": 5.2548036253776435e-05,
      "loss": 1.2953,
      "step": 70100
    },
    {
      "epoch": 21.178247734138974,
      "eval_loss": 1.3359079360961914,
      "eval_runtime": 705.8202,
      "eval_samples_per_second": 75.23,
      "eval_steps_per_second": 0.588,
      "step": 70100
    },
    {
      "epoch": 21.19335347432024,
      "grad_norm": 0.48725003004074097,
      "learning_rate": 5.253796576032226e-05,
      "loss": 1.311,
      "step": 70150
    },
    {
      "epoch": 21.19335347432024,
      "eval_loss": 1.3335515260696411,
      "eval_runtime": 650.981,
      "eval_samples_per_second": 81.568,
      "eval_steps_per_second": 0.637,
      "step": 70150
    },
    {
      "epoch": 21.20845921450151,
      "grad_norm": 0.49341344833374023,
      "learning_rate": 5.252789526686808e-05,
      "loss": 1.3139,
      "step": 70200
    },
    {
      "epoch": 21.20845921450151,
      "eval_loss": 1.333579659461975,
      "eval_runtime": 618.7849,
      "eval_samples_per_second": 85.812,
      "eval_steps_per_second": 0.671,
      "step": 70200
    },
    {
      "epoch": 21.22356495468278,
      "grad_norm": 0.47997525334358215,
      "learning_rate": 5.25178247734139e-05,
      "loss": 1.3208,
      "step": 70250
    },
    {
      "epoch": 21.22356495468278,
      "eval_loss": 1.3331615924835205,
      "eval_runtime": 774.452,
      "eval_samples_per_second": 68.563,
      "eval_steps_per_second": 0.536,
      "step": 70250
    },
    {
      "epoch": 21.238670694864048,
      "grad_norm": 0.5063242316246033,
      "learning_rate": 5.250775427995972e-05,
      "loss": 1.321,
      "step": 70300
    },
    {
      "epoch": 21.238670694864048,
      "eval_loss": 1.3329782485961914,
      "eval_runtime": 636.5359,
      "eval_samples_per_second": 83.419,
      "eval_steps_per_second": 0.652,
      "step": 70300
    },
    {
      "epoch": 21.253776435045317,
      "grad_norm": 0.5120116472244263,
      "learning_rate": 5.249768378650554e-05,
      "loss": 1.323,
      "step": 70350
    },
    {
      "epoch": 21.253776435045317,
      "eval_loss": 1.3349487781524658,
      "eval_runtime": 660.031,
      "eval_samples_per_second": 80.449,
      "eval_steps_per_second": 0.629,
      "step": 70350
    },
    {
      "epoch": 21.268882175226587,
      "grad_norm": 0.4983743727207184,
      "learning_rate": 5.248761329305136e-05,
      "loss": 1.3159,
      "step": 70400
    },
    {
      "epoch": 21.268882175226587,
      "eval_loss": 1.3342255353927612,
      "eval_runtime": 708.4596,
      "eval_samples_per_second": 74.95,
      "eval_steps_per_second": 0.586,
      "step": 70400
    },
    {
      "epoch": 21.283987915407856,
      "grad_norm": 0.4682804346084595,
      "learning_rate": 5.247754279959718e-05,
      "loss": 1.3058,
      "step": 70450
    },
    {
      "epoch": 21.283987915407856,
      "eval_loss": 1.3344638347625732,
      "eval_runtime": 648.1017,
      "eval_samples_per_second": 81.93,
      "eval_steps_per_second": 0.64,
      "step": 70450
    },
    {
      "epoch": 21.299093655589125,
      "grad_norm": 0.48353812098503113,
      "learning_rate": 5.2467472306143e-05,
      "loss": 1.307,
      "step": 70500
    },
    {
      "epoch": 21.299093655589125,
      "eval_loss": 1.3337337970733643,
      "eval_runtime": 677.8787,
      "eval_samples_per_second": 78.331,
      "eval_steps_per_second": 0.612,
      "step": 70500
    },
    {
      "epoch": 21.31419939577039,
      "grad_norm": 0.5251338481903076,
      "learning_rate": 5.2457401812688824e-05,
      "loss": 1.3308,
      "step": 70550
    },
    {
      "epoch": 21.31419939577039,
      "eval_loss": 1.3343626260757446,
      "eval_runtime": 668.7496,
      "eval_samples_per_second": 79.4,
      "eval_steps_per_second": 0.621,
      "step": 70550
    },
    {
      "epoch": 21.32930513595166,
      "grad_norm": 0.5028208494186401,
      "learning_rate": 5.244733131923464e-05,
      "loss": 1.3091,
      "step": 70600
    },
    {
      "epoch": 21.32930513595166,
      "eval_loss": 1.3328553438186646,
      "eval_runtime": 674.8717,
      "eval_samples_per_second": 78.68,
      "eval_steps_per_second": 0.615,
      "step": 70600
    },
    {
      "epoch": 21.34441087613293,
      "grad_norm": 0.5926000475883484,
      "learning_rate": 5.243726082578046e-05,
      "loss": 1.3265,
      "step": 70650
    },
    {
      "epoch": 21.34441087613293,
      "eval_loss": 1.3341516256332397,
      "eval_runtime": 587.8873,
      "eval_samples_per_second": 90.322,
      "eval_steps_per_second": 0.706,
      "step": 70650
    },
    {
      "epoch": 21.3595166163142,
      "grad_norm": 0.5255370736122131,
      "learning_rate": 5.242719033232628e-05,
      "loss": 1.2845,
      "step": 70700
    },
    {
      "epoch": 21.3595166163142,
      "eval_loss": 1.3306448459625244,
      "eval_runtime": 613.6226,
      "eval_samples_per_second": 86.534,
      "eval_steps_per_second": 0.676,
      "step": 70700
    },
    {
      "epoch": 21.37462235649547,
      "grad_norm": 0.5075341463088989,
      "learning_rate": 5.2417119838872105e-05,
      "loss": 1.3,
      "step": 70750
    },
    {
      "epoch": 21.37462235649547,
      "eval_loss": 1.333261489868164,
      "eval_runtime": 681.4572,
      "eval_samples_per_second": 77.92,
      "eval_steps_per_second": 0.609,
      "step": 70750
    },
    {
      "epoch": 21.389728096676738,
      "grad_norm": 0.48703533411026,
      "learning_rate": 5.240704934541793e-05,
      "loss": 1.3193,
      "step": 70800
    },
    {
      "epoch": 21.389728096676738,
      "eval_loss": 1.3308627605438232,
      "eval_runtime": 715.6393,
      "eval_samples_per_second": 74.198,
      "eval_steps_per_second": 0.58,
      "step": 70800
    },
    {
      "epoch": 21.404833836858007,
      "grad_norm": 0.5275097489356995,
      "learning_rate": 5.239697885196375e-05,
      "loss": 1.2906,
      "step": 70850
    },
    {
      "epoch": 21.404833836858007,
      "eval_loss": 1.3349324464797974,
      "eval_runtime": 694.0989,
      "eval_samples_per_second": 76.501,
      "eval_steps_per_second": 0.598,
      "step": 70850
    },
    {
      "epoch": 21.419939577039276,
      "grad_norm": 0.48806363344192505,
      "learning_rate": 5.238690835850957e-05,
      "loss": 1.2888,
      "step": 70900
    },
    {
      "epoch": 21.419939577039276,
      "eval_loss": 1.3339334726333618,
      "eval_runtime": 622.7761,
      "eval_samples_per_second": 85.262,
      "eval_steps_per_second": 0.666,
      "step": 70900
    },
    {
      "epoch": 21.435045317220546,
      "grad_norm": 0.5254908800125122,
      "learning_rate": 5.2376837865055394e-05,
      "loss": 1.2979,
      "step": 70950
    },
    {
      "epoch": 21.435045317220546,
      "eval_loss": 1.3352065086364746,
      "eval_runtime": 699.8353,
      "eval_samples_per_second": 75.874,
      "eval_steps_per_second": 0.593,
      "step": 70950
    },
    {
      "epoch": 21.45015105740181,
      "grad_norm": 0.4746529161930084,
      "learning_rate": 5.236676737160121e-05,
      "loss": 1.3035,
      "step": 71000
    },
    {
      "epoch": 21.45015105740181,
      "eval_loss": 1.3318606615066528,
      "eval_runtime": 639.5326,
      "eval_samples_per_second": 83.028,
      "eval_steps_per_second": 0.649,
      "step": 71000
    },
    {
      "epoch": 21.46525679758308,
      "grad_norm": 0.4815126955509186,
      "learning_rate": 5.235669687814703e-05,
      "loss": 1.2953,
      "step": 71050
    },
    {
      "epoch": 21.46525679758308,
      "eval_loss": 1.3342232704162598,
      "eval_runtime": 617.4875,
      "eval_samples_per_second": 85.992,
      "eval_steps_per_second": 0.672,
      "step": 71050
    },
    {
      "epoch": 21.48036253776435,
      "grad_norm": 0.49186187982559204,
      "learning_rate": 5.234662638469285e-05,
      "loss": 1.2996,
      "step": 71100
    },
    {
      "epoch": 21.48036253776435,
      "eval_loss": 1.333990216255188,
      "eval_runtime": 707.8463,
      "eval_samples_per_second": 75.015,
      "eval_steps_per_second": 0.586,
      "step": 71100
    },
    {
      "epoch": 21.49546827794562,
      "grad_norm": 0.47462260723114014,
      "learning_rate": 5.2336555891238675e-05,
      "loss": 1.2973,
      "step": 71150
    },
    {
      "epoch": 21.49546827794562,
      "eval_loss": 1.3308287858963013,
      "eval_runtime": 599.4007,
      "eval_samples_per_second": 88.587,
      "eval_steps_per_second": 0.692,
      "step": 71150
    },
    {
      "epoch": 21.51057401812689,
      "grad_norm": 0.4715474843978882,
      "learning_rate": 5.2326485397784494e-05,
      "loss": 1.3039,
      "step": 71200
    },
    {
      "epoch": 21.51057401812689,
      "eval_loss": 1.3324742317199707,
      "eval_runtime": 649.7231,
      "eval_samples_per_second": 81.726,
      "eval_steps_per_second": 0.639,
      "step": 71200
    },
    {
      "epoch": 21.525679758308158,
      "grad_norm": 0.5115232467651367,
      "learning_rate": 5.231641490433031e-05,
      "loss": 1.3204,
      "step": 71250
    },
    {
      "epoch": 21.525679758308158,
      "eval_loss": 1.3340717554092407,
      "eval_runtime": 655.6807,
      "eval_samples_per_second": 80.983,
      "eval_steps_per_second": 0.633,
      "step": 71250
    },
    {
      "epoch": 21.540785498489427,
      "grad_norm": 0.48407182097435,
      "learning_rate": 5.230634441087614e-05,
      "loss": 1.2896,
      "step": 71300
    },
    {
      "epoch": 21.540785498489427,
      "eval_loss": 1.332283616065979,
      "eval_runtime": 655.0698,
      "eval_samples_per_second": 81.059,
      "eval_steps_per_second": 0.634,
      "step": 71300
    },
    {
      "epoch": 21.555891238670696,
      "grad_norm": 0.5017513036727905,
      "learning_rate": 5.2296273917421957e-05,
      "loss": 1.3113,
      "step": 71350
    },
    {
      "epoch": 21.555891238670696,
      "eval_loss": 1.3299200534820557,
      "eval_runtime": 702.8444,
      "eval_samples_per_second": 75.549,
      "eval_steps_per_second": 0.59,
      "step": 71350
    },
    {
      "epoch": 21.570996978851962,
      "grad_norm": 0.49478238821029663,
      "learning_rate": 5.2286203423967775e-05,
      "loss": 1.3032,
      "step": 71400
    },
    {
      "epoch": 21.570996978851962,
      "eval_loss": 1.3323220014572144,
      "eval_runtime": 649.3564,
      "eval_samples_per_second": 81.772,
      "eval_steps_per_second": 0.639,
      "step": 71400
    },
    {
      "epoch": 21.58610271903323,
      "grad_norm": 0.4875084161758423,
      "learning_rate": 5.2276132930513594e-05,
      "loss": 1.3215,
      "step": 71450
    },
    {
      "epoch": 21.58610271903323,
      "eval_loss": 1.330190896987915,
      "eval_runtime": 646.1744,
      "eval_samples_per_second": 82.174,
      "eval_steps_per_second": 0.642,
      "step": 71450
    },
    {
      "epoch": 21.6012084592145,
      "grad_norm": 0.49655699729919434,
      "learning_rate": 5.226606243705942e-05,
      "loss": 1.3076,
      "step": 71500
    },
    {
      "epoch": 21.6012084592145,
      "eval_loss": 1.3307000398635864,
      "eval_runtime": 678.5784,
      "eval_samples_per_second": 78.25,
      "eval_steps_per_second": 0.612,
      "step": 71500
    },
    {
      "epoch": 21.61631419939577,
      "grad_norm": 0.520362913608551,
      "learning_rate": 5.225599194360524e-05,
      "loss": 1.3003,
      "step": 71550
    },
    {
      "epoch": 21.61631419939577,
      "eval_loss": 1.3326849937438965,
      "eval_runtime": 691.8989,
      "eval_samples_per_second": 76.744,
      "eval_steps_per_second": 0.6,
      "step": 71550
    },
    {
      "epoch": 21.63141993957704,
      "grad_norm": 0.4787713885307312,
      "learning_rate": 5.224592145015106e-05,
      "loss": 1.2961,
      "step": 71600
    },
    {
      "epoch": 21.63141993957704,
      "eval_loss": 1.3317551612854004,
      "eval_runtime": 670.3693,
      "eval_samples_per_second": 79.209,
      "eval_steps_per_second": 0.619,
      "step": 71600
    },
    {
      "epoch": 21.64652567975831,
      "grad_norm": 0.4683384597301483,
      "learning_rate": 5.2235850956696875e-05,
      "loss": 1.3162,
      "step": 71650
    },
    {
      "epoch": 21.64652567975831,
      "eval_loss": 1.331688404083252,
      "eval_runtime": 645.2635,
      "eval_samples_per_second": 82.29,
      "eval_steps_per_second": 0.643,
      "step": 71650
    },
    {
      "epoch": 21.661631419939578,
      "grad_norm": 0.5120622515678406,
      "learning_rate": 5.22257804632427e-05,
      "loss": 1.3063,
      "step": 71700
    },
    {
      "epoch": 21.661631419939578,
      "eval_loss": 1.3328057527542114,
      "eval_runtime": 679.936,
      "eval_samples_per_second": 78.094,
      "eval_steps_per_second": 0.61,
      "step": 71700
    },
    {
      "epoch": 21.676737160120847,
      "grad_norm": 0.510283887386322,
      "learning_rate": 5.221570996978852e-05,
      "loss": 1.3385,
      "step": 71750
    },
    {
      "epoch": 21.676737160120847,
      "eval_loss": 1.3333969116210938,
      "eval_runtime": 707.0597,
      "eval_samples_per_second": 75.098,
      "eval_steps_per_second": 0.587,
      "step": 71750
    },
    {
      "epoch": 21.691842900302113,
      "grad_norm": 0.46276000142097473,
      "learning_rate": 5.220563947633434e-05,
      "loss": 1.3241,
      "step": 71800
    },
    {
      "epoch": 21.691842900302113,
      "eval_loss": 1.3330882787704468,
      "eval_runtime": 833.2547,
      "eval_samples_per_second": 63.725,
      "eval_steps_per_second": 0.498,
      "step": 71800
    },
    {
      "epoch": 21.706948640483382,
      "grad_norm": 0.45340049266815186,
      "learning_rate": 5.219556898288016e-05,
      "loss": 1.3382,
      "step": 71850
    },
    {
      "epoch": 21.706948640483382,
      "eval_loss": 1.3349792957305908,
      "eval_runtime": 909.7031,
      "eval_samples_per_second": 58.37,
      "eval_steps_per_second": 0.456,
      "step": 71850
    },
    {
      "epoch": 21.72205438066465,
      "grad_norm": 0.46334338188171387,
      "learning_rate": 5.218549848942598e-05,
      "loss": 1.3306,
      "step": 71900
    },
    {
      "epoch": 21.72205438066465,
      "eval_loss": 1.3291115760803223,
      "eval_runtime": 730.8386,
      "eval_samples_per_second": 72.655,
      "eval_steps_per_second": 0.568,
      "step": 71900
    },
    {
      "epoch": 21.73716012084592,
      "grad_norm": 0.512891948223114,
      "learning_rate": 5.217542799597181e-05,
      "loss": 1.3169,
      "step": 71950
    },
    {
      "epoch": 21.73716012084592,
      "eval_loss": 1.3308192491531372,
      "eval_runtime": 662.1773,
      "eval_samples_per_second": 80.188,
      "eval_steps_per_second": 0.627,
      "step": 71950
    },
    {
      "epoch": 21.75226586102719,
      "grad_norm": 0.45967525243759155,
      "learning_rate": 5.216535750251763e-05,
      "loss": 1.295,
      "step": 72000
    },
    {
      "epoch": 21.75226586102719,
      "eval_loss": 1.329721450805664,
      "eval_runtime": 1386.48,
      "eval_samples_per_second": 38.298,
      "eval_steps_per_second": 0.299,
      "step": 72000
    },
    {
      "epoch": 21.76737160120846,
      "grad_norm": 0.47012361884117126,
      "learning_rate": 5.2155287009063445e-05,
      "loss": 1.298,
      "step": 72050
    },
    {
      "epoch": 21.76737160120846,
      "eval_loss": 1.3300291299819946,
      "eval_runtime": 702.2031,
      "eval_samples_per_second": 75.618,
      "eval_steps_per_second": 0.591,
      "step": 72050
    },
    {
      "epoch": 21.78247734138973,
      "grad_norm": 0.452016681432724,
      "learning_rate": 5.214521651560927e-05,
      "loss": 1.3237,
      "step": 72100
    },
    {
      "epoch": 21.78247734138973,
      "eval_loss": 1.3296654224395752,
      "eval_runtime": 775.7091,
      "eval_samples_per_second": 68.452,
      "eval_steps_per_second": 0.535,
      "step": 72100
    },
    {
      "epoch": 21.797583081571,
      "grad_norm": 0.5717103481292725,
      "learning_rate": 5.213514602215509e-05,
      "loss": 1.3114,
      "step": 72150
    },
    {
      "epoch": 21.797583081571,
      "eval_loss": 1.3292992115020752,
      "eval_runtime": 664.5912,
      "eval_samples_per_second": 79.897,
      "eval_steps_per_second": 0.624,
      "step": 72150
    },
    {
      "epoch": 21.812688821752268,
      "grad_norm": 0.47553592920303345,
      "learning_rate": 5.212507552870091e-05,
      "loss": 1.317,
      "step": 72200
    },
    {
      "epoch": 21.812688821752268,
      "eval_loss": 1.3315978050231934,
      "eval_runtime": 705.3806,
      "eval_samples_per_second": 75.277,
      "eval_steps_per_second": 0.588,
      "step": 72200
    },
    {
      "epoch": 21.827794561933533,
      "grad_norm": 0.44849392771720886,
      "learning_rate": 5.211500503524673e-05,
      "loss": 1.3095,
      "step": 72250
    },
    {
      "epoch": 21.827794561933533,
      "eval_loss": 1.3314069509506226,
      "eval_runtime": 631.2137,
      "eval_samples_per_second": 84.122,
      "eval_steps_per_second": 0.657,
      "step": 72250
    },
    {
      "epoch": 21.842900302114803,
      "grad_norm": 0.45318010449409485,
      "learning_rate": 5.210493454179255e-05,
      "loss": 1.2913,
      "step": 72300
    },
    {
      "epoch": 21.842900302114803,
      "eval_loss": 1.329236626625061,
      "eval_runtime": 707.0073,
      "eval_samples_per_second": 75.104,
      "eval_steps_per_second": 0.587,
      "step": 72300
    },
    {
      "epoch": 21.858006042296072,
      "grad_norm": 0.46047699451446533,
      "learning_rate": 5.209486404833837e-05,
      "loss": 1.3097,
      "step": 72350
    },
    {
      "epoch": 21.858006042296072,
      "eval_loss": 1.3307431936264038,
      "eval_runtime": 649.0331,
      "eval_samples_per_second": 81.812,
      "eval_steps_per_second": 0.639,
      "step": 72350
    },
    {
      "epoch": 21.87311178247734,
      "grad_norm": 0.4763020873069763,
      "learning_rate": 5.208479355488419e-05,
      "loss": 1.3227,
      "step": 72400
    },
    {
      "epoch": 21.87311178247734,
      "eval_loss": 1.330920696258545,
      "eval_runtime": 619.1698,
      "eval_samples_per_second": 85.758,
      "eval_steps_per_second": 0.67,
      "step": 72400
    },
    {
      "epoch": 21.88821752265861,
      "grad_norm": 0.5019403100013733,
      "learning_rate": 5.2074723061430015e-05,
      "loss": 1.2999,
      "step": 72450
    },
    {
      "epoch": 21.88821752265861,
      "eval_loss": 1.3321729898452759,
      "eval_runtime": 649.1569,
      "eval_samples_per_second": 81.797,
      "eval_steps_per_second": 0.639,
      "step": 72450
    },
    {
      "epoch": 21.90332326283988,
      "grad_norm": 0.539221465587616,
      "learning_rate": 5.2064652567975834e-05,
      "loss": 1.3171,
      "step": 72500
    },
    {
      "epoch": 21.90332326283988,
      "eval_loss": 1.3305896520614624,
      "eval_runtime": 647.1804,
      "eval_samples_per_second": 82.047,
      "eval_steps_per_second": 0.641,
      "step": 72500
    },
    {
      "epoch": 21.91842900302115,
      "grad_norm": 0.5291388034820557,
      "learning_rate": 5.205458207452165e-05,
      "loss": 1.2951,
      "step": 72550
    },
    {
      "epoch": 21.91842900302115,
      "eval_loss": 1.3318796157836914,
      "eval_runtime": 700.4197,
      "eval_samples_per_second": 75.81,
      "eval_steps_per_second": 0.593,
      "step": 72550
    },
    {
      "epoch": 21.93353474320242,
      "grad_norm": 0.5384737849235535,
      "learning_rate": 5.204451158106747e-05,
      "loss": 1.3101,
      "step": 72600
    },
    {
      "epoch": 21.93353474320242,
      "eval_loss": 1.329888939857483,
      "eval_runtime": 677.007,
      "eval_samples_per_second": 78.432,
      "eval_steps_per_second": 0.613,
      "step": 72600
    },
    {
      "epoch": 21.948640483383684,
      "grad_norm": 0.4989212155342102,
      "learning_rate": 5.20344410876133e-05,
      "loss": 1.3364,
      "step": 72650
    },
    {
      "epoch": 21.948640483383684,
      "eval_loss": 1.330234169960022,
      "eval_runtime": 654.7267,
      "eval_samples_per_second": 81.101,
      "eval_steps_per_second": 0.634,
      "step": 72650
    },
    {
      "epoch": 21.963746223564954,
      "grad_norm": 0.4879325330257416,
      "learning_rate": 5.2024370594159115e-05,
      "loss": 1.3042,
      "step": 72700
    },
    {
      "epoch": 21.963746223564954,
      "eval_loss": 1.3323723077774048,
      "eval_runtime": 672.989,
      "eval_samples_per_second": 78.9,
      "eval_steps_per_second": 0.617,
      "step": 72700
    },
    {
      "epoch": 21.978851963746223,
      "grad_norm": 0.46877938508987427,
      "learning_rate": 5.2014300100704934e-05,
      "loss": 1.328,
      "step": 72750
    },
    {
      "epoch": 21.978851963746223,
      "eval_loss": 1.3306175470352173,
      "eval_runtime": 693.4588,
      "eval_samples_per_second": 76.571,
      "eval_steps_per_second": 0.598,
      "step": 72750
    },
    {
      "epoch": 21.993957703927492,
      "grad_norm": 0.4980379641056061,
      "learning_rate": 5.200422960725075e-05,
      "loss": 1.3114,
      "step": 72800
    },
    {
      "epoch": 21.993957703927492,
      "eval_loss": 1.3290780782699585,
      "eval_runtime": 683.508,
      "eval_samples_per_second": 77.686,
      "eval_steps_per_second": 0.607,
      "step": 72800
    },
    {
      "epoch": 22.00906344410876,
      "grad_norm": 0.4615234136581421,
      "learning_rate": 5.199415911379658e-05,
      "loss": 1.2955,
      "step": 72850
    },
    {
      "epoch": 22.00906344410876,
      "eval_loss": 1.3291233777999878,
      "eval_runtime": 613.5983,
      "eval_samples_per_second": 86.537,
      "eval_steps_per_second": 0.676,
      "step": 72850
    },
    {
      "epoch": 22.02416918429003,
      "grad_norm": 0.5454010963439941,
      "learning_rate": 5.19840886203424e-05,
      "loss": 1.3256,
      "step": 72900
    },
    {
      "epoch": 22.02416918429003,
      "eval_loss": 1.3288582563400269,
      "eval_runtime": 688.241,
      "eval_samples_per_second": 77.152,
      "eval_steps_per_second": 0.603,
      "step": 72900
    },
    {
      "epoch": 22.0392749244713,
      "grad_norm": 0.5297172665596008,
      "learning_rate": 5.1974018126888216e-05,
      "loss": 1.3088,
      "step": 72950
    },
    {
      "epoch": 22.0392749244713,
      "eval_loss": 1.3309231996536255,
      "eval_runtime": 630.3033,
      "eval_samples_per_second": 84.244,
      "eval_steps_per_second": 0.658,
      "step": 72950
    },
    {
      "epoch": 22.05438066465257,
      "grad_norm": 0.5115841627120972,
      "learning_rate": 5.1963947633434034e-05,
      "loss": 1.286,
      "step": 73000
    },
    {
      "epoch": 22.05438066465257,
      "eval_loss": 1.3303775787353516,
      "eval_runtime": 614.7582,
      "eval_samples_per_second": 86.374,
      "eval_steps_per_second": 0.675,
      "step": 73000
    },
    {
      "epoch": 22.069486404833835,
      "grad_norm": 0.5087847113609314,
      "learning_rate": 5.195387713997986e-05,
      "loss": 1.3263,
      "step": 73050
    },
    {
      "epoch": 22.069486404833835,
      "eval_loss": 1.3298701047897339,
      "eval_runtime": 605.4392,
      "eval_samples_per_second": 87.703,
      "eval_steps_per_second": 0.685,
      "step": 73050
    },
    {
      "epoch": 22.084592145015105,
      "grad_norm": 0.5018512606620789,
      "learning_rate": 5.194380664652568e-05,
      "loss": 1.3026,
      "step": 73100
    },
    {
      "epoch": 22.084592145015105,
      "eval_loss": 1.330009937286377,
      "eval_runtime": 643.9922,
      "eval_samples_per_second": 82.453,
      "eval_steps_per_second": 0.644,
      "step": 73100
    },
    {
      "epoch": 22.099697885196374,
      "grad_norm": 0.5119268894195557,
      "learning_rate": 5.1933736153071504e-05,
      "loss": 1.3174,
      "step": 73150
    },
    {
      "epoch": 22.099697885196374,
      "eval_loss": 1.3280247449874878,
      "eval_runtime": 684.9899,
      "eval_samples_per_second": 77.518,
      "eval_steps_per_second": 0.606,
      "step": 73150
    },
    {
      "epoch": 22.114803625377643,
      "grad_norm": 0.554625928401947,
      "learning_rate": 5.192366565961732e-05,
      "loss": 1.2827,
      "step": 73200
    },
    {
      "epoch": 22.114803625377643,
      "eval_loss": 1.3290513753890991,
      "eval_runtime": 622.8913,
      "eval_samples_per_second": 85.246,
      "eval_steps_per_second": 0.666,
      "step": 73200
    },
    {
      "epoch": 22.129909365558913,
      "grad_norm": 0.44830596446990967,
      "learning_rate": 5.191359516616315e-05,
      "loss": 1.3009,
      "step": 73250
    },
    {
      "epoch": 22.129909365558913,
      "eval_loss": 1.3290438652038574,
      "eval_runtime": 710.1809,
      "eval_samples_per_second": 74.768,
      "eval_steps_per_second": 0.584,
      "step": 73250
    },
    {
      "epoch": 22.145015105740182,
      "grad_norm": 0.4594159424304962,
      "learning_rate": 5.190352467270897e-05,
      "loss": 1.3086,
      "step": 73300
    },
    {
      "epoch": 22.145015105740182,
      "eval_loss": 1.328961730003357,
      "eval_runtime": 586.3579,
      "eval_samples_per_second": 90.557,
      "eval_steps_per_second": 0.708,
      "step": 73300
    },
    {
      "epoch": 22.16012084592145,
      "grad_norm": 0.501065731048584,
      "learning_rate": 5.1893454179254785e-05,
      "loss": 1.2933,
      "step": 73350
    },
    {
      "epoch": 22.16012084592145,
      "eval_loss": 1.3313714265823364,
      "eval_runtime": 678.9821,
      "eval_samples_per_second": 78.204,
      "eval_steps_per_second": 0.611,
      "step": 73350
    },
    {
      "epoch": 22.17522658610272,
      "grad_norm": 0.47925445437431335,
      "learning_rate": 5.1883383685800604e-05,
      "loss": 1.2724,
      "step": 73400
    },
    {
      "epoch": 22.17522658610272,
      "eval_loss": 1.327415108680725,
      "eval_runtime": 600.8101,
      "eval_samples_per_second": 88.379,
      "eval_steps_per_second": 0.691,
      "step": 73400
    },
    {
      "epoch": 22.190332326283986,
      "grad_norm": 0.4617269039154053,
      "learning_rate": 5.187331319234643e-05,
      "loss": 1.2823,
      "step": 73450
    },
    {
      "epoch": 22.190332326283986,
      "eval_loss": 1.3289884328842163,
      "eval_runtime": 694.9011,
      "eval_samples_per_second": 76.412,
      "eval_steps_per_second": 0.597,
      "step": 73450
    },
    {
      "epoch": 22.205438066465256,
      "grad_norm": 0.5189163684844971,
      "learning_rate": 5.186324269889225e-05,
      "loss": 1.2857,
      "step": 73500
    },
    {
      "epoch": 22.205438066465256,
      "eval_loss": 1.3284590244293213,
      "eval_runtime": 612.9933,
      "eval_samples_per_second": 86.622,
      "eval_steps_per_second": 0.677,
      "step": 73500
    },
    {
      "epoch": 22.220543806646525,
      "grad_norm": 0.4615842401981354,
      "learning_rate": 5.185317220543807e-05,
      "loss": 1.3241,
      "step": 73550
    },
    {
      "epoch": 22.220543806646525,
      "eval_loss": 1.3303719758987427,
      "eval_runtime": 616.8408,
      "eval_samples_per_second": 86.082,
      "eval_steps_per_second": 0.673,
      "step": 73550
    },
    {
      "epoch": 22.235649546827794,
      "grad_norm": 0.45447027683258057,
      "learning_rate": 5.184310171198389e-05,
      "loss": 1.2916,
      "step": 73600
    },
    {
      "epoch": 22.235649546827794,
      "eval_loss": 1.328607439994812,
      "eval_runtime": 625.7804,
      "eval_samples_per_second": 84.852,
      "eval_steps_per_second": 0.663,
      "step": 73600
    },
    {
      "epoch": 22.250755287009063,
      "grad_norm": 0.4778488278388977,
      "learning_rate": 5.183303121852971e-05,
      "loss": 1.3064,
      "step": 73650
    },
    {
      "epoch": 22.250755287009063,
      "eval_loss": 1.327475666999817,
      "eval_runtime": 698.7844,
      "eval_samples_per_second": 75.988,
      "eval_steps_per_second": 0.594,
      "step": 73650
    },
    {
      "epoch": 22.265861027190333,
      "grad_norm": 0.4878571033477783,
      "learning_rate": 5.182296072507553e-05,
      "loss": 1.3011,
      "step": 73700
    },
    {
      "epoch": 22.265861027190333,
      "eval_loss": 1.3302001953125,
      "eval_runtime": 593.2626,
      "eval_samples_per_second": 89.503,
      "eval_steps_per_second": 0.7,
      "step": 73700
    },
    {
      "epoch": 22.280966767371602,
      "grad_norm": 0.5595672130584717,
      "learning_rate": 5.181289023162135e-05,
      "loss": 1.3196,
      "step": 73750
    },
    {
      "epoch": 22.280966767371602,
      "eval_loss": 1.328925609588623,
      "eval_runtime": 619.2205,
      "eval_samples_per_second": 85.751,
      "eval_steps_per_second": 0.67,
      "step": 73750
    },
    {
      "epoch": 22.29607250755287,
      "grad_norm": 0.5197068452835083,
      "learning_rate": 5.1802819738167174e-05,
      "loss": 1.2942,
      "step": 73800
    },
    {
      "epoch": 22.29607250755287,
      "eval_loss": 1.3287981748580933,
      "eval_runtime": 622.5252,
      "eval_samples_per_second": 85.296,
      "eval_steps_per_second": 0.667,
      "step": 73800
    },
    {
      "epoch": 22.31117824773414,
      "grad_norm": 0.4585707187652588,
      "learning_rate": 5.179274924471299e-05,
      "loss": 1.2862,
      "step": 73850
    },
    {
      "epoch": 22.31117824773414,
      "eval_loss": 1.3289705514907837,
      "eval_runtime": 687.4806,
      "eval_samples_per_second": 77.237,
      "eval_steps_per_second": 0.604,
      "step": 73850
    },
    {
      "epoch": 22.326283987915406,
      "grad_norm": 0.4723888337612152,
      "learning_rate": 5.178267875125881e-05,
      "loss": 1.2932,
      "step": 73900
    },
    {
      "epoch": 22.326283987915406,
      "eval_loss": 1.3296452760696411,
      "eval_runtime": 637.2209,
      "eval_samples_per_second": 83.329,
      "eval_steps_per_second": 0.651,
      "step": 73900
    },
    {
      "epoch": 22.341389728096676,
      "grad_norm": 0.5620577335357666,
      "learning_rate": 5.177260825780463e-05,
      "loss": 1.3114,
      "step": 73950
    },
    {
      "epoch": 22.341389728096676,
      "eval_loss": 1.3277329206466675,
      "eval_runtime": 676.3458,
      "eval_samples_per_second": 78.509,
      "eval_steps_per_second": 0.614,
      "step": 73950
    },
    {
      "epoch": 22.356495468277945,
      "grad_norm": 0.4920583963394165,
      "learning_rate": 5.1762537764350455e-05,
      "loss": 1.2927,
      "step": 74000
    },
    {
      "epoch": 22.356495468277945,
      "eval_loss": 1.327415108680725,
      "eval_runtime": 642.6602,
      "eval_samples_per_second": 82.624,
      "eval_steps_per_second": 0.646,
      "step": 74000
    },
    {
      "epoch": 22.371601208459214,
      "grad_norm": 0.5118684768676758,
      "learning_rate": 5.1752467270896274e-05,
      "loss": 1.3137,
      "step": 74050
    },
    {
      "epoch": 22.371601208459214,
      "eval_loss": 1.3282020092010498,
      "eval_runtime": 647.6571,
      "eval_samples_per_second": 81.986,
      "eval_steps_per_second": 0.641,
      "step": 74050
    },
    {
      "epoch": 22.386706948640484,
      "grad_norm": 0.5205243229866028,
      "learning_rate": 5.174239677744209e-05,
      "loss": 1.2827,
      "step": 74100
    },
    {
      "epoch": 22.386706948640484,
      "eval_loss": 1.3269935846328735,
      "eval_runtime": 684.6789,
      "eval_samples_per_second": 77.553,
      "eval_steps_per_second": 0.606,
      "step": 74100
    },
    {
      "epoch": 22.401812688821753,
      "grad_norm": 0.5462614297866821,
      "learning_rate": 5.173232628398791e-05,
      "loss": 1.3043,
      "step": 74150
    },
    {
      "epoch": 22.401812688821753,
      "eval_loss": 1.3266489505767822,
      "eval_runtime": 698.1964,
      "eval_samples_per_second": 76.052,
      "eval_steps_per_second": 0.594,
      "step": 74150
    },
    {
      "epoch": 22.416918429003022,
      "grad_norm": 0.4723397493362427,
      "learning_rate": 5.172225579053374e-05,
      "loss": 1.2918,
      "step": 74200
    },
    {
      "epoch": 22.416918429003022,
      "eval_loss": 1.325989007949829,
      "eval_runtime": 700.3803,
      "eval_samples_per_second": 75.815,
      "eval_steps_per_second": 0.593,
      "step": 74200
    },
    {
      "epoch": 22.43202416918429,
      "grad_norm": 0.4617471396923065,
      "learning_rate": 5.1712185297079556e-05,
      "loss": 1.2958,
      "step": 74250
    },
    {
      "epoch": 22.43202416918429,
      "eval_loss": 1.3271722793579102,
      "eval_runtime": 712.5732,
      "eval_samples_per_second": 74.517,
      "eval_steps_per_second": 0.582,
      "step": 74250
    },
    {
      "epoch": 22.447129909365557,
      "grad_norm": 0.49511656165122986,
      "learning_rate": 5.170211480362538e-05,
      "loss": 1.283,
      "step": 74300
    },
    {
      "epoch": 22.447129909365557,
      "eval_loss": 1.3280411958694458,
      "eval_runtime": 688.5775,
      "eval_samples_per_second": 77.114,
      "eval_steps_per_second": 0.603,
      "step": 74300
    },
    {
      "epoch": 22.462235649546827,
      "grad_norm": 0.4489690959453583,
      "learning_rate": 5.16920443101712e-05,
      "loss": 1.2932,
      "step": 74350
    },
    {
      "epoch": 22.462235649546827,
      "eval_loss": 1.327327013015747,
      "eval_runtime": 633.0465,
      "eval_samples_per_second": 83.879,
      "eval_steps_per_second": 0.656,
      "step": 74350
    },
    {
      "epoch": 22.477341389728096,
      "grad_norm": 0.5124045014381409,
      "learning_rate": 5.1681973816717025e-05,
      "loss": 1.3232,
      "step": 74400
    },
    {
      "epoch": 22.477341389728096,
      "eval_loss": 1.3289403915405273,
      "eval_runtime": 628.4404,
      "eval_samples_per_second": 84.493,
      "eval_steps_per_second": 0.66,
      "step": 74400
    },
    {
      "epoch": 22.492447129909365,
      "grad_norm": 0.4910081624984741,
      "learning_rate": 5.1671903323262844e-05,
      "loss": 1.2922,
      "step": 74450
    },
    {
      "epoch": 22.492447129909365,
      "eval_loss": 1.3255860805511475,
      "eval_runtime": 604.0993,
      "eval_samples_per_second": 87.898,
      "eval_steps_per_second": 0.687,
      "step": 74450
    },
    {
      "epoch": 22.507552870090635,
      "grad_norm": 0.5533987283706665,
      "learning_rate": 5.166183282980866e-05,
      "loss": 1.2922,
      "step": 74500
    },
    {
      "epoch": 22.507552870090635,
      "eval_loss": 1.3278334140777588,
      "eval_runtime": 658.1328,
      "eval_samples_per_second": 80.681,
      "eval_steps_per_second": 0.631,
      "step": 74500
    },
    {
      "epoch": 22.522658610271904,
      "grad_norm": 0.5128188133239746,
      "learning_rate": 5.165176233635448e-05,
      "loss": 1.3241,
      "step": 74550
    },
    {
      "epoch": 22.522658610271904,
      "eval_loss": 1.3264554738998413,
      "eval_runtime": 660.8909,
      "eval_samples_per_second": 80.345,
      "eval_steps_per_second": 0.628,
      "step": 74550
    },
    {
      "epoch": 22.537764350453173,
      "grad_norm": 0.47459515929222107,
      "learning_rate": 5.164169184290031e-05,
      "loss": 1.2928,
      "step": 74600
    },
    {
      "epoch": 22.537764350453173,
      "eval_loss": 1.3269026279449463,
      "eval_runtime": 621.3481,
      "eval_samples_per_second": 85.458,
      "eval_steps_per_second": 0.668,
      "step": 74600
    },
    {
      "epoch": 22.552870090634443,
      "grad_norm": 0.5021329522132874,
      "learning_rate": 5.1631621349446125e-05,
      "loss": 1.3215,
      "step": 74650
    },
    {
      "epoch": 22.552870090634443,
      "eval_loss": 1.327513575553894,
      "eval_runtime": 680.8608,
      "eval_samples_per_second": 77.988,
      "eval_steps_per_second": 0.61,
      "step": 74650
    },
    {
      "epoch": 22.56797583081571,
      "grad_norm": 0.4753861129283905,
      "learning_rate": 5.1621550855991944e-05,
      "loss": 1.3026,
      "step": 74700
    },
    {
      "epoch": 22.56797583081571,
      "eval_loss": 1.3277664184570312,
      "eval_runtime": 664.1702,
      "eval_samples_per_second": 79.948,
      "eval_steps_per_second": 0.625,
      "step": 74700
    },
    {
      "epoch": 22.583081570996978,
      "grad_norm": 0.4660797715187073,
      "learning_rate": 5.161148036253777e-05,
      "loss": 1.3013,
      "step": 74750
    },
    {
      "epoch": 22.583081570996978,
      "eval_loss": 1.3297274112701416,
      "eval_runtime": 665.3024,
      "eval_samples_per_second": 79.812,
      "eval_steps_per_second": 0.624,
      "step": 74750
    },
    {
      "epoch": 22.598187311178247,
      "grad_norm": 0.4398197829723358,
      "learning_rate": 5.160140986908359e-05,
      "loss": 1.2992,
      "step": 74800
    },
    {
      "epoch": 22.598187311178247,
      "eval_loss": 1.3275370597839355,
      "eval_runtime": 615.8742,
      "eval_samples_per_second": 86.217,
      "eval_steps_per_second": 0.674,
      "step": 74800
    },
    {
      "epoch": 22.613293051359516,
      "grad_norm": 0.477080762386322,
      "learning_rate": 5.159133937562941e-05,
      "loss": 1.3319,
      "step": 74850
    },
    {
      "epoch": 22.613293051359516,
      "eval_loss": 1.3248498439788818,
      "eval_runtime": 619.4728,
      "eval_samples_per_second": 85.716,
      "eval_steps_per_second": 0.67,
      "step": 74850
    },
    {
      "epoch": 22.628398791540786,
      "grad_norm": 0.48532700538635254,
      "learning_rate": 5.1581268882175226e-05,
      "loss": 1.3014,
      "step": 74900
    },
    {
      "epoch": 22.628398791540786,
      "eval_loss": 1.3266406059265137,
      "eval_runtime": 672.239,
      "eval_samples_per_second": 78.988,
      "eval_steps_per_second": 0.617,
      "step": 74900
    },
    {
      "epoch": 22.643504531722055,
      "grad_norm": 0.5241291522979736,
      "learning_rate": 5.157119838872105e-05,
      "loss": 1.3302,
      "step": 74950
    },
    {
      "epoch": 22.643504531722055,
      "eval_loss": 1.3263996839523315,
      "eval_runtime": 679.9218,
      "eval_samples_per_second": 78.096,
      "eval_steps_per_second": 0.61,
      "step": 74950
    },
    {
      "epoch": 22.658610271903324,
      "grad_norm": 0.5116113424301147,
      "learning_rate": 5.156112789526687e-05,
      "loss": 1.3119,
      "step": 75000
    },
    {
      "epoch": 22.658610271903324,
      "eval_loss": 1.3259671926498413,
      "eval_runtime": 663.1034,
      "eval_samples_per_second": 80.077,
      "eval_steps_per_second": 0.626,
      "step": 75000
    },
    {
      "epoch": 22.673716012084594,
      "grad_norm": 0.47366759181022644,
      "learning_rate": 5.155105740181269e-05,
      "loss": 1.3034,
      "step": 75050
    },
    {
      "epoch": 22.673716012084594,
      "eval_loss": 1.3283790349960327,
      "eval_runtime": 667.697,
      "eval_samples_per_second": 79.526,
      "eval_steps_per_second": 0.622,
      "step": 75050
    },
    {
      "epoch": 22.68882175226586,
      "grad_norm": 0.4584835469722748,
      "learning_rate": 5.154098690835851e-05,
      "loss": 1.2852,
      "step": 75100
    },
    {
      "epoch": 22.68882175226586,
      "eval_loss": 1.3272812366485596,
      "eval_runtime": 701.3324,
      "eval_samples_per_second": 75.712,
      "eval_steps_per_second": 0.592,
      "step": 75100
    },
    {
      "epoch": 22.70392749244713,
      "grad_norm": 0.4439404308795929,
      "learning_rate": 5.153091641490433e-05,
      "loss": 1.2933,
      "step": 75150
    },
    {
      "epoch": 22.70392749244713,
      "eval_loss": 1.3245306015014648,
      "eval_runtime": 611.8241,
      "eval_samples_per_second": 86.788,
      "eval_steps_per_second": 0.678,
      "step": 75150
    },
    {
      "epoch": 22.719033232628398,
      "grad_norm": 0.5147709846496582,
      "learning_rate": 5.152084592145015e-05,
      "loss": 1.2856,
      "step": 75200
    },
    {
      "epoch": 22.719033232628398,
      "eval_loss": 1.3258905410766602,
      "eval_runtime": 676.9074,
      "eval_samples_per_second": 78.444,
      "eval_steps_per_second": 0.613,
      "step": 75200
    },
    {
      "epoch": 22.734138972809667,
      "grad_norm": 0.47205546498298645,
      "learning_rate": 5.151077542799597e-05,
      "loss": 1.3146,
      "step": 75250
    },
    {
      "epoch": 22.734138972809667,
      "eval_loss": 1.326972484588623,
      "eval_runtime": 635.0525,
      "eval_samples_per_second": 83.614,
      "eval_steps_per_second": 0.653,
      "step": 75250
    },
    {
      "epoch": 22.749244712990937,
      "grad_norm": 0.4499160945415497,
      "learning_rate": 5.150070493454179e-05,
      "loss": 1.2873,
      "step": 75300
    },
    {
      "epoch": 22.749244712990937,
      "eval_loss": 1.3288731575012207,
      "eval_runtime": 618.5997,
      "eval_samples_per_second": 85.837,
      "eval_steps_per_second": 0.671,
      "step": 75300
    },
    {
      "epoch": 22.764350453172206,
      "grad_norm": 0.5079587697982788,
      "learning_rate": 5.1490634441087614e-05,
      "loss": 1.298,
      "step": 75350
    },
    {
      "epoch": 22.764350453172206,
      "eval_loss": 1.3262733221054077,
      "eval_runtime": 662.691,
      "eval_samples_per_second": 80.126,
      "eval_steps_per_second": 0.626,
      "step": 75350
    },
    {
      "epoch": 22.779456193353475,
      "grad_norm": 0.48606669902801514,
      "learning_rate": 5.148056394763343e-05,
      "loss": 1.3226,
      "step": 75400
    },
    {
      "epoch": 22.779456193353475,
      "eval_loss": 1.3260701894760132,
      "eval_runtime": 696.0257,
      "eval_samples_per_second": 76.289,
      "eval_steps_per_second": 0.596,
      "step": 75400
    },
    {
      "epoch": 22.794561933534744,
      "grad_norm": 0.4416097402572632,
      "learning_rate": 5.147049345417926e-05,
      "loss": 1.2943,
      "step": 75450
    },
    {
      "epoch": 22.794561933534744,
      "eval_loss": 1.3256702423095703,
      "eval_runtime": 631.6394,
      "eval_samples_per_second": 84.065,
      "eval_steps_per_second": 0.657,
      "step": 75450
    },
    {
      "epoch": 22.809667673716014,
      "grad_norm": 0.4885232448577881,
      "learning_rate": 5.146042296072508e-05,
      "loss": 1.3056,
      "step": 75500
    },
    {
      "epoch": 22.809667673716014,
      "eval_loss": 1.3240846395492554,
      "eval_runtime": 696.6728,
      "eval_samples_per_second": 76.218,
      "eval_steps_per_second": 0.596,
      "step": 75500
    },
    {
      "epoch": 22.82477341389728,
      "grad_norm": 0.43826350569725037,
      "learning_rate": 5.14503524672709e-05,
      "loss": 1.2983,
      "step": 75550
    },
    {
      "epoch": 22.82477341389728,
      "eval_loss": 1.3258641958236694,
      "eval_runtime": 660.9641,
      "eval_samples_per_second": 80.336,
      "eval_steps_per_second": 0.628,
      "step": 75550
    },
    {
      "epoch": 22.83987915407855,
      "grad_norm": 0.4716966450214386,
      "learning_rate": 5.144028197381672e-05,
      "loss": 1.3208,
      "step": 75600
    },
    {
      "epoch": 22.83987915407855,
      "eval_loss": 1.3256374597549438,
      "eval_runtime": 660.7071,
      "eval_samples_per_second": 80.367,
      "eval_steps_per_second": 0.628,
      "step": 75600
    },
    {
      "epoch": 22.854984894259818,
      "grad_norm": 0.49345862865448,
      "learning_rate": 5.143021148036254e-05,
      "loss": 1.3097,
      "step": 75650
    },
    {
      "epoch": 22.854984894259818,
      "eval_loss": 1.3254722356796265,
      "eval_runtime": 681.8174,
      "eval_samples_per_second": 77.879,
      "eval_steps_per_second": 0.609,
      "step": 75650
    },
    {
      "epoch": 22.870090634441087,
      "grad_norm": 0.5022035241127014,
      "learning_rate": 5.142014098690836e-05,
      "loss": 1.3032,
      "step": 75700
    },
    {
      "epoch": 22.870090634441087,
      "eval_loss": 1.3261183500289917,
      "eval_runtime": 624.8328,
      "eval_samples_per_second": 84.981,
      "eval_steps_per_second": 0.664,
      "step": 75700
    },
    {
      "epoch": 22.885196374622357,
      "grad_norm": 0.49293187260627747,
      "learning_rate": 5.1410070493454184e-05,
      "loss": 1.3103,
      "step": 75750
    },
    {
      "epoch": 22.885196374622357,
      "eval_loss": 1.3242281675338745,
      "eval_runtime": 617.4871,
      "eval_samples_per_second": 85.992,
      "eval_steps_per_second": 0.672,
      "step": 75750
    },
    {
      "epoch": 22.900302114803626,
      "grad_norm": 0.438840389251709,
      "learning_rate": 5.14e-05,
      "loss": 1.2928,
      "step": 75800
    },
    {
      "epoch": 22.900302114803626,
      "eval_loss": 1.3260844945907593,
      "eval_runtime": 673.3058,
      "eval_samples_per_second": 78.863,
      "eval_steps_per_second": 0.616,
      "step": 75800
    },
    {
      "epoch": 22.915407854984895,
      "grad_norm": 0.4207996726036072,
      "learning_rate": 5.138992950654582e-05,
      "loss": 1.3047,
      "step": 75850
    },
    {
      "epoch": 22.915407854984895,
      "eval_loss": 1.3236457109451294,
      "eval_runtime": 590.9356,
      "eval_samples_per_second": 89.856,
      "eval_steps_per_second": 0.702,
      "step": 75850
    },
    {
      "epoch": 22.930513595166165,
      "grad_norm": 0.45348355174064636,
      "learning_rate": 5.137985901309165e-05,
      "loss": 1.2997,
      "step": 75900
    },
    {
      "epoch": 22.930513595166165,
      "eval_loss": 1.3270231485366821,
      "eval_runtime": 652.4152,
      "eval_samples_per_second": 81.388,
      "eval_steps_per_second": 0.636,
      "step": 75900
    },
    {
      "epoch": 22.94561933534743,
      "grad_norm": 0.4669288396835327,
      "learning_rate": 5.1369788519637465e-05,
      "loss": 1.2958,
      "step": 75950
    },
    {
      "epoch": 22.94561933534743,
      "eval_loss": 1.3234210014343262,
      "eval_runtime": 653.6729,
      "eval_samples_per_second": 81.232,
      "eval_steps_per_second": 0.635,
      "step": 75950
    },
    {
      "epoch": 22.9607250755287,
      "grad_norm": 0.47137030959129333,
      "learning_rate": 5.1359718026183284e-05,
      "loss": 1.2832,
      "step": 76000
    },
    {
      "epoch": 22.9607250755287,
      "eval_loss": 1.3233308792114258,
      "eval_runtime": 666.0252,
      "eval_samples_per_second": 79.725,
      "eval_steps_per_second": 0.623,
      "step": 76000
    },
    {
      "epoch": 22.97583081570997,
      "grad_norm": 0.5051595568656921,
      "learning_rate": 5.13496475327291e-05,
      "loss": 1.3196,
      "step": 76050
    },
    {
      "epoch": 22.97583081570997,
      "eval_loss": 1.3256700038909912,
      "eval_runtime": 638.6283,
      "eval_samples_per_second": 83.145,
      "eval_steps_per_second": 0.65,
      "step": 76050
    },
    {
      "epoch": 22.99093655589124,
      "grad_norm": 0.448812872171402,
      "learning_rate": 5.133957703927493e-05,
      "loss": 1.3197,
      "step": 76100
    },
    {
      "epoch": 22.99093655589124,
      "eval_loss": 1.3225793838500977,
      "eval_runtime": 631.8621,
      "eval_samples_per_second": 84.036,
      "eval_steps_per_second": 0.657,
      "step": 76100
    },
    {
      "epoch": 23.006042296072508,
      "grad_norm": 0.4812786877155304,
      "learning_rate": 5.132950654582075e-05,
      "loss": 1.3338,
      "step": 76150
    },
    {
      "epoch": 23.006042296072508,
      "eval_loss": 1.3222708702087402,
      "eval_runtime": 698.0477,
      "eval_samples_per_second": 76.068,
      "eval_steps_per_second": 0.595,
      "step": 76150
    },
    {
      "epoch": 23.021148036253777,
      "grad_norm": 0.46467363834381104,
      "learning_rate": 5.1319436052366566e-05,
      "loss": 1.2924,
      "step": 76200
    },
    {
      "epoch": 23.021148036253777,
      "eval_loss": 1.3236973285675049,
      "eval_runtime": 722.2777,
      "eval_samples_per_second": 73.516,
      "eval_steps_per_second": 0.575,
      "step": 76200
    },
    {
      "epoch": 23.036253776435046,
      "grad_norm": 0.5262475609779358,
      "learning_rate": 5.1309365558912384e-05,
      "loss": 1.2773,
      "step": 76250
    },
    {
      "epoch": 23.036253776435046,
      "eval_loss": 1.3251217603683472,
      "eval_runtime": 621.921,
      "eval_samples_per_second": 85.379,
      "eval_steps_per_second": 0.667,
      "step": 76250
    },
    {
      "epoch": 23.051359516616316,
      "grad_norm": 0.4998931586742401,
      "learning_rate": 5.129929506545821e-05,
      "loss": 1.3038,
      "step": 76300
    },
    {
      "epoch": 23.051359516616316,
      "eval_loss": 1.3241935968399048,
      "eval_runtime": 682.5812,
      "eval_samples_per_second": 77.791,
      "eval_steps_per_second": 0.608,
      "step": 76300
    },
    {
      "epoch": 23.06646525679758,
      "grad_norm": 0.47088590264320374,
      "learning_rate": 5.128922457200403e-05,
      "loss": 1.2917,
      "step": 76350
    },
    {
      "epoch": 23.06646525679758,
      "eval_loss": 1.3252971172332764,
      "eval_runtime": 705.1058,
      "eval_samples_per_second": 75.306,
      "eval_steps_per_second": 0.589,
      "step": 76350
    },
    {
      "epoch": 23.08157099697885,
      "grad_norm": 0.47348058223724365,
      "learning_rate": 5.127915407854985e-05,
      "loss": 1.2923,
      "step": 76400
    },
    {
      "epoch": 23.08157099697885,
      "eval_loss": 1.3259857892990112,
      "eval_runtime": 659.9753,
      "eval_samples_per_second": 80.456,
      "eval_steps_per_second": 0.629,
      "step": 76400
    },
    {
      "epoch": 23.09667673716012,
      "grad_norm": 0.48211151361465454,
      "learning_rate": 5.1269083585095666e-05,
      "loss": 1.2911,
      "step": 76450
    },
    {
      "epoch": 23.09667673716012,
      "eval_loss": 1.3243201971054077,
      "eval_runtime": 650.0717,
      "eval_samples_per_second": 81.682,
      "eval_steps_per_second": 0.638,
      "step": 76450
    },
    {
      "epoch": 23.11178247734139,
      "grad_norm": 0.47672712802886963,
      "learning_rate": 5.125901309164149e-05,
      "loss": 1.275,
      "step": 76500
    },
    {
      "epoch": 23.11178247734139,
      "eval_loss": 1.3226127624511719,
      "eval_runtime": 680.9921,
      "eval_samples_per_second": 77.973,
      "eval_steps_per_second": 0.609,
      "step": 76500
    },
    {
      "epoch": 23.12688821752266,
      "grad_norm": 0.4751252233982086,
      "learning_rate": 5.124894259818731e-05,
      "loss": 1.3054,
      "step": 76550
    },
    {
      "epoch": 23.12688821752266,
      "eval_loss": 1.3240810632705688,
      "eval_runtime": 639.8121,
      "eval_samples_per_second": 82.992,
      "eval_steps_per_second": 0.649,
      "step": 76550
    },
    {
      "epoch": 23.141993957703928,
      "grad_norm": 0.44598305225372314,
      "learning_rate": 5.1238872104733135e-05,
      "loss": 1.305,
      "step": 76600
    },
    {
      "epoch": 23.141993957703928,
      "eval_loss": 1.3228569030761719,
      "eval_runtime": 604.9335,
      "eval_samples_per_second": 87.777,
      "eval_steps_per_second": 0.686,
      "step": 76600
    },
    {
      "epoch": 23.157099697885197,
      "grad_norm": 0.4484333395957947,
      "learning_rate": 5.1228801611278954e-05,
      "loss": 1.2881,
      "step": 76650
    },
    {
      "epoch": 23.157099697885197,
      "eval_loss": 1.3221611976623535,
      "eval_runtime": 654.6355,
      "eval_samples_per_second": 81.112,
      "eval_steps_per_second": 0.634,
      "step": 76650
    },
    {
      "epoch": 23.172205438066467,
      "grad_norm": 0.44977667927742004,
      "learning_rate": 5.121873111782478e-05,
      "loss": 1.303,
      "step": 76700
    },
    {
      "epoch": 23.172205438066467,
      "eval_loss": 1.322318434715271,
      "eval_runtime": 692.4057,
      "eval_samples_per_second": 76.688,
      "eval_steps_per_second": 0.599,
      "step": 76700
    },
    {
      "epoch": 23.187311178247732,
      "grad_norm": 0.4865100681781769,
      "learning_rate": 5.12086606243706e-05,
      "loss": 1.2949,
      "step": 76750
    },
    {
      "epoch": 23.187311178247732,
      "eval_loss": 1.3220089673995972,
      "eval_runtime": 619.4291,
      "eval_samples_per_second": 85.722,
      "eval_steps_per_second": 0.67,
      "step": 76750
    },
    {
      "epoch": 23.202416918429,
      "grad_norm": 0.4735824167728424,
      "learning_rate": 5.119859013091642e-05,
      "loss": 1.3107,
      "step": 76800
    },
    {
      "epoch": 23.202416918429,
      "eval_loss": 1.3226908445358276,
      "eval_runtime": 714.1646,
      "eval_samples_per_second": 74.351,
      "eval_steps_per_second": 0.581,
      "step": 76800
    },
    {
      "epoch": 23.21752265861027,
      "grad_norm": 0.49576738476753235,
      "learning_rate": 5.1188519637462236e-05,
      "loss": 1.3031,
      "step": 76850
    },
    {
      "epoch": 23.21752265861027,
      "eval_loss": 1.3242138624191284,
      "eval_runtime": 641.7085,
      "eval_samples_per_second": 82.746,
      "eval_steps_per_second": 0.647,
      "step": 76850
    },
    {
      "epoch": 23.23262839879154,
      "grad_norm": 0.5757403373718262,
      "learning_rate": 5.117844914400806e-05,
      "loss": 1.2886,
      "step": 76900
    },
    {
      "epoch": 23.23262839879154,
      "eval_loss": 1.323931336402893,
      "eval_runtime": 601.7875,
      "eval_samples_per_second": 88.235,
      "eval_steps_per_second": 0.69,
      "step": 76900
    },
    {
      "epoch": 23.24773413897281,
      "grad_norm": 0.44769102334976196,
      "learning_rate": 5.116837865055388e-05,
      "loss": 1.3259,
      "step": 76950
    },
    {
      "epoch": 23.24773413897281,
      "eval_loss": 1.3239816427230835,
      "eval_runtime": 647.6258,
      "eval_samples_per_second": 81.99,
      "eval_steps_per_second": 0.641,
      "step": 76950
    },
    {
      "epoch": 23.26283987915408,
      "grad_norm": 0.4597405195236206,
      "learning_rate": 5.11583081570997e-05,
      "loss": 1.2993,
      "step": 77000
    },
    {
      "epoch": 23.26283987915408,
      "eval_loss": 1.322810411453247,
      "eval_runtime": 688.366,
      "eval_samples_per_second": 77.138,
      "eval_steps_per_second": 0.603,
      "step": 77000
    },
    {
      "epoch": 23.27794561933535,
      "grad_norm": 0.4707021415233612,
      "learning_rate": 5.1148237663645524e-05,
      "loss": 1.3242,
      "step": 77050
    },
    {
      "epoch": 23.27794561933535,
      "eval_loss": 1.321181058883667,
      "eval_runtime": 634.9952,
      "eval_samples_per_second": 83.621,
      "eval_steps_per_second": 0.654,
      "step": 77050
    },
    {
      "epoch": 23.293051359516618,
      "grad_norm": 0.4494839012622833,
      "learning_rate": 5.113816717019134e-05,
      "loss": 1.2975,
      "step": 77100
    },
    {
      "epoch": 23.293051359516618,
      "eval_loss": 1.3210328817367554,
      "eval_runtime": 708.5837,
      "eval_samples_per_second": 74.937,
      "eval_steps_per_second": 0.586,
      "step": 77100
    },
    {
      "epoch": 23.308157099697887,
      "grad_norm": 0.45768675208091736,
      "learning_rate": 5.112809667673716e-05,
      "loss": 1.3022,
      "step": 77150
    },
    {
      "epoch": 23.308157099697887,
      "eval_loss": 1.3212809562683105,
      "eval_runtime": 707.364,
      "eval_samples_per_second": 75.066,
      "eval_steps_per_second": 0.587,
      "step": 77150
    },
    {
      "epoch": 23.323262839879153,
      "grad_norm": 0.4921998977661133,
      "learning_rate": 5.111802618328298e-05,
      "loss": 1.3016,
      "step": 77200
    },
    {
      "epoch": 23.323262839879153,
      "eval_loss": 1.32323157787323,
      "eval_runtime": 686.6724,
      "eval_samples_per_second": 77.328,
      "eval_steps_per_second": 0.604,
      "step": 77200
    },
    {
      "epoch": 23.338368580060422,
      "grad_norm": 0.46370598673820496,
      "learning_rate": 5.1107955689828805e-05,
      "loss": 1.3095,
      "step": 77250
    },
    {
      "epoch": 23.338368580060422,
      "eval_loss": 1.3226746320724487,
      "eval_runtime": 708.3161,
      "eval_samples_per_second": 74.965,
      "eval_steps_per_second": 0.586,
      "step": 77250
    },
    {
      "epoch": 23.35347432024169,
      "grad_norm": 0.454009085893631,
      "learning_rate": 5.1097885196374624e-05,
      "loss": 1.3022,
      "step": 77300
    },
    {
      "epoch": 23.35347432024169,
      "eval_loss": 1.3234949111938477,
      "eval_runtime": 631.4134,
      "eval_samples_per_second": 84.095,
      "eval_steps_per_second": 0.657,
      "step": 77300
    },
    {
      "epoch": 23.36858006042296,
      "grad_norm": 0.5646958947181702,
      "learning_rate": 5.108781470292044e-05,
      "loss": 1.2912,
      "step": 77350
    },
    {
      "epoch": 23.36858006042296,
      "eval_loss": 1.320969581604004,
      "eval_runtime": 582.4873,
      "eval_samples_per_second": 91.159,
      "eval_steps_per_second": 0.712,
      "step": 77350
    },
    {
      "epoch": 23.38368580060423,
      "grad_norm": 0.4823387563228607,
      "learning_rate": 5.107774420946626e-05,
      "loss": 1.3043,
      "step": 77400
    },
    {
      "epoch": 23.38368580060423,
      "eval_loss": 1.3218400478363037,
      "eval_runtime": 686.6701,
      "eval_samples_per_second": 77.328,
      "eval_steps_per_second": 0.604,
      "step": 77400
    },
    {
      "epoch": 23.3987915407855,
      "grad_norm": 0.491439551115036,
      "learning_rate": 5.106767371601209e-05,
      "loss": 1.3077,
      "step": 77450
    },
    {
      "epoch": 23.3987915407855,
      "eval_loss": 1.3206816911697388,
      "eval_runtime": 688.5086,
      "eval_samples_per_second": 77.122,
      "eval_steps_per_second": 0.603,
      "step": 77450
    },
    {
      "epoch": 23.41389728096677,
      "grad_norm": 0.4707512855529785,
      "learning_rate": 5.1057603222557906e-05,
      "loss": 1.3042,
      "step": 77500
    },
    {
      "epoch": 23.41389728096677,
      "eval_loss": 1.3219181299209595,
      "eval_runtime": 605.167,
      "eval_samples_per_second": 87.743,
      "eval_steps_per_second": 0.686,
      "step": 77500
    },
    {
      "epoch": 23.429003021148038,
      "grad_norm": 0.49153783917427063,
      "learning_rate": 5.1047532729103724e-05,
      "loss": 1.2701,
      "step": 77550
    },
    {
      "epoch": 23.429003021148038,
      "eval_loss": 1.322061538696289,
      "eval_runtime": 685.1193,
      "eval_samples_per_second": 77.503,
      "eval_steps_per_second": 0.606,
      "step": 77550
    },
    {
      "epoch": 23.444108761329304,
      "grad_norm": 0.45888519287109375,
      "learning_rate": 5.103746223564954e-05,
      "loss": 1.2904,
      "step": 77600
    },
    {
      "epoch": 23.444108761329304,
      "eval_loss": 1.32462477684021,
      "eval_runtime": 725.2625,
      "eval_samples_per_second": 73.213,
      "eval_steps_per_second": 0.572,
      "step": 77600
    },
    {
      "epoch": 23.459214501510573,
      "grad_norm": 0.4536736011505127,
      "learning_rate": 5.102739174219537e-05,
      "loss": 1.3094,
      "step": 77650
    },
    {
      "epoch": 23.459214501510573,
      "eval_loss": 1.3214356899261475,
      "eval_runtime": 702.1575,
      "eval_samples_per_second": 75.623,
      "eval_steps_per_second": 0.591,
      "step": 77650
    },
    {
      "epoch": 23.474320241691842,
      "grad_norm": 0.4855307340621948,
      "learning_rate": 5.101732124874119e-05,
      "loss": 1.2991,
      "step": 77700
    },
    {
      "epoch": 23.474320241691842,
      "eval_loss": 1.320752739906311,
      "eval_runtime": 660.229,
      "eval_samples_per_second": 80.425,
      "eval_steps_per_second": 0.629,
      "step": 77700
    },
    {
      "epoch": 23.48942598187311,
      "grad_norm": 0.5147095918655396,
      "learning_rate": 5.1007250755287006e-05,
      "loss": 1.3091,
      "step": 77750
    },
    {
      "epoch": 23.48942598187311,
      "eval_loss": 1.3230079412460327,
      "eval_runtime": 621.748,
      "eval_samples_per_second": 85.403,
      "eval_steps_per_second": 0.667,
      "step": 77750
    },
    {
      "epoch": 23.50453172205438,
      "grad_norm": 0.455531507730484,
      "learning_rate": 5.099718026183283e-05,
      "loss": 1.3033,
      "step": 77800
    },
    {
      "epoch": 23.50453172205438,
      "eval_loss": 1.3229597806930542,
      "eval_runtime": 638.9246,
      "eval_samples_per_second": 83.107,
      "eval_steps_per_second": 0.65,
      "step": 77800
    },
    {
      "epoch": 23.51963746223565,
      "grad_norm": 0.5131495594978333,
      "learning_rate": 5.098710976837866e-05,
      "loss": 1.2973,
      "step": 77850
    },
    {
      "epoch": 23.51963746223565,
      "eval_loss": 1.3202828168869019,
      "eval_runtime": 641.5176,
      "eval_samples_per_second": 82.771,
      "eval_steps_per_second": 0.647,
      "step": 77850
    },
    {
      "epoch": 23.53474320241692,
      "grad_norm": 0.5185180306434631,
      "learning_rate": 5.0977039274924475e-05,
      "loss": 1.2924,
      "step": 77900
    },
    {
      "epoch": 23.53474320241692,
      "eval_loss": 1.325735330581665,
      "eval_runtime": 590.814,
      "eval_samples_per_second": 89.874,
      "eval_steps_per_second": 0.702,
      "step": 77900
    },
    {
      "epoch": 23.54984894259819,
      "grad_norm": 0.4584827125072479,
      "learning_rate": 5.0966968781470294e-05,
      "loss": 1.3133,
      "step": 77950
    },
    {
      "epoch": 23.54984894259819,
      "eval_loss": 1.3236507177352905,
      "eval_runtime": 697.4116,
      "eval_samples_per_second": 76.137,
      "eval_steps_per_second": 0.595,
      "step": 77950
    },
    {
      "epoch": 23.564954682779454,
      "grad_norm": 0.5037592649459839,
      "learning_rate": 5.095689828801611e-05,
      "loss": 1.3097,
      "step": 78000
    },
    {
      "epoch": 23.564954682779454,
      "eval_loss": 1.320296287536621,
      "eval_runtime": 685.7156,
      "eval_samples_per_second": 77.436,
      "eval_steps_per_second": 0.605,
      "step": 78000
    },
    {
      "epoch": 23.580060422960724,
      "grad_norm": 0.4606115520000458,
      "learning_rate": 5.094682779456194e-05,
      "loss": 1.2861,
      "step": 78050
    },
    {
      "epoch": 23.580060422960724,
      "eval_loss": 1.3232133388519287,
      "eval_runtime": 625.5277,
      "eval_samples_per_second": 84.887,
      "eval_steps_per_second": 0.663,
      "step": 78050
    },
    {
      "epoch": 23.595166163141993,
      "grad_norm": 0.4576776921749115,
      "learning_rate": 5.093675730110776e-05,
      "loss": 1.2757,
      "step": 78100
    },
    {
      "epoch": 23.595166163141993,
      "eval_loss": 1.3202048540115356,
      "eval_runtime": 683.7401,
      "eval_samples_per_second": 77.66,
      "eval_steps_per_second": 0.607,
      "step": 78100
    },
    {
      "epoch": 23.610271903323262,
      "grad_norm": 0.4754238426685333,
      "learning_rate": 5.0926686807653576e-05,
      "loss": 1.2952,
      "step": 78150
    },
    {
      "epoch": 23.610271903323262,
      "eval_loss": 1.3188227415084839,
      "eval_runtime": 662.6636,
      "eval_samples_per_second": 80.13,
      "eval_steps_per_second": 0.626,
      "step": 78150
    },
    {
      "epoch": 23.62537764350453,
      "grad_norm": 0.4963493347167969,
      "learning_rate": 5.09166163141994e-05,
      "loss": 1.3035,
      "step": 78200
    },
    {
      "epoch": 23.62537764350453,
      "eval_loss": 1.3215867280960083,
      "eval_runtime": 737.0194,
      "eval_samples_per_second": 72.046,
      "eval_steps_per_second": 0.563,
      "step": 78200
    },
    {
      "epoch": 23.6404833836858,
      "grad_norm": 0.462895005941391,
      "learning_rate": 5.090654582074522e-05,
      "loss": 1.2966,
      "step": 78250
    },
    {
      "epoch": 23.6404833836858,
      "eval_loss": 1.320940375328064,
      "eval_runtime": 700.6366,
      "eval_samples_per_second": 75.787,
      "eval_steps_per_second": 0.592,
      "step": 78250
    },
    {
      "epoch": 23.65558912386707,
      "grad_norm": 0.5095271468162537,
      "learning_rate": 5.089647532729104e-05,
      "loss": 1.2899,
      "step": 78300
    },
    {
      "epoch": 23.65558912386707,
      "eval_loss": 1.3193656206130981,
      "eval_runtime": 696.1994,
      "eval_samples_per_second": 76.27,
      "eval_steps_per_second": 0.596,
      "step": 78300
    },
    {
      "epoch": 23.67069486404834,
      "grad_norm": 0.47921326756477356,
      "learning_rate": 5.088640483383686e-05,
      "loss": 1.3168,
      "step": 78350
    },
    {
      "epoch": 23.67069486404834,
      "eval_loss": 1.3222949504852295,
      "eval_runtime": 707.357,
      "eval_samples_per_second": 75.067,
      "eval_steps_per_second": 0.587,
      "step": 78350
    },
    {
      "epoch": 23.685800604229605,
      "grad_norm": 0.45527416467666626,
      "learning_rate": 5.087633434038268e-05,
      "loss": 1.2965,
      "step": 78400
    },
    {
      "epoch": 23.685800604229605,
      "eval_loss": 1.32377028465271,
      "eval_runtime": 717.6773,
      "eval_samples_per_second": 73.987,
      "eval_steps_per_second": 0.578,
      "step": 78400
    },
    {
      "epoch": 23.700906344410875,
      "grad_norm": 0.5029861330986023,
      "learning_rate": 5.08662638469285e-05,
      "loss": 1.3033,
      "step": 78450
    },
    {
      "epoch": 23.700906344410875,
      "eval_loss": 1.3222928047180176,
      "eval_runtime": 678.0578,
      "eval_samples_per_second": 78.31,
      "eval_steps_per_second": 0.612,
      "step": 78450
    },
    {
      "epoch": 23.716012084592144,
      "grad_norm": 0.4411560893058777,
      "learning_rate": 5.085619335347432e-05,
      "loss": 1.3085,
      "step": 78500
    },
    {
      "epoch": 23.716012084592144,
      "eval_loss": 1.320381760597229,
      "eval_runtime": 694.043,
      "eval_samples_per_second": 76.507,
      "eval_steps_per_second": 0.598,
      "step": 78500
    },
    {
      "epoch": 23.731117824773413,
      "grad_norm": 0.4652499556541443,
      "learning_rate": 5.084612286002014e-05,
      "loss": 1.2914,
      "step": 78550
    },
    {
      "epoch": 23.731117824773413,
      "eval_loss": 1.319119930267334,
      "eval_runtime": 597.2732,
      "eval_samples_per_second": 88.902,
      "eval_steps_per_second": 0.695,
      "step": 78550
    },
    {
      "epoch": 23.746223564954683,
      "grad_norm": 0.4461818337440491,
      "learning_rate": 5.0836052366565964e-05,
      "loss": 1.2979,
      "step": 78600
    },
    {
      "epoch": 23.746223564954683,
      "eval_loss": 1.3213355541229248,
      "eval_runtime": 691.4829,
      "eval_samples_per_second": 76.79,
      "eval_steps_per_second": 0.6,
      "step": 78600
    },
    {
      "epoch": 23.761329305135952,
      "grad_norm": 0.44963181018829346,
      "learning_rate": 5.082598187311178e-05,
      "loss": 1.278,
      "step": 78650
    },
    {
      "epoch": 23.761329305135952,
      "eval_loss": 1.3218101263046265,
      "eval_runtime": 662.557,
      "eval_samples_per_second": 80.143,
      "eval_steps_per_second": 0.626,
      "step": 78650
    },
    {
      "epoch": 23.77643504531722,
      "grad_norm": 0.5198168158531189,
      "learning_rate": 5.08159113796576e-05,
      "loss": 1.2951,
      "step": 78700
    },
    {
      "epoch": 23.77643504531722,
      "eval_loss": 1.319228172302246,
      "eval_runtime": 636.6908,
      "eval_samples_per_second": 83.398,
      "eval_steps_per_second": 0.652,
      "step": 78700
    },
    {
      "epoch": 23.79154078549849,
      "grad_norm": 0.4362088143825531,
      "learning_rate": 5.080584088620342e-05,
      "loss": 1.3083,
      "step": 78750
    },
    {
      "epoch": 23.79154078549849,
      "eval_loss": 1.3186372518539429,
      "eval_runtime": 622.5692,
      "eval_samples_per_second": 85.29,
      "eval_steps_per_second": 0.667,
      "step": 78750
    },
    {
      "epoch": 23.80664652567976,
      "grad_norm": 0.4911155104637146,
      "learning_rate": 5.0795770392749246e-05,
      "loss": 1.2901,
      "step": 78800
    },
    {
      "epoch": 23.80664652567976,
      "eval_loss": 1.319109320640564,
      "eval_runtime": 643.9308,
      "eval_samples_per_second": 82.461,
      "eval_steps_per_second": 0.644,
      "step": 78800
    },
    {
      "epoch": 23.821752265861026,
      "grad_norm": 0.4449115991592407,
      "learning_rate": 5.0785699899295064e-05,
      "loss": 1.2896,
      "step": 78850
    },
    {
      "epoch": 23.821752265861026,
      "eval_loss": 1.320016860961914,
      "eval_runtime": 680.9626,
      "eval_samples_per_second": 77.976,
      "eval_steps_per_second": 0.609,
      "step": 78850
    },
    {
      "epoch": 23.836858006042295,
      "grad_norm": 0.4880158603191376,
      "learning_rate": 5.077562940584088e-05,
      "loss": 1.2957,
      "step": 78900
    },
    {
      "epoch": 23.836858006042295,
      "eval_loss": 1.3208750486373901,
      "eval_runtime": 673.2733,
      "eval_samples_per_second": 78.867,
      "eval_steps_per_second": 0.616,
      "step": 78900
    },
    {
      "epoch": 23.851963746223564,
      "grad_norm": 0.46312621235847473,
      "learning_rate": 5.076555891238671e-05,
      "loss": 1.3009,
      "step": 78950
    },
    {
      "epoch": 23.851963746223564,
      "eval_loss": 1.3194327354431152,
      "eval_runtime": 616.1142,
      "eval_samples_per_second": 86.184,
      "eval_steps_per_second": 0.674,
      "step": 78950
    },
    {
      "epoch": 23.867069486404834,
      "grad_norm": 0.46600285172462463,
      "learning_rate": 5.0755488418932534e-05,
      "loss": 1.2959,
      "step": 79000
    },
    {
      "epoch": 23.867069486404834,
      "eval_loss": 1.3201475143432617,
      "eval_runtime": 664.3232,
      "eval_samples_per_second": 79.929,
      "eval_steps_per_second": 0.625,
      "step": 79000
    },
    {
      "epoch": 23.882175226586103,
      "grad_norm": 0.46873989701271057,
      "learning_rate": 5.074541792547835e-05,
      "loss": 1.2884,
      "step": 79050
    },
    {
      "epoch": 23.882175226586103,
      "eval_loss": 1.3189585208892822,
      "eval_runtime": 644.2513,
      "eval_samples_per_second": 82.42,
      "eval_steps_per_second": 0.644,
      "step": 79050
    },
    {
      "epoch": 23.897280966767372,
      "grad_norm": 0.4821217358112335,
      "learning_rate": 5.073534743202417e-05,
      "loss": 1.2839,
      "step": 79100
    },
    {
      "epoch": 23.897280966767372,
      "eval_loss": 1.3215409517288208,
      "eval_runtime": 722.5311,
      "eval_samples_per_second": 73.49,
      "eval_steps_per_second": 0.574,
      "step": 79100
    },
    {
      "epoch": 23.91238670694864,
      "grad_norm": 0.4544333219528198,
      "learning_rate": 5.072527693856999e-05,
      "loss": 1.2826,
      "step": 79150
    },
    {
      "epoch": 23.91238670694864,
      "eval_loss": 1.3196732997894287,
      "eval_runtime": 675.4983,
      "eval_samples_per_second": 78.607,
      "eval_steps_per_second": 0.614,
      "step": 79150
    },
    {
      "epoch": 23.92749244712991,
      "grad_norm": 0.5569714307785034,
      "learning_rate": 5.0715206445115815e-05,
      "loss": 1.3101,
      "step": 79200
    },
    {
      "epoch": 23.92749244712991,
      "eval_loss": 1.3199095726013184,
      "eval_runtime": 619.2589,
      "eval_samples_per_second": 85.746,
      "eval_steps_per_second": 0.67,
      "step": 79200
    },
    {
      "epoch": 23.942598187311177,
      "grad_norm": 0.481186181306839,
      "learning_rate": 5.0705135951661634e-05,
      "loss": 1.2987,
      "step": 79250
    },
    {
      "epoch": 23.942598187311177,
      "eval_loss": 1.319998025894165,
      "eval_runtime": 613.8251,
      "eval_samples_per_second": 86.505,
      "eval_steps_per_second": 0.676,
      "step": 79250
    },
    {
      "epoch": 23.957703927492446,
      "grad_norm": 0.4349258244037628,
      "learning_rate": 5.069506545820745e-05,
      "loss": 1.2928,
      "step": 79300
    },
    {
      "epoch": 23.957703927492446,
      "eval_loss": 1.3191404342651367,
      "eval_runtime": 629.7697,
      "eval_samples_per_second": 84.315,
      "eval_steps_per_second": 0.659,
      "step": 79300
    },
    {
      "epoch": 23.972809667673715,
      "grad_norm": 0.4971243441104889,
      "learning_rate": 5.068499496475328e-05,
      "loss": 1.2974,
      "step": 79350
    },
    {
      "epoch": 23.972809667673715,
      "eval_loss": 1.319016456604004,
      "eval_runtime": 721.0768,
      "eval_samples_per_second": 73.638,
      "eval_steps_per_second": 0.576,
      "step": 79350
    },
    {
      "epoch": 23.987915407854985,
      "grad_norm": 0.5118904709815979,
      "learning_rate": 5.06749244712991e-05,
      "loss": 1.2962,
      "step": 79400
    },
    {
      "epoch": 23.987915407854985,
      "eval_loss": 1.3215246200561523,
      "eval_runtime": 680.5054,
      "eval_samples_per_second": 78.029,
      "eval_steps_per_second": 0.61,
      "step": 79400
    },
    {
      "epoch": 24.003021148036254,
      "grad_norm": 0.4885879158973694,
      "learning_rate": 5.0664853977844916e-05,
      "loss": 1.2756,
      "step": 79450
    },
    {
      "epoch": 24.003021148036254,
      "eval_loss": 1.3162533044815063,
      "eval_runtime": 777.4387,
      "eval_samples_per_second": 68.3,
      "eval_steps_per_second": 0.534,
      "step": 79450
    },
    {
      "epoch": 24.018126888217523,
      "grad_norm": 0.4507521092891693,
      "learning_rate": 5.0654783484390734e-05,
      "loss": 1.2846,
      "step": 79500
    },
    {
      "epoch": 24.018126888217523,
      "eval_loss": 1.3172569274902344,
      "eval_runtime": 652.8342,
      "eval_samples_per_second": 81.336,
      "eval_steps_per_second": 0.636,
      "step": 79500
    },
    {
      "epoch": 24.033232628398792,
      "grad_norm": 0.44549766182899475,
      "learning_rate": 5.064471299093656e-05,
      "loss": 1.2834,
      "step": 79550
    },
    {
      "epoch": 24.033232628398792,
      "eval_loss": 1.3205549716949463,
      "eval_runtime": 784.6622,
      "eval_samples_per_second": 67.671,
      "eval_steps_per_second": 0.529,
      "step": 79550
    },
    {
      "epoch": 24.048338368580062,
      "grad_norm": 0.49831998348236084,
      "learning_rate": 5.063464249748238e-05,
      "loss": 1.3228,
      "step": 79600
    },
    {
      "epoch": 24.048338368580062,
      "eval_loss": 1.319702386856079,
      "eval_runtime": 648.5273,
      "eval_samples_per_second": 81.876,
      "eval_steps_per_second": 0.64,
      "step": 79600
    },
    {
      "epoch": 24.063444108761328,
      "grad_norm": 0.4545353949069977,
      "learning_rate": 5.06245720040282e-05,
      "loss": 1.2772,
      "step": 79650
    },
    {
      "epoch": 24.063444108761328,
      "eval_loss": 1.3195327520370483,
      "eval_runtime": 683.2817,
      "eval_samples_per_second": 77.712,
      "eval_steps_per_second": 0.607,
      "step": 79650
    },
    {
      "epoch": 24.078549848942597,
      "grad_norm": 0.4200775921344757,
      "learning_rate": 5.0614501510574016e-05,
      "loss": 1.2818,
      "step": 79700
    },
    {
      "epoch": 24.078549848942597,
      "eval_loss": 1.3191810846328735,
      "eval_runtime": 672.539,
      "eval_samples_per_second": 78.953,
      "eval_steps_per_second": 0.617,
      "step": 79700
    },
    {
      "epoch": 24.093655589123866,
      "grad_norm": 0.48869389295578003,
      "learning_rate": 5.060443101711984e-05,
      "loss": 1.2949,
      "step": 79750
    },
    {
      "epoch": 24.093655589123866,
      "eval_loss": 1.3203822374343872,
      "eval_runtime": 631.2748,
      "eval_samples_per_second": 84.114,
      "eval_steps_per_second": 0.657,
      "step": 79750
    },
    {
      "epoch": 24.108761329305135,
      "grad_norm": 0.4511779248714447,
      "learning_rate": 5.059436052366566e-05,
      "loss": 1.2922,
      "step": 79800
    },
    {
      "epoch": 24.108761329305135,
      "eval_loss": 1.3204365968704224,
      "eval_runtime": 793.2787,
      "eval_samples_per_second": 66.936,
      "eval_steps_per_second": 0.523,
      "step": 79800
    },
    {
      "epoch": 24.123867069486405,
      "grad_norm": 0.6274930834770203,
      "learning_rate": 5.058429003021148e-05,
      "loss": 1.2941,
      "step": 79850
    },
    {
      "epoch": 24.123867069486405,
      "eval_loss": 1.317695140838623,
      "eval_runtime": 706.5652,
      "eval_samples_per_second": 75.151,
      "eval_steps_per_second": 0.587,
      "step": 79850
    },
    {
      "epoch": 24.138972809667674,
      "grad_norm": 0.49166637659072876,
      "learning_rate": 5.05742195367573e-05,
      "loss": 1.3014,
      "step": 79900
    },
    {
      "epoch": 24.138972809667674,
      "eval_loss": 1.3202747106552124,
      "eval_runtime": 673.6094,
      "eval_samples_per_second": 78.828,
      "eval_steps_per_second": 0.616,
      "step": 79900
    },
    {
      "epoch": 24.154078549848943,
      "grad_norm": 0.4863227605819702,
      "learning_rate": 5.056414904330312e-05,
      "loss": 1.2917,
      "step": 79950
    },
    {
      "epoch": 24.154078549848943,
      "eval_loss": 1.3188449144363403,
      "eval_runtime": 651.5184,
      "eval_samples_per_second": 81.5,
      "eval_steps_per_second": 0.637,
      "step": 79950
    },
    {
      "epoch": 24.169184290030213,
      "grad_norm": 0.5179951786994934,
      "learning_rate": 5.055407854984894e-05,
      "loss": 1.292,
      "step": 80000
    },
    {
      "epoch": 24.169184290030213,
      "eval_loss": 1.321439504623413,
      "eval_runtime": 801.084,
      "eval_samples_per_second": 66.284,
      "eval_steps_per_second": 0.518,
      "step": 80000
    },
    {
      "epoch": 24.184290030211482,
      "grad_norm": 0.512138843536377,
      "learning_rate": 5.054400805639476e-05,
      "loss": 1.3127,
      "step": 80050
    },
    {
      "epoch": 24.184290030211482,
      "eval_loss": 1.3171507120132446,
      "eval_runtime": 615.9069,
      "eval_samples_per_second": 86.213,
      "eval_steps_per_second": 0.674,
      "step": 80050
    },
    {
      "epoch": 24.199395770392748,
      "grad_norm": 0.48713958263397217,
      "learning_rate": 5.0533937562940586e-05,
      "loss": 1.286,
      "step": 80100
    },
    {
      "epoch": 24.199395770392748,
      "eval_loss": 1.3160585165023804,
      "eval_runtime": 1238.387,
      "eval_samples_per_second": 42.878,
      "eval_steps_per_second": 0.335,
      "step": 80100
    },
    {
      "epoch": 24.214501510574017,
      "grad_norm": 0.5036013126373291,
      "learning_rate": 5.052386706948641e-05,
      "loss": 1.2955,
      "step": 80150
    },
    {
      "epoch": 24.214501510574017,
      "eval_loss": 1.3174206018447876,
      "eval_runtime": 637.9844,
      "eval_samples_per_second": 83.229,
      "eval_steps_per_second": 0.65,
      "step": 80150
    },
    {
      "epoch": 24.229607250755286,
      "grad_norm": 0.4584927260875702,
      "learning_rate": 5.051379657603223e-05,
      "loss": 1.3168,
      "step": 80200
    },
    {
      "epoch": 24.229607250755286,
      "eval_loss": 1.3198424577713013,
      "eval_runtime": 614.7758,
      "eval_samples_per_second": 86.371,
      "eval_steps_per_second": 0.675,
      "step": 80200
    },
    {
      "epoch": 24.244712990936556,
      "grad_norm": 0.500064492225647,
      "learning_rate": 5.050372608257805e-05,
      "loss": 1.2681,
      "step": 80250
    },
    {
      "epoch": 24.244712990936556,
      "eval_loss": 1.3167650699615479,
      "eval_runtime": 884.0863,
      "eval_samples_per_second": 60.061,
      "eval_steps_per_second": 0.469,
      "step": 80250
    },
    {
      "epoch": 24.259818731117825,
      "grad_norm": 0.4618469774723053,
      "learning_rate": 5.049365558912387e-05,
      "loss": 1.2786,
      "step": 80300
    },
    {
      "epoch": 24.259818731117825,
      "eval_loss": 1.3192256689071655,
      "eval_runtime": 641.4553,
      "eval_samples_per_second": 82.779,
      "eval_steps_per_second": 0.647,
      "step": 80300
    },
    {
      "epoch": 24.274924471299094,
      "grad_norm": 0.5129987001419067,
      "learning_rate": 5.048358509566969e-05,
      "loss": 1.295,
      "step": 80350
    },
    {
      "epoch": 24.274924471299094,
      "eval_loss": 1.3184019327163696,
      "eval_runtime": 605.703,
      "eval_samples_per_second": 87.665,
      "eval_steps_per_second": 0.685,
      "step": 80350
    },
    {
      "epoch": 24.290030211480364,
      "grad_norm": 0.519868791103363,
      "learning_rate": 5.047351460221551e-05,
      "loss": 1.2777,
      "step": 80400
    },
    {
      "epoch": 24.290030211480364,
      "eval_loss": 1.319017767906189,
      "eval_runtime": 623.7956,
      "eval_samples_per_second": 85.122,
      "eval_steps_per_second": 0.665,
      "step": 80400
    },
    {
      "epoch": 24.305135951661633,
      "grad_norm": 0.5352877974510193,
      "learning_rate": 5.046344410876133e-05,
      "loss": 1.2983,
      "step": 80450
    },
    {
      "epoch": 24.305135951661633,
      "eval_loss": 1.3179290294647217,
      "eval_runtime": 611.6127,
      "eval_samples_per_second": 86.818,
      "eval_steps_per_second": 0.679,
      "step": 80450
    },
    {
      "epoch": 24.3202416918429,
      "grad_norm": 0.47532930970191956,
      "learning_rate": 5.0453373615307155e-05,
      "loss": 1.305,
      "step": 80500
    },
    {
      "epoch": 24.3202416918429,
      "eval_loss": 1.318631649017334,
      "eval_runtime": 622.0198,
      "eval_samples_per_second": 85.365,
      "eval_steps_per_second": 0.667,
      "step": 80500
    },
    {
      "epoch": 24.335347432024168,
      "grad_norm": 0.5311901569366455,
      "learning_rate": 5.0443303121852974e-05,
      "loss": 1.2998,
      "step": 80550
    },
    {
      "epoch": 24.335347432024168,
      "eval_loss": 1.3173261880874634,
      "eval_runtime": 635.858,
      "eval_samples_per_second": 83.508,
      "eval_steps_per_second": 0.653,
      "step": 80550
    },
    {
      "epoch": 24.350453172205437,
      "grad_norm": 0.4655347168445587,
      "learning_rate": 5.043323262839879e-05,
      "loss": 1.2832,
      "step": 80600
    },
    {
      "epoch": 24.350453172205437,
      "eval_loss": 1.3189936876296997,
      "eval_runtime": 675.0994,
      "eval_samples_per_second": 78.654,
      "eval_steps_per_second": 0.615,
      "step": 80600
    },
    {
      "epoch": 24.365558912386707,
      "grad_norm": 0.5087378025054932,
      "learning_rate": 5.042316213494461e-05,
      "loss": 1.3056,
      "step": 80650
    },
    {
      "epoch": 24.365558912386707,
      "eval_loss": 1.3189400434494019,
      "eval_runtime": 675.2737,
      "eval_samples_per_second": 78.633,
      "eval_steps_per_second": 0.615,
      "step": 80650
    },
    {
      "epoch": 24.380664652567976,
      "grad_norm": 0.46022218465805054,
      "learning_rate": 5.041309164149044e-05,
      "loss": 1.2878,
      "step": 80700
    },
    {
      "epoch": 24.380664652567976,
      "eval_loss": 1.317468523979187,
      "eval_runtime": 682.5059,
      "eval_samples_per_second": 77.8,
      "eval_steps_per_second": 0.608,
      "step": 80700
    },
    {
      "epoch": 24.395770392749245,
      "grad_norm": 0.4958972930908203,
      "learning_rate": 5.0403021148036256e-05,
      "loss": 1.3002,
      "step": 80750
    },
    {
      "epoch": 24.395770392749245,
      "eval_loss": 1.3186370134353638,
      "eval_runtime": 622.6331,
      "eval_samples_per_second": 85.281,
      "eval_steps_per_second": 0.667,
      "step": 80750
    },
    {
      "epoch": 24.410876132930515,
      "grad_norm": 0.5110448598861694,
      "learning_rate": 5.0392950654582074e-05,
      "loss": 1.3129,
      "step": 80800
    },
    {
      "epoch": 24.410876132930515,
      "eval_loss": 1.317344307899475,
      "eval_runtime": 617.5635,
      "eval_samples_per_second": 85.981,
      "eval_steps_per_second": 0.672,
      "step": 80800
    },
    {
      "epoch": 24.425981873111784,
      "grad_norm": 0.48256927728652954,
      "learning_rate": 5.038288016112789e-05,
      "loss": 1.2996,
      "step": 80850
    },
    {
      "epoch": 24.425981873111784,
      "eval_loss": 1.3182424306869507,
      "eval_runtime": 833.2717,
      "eval_samples_per_second": 63.724,
      "eval_steps_per_second": 0.498,
      "step": 80850
    },
    {
      "epoch": 24.44108761329305,
      "grad_norm": 0.47272196412086487,
      "learning_rate": 5.037280966767372e-05,
      "loss": 1.3096,
      "step": 80900
    },
    {
      "epoch": 24.44108761329305,
      "eval_loss": 1.3181685209274292,
      "eval_runtime": 699.3753,
      "eval_samples_per_second": 75.923,
      "eval_steps_per_second": 0.593,
      "step": 80900
    },
    {
      "epoch": 24.45619335347432,
      "grad_norm": 0.4864951968193054,
      "learning_rate": 5.036273917421954e-05,
      "loss": 1.2966,
      "step": 80950
    },
    {
      "epoch": 24.45619335347432,
      "eval_loss": 1.3175725936889648,
      "eval_runtime": 631.8752,
      "eval_samples_per_second": 84.034,
      "eval_steps_per_second": 0.657,
      "step": 80950
    },
    {
      "epoch": 24.47129909365559,
      "grad_norm": 0.4946593642234802,
      "learning_rate": 5.0352668680765356e-05,
      "loss": 1.2929,
      "step": 81000
    },
    {
      "epoch": 24.47129909365559,
      "eval_loss": 1.3168751001358032,
      "eval_runtime": 607.8049,
      "eval_samples_per_second": 87.362,
      "eval_steps_per_second": 0.683,
      "step": 81000
    },
    {
      "epoch": 24.486404833836858,
      "grad_norm": 0.4964402914047241,
      "learning_rate": 5.0342598187311175e-05,
      "loss": 1.3049,
      "step": 81050
    },
    {
      "epoch": 24.486404833836858,
      "eval_loss": 1.3164490461349487,
      "eval_runtime": 712.1221,
      "eval_samples_per_second": 74.564,
      "eval_steps_per_second": 0.583,
      "step": 81050
    },
    {
      "epoch": 24.501510574018127,
      "grad_norm": 0.4738304018974304,
      "learning_rate": 5.0332527693857e-05,
      "loss": 1.2964,
      "step": 81100
    },
    {
      "epoch": 24.501510574018127,
      "eval_loss": 1.3181265592575073,
      "eval_runtime": 707.3649,
      "eval_samples_per_second": 75.066,
      "eval_steps_per_second": 0.587,
      "step": 81100
    },
    {
      "epoch": 24.516616314199396,
      "grad_norm": 0.48269885778427124,
      "learning_rate": 5.032245720040282e-05,
      "loss": 1.2953,
      "step": 81150
    },
    {
      "epoch": 24.516616314199396,
      "eval_loss": 1.3159836530685425,
      "eval_runtime": 651.301,
      "eval_samples_per_second": 81.528,
      "eval_steps_per_second": 0.637,
      "step": 81150
    },
    {
      "epoch": 24.531722054380666,
      "grad_norm": 0.4892078936100006,
      "learning_rate": 5.031238670694864e-05,
      "loss": 1.2776,
      "step": 81200
    },
    {
      "epoch": 24.531722054380666,
      "eval_loss": 1.3173770904541016,
      "eval_runtime": 707.3969,
      "eval_samples_per_second": 75.063,
      "eval_steps_per_second": 0.587,
      "step": 81200
    },
    {
      "epoch": 24.546827794561935,
      "grad_norm": 0.4613950252532959,
      "learning_rate": 5.0302316213494456e-05,
      "loss": 1.3003,
      "step": 81250
    },
    {
      "epoch": 24.546827794561935,
      "eval_loss": 1.3178637027740479,
      "eval_runtime": 938.1174,
      "eval_samples_per_second": 56.602,
      "eval_steps_per_second": 0.442,
      "step": 81250
    },
    {
      "epoch": 24.561933534743204,
      "grad_norm": 0.44829651713371277,
      "learning_rate": 5.029224572004029e-05,
      "loss": 1.2799,
      "step": 81300
    },
    {
      "epoch": 24.561933534743204,
      "eval_loss": 1.3178328275680542,
      "eval_runtime": 654.4795,
      "eval_samples_per_second": 81.132,
      "eval_steps_per_second": 0.634,
      "step": 81300
    },
    {
      "epoch": 24.57703927492447,
      "grad_norm": 0.4924182891845703,
      "learning_rate": 5.028217522658611e-05,
      "loss": 1.2748,
      "step": 81350
    },
    {
      "epoch": 24.57703927492447,
      "eval_loss": 1.315842628479004,
      "eval_runtime": 674.7487,
      "eval_samples_per_second": 78.694,
      "eval_steps_per_second": 0.615,
      "step": 81350
    },
    {
      "epoch": 24.59214501510574,
      "grad_norm": 0.4897419810295105,
      "learning_rate": 5.0272104733131926e-05,
      "loss": 1.3082,
      "step": 81400
    },
    {
      "epoch": 24.59214501510574,
      "eval_loss": 1.3150994777679443,
      "eval_runtime": 691.1935,
      "eval_samples_per_second": 76.822,
      "eval_steps_per_second": 0.6,
      "step": 81400
    },
    {
      "epoch": 24.60725075528701,
      "grad_norm": 0.4717603325843811,
      "learning_rate": 5.0262034239677744e-05,
      "loss": 1.2841,
      "step": 81450
    },
    {
      "epoch": 24.60725075528701,
      "eval_loss": 1.3166617155075073,
      "eval_runtime": 637.1762,
      "eval_samples_per_second": 83.335,
      "eval_steps_per_second": 0.651,
      "step": 81450
    },
    {
      "epoch": 24.622356495468278,
      "grad_norm": 0.4583789110183716,
      "learning_rate": 5.025196374622357e-05,
      "loss": 1.3077,
      "step": 81500
    },
    {
      "epoch": 24.622356495468278,
      "eval_loss": 1.316737174987793,
      "eval_runtime": 823.9114,
      "eval_samples_per_second": 64.447,
      "eval_steps_per_second": 0.504,
      "step": 81500
    },
    {
      "epoch": 24.637462235649547,
      "grad_norm": 0.4601396322250366,
      "learning_rate": 5.024189325276939e-05,
      "loss": 1.2885,
      "step": 81550
    },
    {
      "epoch": 24.637462235649547,
      "eval_loss": 1.31592857837677,
      "eval_runtime": 616.7134,
      "eval_samples_per_second": 86.1,
      "eval_steps_per_second": 0.673,
      "step": 81550
    },
    {
      "epoch": 24.652567975830816,
      "grad_norm": 0.4705272614955902,
      "learning_rate": 5.023182275931521e-05,
      "loss": 1.2902,
      "step": 81600
    },
    {
      "epoch": 24.652567975830816,
      "eval_loss": 1.316223382949829,
      "eval_runtime": 649.069,
      "eval_samples_per_second": 81.808,
      "eval_steps_per_second": 0.639,
      "step": 81600
    },
    {
      "epoch": 24.667673716012086,
      "grad_norm": 0.4875052571296692,
      "learning_rate": 5.022175226586103e-05,
      "loss": 1.2802,
      "step": 81650
    },
    {
      "epoch": 24.667673716012086,
      "eval_loss": 1.3165768384933472,
      "eval_runtime": 686.6372,
      "eval_samples_per_second": 77.332,
      "eval_steps_per_second": 0.604,
      "step": 81650
    },
    {
      "epoch": 24.682779456193355,
      "grad_norm": 0.4865506887435913,
      "learning_rate": 5.021168177240685e-05,
      "loss": 1.2613,
      "step": 81700
    },
    {
      "epoch": 24.682779456193355,
      "eval_loss": 1.3164142370224,
      "eval_runtime": 667.5246,
      "eval_samples_per_second": 79.546,
      "eval_steps_per_second": 0.622,
      "step": 81700
    },
    {
      "epoch": 24.69788519637462,
      "grad_norm": 0.5309502482414246,
      "learning_rate": 5.020161127895267e-05,
      "loss": 1.3111,
      "step": 81750
    },
    {
      "epoch": 24.69788519637462,
      "eval_loss": 1.3177350759506226,
      "eval_runtime": 746.9085,
      "eval_samples_per_second": 71.092,
      "eval_steps_per_second": 0.556,
      "step": 81750
    },
    {
      "epoch": 24.71299093655589,
      "grad_norm": 0.49631693959236145,
      "learning_rate": 5.019154078549849e-05,
      "loss": 1.2861,
      "step": 81800
    },
    {
      "epoch": 24.71299093655589,
      "eval_loss": 1.3170095682144165,
      "eval_runtime": 686.5662,
      "eval_samples_per_second": 77.34,
      "eval_steps_per_second": 0.604,
      "step": 81800
    },
    {
      "epoch": 24.72809667673716,
      "grad_norm": 0.44569963216781616,
      "learning_rate": 5.0181470292044314e-05,
      "loss": 1.2877,
      "step": 81850
    },
    {
      "epoch": 24.72809667673716,
      "eval_loss": 1.317007064819336,
      "eval_runtime": 624.455,
      "eval_samples_per_second": 85.033,
      "eval_steps_per_second": 0.665,
      "step": 81850
    },
    {
      "epoch": 24.74320241691843,
      "grad_norm": 0.48910924792289734,
      "learning_rate": 5.017139979859013e-05,
      "loss": 1.2799,
      "step": 81900
    },
    {
      "epoch": 24.74320241691843,
      "eval_loss": 1.316033124923706,
      "eval_runtime": 616.2146,
      "eval_samples_per_second": 86.17,
      "eval_steps_per_second": 0.673,
      "step": 81900
    },
    {
      "epoch": 24.758308157099698,
      "grad_norm": 0.4796864688396454,
      "learning_rate": 5.016132930513595e-05,
      "loss": 1.3041,
      "step": 81950
    },
    {
      "epoch": 24.758308157099698,
      "eval_loss": 1.3181467056274414,
      "eval_runtime": 632.2707,
      "eval_samples_per_second": 83.981,
      "eval_steps_per_second": 0.656,
      "step": 81950
    },
    {
      "epoch": 24.773413897280967,
      "grad_norm": 0.49760565161705017,
      "learning_rate": 5.015125881168177e-05,
      "loss": 1.2957,
      "step": 82000
    },
    {
      "epoch": 24.773413897280967,
      "eval_loss": 1.3184846639633179,
      "eval_runtime": 702.0688,
      "eval_samples_per_second": 75.632,
      "eval_steps_per_second": 0.591,
      "step": 82000
    },
    {
      "epoch": 24.788519637462237,
      "grad_norm": 0.5502198934555054,
      "learning_rate": 5.0141188318227596e-05,
      "loss": 1.3077,
      "step": 82050
    },
    {
      "epoch": 24.788519637462237,
      "eval_loss": 1.316511869430542,
      "eval_runtime": 695.6422,
      "eval_samples_per_second": 76.331,
      "eval_steps_per_second": 0.597,
      "step": 82050
    },
    {
      "epoch": 24.803625377643506,
      "grad_norm": 0.47405368089675903,
      "learning_rate": 5.0131117824773414e-05,
      "loss": 1.2726,
      "step": 82100
    },
    {
      "epoch": 24.803625377643506,
      "eval_loss": 1.3157896995544434,
      "eval_runtime": 610.7989,
      "eval_samples_per_second": 86.934,
      "eval_steps_per_second": 0.679,
      "step": 82100
    },
    {
      "epoch": 24.818731117824772,
      "grad_norm": 0.45982638001441956,
      "learning_rate": 5.012104733131923e-05,
      "loss": 1.2841,
      "step": 82150
    },
    {
      "epoch": 24.818731117824772,
      "eval_loss": 1.3165867328643799,
      "eval_runtime": 619.862,
      "eval_samples_per_second": 85.663,
      "eval_steps_per_second": 0.67,
      "step": 82150
    },
    {
      "epoch": 24.83383685800604,
      "grad_norm": 0.5651617646217346,
      "learning_rate": 5.011097683786505e-05,
      "loss": 1.2909,
      "step": 82200
    },
    {
      "epoch": 24.83383685800604,
      "eval_loss": 1.3165174722671509,
      "eval_runtime": 658.9833,
      "eval_samples_per_second": 80.577,
      "eval_steps_per_second": 0.63,
      "step": 82200
    },
    {
      "epoch": 24.84894259818731,
      "grad_norm": 0.4610947370529175,
      "learning_rate": 5.010090634441088e-05,
      "loss": 1.2668,
      "step": 82250
    },
    {
      "epoch": 24.84894259818731,
      "eval_loss": 1.314922571182251,
      "eval_runtime": 630.3331,
      "eval_samples_per_second": 84.24,
      "eval_steps_per_second": 0.658,
      "step": 82250
    },
    {
      "epoch": 24.86404833836858,
      "grad_norm": 0.4298909902572632,
      "learning_rate": 5.0090835850956696e-05,
      "loss": 1.2793,
      "step": 82300
    },
    {
      "epoch": 24.86404833836858,
      "eval_loss": 1.3162866830825806,
      "eval_runtime": 662.5269,
      "eval_samples_per_second": 80.146,
      "eval_steps_per_second": 0.626,
      "step": 82300
    },
    {
      "epoch": 24.87915407854985,
      "grad_norm": 0.44362780451774597,
      "learning_rate": 5.0080765357502515e-05,
      "loss": 1.2832,
      "step": 82350
    },
    {
      "epoch": 24.87915407854985,
      "eval_loss": 1.313928246498108,
      "eval_runtime": 705.8388,
      "eval_samples_per_second": 75.228,
      "eval_steps_per_second": 0.588,
      "step": 82350
    },
    {
      "epoch": 24.89425981873112,
      "grad_norm": 0.5106622576713562,
      "learning_rate": 5.007069486404833e-05,
      "loss": 1.2957,
      "step": 82400
    },
    {
      "epoch": 24.89425981873112,
      "eval_loss": 1.317674160003662,
      "eval_runtime": 666.678,
      "eval_samples_per_second": 79.647,
      "eval_steps_per_second": 0.622,
      "step": 82400
    },
    {
      "epoch": 24.909365558912388,
      "grad_norm": 0.4907281994819641,
      "learning_rate": 5.0060624370594166e-05,
      "loss": 1.306,
      "step": 82450
    },
    {
      "epoch": 24.909365558912388,
      "eval_loss": 1.315373182296753,
      "eval_runtime": 583.2351,
      "eval_samples_per_second": 91.042,
      "eval_steps_per_second": 0.712,
      "step": 82450
    },
    {
      "epoch": 24.924471299093657,
      "grad_norm": 0.49223649501800537,
      "learning_rate": 5.0050553877139984e-05,
      "loss": 1.3201,
      "step": 82500
    },
    {
      "epoch": 24.924471299093657,
      "eval_loss": 1.314405083656311,
      "eval_runtime": 711.6028,
      "eval_samples_per_second": 74.619,
      "eval_steps_per_second": 0.583,
      "step": 82500
    },
    {
      "epoch": 24.939577039274923,
      "grad_norm": 0.4997701942920685,
      "learning_rate": 5.00404833836858e-05,
      "loss": 1.2994,
      "step": 82550
    },
    {
      "epoch": 24.939577039274923,
      "eval_loss": 1.3141586780548096,
      "eval_runtime": 720.448,
      "eval_samples_per_second": 73.703,
      "eval_steps_per_second": 0.576,
      "step": 82550
    },
    {
      "epoch": 24.954682779456192,
      "grad_norm": 0.5091579556465149,
      "learning_rate": 5.003041289023162e-05,
      "loss": 1.3005,
      "step": 82600
    },
    {
      "epoch": 24.954682779456192,
      "eval_loss": 1.3155241012573242,
      "eval_runtime": 648.937,
      "eval_samples_per_second": 81.825,
      "eval_steps_per_second": 0.64,
      "step": 82600
    },
    {
      "epoch": 24.96978851963746,
      "grad_norm": 0.47635889053344727,
      "learning_rate": 5.002034239677745e-05,
      "loss": 1.2967,
      "step": 82650
    },
    {
      "epoch": 24.96978851963746,
      "eval_loss": 1.3150804042816162,
      "eval_runtime": 681.8577,
      "eval_samples_per_second": 77.874,
      "eval_steps_per_second": 0.609,
      "step": 82650
    },
    {
      "epoch": 24.98489425981873,
      "grad_norm": 0.4435907304286957,
      "learning_rate": 5.0010271903323266e-05,
      "loss": 1.2886,
      "step": 82700
    },
    {
      "epoch": 24.98489425981873,
      "eval_loss": 1.3147978782653809,
      "eval_runtime": 613.208,
      "eval_samples_per_second": 86.592,
      "eval_steps_per_second": 0.677,
      "step": 82700
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.4716750383377075,
      "learning_rate": 5.0000201409869084e-05,
      "loss": 1.3102,
      "step": 82750
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.317035436630249,
      "eval_runtime": 677.0753,
      "eval_samples_per_second": 78.424,
      "eval_steps_per_second": 0.613,
      "step": 82750
    },
    {
      "epoch": 25.01510574018127,
      "grad_norm": 0.49690768122673035,
      "learning_rate": 4.999013091641491e-05,
      "loss": 1.273,
      "step": 82800
    },
    {
      "epoch": 25.01510574018127,
      "eval_loss": 1.315809726715088,
      "eval_runtime": 607.2295,
      "eval_samples_per_second": 87.445,
      "eval_steps_per_second": 0.683,
      "step": 82800
    },
    {
      "epoch": 25.03021148036254,
      "grad_norm": 0.4357893764972687,
      "learning_rate": 4.998006042296073e-05,
      "loss": 1.2933,
      "step": 82850
    },
    {
      "epoch": 25.03021148036254,
      "eval_loss": 1.3122743368148804,
      "eval_runtime": 652.7451,
      "eval_samples_per_second": 81.347,
      "eval_steps_per_second": 0.636,
      "step": 82850
    },
    {
      "epoch": 25.045317220543808,
      "grad_norm": 0.4452076852321625,
      "learning_rate": 4.996998992950655e-05,
      "loss": 1.2973,
      "step": 82900
    },
    {
      "epoch": 25.045317220543808,
      "eval_loss": 1.3161029815673828,
      "eval_runtime": 700.4649,
      "eval_samples_per_second": 75.805,
      "eval_steps_per_second": 0.592,
      "step": 82900
    },
    {
      "epoch": 25.060422960725077,
      "grad_norm": 0.4607387185096741,
      "learning_rate": 4.9959919436052366e-05,
      "loss": 1.2829,
      "step": 82950
    },
    {
      "epoch": 25.060422960725077,
      "eval_loss": 1.3131835460662842,
      "eval_runtime": 686.7821,
      "eval_samples_per_second": 77.316,
      "eval_steps_per_second": 0.604,
      "step": 82950
    },
    {
      "epoch": 25.075528700906343,
      "grad_norm": 0.45500972867012024,
      "learning_rate": 4.994984894259819e-05,
      "loss": 1.2939,
      "step": 83000
    },
    {
      "epoch": 25.075528700906343,
      "eval_loss": 1.3154923915863037,
      "eval_runtime": 648.0173,
      "eval_samples_per_second": 81.941,
      "eval_steps_per_second": 0.64,
      "step": 83000
    },
    {
      "epoch": 25.090634441087612,
      "grad_norm": 0.4675874710083008,
      "learning_rate": 4.993977844914401e-05,
      "loss": 1.2973,
      "step": 83050
    },
    {
      "epoch": 25.090634441087612,
      "eval_loss": 1.3172643184661865,
      "eval_runtime": 703.3693,
      "eval_samples_per_second": 75.492,
      "eval_steps_per_second": 0.59,
      "step": 83050
    },
    {
      "epoch": 25.10574018126888,
      "grad_norm": 0.45948538184165955,
      "learning_rate": 4.992970795568983e-05,
      "loss": 1.2966,
      "step": 83100
    },
    {
      "epoch": 25.10574018126888,
      "eval_loss": 1.312268614768982,
      "eval_runtime": 636.9525,
      "eval_samples_per_second": 83.364,
      "eval_steps_per_second": 0.652,
      "step": 83100
    },
    {
      "epoch": 25.12084592145015,
      "grad_norm": 0.5162621140480042,
      "learning_rate": 4.991963746223565e-05,
      "loss": 1.27,
      "step": 83150
    },
    {
      "epoch": 25.12084592145015,
      "eval_loss": 1.3140382766723633,
      "eval_runtime": 623.3542,
      "eval_samples_per_second": 85.183,
      "eval_steps_per_second": 0.666,
      "step": 83150
    },
    {
      "epoch": 25.13595166163142,
      "grad_norm": 0.5083417892456055,
      "learning_rate": 4.990956696878147e-05,
      "loss": 1.2824,
      "step": 83200
    },
    {
      "epoch": 25.13595166163142,
      "eval_loss": 1.3157503604888916,
      "eval_runtime": 600.1026,
      "eval_samples_per_second": 88.483,
      "eval_steps_per_second": 0.692,
      "step": 83200
    },
    {
      "epoch": 25.15105740181269,
      "grad_norm": 0.4890470504760742,
      "learning_rate": 4.989949647532729e-05,
      "loss": 1.2879,
      "step": 83250
    },
    {
      "epoch": 25.15105740181269,
      "eval_loss": 1.3145135641098022,
      "eval_runtime": 678.1544,
      "eval_samples_per_second": 78.299,
      "eval_steps_per_second": 0.612,
      "step": 83250
    },
    {
      "epoch": 25.16616314199396,
      "grad_norm": 0.45217815041542053,
      "learning_rate": 4.988942598187311e-05,
      "loss": 1.2724,
      "step": 83300
    },
    {
      "epoch": 25.16616314199396,
      "eval_loss": 1.3146628141403198,
      "eval_runtime": 603.2805,
      "eval_samples_per_second": 88.017,
      "eval_steps_per_second": 0.688,
      "step": 83300
    },
    {
      "epoch": 25.181268882175228,
      "grad_norm": 0.4417884051799774,
      "learning_rate": 4.987935548841893e-05,
      "loss": 1.2635,
      "step": 83350
    },
    {
      "epoch": 25.181268882175228,
      "eval_loss": 1.314310908317566,
      "eval_runtime": 648.8957,
      "eval_samples_per_second": 81.83,
      "eval_steps_per_second": 0.64,
      "step": 83350
    },
    {
      "epoch": 25.196374622356494,
      "grad_norm": 0.4574931561946869,
      "learning_rate": 4.9869284994964754e-05,
      "loss": 1.3095,
      "step": 83400
    },
    {
      "epoch": 25.196374622356494,
      "eval_loss": 1.3129191398620605,
      "eval_runtime": 590.4577,
      "eval_samples_per_second": 89.929,
      "eval_steps_per_second": 0.703,
      "step": 83400
    },
    {
      "epoch": 25.211480362537763,
      "grad_norm": 0.47865092754364014,
      "learning_rate": 4.985921450151057e-05,
      "loss": 1.2792,
      "step": 83450
    },
    {
      "epoch": 25.211480362537763,
      "eval_loss": 1.3161418437957764,
      "eval_runtime": 698.9724,
      "eval_samples_per_second": 75.967,
      "eval_steps_per_second": 0.594,
      "step": 83450
    },
    {
      "epoch": 25.226586102719033,
      "grad_norm": 0.46839335560798645,
      "learning_rate": 4.984914400805639e-05,
      "loss": 1.2702,
      "step": 83500
    },
    {
      "epoch": 25.226586102719033,
      "eval_loss": 1.3140971660614014,
      "eval_runtime": 641.9382,
      "eval_samples_per_second": 82.717,
      "eval_steps_per_second": 0.646,
      "step": 83500
    },
    {
      "epoch": 25.241691842900302,
      "grad_norm": 0.43453431129455566,
      "learning_rate": 4.983907351460221e-05,
      "loss": 1.2725,
      "step": 83550
    },
    {
      "epoch": 25.241691842900302,
      "eval_loss": 1.3139163255691528,
      "eval_runtime": 603.3376,
      "eval_samples_per_second": 88.009,
      "eval_steps_per_second": 0.688,
      "step": 83550
    },
    {
      "epoch": 25.25679758308157,
      "grad_norm": 0.43562909960746765,
      "learning_rate": 4.982900302114804e-05,
      "loss": 1.2791,
      "step": 83600
    },
    {
      "epoch": 25.25679758308157,
      "eval_loss": 1.313782811164856,
      "eval_runtime": 693.5724,
      "eval_samples_per_second": 76.559,
      "eval_steps_per_second": 0.598,
      "step": 83600
    },
    {
      "epoch": 25.27190332326284,
      "grad_norm": 0.4559774696826935,
      "learning_rate": 4.981893252769386e-05,
      "loss": 1.2843,
      "step": 83650
    },
    {
      "epoch": 25.27190332326284,
      "eval_loss": 1.3135337829589844,
      "eval_runtime": 628.2598,
      "eval_samples_per_second": 84.518,
      "eval_steps_per_second": 0.661,
      "step": 83650
    },
    {
      "epoch": 25.28700906344411,
      "grad_norm": 0.4629223346710205,
      "learning_rate": 4.980886203423968e-05,
      "loss": 1.2826,
      "step": 83700
    },
    {
      "epoch": 25.28700906344411,
      "eval_loss": 1.3151483535766602,
      "eval_runtime": 659.4249,
      "eval_samples_per_second": 80.523,
      "eval_steps_per_second": 0.629,
      "step": 83700
    },
    {
      "epoch": 25.30211480362538,
      "grad_norm": 0.5134764313697815,
      "learning_rate": 4.97987915407855e-05,
      "loss": 1.2947,
      "step": 83750
    },
    {
      "epoch": 25.30211480362538,
      "eval_loss": 1.3137696981430054,
      "eval_runtime": 671.2271,
      "eval_samples_per_second": 79.107,
      "eval_steps_per_second": 0.618,
      "step": 83750
    },
    {
      "epoch": 25.317220543806645,
      "grad_norm": 0.4240787923336029,
      "learning_rate": 4.9788721047331324e-05,
      "loss": 1.2874,
      "step": 83800
    },
    {
      "epoch": 25.317220543806645,
      "eval_loss": 1.3143819570541382,
      "eval_runtime": 681.7859,
      "eval_samples_per_second": 77.882,
      "eval_steps_per_second": 0.609,
      "step": 83800
    },
    {
      "epoch": 25.332326283987914,
      "grad_norm": 0.44618386030197144,
      "learning_rate": 4.977865055387714e-05,
      "loss": 1.2893,
      "step": 83850
    },
    {
      "epoch": 25.332326283987914,
      "eval_loss": 1.3135244846343994,
      "eval_runtime": 591.1987,
      "eval_samples_per_second": 89.816,
      "eval_steps_per_second": 0.702,
      "step": 83850
    },
    {
      "epoch": 25.347432024169184,
      "grad_norm": 0.5360865592956543,
      "learning_rate": 4.976858006042296e-05,
      "loss": 1.2939,
      "step": 83900
    },
    {
      "epoch": 25.347432024169184,
      "eval_loss": 1.3140501976013184,
      "eval_runtime": 618.4271,
      "eval_samples_per_second": 85.861,
      "eval_steps_per_second": 0.671,
      "step": 83900
    },
    {
      "epoch": 25.362537764350453,
      "grad_norm": 0.471534788608551,
      "learning_rate": 4.975850956696879e-05,
      "loss": 1.2764,
      "step": 83950
    },
    {
      "epoch": 25.362537764350453,
      "eval_loss": 1.313666582107544,
      "eval_runtime": 692.5427,
      "eval_samples_per_second": 76.673,
      "eval_steps_per_second": 0.599,
      "step": 83950
    },
    {
      "epoch": 25.377643504531722,
      "grad_norm": 0.4574652910232544,
      "learning_rate": 4.9748439073514606e-05,
      "loss": 1.2996,
      "step": 84000
    },
    {
      "epoch": 25.377643504531722,
      "eval_loss": 1.3138929605484009,
      "eval_runtime": 686.5494,
      "eval_samples_per_second": 77.342,
      "eval_steps_per_second": 0.604,
      "step": 84000
    },
    {
      "epoch": 25.39274924471299,
      "grad_norm": 0.46294400095939636,
      "learning_rate": 4.9738368580060424e-05,
      "loss": 1.2978,
      "step": 84050
    },
    {
      "epoch": 25.39274924471299,
      "eval_loss": 1.3125464916229248,
      "eval_runtime": 636.3369,
      "eval_samples_per_second": 83.445,
      "eval_steps_per_second": 0.652,
      "step": 84050
    },
    {
      "epoch": 25.40785498489426,
      "grad_norm": 0.5305895209312439,
      "learning_rate": 4.972829808660624e-05,
      "loss": 1.2894,
      "step": 84100
    },
    {
      "epoch": 25.40785498489426,
      "eval_loss": 1.3138092756271362,
      "eval_runtime": 618.7113,
      "eval_samples_per_second": 85.822,
      "eval_steps_per_second": 0.671,
      "step": 84100
    },
    {
      "epoch": 25.42296072507553,
      "grad_norm": 0.5258640646934509,
      "learning_rate": 4.971822759315207e-05,
      "loss": 1.2824,
      "step": 84150
    },
    {
      "epoch": 25.42296072507553,
      "eval_loss": 1.3120148181915283,
      "eval_runtime": 641.7285,
      "eval_samples_per_second": 82.744,
      "eval_steps_per_second": 0.647,
      "step": 84150
    },
    {
      "epoch": 25.438066465256796,
      "grad_norm": 0.47055670619010925,
      "learning_rate": 4.970815709969789e-05,
      "loss": 1.2589,
      "step": 84200
    },
    {
      "epoch": 25.438066465256796,
      "eval_loss": 1.3120414018630981,
      "eval_runtime": 631.0945,
      "eval_samples_per_second": 84.138,
      "eval_steps_per_second": 0.658,
      "step": 84200
    },
    {
      "epoch": 25.453172205438065,
      "grad_norm": 0.5068936944007874,
      "learning_rate": 4.9698086606243706e-05,
      "loss": 1.311,
      "step": 84250
    },
    {
      "epoch": 25.453172205438065,
      "eval_loss": 1.3131511211395264,
      "eval_runtime": 698.179,
      "eval_samples_per_second": 76.054,
      "eval_steps_per_second": 0.594,
      "step": 84250
    },
    {
      "epoch": 25.468277945619334,
      "grad_norm": 0.45899689197540283,
      "learning_rate": 4.9688016112789525e-05,
      "loss": 1.2842,
      "step": 84300
    },
    {
      "epoch": 25.468277945619334,
      "eval_loss": 1.3139785528182983,
      "eval_runtime": 650.5746,
      "eval_samples_per_second": 81.619,
      "eval_steps_per_second": 0.638,
      "step": 84300
    },
    {
      "epoch": 25.483383685800604,
      "grad_norm": 0.4491255581378937,
      "learning_rate": 4.967794561933535e-05,
      "loss": 1.273,
      "step": 84350
    },
    {
      "epoch": 25.483383685800604,
      "eval_loss": 1.312059998512268,
      "eval_runtime": 627.0344,
      "eval_samples_per_second": 84.683,
      "eval_steps_per_second": 0.662,
      "step": 84350
    },
    {
      "epoch": 25.498489425981873,
      "grad_norm": 0.5308960676193237,
      "learning_rate": 4.966787512588117e-05,
      "loss": 1.3077,
      "step": 84400
    },
    {
      "epoch": 25.498489425981873,
      "eval_loss": 1.3121840953826904,
      "eval_runtime": 596.3614,
      "eval_samples_per_second": 89.038,
      "eval_steps_per_second": 0.696,
      "step": 84400
    },
    {
      "epoch": 25.513595166163142,
      "grad_norm": 0.4402962028980255,
      "learning_rate": 4.965780463242699e-05,
      "loss": 1.2901,
      "step": 84450
    },
    {
      "epoch": 25.513595166163142,
      "eval_loss": 1.313148856163025,
      "eval_runtime": 703.0153,
      "eval_samples_per_second": 75.53,
      "eval_steps_per_second": 0.59,
      "step": 84450
    },
    {
      "epoch": 25.52870090634441,
      "grad_norm": 0.49610036611557007,
      "learning_rate": 4.9647734138972806e-05,
      "loss": 1.3037,
      "step": 84500
    },
    {
      "epoch": 25.52870090634441,
      "eval_loss": 1.311448574066162,
      "eval_runtime": 718.6136,
      "eval_samples_per_second": 73.891,
      "eval_steps_per_second": 0.578,
      "step": 84500
    },
    {
      "epoch": 25.54380664652568,
      "grad_norm": 0.4672141969203949,
      "learning_rate": 4.963766364551863e-05,
      "loss": 1.2942,
      "step": 84550
    },
    {
      "epoch": 25.54380664652568,
      "eval_loss": 1.31117844581604,
      "eval_runtime": 656.711,
      "eval_samples_per_second": 80.856,
      "eval_steps_per_second": 0.632,
      "step": 84550
    },
    {
      "epoch": 25.55891238670695,
      "grad_norm": 0.4409819543361664,
      "learning_rate": 4.962759315206445e-05,
      "loss": 1.3148,
      "step": 84600
    },
    {
      "epoch": 25.55891238670695,
      "eval_loss": 1.3120607137680054,
      "eval_runtime": 689.5338,
      "eval_samples_per_second": 77.007,
      "eval_steps_per_second": 0.602,
      "step": 84600
    },
    {
      "epoch": 25.574018126888216,
      "grad_norm": 0.47830748558044434,
      "learning_rate": 4.961752265861027e-05,
      "loss": 1.2925,
      "step": 84650
    },
    {
      "epoch": 25.574018126888216,
      "eval_loss": 1.3151671886444092,
      "eval_runtime": 637.1281,
      "eval_samples_per_second": 83.341,
      "eval_steps_per_second": 0.651,
      "step": 84650
    },
    {
      "epoch": 25.589123867069485,
      "grad_norm": 0.48782506585121155,
      "learning_rate": 4.960745216515609e-05,
      "loss": 1.2954,
      "step": 84700
    },
    {
      "epoch": 25.589123867069485,
      "eval_loss": 1.3125851154327393,
      "eval_runtime": 683.2276,
      "eval_samples_per_second": 77.718,
      "eval_steps_per_second": 0.607,
      "step": 84700
    },
    {
      "epoch": 25.604229607250755,
      "grad_norm": 0.456209272146225,
      "learning_rate": 4.959738167170192e-05,
      "loss": 1.2965,
      "step": 84750
    },
    {
      "epoch": 25.604229607250755,
      "eval_loss": 1.3110201358795166,
      "eval_runtime": 643.6001,
      "eval_samples_per_second": 82.503,
      "eval_steps_per_second": 0.645,
      "step": 84750
    },
    {
      "epoch": 25.619335347432024,
      "grad_norm": 0.4692288637161255,
      "learning_rate": 4.958731117824774e-05,
      "loss": 1.2972,
      "step": 84800
    },
    {
      "epoch": 25.619335347432024,
      "eval_loss": 1.309533715248108,
      "eval_runtime": 701.6034,
      "eval_samples_per_second": 75.682,
      "eval_steps_per_second": 0.592,
      "step": 84800
    },
    {
      "epoch": 25.634441087613293,
      "grad_norm": 0.516805112361908,
      "learning_rate": 4.957724068479356e-05,
      "loss": 1.2934,
      "step": 84850
    },
    {
      "epoch": 25.634441087613293,
      "eval_loss": 1.3117989301681519,
      "eval_runtime": 694.2026,
      "eval_samples_per_second": 76.489,
      "eval_steps_per_second": 0.598,
      "step": 84850
    },
    {
      "epoch": 25.649546827794563,
      "grad_norm": 0.49366384744644165,
      "learning_rate": 4.9567170191339376e-05,
      "loss": 1.288,
      "step": 84900
    },
    {
      "epoch": 25.649546827794563,
      "eval_loss": 1.3147746324539185,
      "eval_runtime": 614.6779,
      "eval_samples_per_second": 86.385,
      "eval_steps_per_second": 0.675,
      "step": 84900
    },
    {
      "epoch": 25.664652567975832,
      "grad_norm": 0.48721110820770264,
      "learning_rate": 4.95570996978852e-05,
      "loss": 1.2861,
      "step": 84950
    },
    {
      "epoch": 25.664652567975832,
      "eval_loss": 1.3122154474258423,
      "eval_runtime": 703.3015,
      "eval_samples_per_second": 75.5,
      "eval_steps_per_second": 0.59,
      "step": 84950
    },
    {
      "epoch": 25.6797583081571,
      "grad_norm": 0.4588536322116852,
      "learning_rate": 4.954702920443102e-05,
      "loss": 1.2799,
      "step": 85000
    },
    {
      "epoch": 25.6797583081571,
      "eval_loss": 1.309175968170166,
      "eval_runtime": 630.7897,
      "eval_samples_per_second": 84.179,
      "eval_steps_per_second": 0.658,
      "step": 85000
    },
    {
      "epoch": 25.694864048338367,
      "grad_norm": 0.47122424840927124,
      "learning_rate": 4.953695871097684e-05,
      "loss": 1.2687,
      "step": 85050
    },
    {
      "epoch": 25.694864048338367,
      "eval_loss": 1.311869502067566,
      "eval_runtime": 659.0575,
      "eval_samples_per_second": 80.568,
      "eval_steps_per_second": 0.63,
      "step": 85050
    },
    {
      "epoch": 25.709969788519636,
      "grad_norm": 0.4686802923679352,
      "learning_rate": 4.9526888217522664e-05,
      "loss": 1.3007,
      "step": 85100
    },
    {
      "epoch": 25.709969788519636,
      "eval_loss": 1.3115389347076416,
      "eval_runtime": 716.8041,
      "eval_samples_per_second": 74.077,
      "eval_steps_per_second": 0.579,
      "step": 85100
    },
    {
      "epoch": 25.725075528700906,
      "grad_norm": 0.4945111572742462,
      "learning_rate": 4.951681772406848e-05,
      "loss": 1.2924,
      "step": 85150
    },
    {
      "epoch": 25.725075528700906,
      "eval_loss": 1.3127776384353638,
      "eval_runtime": 698.4869,
      "eval_samples_per_second": 76.02,
      "eval_steps_per_second": 0.594,
      "step": 85150
    },
    {
      "epoch": 25.740181268882175,
      "grad_norm": 0.4482904076576233,
      "learning_rate": 4.95067472306143e-05,
      "loss": 1.2918,
      "step": 85200
    },
    {
      "epoch": 25.740181268882175,
      "eval_loss": 1.3111572265625,
      "eval_runtime": 606.0488,
      "eval_samples_per_second": 87.615,
      "eval_steps_per_second": 0.685,
      "step": 85200
    },
    {
      "epoch": 25.755287009063444,
      "grad_norm": 0.4825757145881653,
      "learning_rate": 4.949667673716012e-05,
      "loss": 1.2695,
      "step": 85250
    },
    {
      "epoch": 25.755287009063444,
      "eval_loss": 1.3105219602584839,
      "eval_runtime": 650.6553,
      "eval_samples_per_second": 81.608,
      "eval_steps_per_second": 0.638,
      "step": 85250
    },
    {
      "epoch": 25.770392749244714,
      "grad_norm": 0.45724061131477356,
      "learning_rate": 4.9486606243705946e-05,
      "loss": 1.283,
      "step": 85300
    },
    {
      "epoch": 25.770392749244714,
      "eval_loss": 1.3121166229248047,
      "eval_runtime": 627.5485,
      "eval_samples_per_second": 84.613,
      "eval_steps_per_second": 0.661,
      "step": 85300
    },
    {
      "epoch": 25.785498489425983,
      "grad_norm": 0.4678953289985657,
      "learning_rate": 4.9476535750251764e-05,
      "loss": 1.3162,
      "step": 85350
    },
    {
      "epoch": 25.785498489425983,
      "eval_loss": 1.3131117820739746,
      "eval_runtime": 643.9807,
      "eval_samples_per_second": 82.454,
      "eval_steps_per_second": 0.644,
      "step": 85350
    },
    {
      "epoch": 25.800604229607252,
      "grad_norm": 0.4657439589500427,
      "learning_rate": 4.946646525679758e-05,
      "loss": 1.2907,
      "step": 85400
    },
    {
      "epoch": 25.800604229607252,
      "eval_loss": 1.311448574066162,
      "eval_runtime": 633.454,
      "eval_samples_per_second": 83.825,
      "eval_steps_per_second": 0.655,
      "step": 85400
    },
    {
      "epoch": 25.815709969788518,
      "grad_norm": 0.44916579127311707,
      "learning_rate": 4.94563947633434e-05,
      "loss": 1.2877,
      "step": 85450
    },
    {
      "epoch": 25.815709969788518,
      "eval_loss": 1.3099334239959717,
      "eval_runtime": 714.917,
      "eval_samples_per_second": 74.273,
      "eval_steps_per_second": 0.58,
      "step": 85450
    },
    {
      "epoch": 25.830815709969787,
      "grad_norm": 0.500785231590271,
      "learning_rate": 4.944632426988923e-05,
      "loss": 1.2829,
      "step": 85500
    },
    {
      "epoch": 25.830815709969787,
      "eval_loss": 1.3104768991470337,
      "eval_runtime": 612.3032,
      "eval_samples_per_second": 86.72,
      "eval_steps_per_second": 0.678,
      "step": 85500
    },
    {
      "epoch": 25.845921450151057,
      "grad_norm": 0.4627523422241211,
      "learning_rate": 4.9436253776435046e-05,
      "loss": 1.3114,
      "step": 85550
    },
    {
      "epoch": 25.845921450151057,
      "eval_loss": 1.3098790645599365,
      "eval_runtime": 626.8847,
      "eval_samples_per_second": 84.703,
      "eval_steps_per_second": 0.662,
      "step": 85550
    },
    {
      "epoch": 25.861027190332326,
      "grad_norm": 0.4797336161136627,
      "learning_rate": 4.9426183282980865e-05,
      "loss": 1.3015,
      "step": 85600
    },
    {
      "epoch": 25.861027190332326,
      "eval_loss": 1.3122342824935913,
      "eval_runtime": 664.9202,
      "eval_samples_per_second": 79.858,
      "eval_steps_per_second": 0.624,
      "step": 85600
    },
    {
      "epoch": 25.876132930513595,
      "grad_norm": 0.44670867919921875,
      "learning_rate": 4.941611278952668e-05,
      "loss": 1.2842,
      "step": 85650
    },
    {
      "epoch": 25.876132930513595,
      "eval_loss": 1.3099331855773926,
      "eval_runtime": 713.7257,
      "eval_samples_per_second": 74.397,
      "eval_steps_per_second": 0.581,
      "step": 85650
    },
    {
      "epoch": 25.891238670694865,
      "grad_norm": 0.4521915018558502,
      "learning_rate": 4.940604229607251e-05,
      "loss": 1.2852,
      "step": 85700
    },
    {
      "epoch": 25.891238670694865,
      "eval_loss": 1.3100693225860596,
      "eval_runtime": 661.7395,
      "eval_samples_per_second": 80.242,
      "eval_steps_per_second": 0.627,
      "step": 85700
    },
    {
      "epoch": 25.906344410876134,
      "grad_norm": 0.4844384491443634,
      "learning_rate": 4.939597180261833e-05,
      "loss": 1.3087,
      "step": 85750
    },
    {
      "epoch": 25.906344410876134,
      "eval_loss": 1.3118404150009155,
      "eval_runtime": 707.1251,
      "eval_samples_per_second": 75.091,
      "eval_steps_per_second": 0.587,
      "step": 85750
    },
    {
      "epoch": 25.921450151057403,
      "grad_norm": 0.4667014479637146,
      "learning_rate": 4.9385901309164146e-05,
      "loss": 1.2991,
      "step": 85800
    },
    {
      "epoch": 25.921450151057403,
      "eval_loss": 1.3119701147079468,
      "eval_runtime": 631.9265,
      "eval_samples_per_second": 84.027,
      "eval_steps_per_second": 0.657,
      "step": 85800
    },
    {
      "epoch": 25.93655589123867,
      "grad_norm": 0.4515012204647064,
      "learning_rate": 4.9375830815709965e-05,
      "loss": 1.2621,
      "step": 85850
    },
    {
      "epoch": 25.93655589123867,
      "eval_loss": 1.311405062675476,
      "eval_runtime": 701.651,
      "eval_samples_per_second": 75.677,
      "eval_steps_per_second": 0.591,
      "step": 85850
    },
    {
      "epoch": 25.951661631419938,
      "grad_norm": 0.4390612840652466,
      "learning_rate": 4.936576032225579e-05,
      "loss": 1.2734,
      "step": 85900
    },
    {
      "epoch": 25.951661631419938,
      "eval_loss": 1.308936595916748,
      "eval_runtime": 662.3009,
      "eval_samples_per_second": 80.174,
      "eval_steps_per_second": 0.627,
      "step": 85900
    },
    {
      "epoch": 25.966767371601208,
      "grad_norm": 0.48263439536094666,
      "learning_rate": 4.9355689828801616e-05,
      "loss": 1.3136,
      "step": 85950
    },
    {
      "epoch": 25.966767371601208,
      "eval_loss": 1.3112199306488037,
      "eval_runtime": 715.4765,
      "eval_samples_per_second": 74.215,
      "eval_steps_per_second": 0.58,
      "step": 85950
    },
    {
      "epoch": 25.981873111782477,
      "grad_norm": 0.5171111226081848,
      "learning_rate": 4.9345619335347434e-05,
      "loss": 1.3019,
      "step": 86000
    },
    {
      "epoch": 25.981873111782477,
      "eval_loss": 1.3115568161010742,
      "eval_runtime": 715.6772,
      "eval_samples_per_second": 74.194,
      "eval_steps_per_second": 0.58,
      "step": 86000
    },
    {
      "epoch": 25.996978851963746,
      "grad_norm": 0.4363158643245697,
      "learning_rate": 4.933554884189326e-05,
      "loss": 1.2859,
      "step": 86050
    },
    {
      "epoch": 25.996978851963746,
      "eval_loss": 1.3126344680786133,
      "eval_runtime": 616.7577,
      "eval_samples_per_second": 86.094,
      "eval_steps_per_second": 0.673,
      "step": 86050
    },
    {
      "epoch": 26.012084592145015,
      "grad_norm": 0.48378986120224,
      "learning_rate": 4.932547834843908e-05,
      "loss": 1.2838,
      "step": 86100
    },
    {
      "epoch": 26.012084592145015,
      "eval_loss": 1.3112163543701172,
      "eval_runtime": 640.9966,
      "eval_samples_per_second": 82.838,
      "eval_steps_per_second": 0.647,
      "step": 86100
    },
    {
      "epoch": 26.027190332326285,
      "grad_norm": 0.5333001017570496,
      "learning_rate": 4.93154078549849e-05,
      "loss": 1.2654,
      "step": 86150
    },
    {
      "epoch": 26.027190332326285,
      "eval_loss": 1.3106416463851929,
      "eval_runtime": 635.0472,
      "eval_samples_per_second": 83.614,
      "eval_steps_per_second": 0.653,
      "step": 86150
    },
    {
      "epoch": 26.042296072507554,
      "grad_norm": 0.45193713903427124,
      "learning_rate": 4.9305337361530716e-05,
      "loss": 1.3012,
      "step": 86200
    },
    {
      "epoch": 26.042296072507554,
      "eval_loss": 1.310363531112671,
      "eval_runtime": 610.1898,
      "eval_samples_per_second": 87.02,
      "eval_steps_per_second": 0.68,
      "step": 86200
    },
    {
      "epoch": 26.057401812688823,
      "grad_norm": 0.41820335388183594,
      "learning_rate": 4.929526686807654e-05,
      "loss": 1.2654,
      "step": 86250
    },
    {
      "epoch": 26.057401812688823,
      "eval_loss": 1.310022234916687,
      "eval_runtime": 675.8502,
      "eval_samples_per_second": 78.566,
      "eval_steps_per_second": 0.614,
      "step": 86250
    },
    {
      "epoch": 26.07250755287009,
      "grad_norm": 0.4621966779232025,
      "learning_rate": 4.928519637462236e-05,
      "loss": 1.2977,
      "step": 86300
    },
    {
      "epoch": 26.07250755287009,
      "eval_loss": 1.3099303245544434,
      "eval_runtime": 706.0285,
      "eval_samples_per_second": 75.208,
      "eval_steps_per_second": 0.588,
      "step": 86300
    },
    {
      "epoch": 26.08761329305136,
      "grad_norm": 0.4388018250465393,
      "learning_rate": 4.927512588116818e-05,
      "loss": 1.2687,
      "step": 86350
    },
    {
      "epoch": 26.08761329305136,
      "eval_loss": 1.3087297677993774,
      "eval_runtime": 612.5672,
      "eval_samples_per_second": 86.683,
      "eval_steps_per_second": 0.677,
      "step": 86350
    },
    {
      "epoch": 26.102719033232628,
      "grad_norm": 0.47893616557121277,
      "learning_rate": 4.9265055387714e-05,
      "loss": 1.2884,
      "step": 86400
    },
    {
      "epoch": 26.102719033232628,
      "eval_loss": 1.3093329668045044,
      "eval_runtime": 662.0048,
      "eval_samples_per_second": 80.209,
      "eval_steps_per_second": 0.627,
      "step": 86400
    },
    {
      "epoch": 26.117824773413897,
      "grad_norm": 0.5219133496284485,
      "learning_rate": 4.925498489425982e-05,
      "loss": 1.2639,
      "step": 86450
    },
    {
      "epoch": 26.117824773413897,
      "eval_loss": 1.309984564781189,
      "eval_runtime": 709.7296,
      "eval_samples_per_second": 74.816,
      "eval_steps_per_second": 0.585,
      "step": 86450
    },
    {
      "epoch": 26.132930513595166,
      "grad_norm": 0.4610082507133484,
      "learning_rate": 4.924491440080564e-05,
      "loss": 1.2904,
      "step": 86500
    },
    {
      "epoch": 26.132930513595166,
      "eval_loss": 1.3100472688674927,
      "eval_runtime": 602.0959,
      "eval_samples_per_second": 88.19,
      "eval_steps_per_second": 0.689,
      "step": 86500
    },
    {
      "epoch": 26.148036253776436,
      "grad_norm": 0.46718987822532654,
      "learning_rate": 4.923484390735146e-05,
      "loss": 1.3176,
      "step": 86550
    },
    {
      "epoch": 26.148036253776436,
      "eval_loss": 1.3117860555648804,
      "eval_runtime": 617.0192,
      "eval_samples_per_second": 86.057,
      "eval_steps_per_second": 0.673,
      "step": 86550
    },
    {
      "epoch": 26.163141993957705,
      "grad_norm": 0.4982423782348633,
      "learning_rate": 4.922477341389728e-05,
      "loss": 1.3074,
      "step": 86600
    },
    {
      "epoch": 26.163141993957705,
      "eval_loss": 1.3101085424423218,
      "eval_runtime": 641.6194,
      "eval_samples_per_second": 82.758,
      "eval_steps_per_second": 0.647,
      "step": 86600
    },
    {
      "epoch": 26.178247734138974,
      "grad_norm": 0.4447454810142517,
      "learning_rate": 4.9214702920443104e-05,
      "loss": 1.2782,
      "step": 86650
    },
    {
      "epoch": 26.178247734138974,
      "eval_loss": 1.3090571165084839,
      "eval_runtime": 680.0577,
      "eval_samples_per_second": 78.08,
      "eval_steps_per_second": 0.61,
      "step": 86650
    },
    {
      "epoch": 26.19335347432024,
      "grad_norm": 0.45125269889831543,
      "learning_rate": 4.920463242698892e-05,
      "loss": 1.2764,
      "step": 86700
    },
    {
      "epoch": 26.19335347432024,
      "eval_loss": 1.310752034187317,
      "eval_runtime": 615.2178,
      "eval_samples_per_second": 86.309,
      "eval_steps_per_second": 0.675,
      "step": 86700
    },
    {
      "epoch": 26.20845921450151,
      "grad_norm": 0.5050298571586609,
      "learning_rate": 4.919456193353474e-05,
      "loss": 1.2716,
      "step": 86750
    },
    {
      "epoch": 26.20845921450151,
      "eval_loss": 1.3108843564987183,
      "eval_runtime": 631.9968,
      "eval_samples_per_second": 84.018,
      "eval_steps_per_second": 0.657,
      "step": 86750
    },
    {
      "epoch": 26.22356495468278,
      "grad_norm": 0.43954381346702576,
      "learning_rate": 4.918449144008056e-05,
      "loss": 1.292,
      "step": 86800
    },
    {
      "epoch": 26.22356495468278,
      "eval_loss": 1.310104489326477,
      "eval_runtime": 628.5091,
      "eval_samples_per_second": 84.484,
      "eval_steps_per_second": 0.66,
      "step": 86800
    },
    {
      "epoch": 26.238670694864048,
      "grad_norm": 0.4657225012779236,
      "learning_rate": 4.9174420946626386e-05,
      "loss": 1.2841,
      "step": 86850
    },
    {
      "epoch": 26.238670694864048,
      "eval_loss": 1.3109453916549683,
      "eval_runtime": 616.2479,
      "eval_samples_per_second": 86.165,
      "eval_steps_per_second": 0.673,
      "step": 86850
    },
    {
      "epoch": 26.253776435045317,
      "grad_norm": 0.48203936219215393,
      "learning_rate": 4.9164350453172205e-05,
      "loss": 1.3044,
      "step": 86900
    },
    {
      "epoch": 26.253776435045317,
      "eval_loss": 1.3076869249343872,
      "eval_runtime": 652.3477,
      "eval_samples_per_second": 81.397,
      "eval_steps_per_second": 0.636,
      "step": 86900
    },
    {
      "epoch": 26.268882175226587,
      "grad_norm": 0.44565823674201965,
      "learning_rate": 4.915427995971802e-05,
      "loss": 1.2781,
      "step": 86950
    },
    {
      "epoch": 26.268882175226587,
      "eval_loss": 1.3118555545806885,
      "eval_runtime": 675.3091,
      "eval_samples_per_second": 78.629,
      "eval_steps_per_second": 0.615,
      "step": 86950
    },
    {
      "epoch": 26.283987915407856,
      "grad_norm": 0.4840335249900818,
      "learning_rate": 4.914420946626384e-05,
      "loss": 1.28,
      "step": 87000
    },
    {
      "epoch": 26.283987915407856,
      "eval_loss": 1.3089207410812378,
      "eval_runtime": 660.0785,
      "eval_samples_per_second": 80.443,
      "eval_steps_per_second": 0.629,
      "step": 87000
    },
    {
      "epoch": 26.299093655589125,
      "grad_norm": 0.47777554392814636,
      "learning_rate": 4.913413897280967e-05,
      "loss": 1.2902,
      "step": 87050
    },
    {
      "epoch": 26.299093655589125,
      "eval_loss": 1.308796763420105,
      "eval_runtime": 670.1822,
      "eval_samples_per_second": 79.231,
      "eval_steps_per_second": 0.619,
      "step": 87050
    },
    {
      "epoch": 26.31419939577039,
      "grad_norm": 0.43397146463394165,
      "learning_rate": 4.912406847935549e-05,
      "loss": 1.292,
      "step": 87100
    },
    {
      "epoch": 26.31419939577039,
      "eval_loss": 1.3089104890823364,
      "eval_runtime": 607.0095,
      "eval_samples_per_second": 87.476,
      "eval_steps_per_second": 0.684,
      "step": 87100
    },
    {
      "epoch": 26.32930513595166,
      "grad_norm": 0.447512686252594,
      "learning_rate": 4.911399798590131e-05,
      "loss": 1.2949,
      "step": 87150
    },
    {
      "epoch": 26.32930513595166,
      "eval_loss": 1.3098195791244507,
      "eval_runtime": 625.8895,
      "eval_samples_per_second": 84.838,
      "eval_steps_per_second": 0.663,
      "step": 87150
    },
    {
      "epoch": 26.34441087613293,
      "grad_norm": 0.47402724623680115,
      "learning_rate": 4.910392749244714e-05,
      "loss": 1.2814,
      "step": 87200
    },
    {
      "epoch": 26.34441087613293,
      "eval_loss": 1.3079053163528442,
      "eval_runtime": 643.2358,
      "eval_samples_per_second": 82.55,
      "eval_steps_per_second": 0.645,
      "step": 87200
    },
    {
      "epoch": 26.3595166163142,
      "grad_norm": 0.5163097977638245,
      "learning_rate": 4.9093856998992956e-05,
      "loss": 1.2741,
      "step": 87250
    },
    {
      "epoch": 26.3595166163142,
      "eval_loss": 1.3091964721679688,
      "eval_runtime": 709.8381,
      "eval_samples_per_second": 74.804,
      "eval_steps_per_second": 0.585,
      "step": 87250
    },
    {
      "epoch": 26.37462235649547,
      "grad_norm": 0.4582723379135132,
      "learning_rate": 4.9083786505538774e-05,
      "loss": 1.2891,
      "step": 87300
    },
    {
      "epoch": 26.37462235649547,
      "eval_loss": 1.3092284202575684,
      "eval_runtime": 599.689,
      "eval_samples_per_second": 88.544,
      "eval_steps_per_second": 0.692,
      "step": 87300
    },
    {
      "epoch": 26.389728096676738,
      "grad_norm": 0.4872133731842041,
      "learning_rate": 4.907371601208459e-05,
      "loss": 1.2719,
      "step": 87350
    },
    {
      "epoch": 26.389728096676738,
      "eval_loss": 1.3084262609481812,
      "eval_runtime": 670.3166,
      "eval_samples_per_second": 79.215,
      "eval_steps_per_second": 0.619,
      "step": 87350
    },
    {
      "epoch": 26.404833836858007,
      "grad_norm": 0.4575880467891693,
      "learning_rate": 4.906364551863042e-05,
      "loss": 1.2814,
      "step": 87400
    },
    {
      "epoch": 26.404833836858007,
      "eval_loss": 1.309099555015564,
      "eval_runtime": 648.9159,
      "eval_samples_per_second": 81.827,
      "eval_steps_per_second": 0.64,
      "step": 87400
    },
    {
      "epoch": 26.419939577039276,
      "grad_norm": 0.43580788373947144,
      "learning_rate": 4.905357502517624e-05,
      "loss": 1.2769,
      "step": 87450
    },
    {
      "epoch": 26.419939577039276,
      "eval_loss": 1.3082891702651978,
      "eval_runtime": 678.2788,
      "eval_samples_per_second": 78.285,
      "eval_steps_per_second": 0.612,
      "step": 87450
    },
    {
      "epoch": 26.435045317220546,
      "grad_norm": 0.43831542134284973,
      "learning_rate": 4.9043504531722056e-05,
      "loss": 1.2746,
      "step": 87500
    },
    {
      "epoch": 26.435045317220546,
      "eval_loss": 1.3080657720565796,
      "eval_runtime": 671.738,
      "eval_samples_per_second": 79.047,
      "eval_steps_per_second": 0.618,
      "step": 87500
    },
    {
      "epoch": 26.45015105740181,
      "grad_norm": 0.511167585849762,
      "learning_rate": 4.9033434038267875e-05,
      "loss": 1.2785,
      "step": 87550
    },
    {
      "epoch": 26.45015105740181,
      "eval_loss": 1.3078231811523438,
      "eval_runtime": 697.0644,
      "eval_samples_per_second": 76.175,
      "eval_steps_per_second": 0.595,
      "step": 87550
    },
    {
      "epoch": 26.46525679758308,
      "grad_norm": 0.4460999667644501,
      "learning_rate": 4.90233635448137e-05,
      "loss": 1.2609,
      "step": 87600
    },
    {
      "epoch": 26.46525679758308,
      "eval_loss": 1.3075977563858032,
      "eval_runtime": 703.8477,
      "eval_samples_per_second": 75.441,
      "eval_steps_per_second": 0.59,
      "step": 87600
    },
    {
      "epoch": 26.48036253776435,
      "grad_norm": 0.4779299199581146,
      "learning_rate": 4.901329305135952e-05,
      "loss": 1.2671,
      "step": 87650
    },
    {
      "epoch": 26.48036253776435,
      "eval_loss": 1.3097929954528809,
      "eval_runtime": 655.0114,
      "eval_samples_per_second": 81.066,
      "eval_steps_per_second": 0.634,
      "step": 87650
    },
    {
      "epoch": 26.49546827794562,
      "grad_norm": 0.46421095728874207,
      "learning_rate": 4.900322255790534e-05,
      "loss": 1.2677,
      "step": 87700
    },
    {
      "epoch": 26.49546827794562,
      "eval_loss": 1.309765338897705,
      "eval_runtime": 661.9062,
      "eval_samples_per_second": 80.221,
      "eval_steps_per_second": 0.627,
      "step": 87700
    },
    {
      "epoch": 26.51057401812689,
      "grad_norm": 0.4680522680282593,
      "learning_rate": 4.8993152064451156e-05,
      "loss": 1.2787,
      "step": 87750
    },
    {
      "epoch": 26.51057401812689,
      "eval_loss": 1.3078322410583496,
      "eval_runtime": 705.5536,
      "eval_samples_per_second": 75.259,
      "eval_steps_per_second": 0.588,
      "step": 87750
    },
    {
      "epoch": 26.525679758308158,
      "grad_norm": 0.4585959017276764,
      "learning_rate": 4.898308157099698e-05,
      "loss": 1.2856,
      "step": 87800
    },
    {
      "epoch": 26.525679758308158,
      "eval_loss": 1.3082489967346191,
      "eval_runtime": 704.729,
      "eval_samples_per_second": 75.347,
      "eval_steps_per_second": 0.589,
      "step": 87800
    },
    {
      "epoch": 26.540785498489427,
      "grad_norm": 0.4520396292209625,
      "learning_rate": 4.89730110775428e-05,
      "loss": 1.2856,
      "step": 87850
    },
    {
      "epoch": 26.540785498489427,
      "eval_loss": 1.3086707592010498,
      "eval_runtime": 704.4765,
      "eval_samples_per_second": 75.374,
      "eval_steps_per_second": 0.589,
      "step": 87850
    },
    {
      "epoch": 26.555891238670696,
      "grad_norm": 0.45333969593048096,
      "learning_rate": 4.896294058408862e-05,
      "loss": 1.2779,
      "step": 87900
    },
    {
      "epoch": 26.555891238670696,
      "eval_loss": 1.3088853359222412,
      "eval_runtime": 667.5647,
      "eval_samples_per_second": 79.541,
      "eval_steps_per_second": 0.622,
      "step": 87900
    },
    {
      "epoch": 26.570996978851962,
      "grad_norm": 0.4695514738559723,
      "learning_rate": 4.895287009063444e-05,
      "loss": 1.2761,
      "step": 87950
    },
    {
      "epoch": 26.570996978851962,
      "eval_loss": 1.3080947399139404,
      "eval_runtime": 655.2558,
      "eval_samples_per_second": 81.036,
      "eval_steps_per_second": 0.633,
      "step": 87950
    },
    {
      "epoch": 26.58610271903323,
      "grad_norm": 0.42338302731513977,
      "learning_rate": 4.894279959718026e-05,
      "loss": 1.2701,
      "step": 88000
    },
    {
      "epoch": 26.58610271903323,
      "eval_loss": 1.3130509853363037,
      "eval_runtime": 658.6004,
      "eval_samples_per_second": 80.624,
      "eval_steps_per_second": 0.63,
      "step": 88000
    },
    {
      "epoch": 26.6012084592145,
      "grad_norm": 0.48872092366218567,
      "learning_rate": 4.893272910372608e-05,
      "loss": 1.2844,
      "step": 88050
    },
    {
      "epoch": 26.6012084592145,
      "eval_loss": 1.3078795671463013,
      "eval_runtime": 675.3467,
      "eval_samples_per_second": 78.625,
      "eval_steps_per_second": 0.614,
      "step": 88050
    },
    {
      "epoch": 26.61631419939577,
      "grad_norm": 0.4625745117664337,
      "learning_rate": 4.89226586102719e-05,
      "loss": 1.2858,
      "step": 88100
    },
    {
      "epoch": 26.61631419939577,
      "eval_loss": 1.3077625036239624,
      "eval_runtime": 706.7582,
      "eval_samples_per_second": 75.13,
      "eval_steps_per_second": 0.587,
      "step": 88100
    },
    {
      "epoch": 26.63141993957704,
      "grad_norm": 0.4521857500076294,
      "learning_rate": 4.891258811681772e-05,
      "loss": 1.2926,
      "step": 88150
    },
    {
      "epoch": 26.63141993957704,
      "eval_loss": 1.3096038103103638,
      "eval_runtime": 692.0193,
      "eval_samples_per_second": 76.731,
      "eval_steps_per_second": 0.6,
      "step": 88150
    },
    {
      "epoch": 26.64652567975831,
      "grad_norm": 0.5310091972351074,
      "learning_rate": 4.8902517623363545e-05,
      "loss": 1.2926,
      "step": 88200
    },
    {
      "epoch": 26.64652567975831,
      "eval_loss": 1.3098957538604736,
      "eval_runtime": 676.2489,
      "eval_samples_per_second": 78.52,
      "eval_steps_per_second": 0.614,
      "step": 88200
    },
    {
      "epoch": 26.661631419939578,
      "grad_norm": 0.5064386129379272,
      "learning_rate": 4.889244712990937e-05,
      "loss": 1.298,
      "step": 88250
    },
    {
      "epoch": 26.661631419939578,
      "eval_loss": 1.3075345754623413,
      "eval_runtime": 650.6707,
      "eval_samples_per_second": 81.607,
      "eval_steps_per_second": 0.638,
      "step": 88250
    },
    {
      "epoch": 26.676737160120847,
      "grad_norm": 0.46745264530181885,
      "learning_rate": 4.888237663645519e-05,
      "loss": 1.2822,
      "step": 88300
    },
    {
      "epoch": 26.676737160120847,
      "eval_loss": 1.3079713582992554,
      "eval_runtime": 893.7708,
      "eval_samples_per_second": 59.41,
      "eval_steps_per_second": 0.464,
      "step": 88300
    },
    {
      "epoch": 26.691842900302113,
      "grad_norm": 0.4537753462791443,
      "learning_rate": 4.8872306143001014e-05,
      "loss": 1.2852,
      "step": 88350
    },
    {
      "epoch": 26.691842900302113,
      "eval_loss": 1.3084779977798462,
      "eval_runtime": 683.7061,
      "eval_samples_per_second": 77.663,
      "eval_steps_per_second": 0.607,
      "step": 88350
    },
    {
      "epoch": 26.706948640483382,
      "grad_norm": 0.49029040336608887,
      "learning_rate": 4.886223564954683e-05,
      "loss": 1.2568,
      "step": 88400
    },
    {
      "epoch": 26.706948640483382,
      "eval_loss": 1.3082462549209595,
      "eval_runtime": 672.6056,
      "eval_samples_per_second": 78.945,
      "eval_steps_per_second": 0.617,
      "step": 88400
    },
    {
      "epoch": 26.72205438066465,
      "grad_norm": 0.46070972084999084,
      "learning_rate": 4.885216515609265e-05,
      "loss": 1.2831,
      "step": 88450
    },
    {
      "epoch": 26.72205438066465,
      "eval_loss": 1.308377742767334,
      "eval_runtime": 686.6942,
      "eval_samples_per_second": 77.326,
      "eval_steps_per_second": 0.604,
      "step": 88450
    },
    {
      "epoch": 26.73716012084592,
      "grad_norm": 0.47314727306365967,
      "learning_rate": 4.884209466263847e-05,
      "loss": 1.2748,
      "step": 88500
    },
    {
      "epoch": 26.73716012084592,
      "eval_loss": 1.3073906898498535,
      "eval_runtime": 802.6431,
      "eval_samples_per_second": 66.155,
      "eval_steps_per_second": 0.517,
      "step": 88500
    },
    {
      "epoch": 26.75226586102719,
      "grad_norm": 0.44528859853744507,
      "learning_rate": 4.8832024169184296e-05,
      "loss": 1.2933,
      "step": 88550
    },
    {
      "epoch": 26.75226586102719,
      "eval_loss": 1.3073731660842896,
      "eval_runtime": 590.9583,
      "eval_samples_per_second": 89.852,
      "eval_steps_per_second": 0.702,
      "step": 88550
    },
    {
      "epoch": 26.76737160120846,
      "grad_norm": 0.5285518765449524,
      "learning_rate": 4.8821953675730115e-05,
      "loss": 1.2719,
      "step": 88600
    },
    {
      "epoch": 26.76737160120846,
      "eval_loss": 1.3088915348052979,
      "eval_runtime": 690.082,
      "eval_samples_per_second": 76.946,
      "eval_steps_per_second": 0.601,
      "step": 88600
    },
    {
      "epoch": 26.78247734138973,
      "grad_norm": 0.46713167428970337,
      "learning_rate": 4.881188318227593e-05,
      "loss": 1.2905,
      "step": 88650
    },
    {
      "epoch": 26.78247734138973,
      "eval_loss": 1.3075244426727295,
      "eval_runtime": 707.2276,
      "eval_samples_per_second": 75.08,
      "eval_steps_per_second": 0.587,
      "step": 88650
    },
    {
      "epoch": 26.797583081571,
      "grad_norm": 0.4891170263290405,
      "learning_rate": 4.880181268882175e-05,
      "loss": 1.2872,
      "step": 88700
    },
    {
      "epoch": 26.797583081571,
      "eval_loss": 1.3089687824249268,
      "eval_runtime": 635.7228,
      "eval_samples_per_second": 83.525,
      "eval_steps_per_second": 0.653,
      "step": 88700
    },
    {
      "epoch": 26.812688821752268,
      "grad_norm": 0.48541173338890076,
      "learning_rate": 4.879174219536758e-05,
      "loss": 1.2913,
      "step": 88750
    },
    {
      "epoch": 26.812688821752268,
      "eval_loss": 1.3062881231307983,
      "eval_runtime": 646.8152,
      "eval_samples_per_second": 82.093,
      "eval_steps_per_second": 0.642,
      "step": 88750
    },
    {
      "epoch": 26.827794561933533,
      "grad_norm": 0.46360668540000916,
      "learning_rate": 4.8781671701913396e-05,
      "loss": 1.3018,
      "step": 88800
    },
    {
      "epoch": 26.827794561933533,
      "eval_loss": 1.3063077926635742,
      "eval_runtime": 705.9014,
      "eval_samples_per_second": 75.222,
      "eval_steps_per_second": 0.588,
      "step": 88800
    },
    {
      "epoch": 26.842900302114803,
      "grad_norm": 0.4751562476158142,
      "learning_rate": 4.8771601208459215e-05,
      "loss": 1.2931,
      "step": 88850
    },
    {
      "epoch": 26.842900302114803,
      "eval_loss": 1.3075025081634521,
      "eval_runtime": 600.9506,
      "eval_samples_per_second": 88.358,
      "eval_steps_per_second": 0.691,
      "step": 88850
    },
    {
      "epoch": 26.858006042296072,
      "grad_norm": 0.4280494749546051,
      "learning_rate": 4.8761530715005033e-05,
      "loss": 1.2814,
      "step": 88900
    },
    {
      "epoch": 26.858006042296072,
      "eval_loss": 1.3067690134048462,
      "eval_runtime": 606.3541,
      "eval_samples_per_second": 87.571,
      "eval_steps_per_second": 0.684,
      "step": 88900
    },
    {
      "epoch": 26.87311178247734,
      "grad_norm": 0.43289902806282043,
      "learning_rate": 4.875146022155086e-05,
      "loss": 1.2914,
      "step": 88950
    },
    {
      "epoch": 26.87311178247734,
      "eval_loss": 1.3084264993667603,
      "eval_runtime": 660.3513,
      "eval_samples_per_second": 80.41,
      "eval_steps_per_second": 0.628,
      "step": 88950
    },
    {
      "epoch": 26.88821752265861,
      "grad_norm": 0.4405214786529541,
      "learning_rate": 4.874138972809668e-05,
      "loss": 1.3043,
      "step": 89000
    },
    {
      "epoch": 26.88821752265861,
      "eval_loss": 1.3061860799789429,
      "eval_runtime": 699.2642,
      "eval_samples_per_second": 75.936,
      "eval_steps_per_second": 0.593,
      "step": 89000
    },
    {
      "epoch": 26.90332326283988,
      "grad_norm": 0.46328452229499817,
      "learning_rate": 4.8731319234642496e-05,
      "loss": 1.275,
      "step": 89050
    },
    {
      "epoch": 26.90332326283988,
      "eval_loss": 1.306117057800293,
      "eval_runtime": 711.6712,
      "eval_samples_per_second": 74.612,
      "eval_steps_per_second": 0.583,
      "step": 89050
    },
    {
      "epoch": 26.91842900302115,
      "grad_norm": 0.46960657835006714,
      "learning_rate": 4.8721248741188315e-05,
      "loss": 1.2806,
      "step": 89100
    },
    {
      "epoch": 26.91842900302115,
      "eval_loss": 1.305894374847412,
      "eval_runtime": 696.6317,
      "eval_samples_per_second": 76.222,
      "eval_steps_per_second": 0.596,
      "step": 89100
    },
    {
      "epoch": 26.93353474320242,
      "grad_norm": 0.5016254186630249,
      "learning_rate": 4.871117824773414e-05,
      "loss": 1.2953,
      "step": 89150
    },
    {
      "epoch": 26.93353474320242,
      "eval_loss": 1.305936336517334,
      "eval_runtime": 688.2776,
      "eval_samples_per_second": 77.148,
      "eval_steps_per_second": 0.603,
      "step": 89150
    },
    {
      "epoch": 26.948640483383684,
      "grad_norm": 0.45696839690208435,
      "learning_rate": 4.870110775427996e-05,
      "loss": 1.2981,
      "step": 89200
    },
    {
      "epoch": 26.948640483383684,
      "eval_loss": 1.306859016418457,
      "eval_runtime": 682.8679,
      "eval_samples_per_second": 77.759,
      "eval_steps_per_second": 0.608,
      "step": 89200
    },
    {
      "epoch": 26.963746223564954,
      "grad_norm": 0.45820605754852295,
      "learning_rate": 4.869103726082578e-05,
      "loss": 1.2767,
      "step": 89250
    },
    {
      "epoch": 26.963746223564954,
      "eval_loss": 1.307800054550171,
      "eval_runtime": 660.6844,
      "eval_samples_per_second": 80.37,
      "eval_steps_per_second": 0.628,
      "step": 89250
    },
    {
      "epoch": 26.978851963746223,
      "grad_norm": 0.4302898645401001,
      "learning_rate": 4.8680966767371596e-05,
      "loss": 1.2804,
      "step": 89300
    },
    {
      "epoch": 26.978851963746223,
      "eval_loss": 1.3077787160873413,
      "eval_runtime": 658.8673,
      "eval_samples_per_second": 80.591,
      "eval_steps_per_second": 0.63,
      "step": 89300
    },
    {
      "epoch": 26.993957703927492,
      "grad_norm": 0.4841464161872864,
      "learning_rate": 4.867089627391742e-05,
      "loss": 1.2942,
      "step": 89350
    },
    {
      "epoch": 26.993957703927492,
      "eval_loss": 1.3048309087753296,
      "eval_runtime": 705.205,
      "eval_samples_per_second": 75.296,
      "eval_steps_per_second": 0.588,
      "step": 89350
    },
    {
      "epoch": 27.00906344410876,
      "grad_norm": 0.4414893686771393,
      "learning_rate": 4.866082578046325e-05,
      "loss": 1.2762,
      "step": 89400
    },
    {
      "epoch": 27.00906344410876,
      "eval_loss": 1.3089014291763306,
      "eval_runtime": 770.0076,
      "eval_samples_per_second": 68.959,
      "eval_steps_per_second": 0.539,
      "step": 89400
    },
    {
      "epoch": 27.02416918429003,
      "grad_norm": 0.46688252687454224,
      "learning_rate": 4.8650755287009066e-05,
      "loss": 1.2611,
      "step": 89450
    },
    {
      "epoch": 27.02416918429003,
      "eval_loss": 1.3062480688095093,
      "eval_runtime": 691.2844,
      "eval_samples_per_second": 76.812,
      "eval_steps_per_second": 0.6,
      "step": 89450
    },
    {
      "epoch": 27.0392749244713,
      "grad_norm": 0.4584994912147522,
      "learning_rate": 4.864068479355489e-05,
      "loss": 1.2795,
      "step": 89500
    },
    {
      "epoch": 27.0392749244713,
      "eval_loss": 1.3064547777175903,
      "eval_runtime": 713.1352,
      "eval_samples_per_second": 74.459,
      "eval_steps_per_second": 0.582,
      "step": 89500
    },
    {
      "epoch": 27.05438066465257,
      "grad_norm": 0.4959431290626526,
      "learning_rate": 4.863061430010071e-05,
      "loss": 1.2841,
      "step": 89550
    },
    {
      "epoch": 27.05438066465257,
      "eval_loss": 1.3062618970870972,
      "eval_runtime": 655.1564,
      "eval_samples_per_second": 81.048,
      "eval_steps_per_second": 0.633,
      "step": 89550
    },
    {
      "epoch": 27.069486404833835,
      "grad_norm": 0.49780261516571045,
      "learning_rate": 4.862054380664653e-05,
      "loss": 1.2719,
      "step": 89600
    },
    {
      "epoch": 27.069486404833835,
      "eval_loss": 1.3076790571212769,
      "eval_runtime": 903.0518,
      "eval_samples_per_second": 58.8,
      "eval_steps_per_second": 0.46,
      "step": 89600
    },
    {
      "epoch": 27.084592145015105,
      "grad_norm": 0.48589497804641724,
      "learning_rate": 4.861047331319235e-05,
      "loss": 1.2641,
      "step": 89650
    },
    {
      "epoch": 27.084592145015105,
      "eval_loss": 1.3084850311279297,
      "eval_runtime": 705.4955,
      "eval_samples_per_second": 75.265,
      "eval_steps_per_second": 0.588,
      "step": 89650
    },
    {
      "epoch": 27.099697885196374,
      "grad_norm": 0.4902888238430023,
      "learning_rate": 4.860040281973817e-05,
      "loss": 1.2518,
      "step": 89700
    },
    {
      "epoch": 27.099697885196374,
      "eval_loss": 1.3049566745758057,
      "eval_runtime": 641.1988,
      "eval_samples_per_second": 82.812,
      "eval_steps_per_second": 0.647,
      "step": 89700
    },
    {
      "epoch": 27.114803625377643,
      "grad_norm": 0.44859078526496887,
      "learning_rate": 4.859033232628399e-05,
      "loss": 1.275,
      "step": 89750
    },
    {
      "epoch": 27.114803625377643,
      "eval_loss": 1.3067042827606201,
      "eval_runtime": 691.1593,
      "eval_samples_per_second": 76.826,
      "eval_steps_per_second": 0.6,
      "step": 89750
    },
    {
      "epoch": 27.129909365558913,
      "grad_norm": 0.4999149739742279,
      "learning_rate": 4.858026183282981e-05,
      "loss": 1.2892,
      "step": 89800
    },
    {
      "epoch": 27.129909365558913,
      "eval_loss": 1.3076180219650269,
      "eval_runtime": 671.738,
      "eval_samples_per_second": 79.047,
      "eval_steps_per_second": 0.618,
      "step": 89800
    },
    {
      "epoch": 27.145015105740182,
      "grad_norm": 0.4252629280090332,
      "learning_rate": 4.857019133937563e-05,
      "loss": 1.2784,
      "step": 89850
    },
    {
      "epoch": 27.145015105740182,
      "eval_loss": 1.304753065109253,
      "eval_runtime": 714.7581,
      "eval_samples_per_second": 74.289,
      "eval_steps_per_second": 0.581,
      "step": 89850
    },
    {
      "epoch": 27.16012084592145,
      "grad_norm": 0.4709084630012512,
      "learning_rate": 4.8560120845921455e-05,
      "loss": 1.2825,
      "step": 89900
    },
    {
      "epoch": 27.16012084592145,
      "eval_loss": 1.3066428899765015,
      "eval_runtime": 587.0925,
      "eval_samples_per_second": 90.444,
      "eval_steps_per_second": 0.707,
      "step": 89900
    },
    {
      "epoch": 27.17522658610272,
      "grad_norm": 0.4935730993747711,
      "learning_rate": 4.855005035246727e-05,
      "loss": 1.2766,
      "step": 89950
    },
    {
      "epoch": 27.17522658610272,
      "eval_loss": 1.3059401512145996,
      "eval_runtime": 706.8895,
      "eval_samples_per_second": 75.116,
      "eval_steps_per_second": 0.587,
      "step": 89950
    },
    {
      "epoch": 27.190332326283986,
      "grad_norm": 0.47408899664878845,
      "learning_rate": 4.853997985901309e-05,
      "loss": 1.282,
      "step": 90000
    },
    {
      "epoch": 27.190332326283986,
      "eval_loss": 1.3052456378936768,
      "eval_runtime": 608.615,
      "eval_samples_per_second": 87.246,
      "eval_steps_per_second": 0.682,
      "step": 90000
    },
    {
      "epoch": 27.205438066465256,
      "grad_norm": 0.42001548409461975,
      "learning_rate": 4.852990936555891e-05,
      "loss": 1.2801,
      "step": 90050
    },
    {
      "epoch": 27.205438066465256,
      "eval_loss": 1.3061755895614624,
      "eval_runtime": 714.8026,
      "eval_samples_per_second": 74.285,
      "eval_steps_per_second": 0.581,
      "step": 90050
    },
    {
      "epoch": 27.220543806646525,
      "grad_norm": 0.475521981716156,
      "learning_rate": 4.8519838872104736e-05,
      "loss": 1.2664,
      "step": 90100
    },
    {
      "epoch": 27.220543806646525,
      "eval_loss": 1.306143045425415,
      "eval_runtime": 645.1994,
      "eval_samples_per_second": 82.299,
      "eval_steps_per_second": 0.643,
      "step": 90100
    },
    {
      "epoch": 27.235649546827794,
      "grad_norm": 0.425575315952301,
      "learning_rate": 4.8509768378650555e-05,
      "loss": 1.2995,
      "step": 90150
    },
    {
      "epoch": 27.235649546827794,
      "eval_loss": 1.307366132736206,
      "eval_runtime": 708.4899,
      "eval_samples_per_second": 74.947,
      "eval_steps_per_second": 0.586,
      "step": 90150
    },
    {
      "epoch": 27.250755287009063,
      "grad_norm": 0.5802826881408691,
      "learning_rate": 4.8499697885196373e-05,
      "loss": 1.2686,
      "step": 90200
    },
    {
      "epoch": 27.250755287009063,
      "eval_loss": 1.3062303066253662,
      "eval_runtime": 661.5424,
      "eval_samples_per_second": 80.265,
      "eval_steps_per_second": 0.627,
      "step": 90200
    },
    {
      "epoch": 27.265861027190333,
      "grad_norm": 0.4282177984714508,
      "learning_rate": 4.848962739174219e-05,
      "loss": 1.2909,
      "step": 90250
    },
    {
      "epoch": 27.265861027190333,
      "eval_loss": 1.3055293560028076,
      "eval_runtime": 624.582,
      "eval_samples_per_second": 85.015,
      "eval_steps_per_second": 0.664,
      "step": 90250
    },
    {
      "epoch": 27.280966767371602,
      "grad_norm": 0.4442974328994751,
      "learning_rate": 4.847955689828802e-05,
      "loss": 1.2874,
      "step": 90300
    },
    {
      "epoch": 27.280966767371602,
      "eval_loss": 1.3076220750808716,
      "eval_runtime": 646.8522,
      "eval_samples_per_second": 82.088,
      "eval_steps_per_second": 0.642,
      "step": 90300
    },
    {
      "epoch": 27.29607250755287,
      "grad_norm": 0.5068663358688354,
      "learning_rate": 4.8469486404833836e-05,
      "loss": 1.2889,
      "step": 90350
    },
    {
      "epoch": 27.29607250755287,
      "eval_loss": 1.304722547531128,
      "eval_runtime": 985.918,
      "eval_samples_per_second": 53.857,
      "eval_steps_per_second": 0.421,
      "step": 90350
    },
    {
      "epoch": 27.31117824773414,
      "grad_norm": 0.5055004954338074,
      "learning_rate": 4.8459415911379655e-05,
      "loss": 1.2854,
      "step": 90400
    },
    {
      "epoch": 27.31117824773414,
      "eval_loss": 1.303646206855774,
      "eval_runtime": 601.0026,
      "eval_samples_per_second": 88.351,
      "eval_steps_per_second": 0.691,
      "step": 90400
    },
    {
      "epoch": 27.326283987915406,
      "grad_norm": 0.47017765045166016,
      "learning_rate": 4.8449345417925474e-05,
      "loss": 1.2802,
      "step": 90450
    },
    {
      "epoch": 27.326283987915406,
      "eval_loss": 1.3059933185577393,
      "eval_runtime": 636.2221,
      "eval_samples_per_second": 83.46,
      "eval_steps_per_second": 0.652,
      "step": 90450
    },
    {
      "epoch": 27.341389728096676,
      "grad_norm": 0.46088603138923645,
      "learning_rate": 4.84392749244713e-05,
      "loss": 1.2885,
      "step": 90500
    },
    {
      "epoch": 27.341389728096676,
      "eval_loss": 1.3037418127059937,
      "eval_runtime": 755.4311,
      "eval_samples_per_second": 70.29,
      "eval_steps_per_second": 0.549,
      "step": 90500
    },
    {
      "epoch": 27.356495468277945,
      "grad_norm": 0.5551289319992065,
      "learning_rate": 4.842920443101712e-05,
      "loss": 1.2799,
      "step": 90550
    },
    {
      "epoch": 27.356495468277945,
      "eval_loss": 1.3061171770095825,
      "eval_runtime": 672.7881,
      "eval_samples_per_second": 78.924,
      "eval_steps_per_second": 0.617,
      "step": 90550
    },
    {
      "epoch": 27.371601208459214,
      "grad_norm": 0.5093063712120056,
      "learning_rate": 4.841913393756294e-05,
      "loss": 1.2839,
      "step": 90600
    },
    {
      "epoch": 27.371601208459214,
      "eval_loss": 1.3051130771636963,
      "eval_runtime": 647.6674,
      "eval_samples_per_second": 81.985,
      "eval_steps_per_second": 0.641,
      "step": 90600
    },
    {
      "epoch": 27.386706948640484,
      "grad_norm": 0.4232286214828491,
      "learning_rate": 4.840906344410877e-05,
      "loss": 1.2868,
      "step": 90650
    },
    {
      "epoch": 27.386706948640484,
      "eval_loss": 1.3065029382705688,
      "eval_runtime": 697.6316,
      "eval_samples_per_second": 76.113,
      "eval_steps_per_second": 0.595,
      "step": 90650
    },
    {
      "epoch": 27.401812688821753,
      "grad_norm": 0.4553993344306946,
      "learning_rate": 4.839899295065459e-05,
      "loss": 1.2858,
      "step": 90700
    },
    {
      "epoch": 27.401812688821753,
      "eval_loss": 1.3040127754211426,
      "eval_runtime": 678.084,
      "eval_samples_per_second": 78.307,
      "eval_steps_per_second": 0.612,
      "step": 90700
    },
    {
      "epoch": 27.416918429003022,
      "grad_norm": 0.5080986618995667,
      "learning_rate": 4.8388922457200406e-05,
      "loss": 1.2819,
      "step": 90750
    },
    {
      "epoch": 27.416918429003022,
      "eval_loss": 1.3069140911102295,
      "eval_runtime": 635.237,
      "eval_samples_per_second": 83.589,
      "eval_steps_per_second": 0.653,
      "step": 90750
    },
    {
      "epoch": 27.43202416918429,
      "grad_norm": 0.5207749605178833,
      "learning_rate": 4.8378851963746225e-05,
      "loss": 1.2849,
      "step": 90800
    },
    {
      "epoch": 27.43202416918429,
      "eval_loss": 1.3064762353897095,
      "eval_runtime": 625.4893,
      "eval_samples_per_second": 84.892,
      "eval_steps_per_second": 0.663,
      "step": 90800
    },
    {
      "epoch": 27.447129909365557,
      "grad_norm": 0.462350994348526,
      "learning_rate": 4.836878147029205e-05,
      "loss": 1.2735,
      "step": 90850
    },
    {
      "epoch": 27.447129909365557,
      "eval_loss": 1.306149959564209,
      "eval_runtime": 952.0804,
      "eval_samples_per_second": 55.772,
      "eval_steps_per_second": 0.436,
      "step": 90850
    },
    {
      "epoch": 27.462235649546827,
      "grad_norm": 0.4568938612937927,
      "learning_rate": 4.835871097683787e-05,
      "loss": 1.2731,
      "step": 90900
    },
    {
      "epoch": 27.462235649546827,
      "eval_loss": 1.3020473718643188,
      "eval_runtime": 611.1826,
      "eval_samples_per_second": 86.879,
      "eval_steps_per_second": 0.679,
      "step": 90900
    },
    {
      "epoch": 27.477341389728096,
      "grad_norm": 0.45598453283309937,
      "learning_rate": 4.834864048338369e-05,
      "loss": 1.302,
      "step": 90950
    },
    {
      "epoch": 27.477341389728096,
      "eval_loss": 1.3018635511398315,
      "eval_runtime": 676.1377,
      "eval_samples_per_second": 78.533,
      "eval_steps_per_second": 0.614,
      "step": 90950
    },
    {
      "epoch": 27.492447129909365,
      "grad_norm": 0.4682573974132538,
      "learning_rate": 4.8338569989929506e-05,
      "loss": 1.2417,
      "step": 91000
    },
    {
      "epoch": 27.492447129909365,
      "eval_loss": 1.304464340209961,
      "eval_runtime": 652.5258,
      "eval_samples_per_second": 81.375,
      "eval_steps_per_second": 0.636,
      "step": 91000
    },
    {
      "epoch": 27.507552870090635,
      "grad_norm": 0.5188936591148376,
      "learning_rate": 4.832849949647533e-05,
      "loss": 1.29,
      "step": 91050
    },
    {
      "epoch": 27.507552870090635,
      "eval_loss": 1.3043195009231567,
      "eval_runtime": 659.3508,
      "eval_samples_per_second": 80.532,
      "eval_steps_per_second": 0.629,
      "step": 91050
    },
    {
      "epoch": 27.522658610271904,
      "grad_norm": 0.46745193004608154,
      "learning_rate": 4.831842900302115e-05,
      "loss": 1.2807,
      "step": 91100
    },
    {
      "epoch": 27.522658610271904,
      "eval_loss": 1.3054943084716797,
      "eval_runtime": 614.5617,
      "eval_samples_per_second": 86.401,
      "eval_steps_per_second": 0.675,
      "step": 91100
    },
    {
      "epoch": 27.537764350453173,
      "grad_norm": 0.43298089504241943,
      "learning_rate": 4.830835850956697e-05,
      "loss": 1.2742,
      "step": 91150
    },
    {
      "epoch": 27.537764350453173,
      "eval_loss": 1.3047231435775757,
      "eval_runtime": 705.2197,
      "eval_samples_per_second": 75.294,
      "eval_steps_per_second": 0.588,
      "step": 91150
    },
    {
      "epoch": 27.552870090634443,
      "grad_norm": 0.4902052879333496,
      "learning_rate": 4.829828801611279e-05,
      "loss": 1.2784,
      "step": 91200
    },
    {
      "epoch": 27.552870090634443,
      "eval_loss": 1.3022301197052002,
      "eval_runtime": 645.2166,
      "eval_samples_per_second": 82.296,
      "eval_steps_per_second": 0.643,
      "step": 91200
    },
    {
      "epoch": 27.56797583081571,
      "grad_norm": 0.49310341477394104,
      "learning_rate": 4.828821752265861e-05,
      "loss": 1.2982,
      "step": 91250
    },
    {
      "epoch": 27.56797583081571,
      "eval_loss": 1.3024098873138428,
      "eval_runtime": 606.159,
      "eval_samples_per_second": 87.599,
      "eval_steps_per_second": 0.685,
      "step": 91250
    },
    {
      "epoch": 27.583081570996978,
      "grad_norm": 0.46623826026916504,
      "learning_rate": 4.827814702920443e-05,
      "loss": 1.2723,
      "step": 91300
    },
    {
      "epoch": 27.583081570996978,
      "eval_loss": 1.3059443235397339,
      "eval_runtime": 710.142,
      "eval_samples_per_second": 74.772,
      "eval_steps_per_second": 0.584,
      "step": 91300
    },
    {
      "epoch": 27.598187311178247,
      "grad_norm": 0.4786323606967926,
      "learning_rate": 4.826807653575025e-05,
      "loss": 1.2798,
      "step": 91350
    },
    {
      "epoch": 27.598187311178247,
      "eval_loss": 1.3044767379760742,
      "eval_runtime": 689.3255,
      "eval_samples_per_second": 77.03,
      "eval_steps_per_second": 0.602,
      "step": 91350
    },
    {
      "epoch": 27.613293051359516,
      "grad_norm": 0.43485990166664124,
      "learning_rate": 4.825800604229607e-05,
      "loss": 1.2967,
      "step": 91400
    },
    {
      "epoch": 27.613293051359516,
      "eval_loss": 1.3041937351226807,
      "eval_runtime": 686.2933,
      "eval_samples_per_second": 77.371,
      "eval_steps_per_second": 0.605,
      "step": 91400
    },
    {
      "epoch": 27.628398791540786,
      "grad_norm": 0.45809242129325867,
      "learning_rate": 4.8247935548841895e-05,
      "loss": 1.2724,
      "step": 91450
    },
    {
      "epoch": 27.628398791540786,
      "eval_loss": 1.303673267364502,
      "eval_runtime": 632.5334,
      "eval_samples_per_second": 83.947,
      "eval_steps_per_second": 0.656,
      "step": 91450
    },
    {
      "epoch": 27.643504531722055,
      "grad_norm": 0.47750622034072876,
      "learning_rate": 4.8237865055387713e-05,
      "loss": 1.2939,
      "step": 91500
    },
    {
      "epoch": 27.643504531722055,
      "eval_loss": 1.3043019771575928,
      "eval_runtime": 675.6535,
      "eval_samples_per_second": 78.589,
      "eval_steps_per_second": 0.614,
      "step": 91500
    },
    {
      "epoch": 27.658610271903324,
      "grad_norm": 0.5154668092727661,
      "learning_rate": 4.822779456193353e-05,
      "loss": 1.2806,
      "step": 91550
    },
    {
      "epoch": 27.658610271903324,
      "eval_loss": 1.3041503429412842,
      "eval_runtime": 708.7268,
      "eval_samples_per_second": 74.922,
      "eval_steps_per_second": 0.586,
      "step": 91550
    },
    {
      "epoch": 27.673716012084594,
      "grad_norm": 0.45112717151641846,
      "learning_rate": 4.821772406847935e-05,
      "loss": 1.2845,
      "step": 91600
    },
    {
      "epoch": 27.673716012084594,
      "eval_loss": 1.3031333684921265,
      "eval_runtime": 669.2227,
      "eval_samples_per_second": 79.344,
      "eval_steps_per_second": 0.62,
      "step": 91600
    },
    {
      "epoch": 27.68882175226586,
      "grad_norm": 0.518778383731842,
      "learning_rate": 4.8207653575025176e-05,
      "loss": 1.2807,
      "step": 91650
    },
    {
      "epoch": 27.68882175226586,
      "eval_loss": 1.30573570728302,
      "eval_runtime": 682.4095,
      "eval_samples_per_second": 77.811,
      "eval_steps_per_second": 0.608,
      "step": 91650
    },
    {
      "epoch": 27.70392749244713,
      "grad_norm": 0.4249962270259857,
      "learning_rate": 4.8197583081570995e-05,
      "loss": 1.2935,
      "step": 91700
    },
    {
      "epoch": 27.70392749244713,
      "eval_loss": 1.3029495477676392,
      "eval_runtime": 670.3808,
      "eval_samples_per_second": 79.207,
      "eval_steps_per_second": 0.619,
      "step": 91700
    },
    {
      "epoch": 27.719033232628398,
      "grad_norm": 0.4889061152935028,
      "learning_rate": 4.818751258811682e-05,
      "loss": 1.2904,
      "step": 91750
    },
    {
      "epoch": 27.719033232628398,
      "eval_loss": 1.3020375967025757,
      "eval_runtime": 633.4387,
      "eval_samples_per_second": 83.827,
      "eval_steps_per_second": 0.655,
      "step": 91750
    },
    {
      "epoch": 27.734138972809667,
      "grad_norm": 0.47378918528556824,
      "learning_rate": 4.8177442094662646e-05,
      "loss": 1.2723,
      "step": 91800
    },
    {
      "epoch": 27.734138972809667,
      "eval_loss": 1.302176833152771,
      "eval_runtime": 992.4552,
      "eval_samples_per_second": 53.503,
      "eval_steps_per_second": 0.418,
      "step": 91800
    },
    {
      "epoch": 27.749244712990937,
      "grad_norm": 0.5009889602661133,
      "learning_rate": 4.8167371601208465e-05,
      "loss": 1.2846,
      "step": 91850
    },
    {
      "epoch": 27.749244712990937,
      "eval_loss": 1.3043842315673828,
      "eval_runtime": 674.0123,
      "eval_samples_per_second": 78.78,
      "eval_steps_per_second": 0.616,
      "step": 91850
    },
    {
      "epoch": 27.764350453172206,
      "grad_norm": 0.42516693472862244,
      "learning_rate": 4.815730110775428e-05,
      "loss": 1.2811,
      "step": 91900
    },
    {
      "epoch": 27.764350453172206,
      "eval_loss": 1.3052537441253662,
      "eval_runtime": 663.7849,
      "eval_samples_per_second": 79.994,
      "eval_steps_per_second": 0.625,
      "step": 91900
    },
    {
      "epoch": 27.779456193353475,
      "grad_norm": 0.4646083414554596,
      "learning_rate": 4.81472306143001e-05,
      "loss": 1.2782,
      "step": 91950
    },
    {
      "epoch": 27.779456193353475,
      "eval_loss": 1.303588628768921,
      "eval_runtime": 629.5234,
      "eval_samples_per_second": 84.348,
      "eval_steps_per_second": 0.659,
      "step": 91950
    },
    {
      "epoch": 27.794561933534744,
      "grad_norm": 0.4926406741142273,
      "learning_rate": 4.813716012084593e-05,
      "loss": 1.2622,
      "step": 92000
    },
    {
      "epoch": 27.794561933534744,
      "eval_loss": 1.3023818731307983,
      "eval_runtime": 871.2134,
      "eval_samples_per_second": 60.948,
      "eval_steps_per_second": 0.476,
      "step": 92000
    },
    {
      "epoch": 27.809667673716014,
      "grad_norm": 0.4711741805076599,
      "learning_rate": 4.8127089627391746e-05,
      "loss": 1.2897,
      "step": 92050
    },
    {
      "epoch": 27.809667673716014,
      "eval_loss": 1.304891586303711,
      "eval_runtime": 783.4345,
      "eval_samples_per_second": 67.777,
      "eval_steps_per_second": 0.53,
      "step": 92050
    },
    {
      "epoch": 27.82477341389728,
      "grad_norm": 0.45796042680740356,
      "learning_rate": 4.8117019133937565e-05,
      "loss": 1.2764,
      "step": 92100
    },
    {
      "epoch": 27.82477341389728,
      "eval_loss": 1.3029359579086304,
      "eval_runtime": 710.7068,
      "eval_samples_per_second": 74.713,
      "eval_steps_per_second": 0.584,
      "step": 92100
    },
    {
      "epoch": 27.83987915407855,
      "grad_norm": 0.4399052560329437,
      "learning_rate": 4.8106948640483383e-05,
      "loss": 1.272,
      "step": 92150
    },
    {
      "epoch": 27.83987915407855,
      "eval_loss": 1.304092288017273,
      "eval_runtime": 712.7363,
      "eval_samples_per_second": 74.5,
      "eval_steps_per_second": 0.582,
      "step": 92150
    },
    {
      "epoch": 27.854984894259818,
      "grad_norm": 0.47590377926826477,
      "learning_rate": 4.809687814702921e-05,
      "loss": 1.2745,
      "step": 92200
    },
    {
      "epoch": 27.854984894259818,
      "eval_loss": 1.3052531480789185,
      "eval_runtime": 614.8137,
      "eval_samples_per_second": 86.366,
      "eval_steps_per_second": 0.675,
      "step": 92200
    },
    {
      "epoch": 27.870090634441087,
      "grad_norm": 0.5013238787651062,
      "learning_rate": 4.808680765357503e-05,
      "loss": 1.2734,
      "step": 92250
    },
    {
      "epoch": 27.870090634441087,
      "eval_loss": 1.3052597045898438,
      "eval_runtime": 611.7677,
      "eval_samples_per_second": 86.796,
      "eval_steps_per_second": 0.678,
      "step": 92250
    },
    {
      "epoch": 27.885196374622357,
      "grad_norm": 0.4631352722644806,
      "learning_rate": 4.8076737160120846e-05,
      "loss": 1.2938,
      "step": 92300
    },
    {
      "epoch": 27.885196374622357,
      "eval_loss": 1.305384874343872,
      "eval_runtime": 675.6836,
      "eval_samples_per_second": 78.586,
      "eval_steps_per_second": 0.614,
      "step": 92300
    },
    {
      "epoch": 27.900302114803626,
      "grad_norm": 0.5445376634597778,
      "learning_rate": 4.8066666666666665e-05,
      "loss": 1.287,
      "step": 92350
    },
    {
      "epoch": 27.900302114803626,
      "eval_loss": 1.305206537246704,
      "eval_runtime": 694.8784,
      "eval_samples_per_second": 76.415,
      "eval_steps_per_second": 0.597,
      "step": 92350
    },
    {
      "epoch": 27.915407854984895,
      "grad_norm": 0.4492200016975403,
      "learning_rate": 4.805659617321249e-05,
      "loss": 1.2968,
      "step": 92400
    },
    {
      "epoch": 27.915407854984895,
      "eval_loss": 1.3037078380584717,
      "eval_runtime": 629.73,
      "eval_samples_per_second": 84.32,
      "eval_steps_per_second": 0.659,
      "step": 92400
    },
    {
      "epoch": 27.930513595166165,
      "grad_norm": 0.46838805079460144,
      "learning_rate": 4.804652567975831e-05,
      "loss": 1.2661,
      "step": 92450
    },
    {
      "epoch": 27.930513595166165,
      "eval_loss": 1.3009330034255981,
      "eval_runtime": 628.9637,
      "eval_samples_per_second": 84.423,
      "eval_steps_per_second": 0.66,
      "step": 92450
    },
    {
      "epoch": 27.94561933534743,
      "grad_norm": 0.43486398458480835,
      "learning_rate": 4.803645518630413e-05,
      "loss": 1.2978,
      "step": 92500
    },
    {
      "epoch": 27.94561933534743,
      "eval_loss": 1.3013883829116821,
      "eval_runtime": 633.7698,
      "eval_samples_per_second": 83.783,
      "eval_steps_per_second": 0.655,
      "step": 92500
    },
    {
      "epoch": 27.9607250755287,
      "grad_norm": 0.478440523147583,
      "learning_rate": 4.8026384692849947e-05,
      "loss": 1.2756,
      "step": 92550
    },
    {
      "epoch": 27.9607250755287,
      "eval_loss": 1.3017654418945312,
      "eval_runtime": 591.7175,
      "eval_samples_per_second": 89.737,
      "eval_steps_per_second": 0.701,
      "step": 92550
    },
    {
      "epoch": 27.97583081570997,
      "grad_norm": 0.4510187804698944,
      "learning_rate": 4.801631419939577e-05,
      "loss": 1.2769,
      "step": 92600
    },
    {
      "epoch": 27.97583081570997,
      "eval_loss": 1.3024015426635742,
      "eval_runtime": 666.8776,
      "eval_samples_per_second": 79.623,
      "eval_steps_per_second": 0.622,
      "step": 92600
    },
    {
      "epoch": 27.99093655589124,
      "grad_norm": 0.5071067214012146,
      "learning_rate": 4.800624370594159e-05,
      "loss": 1.2739,
      "step": 92650
    },
    {
      "epoch": 27.99093655589124,
      "eval_loss": 1.303672432899475,
      "eval_runtime": 677.1352,
      "eval_samples_per_second": 78.417,
      "eval_steps_per_second": 0.613,
      "step": 92650
    },
    {
      "epoch": 28.006042296072508,
      "grad_norm": 0.5007191300392151,
      "learning_rate": 4.799617321248741e-05,
      "loss": 1.2607,
      "step": 92700
    },
    {
      "epoch": 28.006042296072508,
      "eval_loss": 1.30434250831604,
      "eval_runtime": 703.365,
      "eval_samples_per_second": 75.493,
      "eval_steps_per_second": 0.59,
      "step": 92700
    },
    {
      "epoch": 28.021148036253777,
      "grad_norm": 0.5400055646896362,
      "learning_rate": 4.798610271903323e-05,
      "loss": 1.2959,
      "step": 92750
    },
    {
      "epoch": 28.021148036253777,
      "eval_loss": 1.3029053211212158,
      "eval_runtime": 697.4817,
      "eval_samples_per_second": 76.13,
      "eval_steps_per_second": 0.595,
      "step": 92750
    },
    {
      "epoch": 28.036253776435046,
      "grad_norm": 0.45719069242477417,
      "learning_rate": 4.7976032225579053e-05,
      "loss": 1.2755,
      "step": 92800
    },
    {
      "epoch": 28.036253776435046,
      "eval_loss": 1.3038078546524048,
      "eval_runtime": 626.9285,
      "eval_samples_per_second": 84.697,
      "eval_steps_per_second": 0.662,
      "step": 92800
    },
    {
      "epoch": 28.051359516616316,
      "grad_norm": 0.48213881254196167,
      "learning_rate": 4.796596173212487e-05,
      "loss": 1.2766,
      "step": 92850
    },
    {
      "epoch": 28.051359516616316,
      "eval_loss": 1.2996629476547241,
      "eval_runtime": 708.3718,
      "eval_samples_per_second": 74.959,
      "eval_steps_per_second": 0.586,
      "step": 92850
    },
    {
      "epoch": 28.06646525679758,
      "grad_norm": 0.49075499176979065,
      "learning_rate": 4.79558912386707e-05,
      "loss": 1.2912,
      "step": 92900
    },
    {
      "epoch": 28.06646525679758,
      "eval_loss": 1.3004087209701538,
      "eval_runtime": 705.61,
      "eval_samples_per_second": 75.253,
      "eval_steps_per_second": 0.588,
      "step": 92900
    },
    {
      "epoch": 28.08157099697885,
      "grad_norm": 0.45224475860595703,
      "learning_rate": 4.794582074521652e-05,
      "loss": 1.2775,
      "step": 92950
    },
    {
      "epoch": 28.08157099697885,
      "eval_loss": 1.3030647039413452,
      "eval_runtime": 762.278,
      "eval_samples_per_second": 69.658,
      "eval_steps_per_second": 0.544,
      "step": 92950
    },
    {
      "epoch": 28.09667673716012,
      "grad_norm": 0.45335957407951355,
      "learning_rate": 4.793575025176234e-05,
      "loss": 1.287,
      "step": 93000
    },
    {
      "epoch": 28.09667673716012,
      "eval_loss": 1.3044646978378296,
      "eval_runtime": 691.7609,
      "eval_samples_per_second": 76.759,
      "eval_steps_per_second": 0.6,
      "step": 93000
    },
    {
      "epoch": 28.11178247734139,
      "grad_norm": 0.46654510498046875,
      "learning_rate": 4.792567975830816e-05,
      "loss": 1.2722,
      "step": 93050
    },
    {
      "epoch": 28.11178247734139,
      "eval_loss": 1.30315101146698,
      "eval_runtime": 706.8506,
      "eval_samples_per_second": 75.121,
      "eval_steps_per_second": 0.587,
      "step": 93050
    },
    {
      "epoch": 28.12688821752266,
      "grad_norm": 0.4360519051551819,
      "learning_rate": 4.791560926485398e-05,
      "loss": 1.2821,
      "step": 93100
    },
    {
      "epoch": 28.12688821752266,
      "eval_loss": 1.3033818006515503,
      "eval_runtime": 709.5076,
      "eval_samples_per_second": 74.839,
      "eval_steps_per_second": 0.585,
      "step": 93100
    },
    {
      "epoch": 28.141993957703928,
      "grad_norm": 0.4971073865890503,
      "learning_rate": 4.7905538771399805e-05,
      "loss": 1.2683,
      "step": 93150
    },
    {
      "epoch": 28.141993957703928,
      "eval_loss": 1.3013370037078857,
      "eval_runtime": 714.923,
      "eval_samples_per_second": 74.272,
      "eval_steps_per_second": 0.58,
      "step": 93150
    },
    {
      "epoch": 28.157099697885197,
      "grad_norm": 0.4699023962020874,
      "learning_rate": 4.789546827794562e-05,
      "loss": 1.2698,
      "step": 93200
    },
    {
      "epoch": 28.157099697885197,
      "eval_loss": 1.302777647972107,
      "eval_runtime": 674.6564,
      "eval_samples_per_second": 78.705,
      "eval_steps_per_second": 0.615,
      "step": 93200
    },
    {
      "epoch": 28.172205438066467,
      "grad_norm": 0.5084685683250427,
      "learning_rate": 4.788539778449144e-05,
      "loss": 1.2845,
      "step": 93250
    },
    {
      "epoch": 28.172205438066467,
      "eval_loss": 1.3032925128936768,
      "eval_runtime": 610.692,
      "eval_samples_per_second": 86.949,
      "eval_steps_per_second": 0.68,
      "step": 93250
    },
    {
      "epoch": 28.187311178247732,
      "grad_norm": 0.4200358986854553,
      "learning_rate": 4.787532729103726e-05,
      "loss": 1.2618,
      "step": 93300
    },
    {
      "epoch": 28.187311178247732,
      "eval_loss": 1.301113247871399,
      "eval_runtime": 654.8803,
      "eval_samples_per_second": 81.082,
      "eval_steps_per_second": 0.634,
      "step": 93300
    },
    {
      "epoch": 28.202416918429,
      "grad_norm": 0.4596119225025177,
      "learning_rate": 4.7865256797583086e-05,
      "loss": 1.2699,
      "step": 93350
    },
    {
      "epoch": 28.202416918429,
      "eval_loss": 1.2994918823242188,
      "eval_runtime": 606.9874,
      "eval_samples_per_second": 87.48,
      "eval_steps_per_second": 0.684,
      "step": 93350
    },
    {
      "epoch": 28.21752265861027,
      "grad_norm": 0.4368215501308441,
      "learning_rate": 4.7855186304128905e-05,
      "loss": 1.2971,
      "step": 93400
    },
    {
      "epoch": 28.21752265861027,
      "eval_loss": 1.3043229579925537,
      "eval_runtime": 604.6624,
      "eval_samples_per_second": 87.816,
      "eval_steps_per_second": 0.686,
      "step": 93400
    },
    {
      "epoch": 28.23262839879154,
      "grad_norm": 0.4677923321723938,
      "learning_rate": 4.7845115810674723e-05,
      "loss": 1.2781,
      "step": 93450
    },
    {
      "epoch": 28.23262839879154,
      "eval_loss": 1.3020480871200562,
      "eval_runtime": 714.147,
      "eval_samples_per_second": 74.353,
      "eval_steps_per_second": 0.581,
      "step": 93450
    },
    {
      "epoch": 28.24773413897281,
      "grad_norm": 0.45115533471107483,
      "learning_rate": 4.783504531722054e-05,
      "loss": 1.2704,
      "step": 93500
    },
    {
      "epoch": 28.24773413897281,
      "eval_loss": 1.3027688264846802,
      "eval_runtime": 635.0749,
      "eval_samples_per_second": 83.611,
      "eval_steps_per_second": 0.653,
      "step": 93500
    },
    {
      "epoch": 28.26283987915408,
      "grad_norm": 0.40576326847076416,
      "learning_rate": 4.782497482376637e-05,
      "loss": 1.2815,
      "step": 93550
    },
    {
      "epoch": 28.26283987915408,
      "eval_loss": 1.3039606809616089,
      "eval_runtime": 673.0139,
      "eval_samples_per_second": 78.897,
      "eval_steps_per_second": 0.617,
      "step": 93550
    },
    {
      "epoch": 28.27794561933535,
      "grad_norm": 0.4774651825428009,
      "learning_rate": 4.7814904330312186e-05,
      "loss": 1.2755,
      "step": 93600
    },
    {
      "epoch": 28.27794561933535,
      "eval_loss": 1.303352952003479,
      "eval_runtime": 704.2505,
      "eval_samples_per_second": 75.398,
      "eval_steps_per_second": 0.589,
      "step": 93600
    },
    {
      "epoch": 28.293051359516618,
      "grad_norm": 0.4297606348991394,
      "learning_rate": 4.7804833836858005e-05,
      "loss": 1.2707,
      "step": 93650
    },
    {
      "epoch": 28.293051359516618,
      "eval_loss": 1.3025834560394287,
      "eval_runtime": 678.5644,
      "eval_samples_per_second": 78.252,
      "eval_steps_per_second": 0.612,
      "step": 93650
    },
    {
      "epoch": 28.308157099697887,
      "grad_norm": 0.4613199532032013,
      "learning_rate": 4.7794763343403824e-05,
      "loss": 1.2814,
      "step": 93700
    },
    {
      "epoch": 28.308157099697887,
      "eval_loss": 1.3014860153198242,
      "eval_runtime": 625.158,
      "eval_samples_per_second": 84.937,
      "eval_steps_per_second": 0.664,
      "step": 93700
    },
    {
      "epoch": 28.323262839879153,
      "grad_norm": 0.42522305250167847,
      "learning_rate": 4.778469284994965e-05,
      "loss": 1.2911,
      "step": 93750
    },
    {
      "epoch": 28.323262839879153,
      "eval_loss": 1.3014270067214966,
      "eval_runtime": 782.8387,
      "eval_samples_per_second": 67.829,
      "eval_steps_per_second": 0.53,
      "step": 93750
    },
    {
      "epoch": 28.338368580060422,
      "grad_norm": 0.43471476435661316,
      "learning_rate": 4.777462235649547e-05,
      "loss": 1.2798,
      "step": 93800
    },
    {
      "epoch": 28.338368580060422,
      "eval_loss": 1.3002073764801025,
      "eval_runtime": 648.0771,
      "eval_samples_per_second": 81.933,
      "eval_steps_per_second": 0.64,
      "step": 93800
    },
    {
      "epoch": 28.35347432024169,
      "grad_norm": 0.43257585167884827,
      "learning_rate": 4.7764551863041287e-05,
      "loss": 1.262,
      "step": 93850
    },
    {
      "epoch": 28.35347432024169,
      "eval_loss": 1.3035542964935303,
      "eval_runtime": 671.0768,
      "eval_samples_per_second": 79.125,
      "eval_steps_per_second": 0.618,
      "step": 93850
    },
    {
      "epoch": 28.36858006042296,
      "grad_norm": 0.48396140336990356,
      "learning_rate": 4.7754481369587105e-05,
      "loss": 1.279,
      "step": 93900
    },
    {
      "epoch": 28.36858006042296,
      "eval_loss": 1.302677869796753,
      "eval_runtime": 620.1229,
      "eval_samples_per_second": 85.627,
      "eval_steps_per_second": 0.669,
      "step": 93900
    },
    {
      "epoch": 28.38368580060423,
      "grad_norm": 0.48655959963798523,
      "learning_rate": 4.774441087613293e-05,
      "loss": 1.2996,
      "step": 93950
    },
    {
      "epoch": 28.38368580060423,
      "eval_loss": 1.3031941652297974,
      "eval_runtime": 728.5356,
      "eval_samples_per_second": 72.885,
      "eval_steps_per_second": 0.57,
      "step": 93950
    },
    {
      "epoch": 28.3987915407855,
      "grad_norm": 0.5250278115272522,
      "learning_rate": 4.773434038267875e-05,
      "loss": 1.2751,
      "step": 94000
    },
    {
      "epoch": 28.3987915407855,
      "eval_loss": 1.302830457687378,
      "eval_runtime": 637.524,
      "eval_samples_per_second": 83.289,
      "eval_steps_per_second": 0.651,
      "step": 94000
    },
    {
      "epoch": 28.41389728096677,
      "grad_norm": 0.4520387351512909,
      "learning_rate": 4.772426988922457e-05,
      "loss": 1.2831,
      "step": 94050
    },
    {
      "epoch": 28.41389728096677,
      "eval_loss": 1.3043054342269897,
      "eval_runtime": 708.3272,
      "eval_samples_per_second": 74.964,
      "eval_steps_per_second": 0.586,
      "step": 94050
    },
    {
      "epoch": 28.429003021148038,
      "grad_norm": 0.5102301836013794,
      "learning_rate": 4.77141993957704e-05,
      "loss": 1.2824,
      "step": 94100
    },
    {
      "epoch": 28.429003021148038,
      "eval_loss": 1.301505446434021,
      "eval_runtime": 677.6592,
      "eval_samples_per_second": 78.356,
      "eval_steps_per_second": 0.612,
      "step": 94100
    },
    {
      "epoch": 28.444108761329304,
      "grad_norm": 0.435621440410614,
      "learning_rate": 4.770412890231622e-05,
      "loss": 1.2614,
      "step": 94150
    },
    {
      "epoch": 28.444108761329304,
      "eval_loss": 1.3022462129592896,
      "eval_runtime": 613.2086,
      "eval_samples_per_second": 86.592,
      "eval_steps_per_second": 0.677,
      "step": 94150
    },
    {
      "epoch": 28.459214501510573,
      "grad_norm": 0.4344462454319,
      "learning_rate": 4.769405840886204e-05,
      "loss": 1.2846,
      "step": 94200
    },
    {
      "epoch": 28.459214501510573,
      "eval_loss": 1.3011387586593628,
      "eval_runtime": 1139.9212,
      "eval_samples_per_second": 46.581,
      "eval_steps_per_second": 0.364,
      "step": 94200
    },
    {
      "epoch": 28.474320241691842,
      "grad_norm": 0.44313380122184753,
      "learning_rate": 4.7683987915407856e-05,
      "loss": 1.27,
      "step": 94250
    },
    {
      "epoch": 28.474320241691842,
      "eval_loss": 1.3028970956802368,
      "eval_runtime": 708.1679,
      "eval_samples_per_second": 74.981,
      "eval_steps_per_second": 0.586,
      "step": 94250
    },
    {
      "epoch": 28.48942598187311,
      "grad_norm": 0.4255678653717041,
      "learning_rate": 4.767391742195368e-05,
      "loss": 1.2721,
      "step": 94300
    },
    {
      "epoch": 28.48942598187311,
      "eval_loss": 1.2996058464050293,
      "eval_runtime": 655.4635,
      "eval_samples_per_second": 81.01,
      "eval_steps_per_second": 0.633,
      "step": 94300
    },
    {
      "epoch": 28.50453172205438,
      "grad_norm": 0.4655730128288269,
      "learning_rate": 4.76638469284995e-05,
      "loss": 1.2798,
      "step": 94350
    },
    {
      "epoch": 28.50453172205438,
      "eval_loss": 1.3012604713439941,
      "eval_runtime": 620.7156,
      "eval_samples_per_second": 85.545,
      "eval_steps_per_second": 0.669,
      "step": 94350
    },
    {
      "epoch": 28.51963746223565,
      "grad_norm": 0.5134410262107849,
      "learning_rate": 4.765377643504532e-05,
      "loss": 1.2873,
      "step": 94400
    },
    {
      "epoch": 28.51963746223565,
      "eval_loss": 1.3012008666992188,
      "eval_runtime": 694.6172,
      "eval_samples_per_second": 76.444,
      "eval_steps_per_second": 0.597,
      "step": 94400
    },
    {
      "epoch": 28.53474320241692,
      "grad_norm": 0.5251632928848267,
      "learning_rate": 4.764370594159114e-05,
      "loss": 1.2805,
      "step": 94450
    },
    {
      "epoch": 28.53474320241692,
      "eval_loss": 1.3016067743301392,
      "eval_runtime": 614.6606,
      "eval_samples_per_second": 86.388,
      "eval_steps_per_second": 0.675,
      "step": 94450
    },
    {
      "epoch": 28.54984894259819,
      "grad_norm": 0.468414306640625,
      "learning_rate": 4.763363544813696e-05,
      "loss": 1.27,
      "step": 94500
    },
    {
      "epoch": 28.54984894259819,
      "eval_loss": 1.2994543313980103,
      "eval_runtime": 651.0902,
      "eval_samples_per_second": 81.554,
      "eval_steps_per_second": 0.637,
      "step": 94500
    },
    {
      "epoch": 28.564954682779454,
      "grad_norm": 0.4459928572177887,
      "learning_rate": 4.762356495468278e-05,
      "loss": 1.2964,
      "step": 94550
    },
    {
      "epoch": 28.564954682779454,
      "eval_loss": 1.3012080192565918,
      "eval_runtime": 651.3836,
      "eval_samples_per_second": 81.517,
      "eval_steps_per_second": 0.637,
      "step": 94550
    },
    {
      "epoch": 28.580060422960724,
      "grad_norm": 0.4560578465461731,
      "learning_rate": 4.76134944612286e-05,
      "loss": 1.275,
      "step": 94600
    },
    {
      "epoch": 28.580060422960724,
      "eval_loss": 1.3005681037902832,
      "eval_runtime": 714.8242,
      "eval_samples_per_second": 74.283,
      "eval_steps_per_second": 0.581,
      "step": 94600
    },
    {
      "epoch": 28.595166163141993,
      "grad_norm": 0.49067485332489014,
      "learning_rate": 4.760342396777442e-05,
      "loss": 1.2869,
      "step": 94650
    },
    {
      "epoch": 28.595166163141993,
      "eval_loss": 1.302323579788208,
      "eval_runtime": 783.5029,
      "eval_samples_per_second": 67.771,
      "eval_steps_per_second": 0.53,
      "step": 94650
    },
    {
      "epoch": 28.610271903323262,
      "grad_norm": 0.48791399598121643,
      "learning_rate": 4.7593353474320245e-05,
      "loss": 1.2688,
      "step": 94700
    },
    {
      "epoch": 28.610271903323262,
      "eval_loss": 1.3015203475952148,
      "eval_runtime": 620.3942,
      "eval_samples_per_second": 85.589,
      "eval_steps_per_second": 0.669,
      "step": 94700
    },
    {
      "epoch": 28.62537764350453,
      "grad_norm": 0.43683263659477234,
      "learning_rate": 4.7583282980866064e-05,
      "loss": 1.2791,
      "step": 94750
    },
    {
      "epoch": 28.62537764350453,
      "eval_loss": 1.3005176782608032,
      "eval_runtime": 702.4164,
      "eval_samples_per_second": 75.595,
      "eval_steps_per_second": 0.591,
      "step": 94750
    },
    {
      "epoch": 28.6404833836858,
      "grad_norm": 0.46861040592193604,
      "learning_rate": 4.757321248741188e-05,
      "loss": 1.2579,
      "step": 94800
    },
    {
      "epoch": 28.6404833836858,
      "eval_loss": 1.3001772165298462,
      "eval_runtime": 600.8369,
      "eval_samples_per_second": 88.375,
      "eval_steps_per_second": 0.691,
      "step": 94800
    },
    {
      "epoch": 28.65558912386707,
      "grad_norm": 0.4362894296646118,
      "learning_rate": 4.75631419939577e-05,
      "loss": 1.2753,
      "step": 94850
    },
    {
      "epoch": 28.65558912386707,
      "eval_loss": 1.3016561269760132,
      "eval_runtime": 662.055,
      "eval_samples_per_second": 80.203,
      "eval_steps_per_second": 0.627,
      "step": 94850
    },
    {
      "epoch": 28.67069486404834,
      "grad_norm": 0.47792699933052063,
      "learning_rate": 4.7553071500503526e-05,
      "loss": 1.2917,
      "step": 94900
    },
    {
      "epoch": 28.67069486404834,
      "eval_loss": 1.2997082471847534,
      "eval_runtime": 723.8946,
      "eval_samples_per_second": 73.352,
      "eval_steps_per_second": 0.573,
      "step": 94900
    },
    {
      "epoch": 28.685800604229605,
      "grad_norm": 0.4648764431476593,
      "learning_rate": 4.7543001007049345e-05,
      "loss": 1.273,
      "step": 94950
    },
    {
      "epoch": 28.685800604229605,
      "eval_loss": 1.2997883558273315,
      "eval_runtime": 620.6148,
      "eval_samples_per_second": 85.559,
      "eval_steps_per_second": 0.669,
      "step": 94950
    },
    {
      "epoch": 28.700906344410875,
      "grad_norm": 0.4364534914493561,
      "learning_rate": 4.7532930513595164e-05,
      "loss": 1.267,
      "step": 95000
    },
    {
      "epoch": 28.700906344410875,
      "eval_loss": 1.2999240159988403,
      "eval_runtime": 643.407,
      "eval_samples_per_second": 82.528,
      "eval_steps_per_second": 0.645,
      "step": 95000
    },
    {
      "epoch": 28.716012084592144,
      "grad_norm": 0.4422009289264679,
      "learning_rate": 4.752286002014098e-05,
      "loss": 1.2557,
      "step": 95050
    },
    {
      "epoch": 28.716012084592144,
      "eval_loss": 1.3001137971878052,
      "eval_runtime": 690.7813,
      "eval_samples_per_second": 76.868,
      "eval_steps_per_second": 0.601,
      "step": 95050
    },
    {
      "epoch": 28.731117824773413,
      "grad_norm": 0.5055420994758606,
      "learning_rate": 4.751278952668681e-05,
      "loss": 1.2742,
      "step": 95100
    },
    {
      "epoch": 28.731117824773413,
      "eval_loss": 1.2997009754180908,
      "eval_runtime": 708.7315,
      "eval_samples_per_second": 74.921,
      "eval_steps_per_second": 0.586,
      "step": 95100
    },
    {
      "epoch": 28.746223564954683,
      "grad_norm": 0.4711316227912903,
      "learning_rate": 4.7502719033232627e-05,
      "loss": 1.2652,
      "step": 95150
    },
    {
      "epoch": 28.746223564954683,
      "eval_loss": 1.2992838621139526,
      "eval_runtime": 1040.3869,
      "eval_samples_per_second": 51.038,
      "eval_steps_per_second": 0.399,
      "step": 95150
    },
    {
      "epoch": 28.761329305135952,
      "grad_norm": 0.4932396411895752,
      "learning_rate": 4.7492648539778445e-05,
      "loss": 1.2652,
      "step": 95200
    },
    {
      "epoch": 28.761329305135952,
      "eval_loss": 1.3009424209594727,
      "eval_runtime": 652.3957,
      "eval_samples_per_second": 81.391,
      "eval_steps_per_second": 0.636,
      "step": 95200
    },
    {
      "epoch": 28.77643504531722,
      "grad_norm": 0.4384917914867401,
      "learning_rate": 4.748257804632428e-05,
      "loss": 1.2541,
      "step": 95250
    },
    {
      "epoch": 28.77643504531722,
      "eval_loss": 1.2973297834396362,
      "eval_runtime": 575.381,
      "eval_samples_per_second": 92.285,
      "eval_steps_per_second": 0.721,
      "step": 95250
    },
    {
      "epoch": 28.79154078549849,
      "grad_norm": 0.44357654452323914,
      "learning_rate": 4.7472507552870096e-05,
      "loss": 1.2661,
      "step": 95300
    },
    {
      "epoch": 28.79154078549849,
      "eval_loss": 1.3001023530960083,
      "eval_runtime": 619.0052,
      "eval_samples_per_second": 85.781,
      "eval_steps_per_second": 0.67,
      "step": 95300
    },
    {
      "epoch": 28.80664652567976,
      "grad_norm": 0.4244288504123688,
      "learning_rate": 4.7462437059415915e-05,
      "loss": 1.2807,
      "step": 95350
    },
    {
      "epoch": 28.80664652567976,
      "eval_loss": 1.3002276420593262,
      "eval_runtime": 708.8267,
      "eval_samples_per_second": 74.911,
      "eval_steps_per_second": 0.585,
      "step": 95350
    },
    {
      "epoch": 28.821752265861026,
      "grad_norm": 0.4505724310874939,
      "learning_rate": 4.7452366565961734e-05,
      "loss": 1.2796,
      "step": 95400
    },
    {
      "epoch": 28.821752265861026,
      "eval_loss": 1.3004013299942017,
      "eval_runtime": 631.3622,
      "eval_samples_per_second": 84.102,
      "eval_steps_per_second": 0.657,
      "step": 95400
    },
    {
      "epoch": 28.836858006042295,
      "grad_norm": 0.43746432662010193,
      "learning_rate": 4.744229607250756e-05,
      "loss": 1.2673,
      "step": 95450
    },
    {
      "epoch": 28.836858006042295,
      "eval_loss": 1.3000997304916382,
      "eval_runtime": 623.5414,
      "eval_samples_per_second": 85.157,
      "eval_steps_per_second": 0.666,
      "step": 95450
    },
    {
      "epoch": 28.851963746223564,
      "grad_norm": 0.4834735095500946,
      "learning_rate": 4.743222557905338e-05,
      "loss": 1.2759,
      "step": 95500
    },
    {
      "epoch": 28.851963746223564,
      "eval_loss": 1.3003132343292236,
      "eval_runtime": 669.2928,
      "eval_samples_per_second": 79.336,
      "eval_steps_per_second": 0.62,
      "step": 95500
    },
    {
      "epoch": 28.867069486404834,
      "grad_norm": 0.47350746393203735,
      "learning_rate": 4.7422155085599196e-05,
      "loss": 1.3085,
      "step": 95550
    },
    {
      "epoch": 28.867069486404834,
      "eval_loss": 1.298991322517395,
      "eval_runtime": 628.0758,
      "eval_samples_per_second": 84.542,
      "eval_steps_per_second": 0.661,
      "step": 95550
    },
    {
      "epoch": 28.882175226586103,
      "grad_norm": 0.5161714553833008,
      "learning_rate": 4.7412084592145015e-05,
      "loss": 1.2569,
      "step": 95600
    },
    {
      "epoch": 28.882175226586103,
      "eval_loss": 1.2993100881576538,
      "eval_runtime": 628.8527,
      "eval_samples_per_second": 84.438,
      "eval_steps_per_second": 0.66,
      "step": 95600
    },
    {
      "epoch": 28.897280966767372,
      "grad_norm": 0.49879658222198486,
      "learning_rate": 4.740201409869084e-05,
      "loss": 1.2671,
      "step": 95650
    },
    {
      "epoch": 28.897280966767372,
      "eval_loss": 1.3002805709838867,
      "eval_runtime": 717.3712,
      "eval_samples_per_second": 74.019,
      "eval_steps_per_second": 0.579,
      "step": 95650
    },
    {
      "epoch": 28.91238670694864,
      "grad_norm": 0.476411908864975,
      "learning_rate": 4.739194360523666e-05,
      "loss": 1.2628,
      "step": 95700
    },
    {
      "epoch": 28.91238670694864,
      "eval_loss": 1.2977674007415771,
      "eval_runtime": 662.6015,
      "eval_samples_per_second": 80.137,
      "eval_steps_per_second": 0.626,
      "step": 95700
    },
    {
      "epoch": 28.92749244712991,
      "grad_norm": 0.4582662582397461,
      "learning_rate": 4.738187311178248e-05,
      "loss": 1.2833,
      "step": 95750
    },
    {
      "epoch": 28.92749244712991,
      "eval_loss": 1.2973439693450928,
      "eval_runtime": 610.2669,
      "eval_samples_per_second": 87.009,
      "eval_steps_per_second": 0.68,
      "step": 95750
    },
    {
      "epoch": 28.942598187311177,
      "grad_norm": 0.4865252375602722,
      "learning_rate": 4.7371802618328297e-05,
      "loss": 1.2708,
      "step": 95800
    },
    {
      "epoch": 28.942598187311177,
      "eval_loss": 1.3006622791290283,
      "eval_runtime": 703.2433,
      "eval_samples_per_second": 75.506,
      "eval_steps_per_second": 0.59,
      "step": 95800
    },
    {
      "epoch": 28.957703927492446,
      "grad_norm": 0.4477405846118927,
      "learning_rate": 4.736173212487412e-05,
      "loss": 1.3166,
      "step": 95850
    },
    {
      "epoch": 28.957703927492446,
      "eval_loss": 1.2993372678756714,
      "eval_runtime": 642.8253,
      "eval_samples_per_second": 82.603,
      "eval_steps_per_second": 0.646,
      "step": 95850
    },
    {
      "epoch": 28.972809667673715,
      "grad_norm": 0.4473375678062439,
      "learning_rate": 4.735166163141994e-05,
      "loss": 1.2633,
      "step": 95900
    },
    {
      "epoch": 28.972809667673715,
      "eval_loss": 1.3019981384277344,
      "eval_runtime": 654.9768,
      "eval_samples_per_second": 81.07,
      "eval_steps_per_second": 0.634,
      "step": 95900
    },
    {
      "epoch": 28.987915407854985,
      "grad_norm": 0.440530002117157,
      "learning_rate": 4.734159113796576e-05,
      "loss": 1.2531,
      "step": 95950
    },
    {
      "epoch": 28.987915407854985,
      "eval_loss": 1.2982523441314697,
      "eval_runtime": 611.8596,
      "eval_samples_per_second": 86.783,
      "eval_steps_per_second": 0.678,
      "step": 95950
    },
    {
      "epoch": 29.003021148036254,
      "grad_norm": 0.458914190530777,
      "learning_rate": 4.733152064451158e-05,
      "loss": 1.2785,
      "step": 96000
    },
    {
      "epoch": 29.003021148036254,
      "eval_loss": 1.2998642921447754,
      "eval_runtime": 664.2652,
      "eval_samples_per_second": 79.936,
      "eval_steps_per_second": 0.625,
      "step": 96000
    },
    {
      "epoch": 29.018126888217523,
      "grad_norm": 0.45651304721832275,
      "learning_rate": 4.7321450151057404e-05,
      "loss": 1.2672,
      "step": 96050
    },
    {
      "epoch": 29.018126888217523,
      "eval_loss": 1.2986613512039185,
      "eval_runtime": 647.2942,
      "eval_samples_per_second": 82.032,
      "eval_steps_per_second": 0.641,
      "step": 96050
    },
    {
      "epoch": 29.033232628398792,
      "grad_norm": 0.46183085441589355,
      "learning_rate": 4.731137965760322e-05,
      "loss": 1.2803,
      "step": 96100
    },
    {
      "epoch": 29.033232628398792,
      "eval_loss": 1.298490047454834,
      "eval_runtime": 664.0471,
      "eval_samples_per_second": 79.963,
      "eval_steps_per_second": 0.625,
      "step": 96100
    },
    {
      "epoch": 29.048338368580062,
      "grad_norm": 0.5031977295875549,
      "learning_rate": 4.730130916414904e-05,
      "loss": 1.261,
      "step": 96150
    },
    {
      "epoch": 29.048338368580062,
      "eval_loss": 1.2994704246520996,
      "eval_runtime": 680.5069,
      "eval_samples_per_second": 78.029,
      "eval_steps_per_second": 0.61,
      "step": 96150
    },
    {
      "epoch": 29.063444108761328,
      "grad_norm": 0.4421798586845398,
      "learning_rate": 4.729123867069486e-05,
      "loss": 1.2684,
      "step": 96200
    },
    {
      "epoch": 29.063444108761328,
      "eval_loss": 1.2999036312103271,
      "eval_runtime": 743.2383,
      "eval_samples_per_second": 71.443,
      "eval_steps_per_second": 0.558,
      "step": 96200
    },
    {
      "epoch": 29.078549848942597,
      "grad_norm": 0.4695824384689331,
      "learning_rate": 4.7281168177240685e-05,
      "loss": 1.2734,
      "step": 96250
    },
    {
      "epoch": 29.078549848942597,
      "eval_loss": 1.2983380556106567,
      "eval_runtime": 634.3796,
      "eval_samples_per_second": 83.702,
      "eval_steps_per_second": 0.654,
      "step": 96250
    },
    {
      "epoch": 29.093655589123866,
      "grad_norm": 0.44279688596725464,
      "learning_rate": 4.7271097683786504e-05,
      "loss": 1.2749,
      "step": 96300
    },
    {
      "epoch": 29.093655589123866,
      "eval_loss": 1.300365924835205,
      "eval_runtime": 647.8708,
      "eval_samples_per_second": 81.959,
      "eval_steps_per_second": 0.641,
      "step": 96300
    },
    {
      "epoch": 29.108761329305135,
      "grad_norm": 0.6304208040237427,
      "learning_rate": 4.726102719033232e-05,
      "loss": 1.2765,
      "step": 96350
    },
    {
      "epoch": 29.108761329305135,
      "eval_loss": 1.299220085144043,
      "eval_runtime": 701.35,
      "eval_samples_per_second": 75.71,
      "eval_steps_per_second": 0.592,
      "step": 96350
    },
    {
      "epoch": 29.123867069486405,
      "grad_norm": 0.4717366695404053,
      "learning_rate": 4.7250956696878155e-05,
      "loss": 1.2651,
      "step": 96400
    },
    {
      "epoch": 29.123867069486405,
      "eval_loss": 1.3010444641113281,
      "eval_runtime": 631.2508,
      "eval_samples_per_second": 84.117,
      "eval_steps_per_second": 0.657,
      "step": 96400
    },
    {
      "epoch": 29.138972809667674,
      "grad_norm": 0.48126769065856934,
      "learning_rate": 4.724088620342397e-05,
      "loss": 1.2551,
      "step": 96450
    },
    {
      "epoch": 29.138972809667674,
      "eval_loss": 1.2979862689971924,
      "eval_runtime": 645.3204,
      "eval_samples_per_second": 82.283,
      "eval_steps_per_second": 0.643,
      "step": 96450
    },
    {
      "epoch": 29.154078549848943,
      "grad_norm": 0.43397194147109985,
      "learning_rate": 4.723081570996979e-05,
      "loss": 1.2571,
      "step": 96500
    },
    {
      "epoch": 29.154078549848943,
      "eval_loss": 1.3000104427337646,
      "eval_runtime": 719.118,
      "eval_samples_per_second": 73.839,
      "eval_steps_per_second": 0.577,
      "step": 96500
    },
    {
      "epoch": 29.169184290030213,
      "grad_norm": 0.455965518951416,
      "learning_rate": 4.722074521651561e-05,
      "loss": 1.277,
      "step": 96550
    },
    {
      "epoch": 29.169184290030213,
      "eval_loss": 1.2979636192321777,
      "eval_runtime": 630.9235,
      "eval_samples_per_second": 84.161,
      "eval_steps_per_second": 0.658,
      "step": 96550
    },
    {
      "epoch": 29.184290030211482,
      "grad_norm": 0.45336657762527466,
      "learning_rate": 4.7210674723061436e-05,
      "loss": 1.2531,
      "step": 96600
    },
    {
      "epoch": 29.184290030211482,
      "eval_loss": 1.2983932495117188,
      "eval_runtime": 704.2195,
      "eval_samples_per_second": 75.401,
      "eval_steps_per_second": 0.589,
      "step": 96600
    },
    {
      "epoch": 29.199395770392748,
      "grad_norm": 0.45945870876312256,
      "learning_rate": 4.7200604229607255e-05,
      "loss": 1.2852,
      "step": 96650
    },
    {
      "epoch": 29.199395770392748,
      "eval_loss": 1.2986071109771729,
      "eval_runtime": 703.9761,
      "eval_samples_per_second": 75.427,
      "eval_steps_per_second": 0.59,
      "step": 96650
    },
    {
      "epoch": 29.214501510574017,
      "grad_norm": 0.4905067980289459,
      "learning_rate": 4.7190533736153074e-05,
      "loss": 1.2885,
      "step": 96700
    },
    {
      "epoch": 29.214501510574017,
      "eval_loss": 1.3001823425292969,
      "eval_runtime": 708.227,
      "eval_samples_per_second": 74.975,
      "eval_steps_per_second": 0.586,
      "step": 96700
    },
    {
      "epoch": 29.229607250755286,
      "grad_norm": 0.4778378903865814,
      "learning_rate": 4.718046324269889e-05,
      "loss": 1.2716,
      "step": 96750
    },
    {
      "epoch": 29.229607250755286,
      "eval_loss": 1.2999846935272217,
      "eval_runtime": 673.3069,
      "eval_samples_per_second": 78.863,
      "eval_steps_per_second": 0.616,
      "step": 96750
    },
    {
      "epoch": 29.244712990936556,
      "grad_norm": 0.43808865547180176,
      "learning_rate": 4.717039274924472e-05,
      "loss": 1.2669,
      "step": 96800
    },
    {
      "epoch": 29.244712990936556,
      "eval_loss": 1.2961453199386597,
      "eval_runtime": 663.4119,
      "eval_samples_per_second": 80.039,
      "eval_steps_per_second": 0.626,
      "step": 96800
    },
    {
      "epoch": 29.259818731117825,
      "grad_norm": 0.42952486872673035,
      "learning_rate": 4.7160322255790536e-05,
      "loss": 1.2636,
      "step": 96850
    },
    {
      "epoch": 29.259818731117825,
      "eval_loss": 1.2963790893554688,
      "eval_runtime": 687.3146,
      "eval_samples_per_second": 77.256,
      "eval_steps_per_second": 0.604,
      "step": 96850
    },
    {
      "epoch": 29.274924471299094,
      "grad_norm": 0.45368635654449463,
      "learning_rate": 4.7150251762336355e-05,
      "loss": 1.2705,
      "step": 96900
    },
    {
      "epoch": 29.274924471299094,
      "eval_loss": 1.3001772165298462,
      "eval_runtime": 640.3968,
      "eval_samples_per_second": 82.916,
      "eval_steps_per_second": 0.648,
      "step": 96900
    },
    {
      "epoch": 29.290030211480364,
      "grad_norm": 0.4607838988304138,
      "learning_rate": 4.7140181268882174e-05,
      "loss": 1.2774,
      "step": 96950
    },
    {
      "epoch": 29.290030211480364,
      "eval_loss": 1.2994166612625122,
      "eval_runtime": 689.4104,
      "eval_samples_per_second": 77.021,
      "eval_steps_per_second": 0.602,
      "step": 96950
    },
    {
      "epoch": 29.305135951661633,
      "grad_norm": 0.46899303793907166,
      "learning_rate": 4.7130110775428e-05,
      "loss": 1.279,
      "step": 97000
    },
    {
      "epoch": 29.305135951661633,
      "eval_loss": 1.297453761100769,
      "eval_runtime": 645.9188,
      "eval_samples_per_second": 82.207,
      "eval_steps_per_second": 0.642,
      "step": 97000
    },
    {
      "epoch": 29.3202416918429,
      "grad_norm": 0.4215998947620392,
      "learning_rate": 4.712004028197382e-05,
      "loss": 1.2853,
      "step": 97050
    },
    {
      "epoch": 29.3202416918429,
      "eval_loss": 1.299307107925415,
      "eval_runtime": 651.6529,
      "eval_samples_per_second": 81.484,
      "eval_steps_per_second": 0.637,
      "step": 97050
    },
    {
      "epoch": 29.335347432024168,
      "grad_norm": 0.45194247364997864,
      "learning_rate": 4.7109969788519637e-05,
      "loss": 1.2581,
      "step": 97100
    },
    {
      "epoch": 29.335347432024168,
      "eval_loss": 1.298986792564392,
      "eval_runtime": 693.9763,
      "eval_samples_per_second": 76.514,
      "eval_steps_per_second": 0.598,
      "step": 97100
    },
    {
      "epoch": 29.350453172205437,
      "grad_norm": 0.4527895450592041,
      "learning_rate": 4.7099899295065455e-05,
      "loss": 1.27,
      "step": 97150
    },
    {
      "epoch": 29.350453172205437,
      "eval_loss": 1.299431562423706,
      "eval_runtime": 697.5308,
      "eval_samples_per_second": 76.124,
      "eval_steps_per_second": 0.595,
      "step": 97150
    },
    {
      "epoch": 29.365558912386707,
      "grad_norm": 0.449719101190567,
      "learning_rate": 4.708982880161128e-05,
      "loss": 1.26,
      "step": 97200
    },
    {
      "epoch": 29.365558912386707,
      "eval_loss": 1.2973544597625732,
      "eval_runtime": 658.1888,
      "eval_samples_per_second": 80.674,
      "eval_steps_per_second": 0.631,
      "step": 97200
    },
    {
      "epoch": 29.380664652567976,
      "grad_norm": 0.5182238221168518,
      "learning_rate": 4.70797583081571e-05,
      "loss": 1.2664,
      "step": 97250
    },
    {
      "epoch": 29.380664652567976,
      "eval_loss": 1.2981122732162476,
      "eval_runtime": 629.1013,
      "eval_samples_per_second": 84.405,
      "eval_steps_per_second": 0.66,
      "step": 97250
    },
    {
      "epoch": 29.395770392749245,
      "grad_norm": 0.43185341358184814,
      "learning_rate": 4.706968781470292e-05,
      "loss": 1.2647,
      "step": 97300
    },
    {
      "epoch": 29.395770392749245,
      "eval_loss": 1.2978906631469727,
      "eval_runtime": 673.9271,
      "eval_samples_per_second": 78.79,
      "eval_steps_per_second": 0.616,
      "step": 97300
    },
    {
      "epoch": 29.410876132930515,
      "grad_norm": 0.4491877853870392,
      "learning_rate": 4.705961732124874e-05,
      "loss": 1.2876,
      "step": 97350
    },
    {
      "epoch": 29.410876132930515,
      "eval_loss": 1.2984036207199097,
      "eval_runtime": 681.8702,
      "eval_samples_per_second": 77.873,
      "eval_steps_per_second": 0.609,
      "step": 97350
    },
    {
      "epoch": 29.425981873111784,
      "grad_norm": 0.47278979420661926,
      "learning_rate": 4.704954682779456e-05,
      "loss": 1.278,
      "step": 97400
    },
    {
      "epoch": 29.425981873111784,
      "eval_loss": 1.298398494720459,
      "eval_runtime": 709.8138,
      "eval_samples_per_second": 74.807,
      "eval_steps_per_second": 0.585,
      "step": 97400
    },
    {
      "epoch": 29.44108761329305,
      "grad_norm": 0.4750141203403473,
      "learning_rate": 4.703947633434038e-05,
      "loss": 1.2762,
      "step": 97450
    },
    {
      "epoch": 29.44108761329305,
      "eval_loss": 1.2976500988006592,
      "eval_runtime": 613.6547,
      "eval_samples_per_second": 86.529,
      "eval_steps_per_second": 0.676,
      "step": 97450
    },
    {
      "epoch": 29.45619335347432,
      "grad_norm": 0.42467638850212097,
      "learning_rate": 4.70294058408862e-05,
      "loss": 1.2719,
      "step": 97500
    },
    {
      "epoch": 29.45619335347432,
      "eval_loss": 1.3004767894744873,
      "eval_runtime": 695.3745,
      "eval_samples_per_second": 76.36,
      "eval_steps_per_second": 0.597,
      "step": 97500
    },
    {
      "epoch": 29.47129909365559,
      "grad_norm": 0.46091511845588684,
      "learning_rate": 4.701933534743203e-05,
      "loss": 1.2647,
      "step": 97550
    },
    {
      "epoch": 29.47129909365559,
      "eval_loss": 1.2956173419952393,
      "eval_runtime": 631.8232,
      "eval_samples_per_second": 84.041,
      "eval_steps_per_second": 0.657,
      "step": 97550
    },
    {
      "epoch": 29.486404833836858,
      "grad_norm": 0.4631686210632324,
      "learning_rate": 4.700926485397785e-05,
      "loss": 1.2989,
      "step": 97600
    },
    {
      "epoch": 29.486404833836858,
      "eval_loss": 1.2963743209838867,
      "eval_runtime": 689.7958,
      "eval_samples_per_second": 76.978,
      "eval_steps_per_second": 0.602,
      "step": 97600
    },
    {
      "epoch": 29.501510574018127,
      "grad_norm": 0.4892071783542633,
      "learning_rate": 4.699919436052367e-05,
      "loss": 1.2684,
      "step": 97650
    },
    {
      "epoch": 29.501510574018127,
      "eval_loss": 1.2970774173736572,
      "eval_runtime": 728.4971,
      "eval_samples_per_second": 72.888,
      "eval_steps_per_second": 0.57,
      "step": 97650
    },
    {
      "epoch": 29.516616314199396,
      "grad_norm": 0.5031654238700867,
      "learning_rate": 4.698912386706949e-05,
      "loss": 1.2688,
      "step": 97700
    },
    {
      "epoch": 29.516616314199396,
      "eval_loss": 1.2983015775680542,
      "eval_runtime": 945.5565,
      "eval_samples_per_second": 56.156,
      "eval_steps_per_second": 0.439,
      "step": 97700
    },
    {
      "epoch": 29.531722054380666,
      "grad_norm": 0.4746204912662506,
      "learning_rate": 4.697905337361531e-05,
      "loss": 1.262,
      "step": 97750
    },
    {
      "epoch": 29.531722054380666,
      "eval_loss": 1.297767996788025,
      "eval_runtime": 673.6505,
      "eval_samples_per_second": 78.823,
      "eval_steps_per_second": 0.616,
      "step": 97750
    },
    {
      "epoch": 29.546827794561935,
      "grad_norm": 0.46857357025146484,
      "learning_rate": 4.696898288016113e-05,
      "loss": 1.2802,
      "step": 97800
    },
    {
      "epoch": 29.546827794561935,
      "eval_loss": 1.2995431423187256,
      "eval_runtime": 768.9838,
      "eval_samples_per_second": 69.051,
      "eval_steps_per_second": 0.54,
      "step": 97800
    },
    {
      "epoch": 29.561933534743204,
      "grad_norm": 0.4592112600803375,
      "learning_rate": 4.695891238670695e-05,
      "loss": 1.2642,
      "step": 97850
    },
    {
      "epoch": 29.561933534743204,
      "eval_loss": 1.2965589761734009,
      "eval_runtime": 611.6477,
      "eval_samples_per_second": 86.813,
      "eval_steps_per_second": 0.678,
      "step": 97850
    },
    {
      "epoch": 29.57703927492447,
      "grad_norm": 0.43387162685394287,
      "learning_rate": 4.694884189325277e-05,
      "loss": 1.275,
      "step": 97900
    },
    {
      "epoch": 29.57703927492447,
      "eval_loss": 1.2970885038375854,
      "eval_runtime": 667.1944,
      "eval_samples_per_second": 79.585,
      "eval_steps_per_second": 0.622,
      "step": 97900
    },
    {
      "epoch": 29.59214501510574,
      "grad_norm": 0.46262240409851074,
      "learning_rate": 4.6938771399798595e-05,
      "loss": 1.2645,
      "step": 97950
    },
    {
      "epoch": 29.59214501510574,
      "eval_loss": 1.297634482383728,
      "eval_runtime": 653.4956,
      "eval_samples_per_second": 81.254,
      "eval_steps_per_second": 0.635,
      "step": 97950
    },
    {
      "epoch": 29.60725075528701,
      "grad_norm": 0.4524041712284088,
      "learning_rate": 4.6928700906344414e-05,
      "loss": 1.2848,
      "step": 98000
    },
    {
      "epoch": 29.60725075528701,
      "eval_loss": 1.2962380647659302,
      "eval_runtime": 692.4294,
      "eval_samples_per_second": 76.685,
      "eval_steps_per_second": 0.599,
      "step": 98000
    },
    {
      "epoch": 29.622356495468278,
      "grad_norm": 0.4453446567058563,
      "learning_rate": 4.691863041289023e-05,
      "loss": 1.281,
      "step": 98050
    },
    {
      "epoch": 29.622356495468278,
      "eval_loss": 1.2963353395462036,
      "eval_runtime": 727.5016,
      "eval_samples_per_second": 72.988,
      "eval_steps_per_second": 0.57,
      "step": 98050
    },
    {
      "epoch": 29.637462235649547,
      "grad_norm": 0.4529944062232971,
      "learning_rate": 4.690855991943605e-05,
      "loss": 1.2718,
      "step": 98100
    },
    {
      "epoch": 29.637462235649547,
      "eval_loss": 1.2974116802215576,
      "eval_runtime": 734.7302,
      "eval_samples_per_second": 72.27,
      "eval_steps_per_second": 0.565,
      "step": 98100
    },
    {
      "epoch": 29.652567975830816,
      "grad_norm": 0.4628339409828186,
      "learning_rate": 4.6898489425981876e-05,
      "loss": 1.2816,
      "step": 98150
    },
    {
      "epoch": 29.652567975830816,
      "eval_loss": 1.296647071838379,
      "eval_runtime": 628.3439,
      "eval_samples_per_second": 84.506,
      "eval_steps_per_second": 0.66,
      "step": 98150
    },
    {
      "epoch": 29.667673716012086,
      "grad_norm": 0.45784425735473633,
      "learning_rate": 4.6888418932527695e-05,
      "loss": 1.247,
      "step": 98200
    },
    {
      "epoch": 29.667673716012086,
      "eval_loss": 1.2955396175384521,
      "eval_runtime": 707.6138,
      "eval_samples_per_second": 75.04,
      "eval_steps_per_second": 0.586,
      "step": 98200
    },
    {
      "epoch": 29.682779456193355,
      "grad_norm": 0.4853931963443756,
      "learning_rate": 4.6878348439073514e-05,
      "loss": 1.2737,
      "step": 98250
    },
    {
      "epoch": 29.682779456193355,
      "eval_loss": 1.2963019609451294,
      "eval_runtime": 614.6014,
      "eval_samples_per_second": 86.396,
      "eval_steps_per_second": 0.675,
      "step": 98250
    },
    {
      "epoch": 29.69788519637462,
      "grad_norm": 0.4706984758377075,
      "learning_rate": 4.686827794561933e-05,
      "loss": 1.293,
      "step": 98300
    },
    {
      "epoch": 29.69788519637462,
      "eval_loss": 1.297791600227356,
      "eval_runtime": 663.6695,
      "eval_samples_per_second": 80.008,
      "eval_steps_per_second": 0.625,
      "step": 98300
    },
    {
      "epoch": 29.71299093655589,
      "grad_norm": 0.43978455662727356,
      "learning_rate": 4.685820745216516e-05,
      "loss": 1.2624,
      "step": 98350
    },
    {
      "epoch": 29.71299093655589,
      "eval_loss": 1.2971127033233643,
      "eval_runtime": 676.1264,
      "eval_samples_per_second": 78.534,
      "eval_steps_per_second": 0.614,
      "step": 98350
    },
    {
      "epoch": 29.72809667673716,
      "grad_norm": 0.43476080894470215,
      "learning_rate": 4.684813695871098e-05,
      "loss": 1.282,
      "step": 98400
    },
    {
      "epoch": 29.72809667673716,
      "eval_loss": 1.2969499826431274,
      "eval_runtime": 706.0498,
      "eval_samples_per_second": 75.206,
      "eval_steps_per_second": 0.588,
      "step": 98400
    },
    {
      "epoch": 29.74320241691843,
      "grad_norm": 0.4803276062011719,
      "learning_rate": 4.6838066465256795e-05,
      "loss": 1.2683,
      "step": 98450
    },
    {
      "epoch": 29.74320241691843,
      "eval_loss": 1.298991084098816,
      "eval_runtime": 604.4582,
      "eval_samples_per_second": 87.846,
      "eval_steps_per_second": 0.687,
      "step": 98450
    },
    {
      "epoch": 29.758308157099698,
      "grad_norm": 0.4312417507171631,
      "learning_rate": 4.6827995971802614e-05,
      "loss": 1.2651,
      "step": 98500
    },
    {
      "epoch": 29.758308157099698,
      "eval_loss": 1.2970768213272095,
      "eval_runtime": 608.8334,
      "eval_samples_per_second": 87.214,
      "eval_steps_per_second": 0.682,
      "step": 98500
    },
    {
      "epoch": 29.773413897280967,
      "grad_norm": 0.4831579327583313,
      "learning_rate": 4.681792547834844e-05,
      "loss": 1.2709,
      "step": 98550
    },
    {
      "epoch": 29.773413897280967,
      "eval_loss": 1.2966264486312866,
      "eval_runtime": 726.8593,
      "eval_samples_per_second": 73.053,
      "eval_steps_per_second": 0.571,
      "step": 98550
    },
    {
      "epoch": 29.788519637462237,
      "grad_norm": 0.453061044216156,
      "learning_rate": 4.680785498489426e-05,
      "loss": 1.256,
      "step": 98600
    },
    {
      "epoch": 29.788519637462237,
      "eval_loss": 1.2965433597564697,
      "eval_runtime": 663.0996,
      "eval_samples_per_second": 80.077,
      "eval_steps_per_second": 0.626,
      "step": 98600
    },
    {
      "epoch": 29.803625377643506,
      "grad_norm": 0.41142576932907104,
      "learning_rate": 4.679778449144008e-05,
      "loss": 1.2746,
      "step": 98650
    },
    {
      "epoch": 29.803625377643506,
      "eval_loss": 1.2957298755645752,
      "eval_runtime": 716.7683,
      "eval_samples_per_second": 74.081,
      "eval_steps_per_second": 0.579,
      "step": 98650
    },
    {
      "epoch": 29.818731117824772,
      "grad_norm": 0.4410691559314728,
      "learning_rate": 4.67877139979859e-05,
      "loss": 1.2725,
      "step": 98700
    },
    {
      "epoch": 29.818731117824772,
      "eval_loss": 1.2956385612487793,
      "eval_runtime": 704.5625,
      "eval_samples_per_second": 75.364,
      "eval_steps_per_second": 0.589,
      "step": 98700
    },
    {
      "epoch": 29.83383685800604,
      "grad_norm": 0.4725739061832428,
      "learning_rate": 4.677764350453173e-05,
      "loss": 1.2782,
      "step": 98750
    },
    {
      "epoch": 29.83383685800604,
      "eval_loss": 1.2961578369140625,
      "eval_runtime": 688.8418,
      "eval_samples_per_second": 77.084,
      "eval_steps_per_second": 0.602,
      "step": 98750
    },
    {
      "epoch": 29.84894259818731,
      "grad_norm": 0.4276091158390045,
      "learning_rate": 4.6767573011077546e-05,
      "loss": 1.2917,
      "step": 98800
    },
    {
      "epoch": 29.84894259818731,
      "eval_loss": 1.2973146438598633,
      "eval_runtime": 651.3647,
      "eval_samples_per_second": 81.52,
      "eval_steps_per_second": 0.637,
      "step": 98800
    },
    {
      "epoch": 29.86404833836858,
      "grad_norm": 0.4893152117729187,
      "learning_rate": 4.6757502517623365e-05,
      "loss": 1.2532,
      "step": 98850
    },
    {
      "epoch": 29.86404833836858,
      "eval_loss": 1.2971160411834717,
      "eval_runtime": 659.0699,
      "eval_samples_per_second": 80.567,
      "eval_steps_per_second": 0.63,
      "step": 98850
    },
    {
      "epoch": 29.87915407854985,
      "grad_norm": 0.48660096526145935,
      "learning_rate": 4.674743202416919e-05,
      "loss": 1.2834,
      "step": 98900
    },
    {
      "epoch": 29.87915407854985,
      "eval_loss": 1.2980380058288574,
      "eval_runtime": 611.0488,
      "eval_samples_per_second": 86.898,
      "eval_steps_per_second": 0.679,
      "step": 98900
    },
    {
      "epoch": 29.89425981873112,
      "grad_norm": 0.46738892793655396,
      "learning_rate": 4.673736153071501e-05,
      "loss": 1.2746,
      "step": 98950
    },
    {
      "epoch": 29.89425981873112,
      "eval_loss": 1.2946141958236694,
      "eval_runtime": 616.989,
      "eval_samples_per_second": 86.062,
      "eval_steps_per_second": 0.673,
      "step": 98950
    },
    {
      "epoch": 29.909365558912388,
      "grad_norm": 0.44311830401420593,
      "learning_rate": 4.672729103726083e-05,
      "loss": 1.2913,
      "step": 99000
    },
    {
      "epoch": 29.909365558912388,
      "eval_loss": 1.296705722808838,
      "eval_runtime": 674.3561,
      "eval_samples_per_second": 78.74,
      "eval_steps_per_second": 0.615,
      "step": 99000
    },
    {
      "epoch": 29.924471299093657,
      "grad_norm": 0.443665474653244,
      "learning_rate": 4.671722054380665e-05,
      "loss": 1.2856,
      "step": 99050
    },
    {
      "epoch": 29.924471299093657,
      "eval_loss": 1.2970837354660034,
      "eval_runtime": 641.5875,
      "eval_samples_per_second": 82.762,
      "eval_steps_per_second": 0.647,
      "step": 99050
    },
    {
      "epoch": 29.939577039274923,
      "grad_norm": 0.4843054711818695,
      "learning_rate": 4.670715005035247e-05,
      "loss": 1.2962,
      "step": 99100
    },
    {
      "epoch": 29.939577039274923,
      "eval_loss": 1.2954858541488647,
      "eval_runtime": 627.9605,
      "eval_samples_per_second": 84.558,
      "eval_steps_per_second": 0.661,
      "step": 99100
    },
    {
      "epoch": 29.954682779456192,
      "grad_norm": 0.4748570919036865,
      "learning_rate": 4.669707955689829e-05,
      "loss": 1.2752,
      "step": 99150
    },
    {
      "epoch": 29.954682779456192,
      "eval_loss": 1.2983683347702026,
      "eval_runtime": 689.1521,
      "eval_samples_per_second": 77.05,
      "eval_steps_per_second": 0.602,
      "step": 99150
    },
    {
      "epoch": 29.96978851963746,
      "grad_norm": 0.4420233368873596,
      "learning_rate": 4.668700906344411e-05,
      "loss": 1.2794,
      "step": 99200
    },
    {
      "epoch": 29.96978851963746,
      "eval_loss": 1.2936285734176636,
      "eval_runtime": 644.8808,
      "eval_samples_per_second": 82.339,
      "eval_steps_per_second": 0.644,
      "step": 99200
    },
    {
      "epoch": 29.98489425981873,
      "grad_norm": 0.43698886036872864,
      "learning_rate": 4.667693856998993e-05,
      "loss": 1.2601,
      "step": 99250
    },
    {
      "epoch": 29.98489425981873,
      "eval_loss": 1.2951151132583618,
      "eval_runtime": 745.1467,
      "eval_samples_per_second": 71.26,
      "eval_steps_per_second": 0.557,
      "step": 99250
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.4576821029186249,
      "learning_rate": 4.6666868076535754e-05,
      "loss": 1.2768,
      "step": 99300
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.2954680919647217,
      "eval_runtime": 680.566,
      "eval_samples_per_second": 78.022,
      "eval_steps_per_second": 0.61,
      "step": 99300
    },
    {
      "epoch": 30.01510574018127,
      "grad_norm": 0.49768924713134766,
      "learning_rate": 4.665679758308157e-05,
      "loss": 1.2832,
      "step": 99350
    },
    {
      "epoch": 30.01510574018127,
      "eval_loss": 1.2942712306976318,
      "eval_runtime": 652.0858,
      "eval_samples_per_second": 81.429,
      "eval_steps_per_second": 0.636,
      "step": 99350
    },
    {
      "epoch": 30.03021148036254,
      "grad_norm": 0.4564651846885681,
      "learning_rate": 4.664672708962739e-05,
      "loss": 1.2752,
      "step": 99400
    },
    {
      "epoch": 30.03021148036254,
      "eval_loss": 1.2965786457061768,
      "eval_runtime": 698.5243,
      "eval_samples_per_second": 76.016,
      "eval_steps_per_second": 0.594,
      "step": 99400
    },
    {
      "epoch": 30.045317220543808,
      "grad_norm": 0.4504666030406952,
      "learning_rate": 4.663665659617321e-05,
      "loss": 1.2708,
      "step": 99450
    },
    {
      "epoch": 30.045317220543808,
      "eval_loss": 1.2945365905761719,
      "eval_runtime": 710.2929,
      "eval_samples_per_second": 74.756,
      "eval_steps_per_second": 0.584,
      "step": 99450
    },
    {
      "epoch": 30.060422960725077,
      "grad_norm": 0.4492913782596588,
      "learning_rate": 4.6626586102719035e-05,
      "loss": 1.262,
      "step": 99500
    },
    {
      "epoch": 30.060422960725077,
      "eval_loss": 1.2950085401535034,
      "eval_runtime": 676.1279,
      "eval_samples_per_second": 78.534,
      "eval_steps_per_second": 0.614,
      "step": 99500
    },
    {
      "epoch": 30.075528700906343,
      "grad_norm": 0.4541398286819458,
      "learning_rate": 4.6616515609264854e-05,
      "loss": 1.2608,
      "step": 99550
    },
    {
      "epoch": 30.075528700906343,
      "eval_loss": 1.2945984601974487,
      "eval_runtime": 702.1965,
      "eval_samples_per_second": 75.618,
      "eval_steps_per_second": 0.591,
      "step": 99550
    },
    {
      "epoch": 30.090634441087612,
      "grad_norm": 0.5154846906661987,
      "learning_rate": 4.660644511581067e-05,
      "loss": 1.2518,
      "step": 99600
    },
    {
      "epoch": 30.090634441087612,
      "eval_loss": 1.2966102361679077,
      "eval_runtime": 634.5682,
      "eval_samples_per_second": 83.677,
      "eval_steps_per_second": 0.654,
      "step": 99600
    },
    {
      "epoch": 30.10574018126888,
      "grad_norm": 0.4716598093509674,
      "learning_rate": 4.65963746223565e-05,
      "loss": 1.2746,
      "step": 99650
    },
    {
      "epoch": 30.10574018126888,
      "eval_loss": 1.297359585762024,
      "eval_runtime": 602.545,
      "eval_samples_per_second": 88.125,
      "eval_steps_per_second": 0.689,
      "step": 99650
    },
    {
      "epoch": 30.12084592145015,
      "grad_norm": 0.4669826328754425,
      "learning_rate": 4.658630412890232e-05,
      "loss": 1.2637,
      "step": 99700
    },
    {
      "epoch": 30.12084592145015,
      "eval_loss": 1.293396234512329,
      "eval_runtime": 654.6965,
      "eval_samples_per_second": 81.105,
      "eval_steps_per_second": 0.634,
      "step": 99700
    },
    {
      "epoch": 30.13595166163142,
      "grad_norm": 0.4431989789009094,
      "learning_rate": 4.6576233635448135e-05,
      "loss": 1.2682,
      "step": 99750
    },
    {
      "epoch": 30.13595166163142,
      "eval_loss": 1.2967838048934937,
      "eval_runtime": 613.3327,
      "eval_samples_per_second": 86.575,
      "eval_steps_per_second": 0.677,
      "step": 99750
    },
    {
      "epoch": 30.15105740181269,
      "grad_norm": 0.4419807195663452,
      "learning_rate": 4.6566163141993954e-05,
      "loss": 1.2754,
      "step": 99800
    },
    {
      "epoch": 30.15105740181269,
      "eval_loss": 1.2956277132034302,
      "eval_runtime": 710.6136,
      "eval_samples_per_second": 74.723,
      "eval_steps_per_second": 0.584,
      "step": 99800
    },
    {
      "epoch": 30.16616314199396,
      "grad_norm": 0.47896361351013184,
      "learning_rate": 4.655609264853978e-05,
      "loss": 1.2727,
      "step": 99850
    },
    {
      "epoch": 30.16616314199396,
      "eval_loss": 1.2972140312194824,
      "eval_runtime": 599.5552,
      "eval_samples_per_second": 88.564,
      "eval_steps_per_second": 0.692,
      "step": 99850
    },
    {
      "epoch": 30.181268882175228,
      "grad_norm": 0.4578366279602051,
      "learning_rate": 4.6546022155085605e-05,
      "loss": 1.2738,
      "step": 99900
    },
    {
      "epoch": 30.181268882175228,
      "eval_loss": 1.2941172122955322,
      "eval_runtime": 642.8974,
      "eval_samples_per_second": 82.593,
      "eval_steps_per_second": 0.646,
      "step": 99900
    },
    {
      "epoch": 30.196374622356494,
      "grad_norm": 0.48543739318847656,
      "learning_rate": 4.6535951661631424e-05,
      "loss": 1.2806,
      "step": 99950
    },
    {
      "epoch": 30.196374622356494,
      "eval_loss": 1.2938679456710815,
      "eval_runtime": 648.1306,
      "eval_samples_per_second": 81.926,
      "eval_steps_per_second": 0.64,
      "step": 99950
    },
    {
      "epoch": 30.211480362537763,
      "grad_norm": 0.4674395024776459,
      "learning_rate": 4.652588116817724e-05,
      "loss": 1.2657,
      "step": 100000
    },
    {
      "epoch": 30.211480362537763,
      "eval_loss": 1.295007586479187,
      "eval_runtime": 705.0355,
      "eval_samples_per_second": 75.314,
      "eval_steps_per_second": 0.589,
      "step": 100000
    },
    {
      "epoch": 30.226586102719033,
      "grad_norm": 0.44216373562812805,
      "learning_rate": 4.651581067472307e-05,
      "loss": 1.2882,
      "step": 100050
    },
    {
      "epoch": 30.226586102719033,
      "eval_loss": 1.293544888496399,
      "eval_runtime": 709.5297,
      "eval_samples_per_second": 74.837,
      "eval_steps_per_second": 0.585,
      "step": 100050
    },
    {
      "epoch": 30.241691842900302,
      "grad_norm": 0.44567790627479553,
      "learning_rate": 4.6505740181268886e-05,
      "loss": 1.2771,
      "step": 100100
    },
    {
      "epoch": 30.241691842900302,
      "eval_loss": 1.2964123487472534,
      "eval_runtime": 706.4064,
      "eval_samples_per_second": 75.168,
      "eval_steps_per_second": 0.587,
      "step": 100100
    },
    {
      "epoch": 30.25679758308157,
      "grad_norm": 0.49589380621910095,
      "learning_rate": 4.6495669687814705e-05,
      "loss": 1.2545,
      "step": 100150
    },
    {
      "epoch": 30.25679758308157,
      "eval_loss": 1.2937859296798706,
      "eval_runtime": 648.436,
      "eval_samples_per_second": 81.888,
      "eval_steps_per_second": 0.64,
      "step": 100150
    },
    {
      "epoch": 30.27190332326284,
      "grad_norm": 0.4763811230659485,
      "learning_rate": 4.6485599194360524e-05,
      "loss": 1.2779,
      "step": 100200
    },
    {
      "epoch": 30.27190332326284,
      "eval_loss": 1.2956271171569824,
      "eval_runtime": 618.3023,
      "eval_samples_per_second": 85.879,
      "eval_steps_per_second": 0.671,
      "step": 100200
    },
    {
      "epoch": 30.28700906344411,
      "grad_norm": 0.43975701928138733,
      "learning_rate": 4.647552870090635e-05,
      "loss": 1.2451,
      "step": 100250
    },
    {
      "epoch": 30.28700906344411,
      "eval_loss": 1.2954399585723877,
      "eval_runtime": 688.2918,
      "eval_samples_per_second": 77.146,
      "eval_steps_per_second": 0.603,
      "step": 100250
    },
    {
      "epoch": 30.30211480362538,
      "grad_norm": 0.4806300401687622,
      "learning_rate": 4.646545820745217e-05,
      "loss": 1.2749,
      "step": 100300
    },
    {
      "epoch": 30.30211480362538,
      "eval_loss": 1.2936925888061523,
      "eval_runtime": 669.5366,
      "eval_samples_per_second": 79.307,
      "eval_steps_per_second": 0.62,
      "step": 100300
    },
    {
      "epoch": 30.317220543806645,
      "grad_norm": 0.44168615341186523,
      "learning_rate": 4.645538771399799e-05,
      "loss": 1.2812,
      "step": 100350
    },
    {
      "epoch": 30.317220543806645,
      "eval_loss": 1.2944560050964355,
      "eval_runtime": 601.3473,
      "eval_samples_per_second": 88.3,
      "eval_steps_per_second": 0.69,
      "step": 100350
    },
    {
      "epoch": 30.332326283987914,
      "grad_norm": 0.49134522676467896,
      "learning_rate": 4.6445317220543805e-05,
      "loss": 1.2758,
      "step": 100400
    },
    {
      "epoch": 30.332326283987914,
      "eval_loss": 1.2952560186386108,
      "eval_runtime": 633.9306,
      "eval_samples_per_second": 83.762,
      "eval_steps_per_second": 0.655,
      "step": 100400
    },
    {
      "epoch": 30.347432024169184,
      "grad_norm": 0.4414744973182678,
      "learning_rate": 4.643524672708963e-05,
      "loss": 1.2691,
      "step": 100450
    },
    {
      "epoch": 30.347432024169184,
      "eval_loss": 1.2960389852523804,
      "eval_runtime": 670.3599,
      "eval_samples_per_second": 79.21,
      "eval_steps_per_second": 0.619,
      "step": 100450
    },
    {
      "epoch": 30.362537764350453,
      "grad_norm": 0.4363314211368561,
      "learning_rate": 4.642517623363545e-05,
      "loss": 1.2477,
      "step": 100500
    },
    {
      "epoch": 30.362537764350453,
      "eval_loss": 1.2947216033935547,
      "eval_runtime": 662.8904,
      "eval_samples_per_second": 80.102,
      "eval_steps_per_second": 0.626,
      "step": 100500
    },
    {
      "epoch": 30.377643504531722,
      "grad_norm": 0.4594845175743103,
      "learning_rate": 4.641510574018127e-05,
      "loss": 1.2609,
      "step": 100550
    },
    {
      "epoch": 30.377643504531722,
      "eval_loss": 1.2945561408996582,
      "eval_runtime": 688.5462,
      "eval_samples_per_second": 77.118,
      "eval_steps_per_second": 0.603,
      "step": 100550
    },
    {
      "epoch": 30.39274924471299,
      "grad_norm": 0.4692375361919403,
      "learning_rate": 4.640503524672709e-05,
      "loss": 1.2617,
      "step": 100600
    },
    {
      "epoch": 30.39274924471299,
      "eval_loss": 1.2956146001815796,
      "eval_runtime": 670.4239,
      "eval_samples_per_second": 79.202,
      "eval_steps_per_second": 0.619,
      "step": 100600
    },
    {
      "epoch": 30.40785498489426,
      "grad_norm": 0.4211503267288208,
      "learning_rate": 4.639496475327291e-05,
      "loss": 1.2514,
      "step": 100650
    },
    {
      "epoch": 30.40785498489426,
      "eval_loss": 1.294772982597351,
      "eval_runtime": 655.2683,
      "eval_samples_per_second": 81.034,
      "eval_steps_per_second": 0.633,
      "step": 100650
    },
    {
      "epoch": 30.42296072507553,
      "grad_norm": 0.4724462032318115,
      "learning_rate": 4.638489425981873e-05,
      "loss": 1.2711,
      "step": 100700
    },
    {
      "epoch": 30.42296072507553,
      "eval_loss": 1.2952748537063599,
      "eval_runtime": 612.0889,
      "eval_samples_per_second": 86.75,
      "eval_steps_per_second": 0.678,
      "step": 100700
    },
    {
      "epoch": 30.438066465256796,
      "grad_norm": 0.48047593235969543,
      "learning_rate": 4.637482376636455e-05,
      "loss": 1.2916,
      "step": 100750
    },
    {
      "epoch": 30.438066465256796,
      "eval_loss": 1.2965259552001953,
      "eval_runtime": 653.5873,
      "eval_samples_per_second": 81.242,
      "eval_steps_per_second": 0.635,
      "step": 100750
    },
    {
      "epoch": 30.453172205438065,
      "grad_norm": 0.4685734808444977,
      "learning_rate": 4.6364753272910375e-05,
      "loss": 1.2867,
      "step": 100800
    },
    {
      "epoch": 30.453172205438065,
      "eval_loss": 1.294265627861023,
      "eval_runtime": 647.899,
      "eval_samples_per_second": 81.956,
      "eval_steps_per_second": 0.641,
      "step": 100800
    },
    {
      "epoch": 30.468277945619334,
      "grad_norm": 0.4145122170448303,
      "learning_rate": 4.6354682779456194e-05,
      "loss": 1.2789,
      "step": 100850
    },
    {
      "epoch": 30.468277945619334,
      "eval_loss": 1.2941317558288574,
      "eval_runtime": 642.4369,
      "eval_samples_per_second": 82.652,
      "eval_steps_per_second": 0.646,
      "step": 100850
    },
    {
      "epoch": 30.483383685800604,
      "grad_norm": 0.4563544690608978,
      "learning_rate": 4.634461228600201e-05,
      "loss": 1.2709,
      "step": 100900
    },
    {
      "epoch": 30.483383685800604,
      "eval_loss": 1.2950797080993652,
      "eval_runtime": 619.7151,
      "eval_samples_per_second": 85.683,
      "eval_steps_per_second": 0.67,
      "step": 100900
    },
    {
      "epoch": 30.498489425981873,
      "grad_norm": 0.460307776927948,
      "learning_rate": 4.633454179254783e-05,
      "loss": 1.2668,
      "step": 100950
    },
    {
      "epoch": 30.498489425981873,
      "eval_loss": 1.2925058603286743,
      "eval_runtime": 650.2088,
      "eval_samples_per_second": 81.665,
      "eval_steps_per_second": 0.638,
      "step": 100950
    },
    {
      "epoch": 30.513595166163142,
      "grad_norm": 0.4219672381877899,
      "learning_rate": 4.632447129909366e-05,
      "loss": 1.2791,
      "step": 101000
    },
    {
      "epoch": 30.513595166163142,
      "eval_loss": 1.2959100008010864,
      "eval_runtime": 696.0736,
      "eval_samples_per_second": 76.284,
      "eval_steps_per_second": 0.596,
      "step": 101000
    },
    {
      "epoch": 30.52870090634441,
      "grad_norm": 0.4334053099155426,
      "learning_rate": 4.631440080563948e-05,
      "loss": 1.2993,
      "step": 101050
    },
    {
      "epoch": 30.52870090634441,
      "eval_loss": 1.2937177419662476,
      "eval_runtime": 617.6565,
      "eval_samples_per_second": 85.968,
      "eval_steps_per_second": 0.672,
      "step": 101050
    },
    {
      "epoch": 30.54380664652568,
      "grad_norm": 0.45192161202430725,
      "learning_rate": 4.63043303121853e-05,
      "loss": 1.2663,
      "step": 101100
    },
    {
      "epoch": 30.54380664652568,
      "eval_loss": 1.2944443225860596,
      "eval_runtime": 698.2317,
      "eval_samples_per_second": 76.048,
      "eval_steps_per_second": 0.594,
      "step": 101100
    },
    {
      "epoch": 30.55891238670695,
      "grad_norm": 0.44495290517807007,
      "learning_rate": 4.629425981873112e-05,
      "loss": 1.2868,
      "step": 101150
    },
    {
      "epoch": 30.55891238670695,
      "eval_loss": 1.2941389083862305,
      "eval_runtime": 665.7157,
      "eval_samples_per_second": 79.762,
      "eval_steps_per_second": 0.623,
      "step": 101150
    },
    {
      "epoch": 30.574018126888216,
      "grad_norm": 0.4809156358242035,
      "learning_rate": 4.6284189325276945e-05,
      "loss": 1.2797,
      "step": 101200
    },
    {
      "epoch": 30.574018126888216,
      "eval_loss": 1.2928152084350586,
      "eval_runtime": 599.5158,
      "eval_samples_per_second": 88.57,
      "eval_steps_per_second": 0.692,
      "step": 101200
    },
    {
      "epoch": 30.589123867069485,
      "grad_norm": 0.4355888068675995,
      "learning_rate": 4.6274118831822764e-05,
      "loss": 1.2727,
      "step": 101250
    },
    {
      "epoch": 30.589123867069485,
      "eval_loss": 1.2947694063186646,
      "eval_runtime": 622.6614,
      "eval_samples_per_second": 85.277,
      "eval_steps_per_second": 0.666,
      "step": 101250
    },
    {
      "epoch": 30.604229607250755,
      "grad_norm": 0.43824756145477295,
      "learning_rate": 4.626404833836858e-05,
      "loss": 1.2776,
      "step": 101300
    },
    {
      "epoch": 30.604229607250755,
      "eval_loss": 1.2934691905975342,
      "eval_runtime": 654.652,
      "eval_samples_per_second": 81.11,
      "eval_steps_per_second": 0.634,
      "step": 101300
    },
    {
      "epoch": 30.619335347432024,
      "grad_norm": 0.43534618616104126,
      "learning_rate": 4.62539778449144e-05,
      "loss": 1.2663,
      "step": 101350
    },
    {
      "epoch": 30.619335347432024,
      "eval_loss": 1.2932324409484863,
      "eval_runtime": 698.9546,
      "eval_samples_per_second": 75.969,
      "eval_steps_per_second": 0.594,
      "step": 101350
    },
    {
      "epoch": 30.634441087613293,
      "grad_norm": 0.4533464014530182,
      "learning_rate": 4.6243907351460226e-05,
      "loss": 1.2778,
      "step": 101400
    },
    {
      "epoch": 30.634441087613293,
      "eval_loss": 1.2926851511001587,
      "eval_runtime": 684.6374,
      "eval_samples_per_second": 77.558,
      "eval_steps_per_second": 0.606,
      "step": 101400
    },
    {
      "epoch": 30.649546827794563,
      "grad_norm": 0.45504769682884216,
      "learning_rate": 4.6233836858006045e-05,
      "loss": 1.2801,
      "step": 101450
    },
    {
      "epoch": 30.649546827794563,
      "eval_loss": 1.2952533960342407,
      "eval_runtime": 707.5255,
      "eval_samples_per_second": 75.049,
      "eval_steps_per_second": 0.587,
      "step": 101450
    },
    {
      "epoch": 30.664652567975832,
      "grad_norm": 0.49071964621543884,
      "learning_rate": 4.6223766364551864e-05,
      "loss": 1.2701,
      "step": 101500
    },
    {
      "epoch": 30.664652567975832,
      "eval_loss": 1.293723225593567,
      "eval_runtime": 701.2969,
      "eval_samples_per_second": 75.715,
      "eval_steps_per_second": 0.592,
      "step": 101500
    },
    {
      "epoch": 30.6797583081571,
      "grad_norm": 0.4462107717990875,
      "learning_rate": 4.621369587109768e-05,
      "loss": 1.2708,
      "step": 101550
    },
    {
      "epoch": 30.6797583081571,
      "eval_loss": 1.2916221618652344,
      "eval_runtime": 707.8516,
      "eval_samples_per_second": 75.014,
      "eval_steps_per_second": 0.586,
      "step": 101550
    },
    {
      "epoch": 30.694864048338367,
      "grad_norm": 0.4575642943382263,
      "learning_rate": 4.620362537764351e-05,
      "loss": 1.2641,
      "step": 101600
    },
    {
      "epoch": 30.694864048338367,
      "eval_loss": 1.2913727760314941,
      "eval_runtime": 616.0573,
      "eval_samples_per_second": 86.192,
      "eval_steps_per_second": 0.674,
      "step": 101600
    },
    {
      "epoch": 30.709969788519636,
      "grad_norm": 0.49131014943122864,
      "learning_rate": 4.619355488418933e-05,
      "loss": 1.2565,
      "step": 101650
    },
    {
      "epoch": 30.709969788519636,
      "eval_loss": 1.2930915355682373,
      "eval_runtime": 707.0532,
      "eval_samples_per_second": 75.099,
      "eval_steps_per_second": 0.587,
      "step": 101650
    },
    {
      "epoch": 30.725075528700906,
      "grad_norm": 0.495583176612854,
      "learning_rate": 4.6183484390735145e-05,
      "loss": 1.2817,
      "step": 101700
    },
    {
      "epoch": 30.725075528700906,
      "eval_loss": 1.2930793762207031,
      "eval_runtime": 687.0184,
      "eval_samples_per_second": 77.289,
      "eval_steps_per_second": 0.604,
      "step": 101700
    },
    {
      "epoch": 30.740181268882175,
      "grad_norm": 0.47348448634147644,
      "learning_rate": 4.6173413897280964e-05,
      "loss": 1.2568,
      "step": 101750
    },
    {
      "epoch": 30.740181268882175,
      "eval_loss": 1.2957875728607178,
      "eval_runtime": 702.9912,
      "eval_samples_per_second": 75.533,
      "eval_steps_per_second": 0.59,
      "step": 101750
    },
    {
      "epoch": 30.755287009063444,
      "grad_norm": 0.48356837034225464,
      "learning_rate": 4.616334340382679e-05,
      "loss": 1.2628,
      "step": 101800
    },
    {
      "epoch": 30.755287009063444,
      "eval_loss": 1.2935281991958618,
      "eval_runtime": 638.7783,
      "eval_samples_per_second": 83.126,
      "eval_steps_per_second": 0.65,
      "step": 101800
    },
    {
      "epoch": 30.770392749244714,
      "grad_norm": 0.46594348549842834,
      "learning_rate": 4.615327291037261e-05,
      "loss": 1.2506,
      "step": 101850
    },
    {
      "epoch": 30.770392749244714,
      "eval_loss": 1.2923976182937622,
      "eval_runtime": 666.3621,
      "eval_samples_per_second": 79.685,
      "eval_steps_per_second": 0.623,
      "step": 101850
    },
    {
      "epoch": 30.785498489425983,
      "grad_norm": 0.4515989124774933,
      "learning_rate": 4.614320241691843e-05,
      "loss": 1.2605,
      "step": 101900
    },
    {
      "epoch": 30.785498489425983,
      "eval_loss": 1.29212486743927,
      "eval_runtime": 701.0281,
      "eval_samples_per_second": 75.744,
      "eval_steps_per_second": 0.592,
      "step": 101900
    },
    {
      "epoch": 30.800604229607252,
      "grad_norm": 0.47166404128074646,
      "learning_rate": 4.613313192346425e-05,
      "loss": 1.2706,
      "step": 101950
    },
    {
      "epoch": 30.800604229607252,
      "eval_loss": 1.293900728225708,
      "eval_runtime": 759.8983,
      "eval_samples_per_second": 69.876,
      "eval_steps_per_second": 0.546,
      "step": 101950
    },
    {
      "epoch": 30.815709969788518,
      "grad_norm": 0.4687289893627167,
      "learning_rate": 4.612306143001007e-05,
      "loss": 1.2696,
      "step": 102000
    },
    {
      "epoch": 30.815709969788518,
      "eval_loss": 1.2900118827819824,
      "eval_runtime": 718.885,
      "eval_samples_per_second": 73.863,
      "eval_steps_per_second": 0.577,
      "step": 102000
    },
    {
      "epoch": 30.830815709969787,
      "grad_norm": 0.46351465582847595,
      "learning_rate": 4.611299093655589e-05,
      "loss": 1.2595,
      "step": 102050
    },
    {
      "epoch": 30.830815709969787,
      "eval_loss": 1.2945668697357178,
      "eval_runtime": 609.5662,
      "eval_samples_per_second": 87.109,
      "eval_steps_per_second": 0.681,
      "step": 102050
    },
    {
      "epoch": 30.845921450151057,
      "grad_norm": 0.4383859932422638,
      "learning_rate": 4.610292044310171e-05,
      "loss": 1.2613,
      "step": 102100
    },
    {
      "epoch": 30.845921450151057,
      "eval_loss": 1.2926156520843506,
      "eval_runtime": 707.3217,
      "eval_samples_per_second": 75.071,
      "eval_steps_per_second": 0.587,
      "step": 102100
    },
    {
      "epoch": 30.861027190332326,
      "grad_norm": 0.46493294835090637,
      "learning_rate": 4.6092849949647534e-05,
      "loss": 1.2592,
      "step": 102150
    },
    {
      "epoch": 30.861027190332326,
      "eval_loss": 1.2932766675949097,
      "eval_runtime": 690.9283,
      "eval_samples_per_second": 76.852,
      "eval_steps_per_second": 0.601,
      "step": 102150
    },
    {
      "epoch": 30.876132930513595,
      "grad_norm": 0.42391976714134216,
      "learning_rate": 4.608277945619336e-05,
      "loss": 1.2607,
      "step": 102200
    },
    {
      "epoch": 30.876132930513595,
      "eval_loss": 1.2926214933395386,
      "eval_runtime": 695.7884,
      "eval_samples_per_second": 76.315,
      "eval_steps_per_second": 0.596,
      "step": 102200
    },
    {
      "epoch": 30.891238670694865,
      "grad_norm": 0.4461987614631653,
      "learning_rate": 4.607270896273918e-05,
      "loss": 1.2673,
      "step": 102250
    },
    {
      "epoch": 30.891238670694865,
      "eval_loss": 1.2955299615859985,
      "eval_runtime": 708.6238,
      "eval_samples_per_second": 74.933,
      "eval_steps_per_second": 0.586,
      "step": 102250
    },
    {
      "epoch": 30.906344410876134,
      "grad_norm": 0.4911927282810211,
      "learning_rate": 4.6062638469285e-05,
      "loss": 1.2661,
      "step": 102300
    },
    {
      "epoch": 30.906344410876134,
      "eval_loss": 1.2941254377365112,
      "eval_runtime": 1050.7339,
      "eval_samples_per_second": 50.535,
      "eval_steps_per_second": 0.395,
      "step": 102300
    },
    {
      "epoch": 30.921450151057403,
      "grad_norm": 0.44795504212379456,
      "learning_rate": 4.605256797583082e-05,
      "loss": 1.256,
      "step": 102350
    },
    {
      "epoch": 30.921450151057403,
      "eval_loss": 1.2921258211135864,
      "eval_runtime": 700.8951,
      "eval_samples_per_second": 75.759,
      "eval_steps_per_second": 0.592,
      "step": 102350
    },
    {
      "epoch": 30.93655589123867,
      "grad_norm": 0.42386436462402344,
      "learning_rate": 4.604249748237664e-05,
      "loss": 1.2613,
      "step": 102400
    },
    {
      "epoch": 30.93655589123867,
      "eval_loss": 1.2935761213302612,
      "eval_runtime": 622.6938,
      "eval_samples_per_second": 85.273,
      "eval_steps_per_second": 0.666,
      "step": 102400
    },
    {
      "epoch": 30.951661631419938,
      "grad_norm": 0.46825599670410156,
      "learning_rate": 4.603242698892246e-05,
      "loss": 1.2886,
      "step": 102450
    },
    {
      "epoch": 30.951661631419938,
      "eval_loss": 1.2923471927642822,
      "eval_runtime": 667.0221,
      "eval_samples_per_second": 79.606,
      "eval_steps_per_second": 0.622,
      "step": 102450
    },
    {
      "epoch": 30.966767371601208,
      "grad_norm": 0.4103831350803375,
      "learning_rate": 4.602235649546828e-05,
      "loss": 1.267,
      "step": 102500
    },
    {
      "epoch": 30.966767371601208,
      "eval_loss": 1.2916805744171143,
      "eval_runtime": 739.5011,
      "eval_samples_per_second": 71.804,
      "eval_steps_per_second": 0.561,
      "step": 102500
    },
    {
      "epoch": 30.981873111782477,
      "grad_norm": 0.46789270639419556,
      "learning_rate": 4.6012286002014104e-05,
      "loss": 1.265,
      "step": 102550
    },
    {
      "epoch": 30.981873111782477,
      "eval_loss": 1.2946248054504395,
      "eval_runtime": 698.416,
      "eval_samples_per_second": 76.028,
      "eval_steps_per_second": 0.594,
      "step": 102550
    },
    {
      "epoch": 30.996978851963746,
      "grad_norm": 0.5075309872627258,
      "learning_rate": 4.600221550855992e-05,
      "loss": 1.2826,
      "step": 102600
    },
    {
      "epoch": 30.996978851963746,
      "eval_loss": 1.2937620878219604,
      "eval_runtime": 678.9576,
      "eval_samples_per_second": 78.207,
      "eval_steps_per_second": 0.611,
      "step": 102600
    },
    {
      "epoch": 31.012084592145015,
      "grad_norm": 0.4287222921848297,
      "learning_rate": 4.599214501510574e-05,
      "loss": 1.2719,
      "step": 102650
    },
    {
      "epoch": 31.012084592145015,
      "eval_loss": 1.2945002317428589,
      "eval_runtime": 688.2528,
      "eval_samples_per_second": 77.15,
      "eval_steps_per_second": 0.603,
      "step": 102650
    },
    {
      "epoch": 31.027190332326285,
      "grad_norm": 0.4770656228065491,
      "learning_rate": 4.598207452165156e-05,
      "loss": 1.2407,
      "step": 102700
    },
    {
      "epoch": 31.027190332326285,
      "eval_loss": 1.292886734008789,
      "eval_runtime": 895.1701,
      "eval_samples_per_second": 59.317,
      "eval_steps_per_second": 0.464,
      "step": 102700
    },
    {
      "epoch": 31.042296072507554,
      "grad_norm": 0.5205562710762024,
      "learning_rate": 4.5972004028197385e-05,
      "loss": 1.2642,
      "step": 102750
    },
    {
      "epoch": 31.042296072507554,
      "eval_loss": 1.2915529012680054,
      "eval_runtime": 658.1709,
      "eval_samples_per_second": 80.677,
      "eval_steps_per_second": 0.631,
      "step": 102750
    },
    {
      "epoch": 31.057401812688823,
      "grad_norm": 0.4704623520374298,
      "learning_rate": 4.5961933534743204e-05,
      "loss": 1.2514,
      "step": 102800
    },
    {
      "epoch": 31.057401812688823,
      "eval_loss": 1.2922459840774536,
      "eval_runtime": 669.3744,
      "eval_samples_per_second": 79.326,
      "eval_steps_per_second": 0.62,
      "step": 102800
    },
    {
      "epoch": 31.07250755287009,
      "grad_norm": 0.4644072353839874,
      "learning_rate": 4.595186304128902e-05,
      "loss": 1.2824,
      "step": 102850
    },
    {
      "epoch": 31.07250755287009,
      "eval_loss": 1.2931486368179321,
      "eval_runtime": 718.434,
      "eval_samples_per_second": 73.909,
      "eval_steps_per_second": 0.578,
      "step": 102850
    },
    {
      "epoch": 31.08761329305136,
      "grad_norm": 0.45669493079185486,
      "learning_rate": 4.594179254783484e-05,
      "loss": 1.2963,
      "step": 102900
    },
    {
      "epoch": 31.08761329305136,
      "eval_loss": 1.2937240600585938,
      "eval_runtime": 702.8502,
      "eval_samples_per_second": 75.548,
      "eval_steps_per_second": 0.59,
      "step": 102900
    },
    {
      "epoch": 31.102719033232628,
      "grad_norm": 0.42974263429641724,
      "learning_rate": 4.593172205438067e-05,
      "loss": 1.2651,
      "step": 102950
    },
    {
      "epoch": 31.102719033232628,
      "eval_loss": 1.2921727895736694,
      "eval_runtime": 703.8208,
      "eval_samples_per_second": 75.444,
      "eval_steps_per_second": 0.59,
      "step": 102950
    },
    {
      "epoch": 31.117824773413897,
      "grad_norm": 0.4945458471775055,
      "learning_rate": 4.5921651560926485e-05,
      "loss": 1.3028,
      "step": 103000
    },
    {
      "epoch": 31.117824773413897,
      "eval_loss": 1.2909822463989258,
      "eval_runtime": 681.6996,
      "eval_samples_per_second": 77.892,
      "eval_steps_per_second": 0.609,
      "step": 103000
    },
    {
      "epoch": 31.132930513595166,
      "grad_norm": 0.4472636282444,
      "learning_rate": 4.5911581067472304e-05,
      "loss": 1.2699,
      "step": 103050
    },
    {
      "epoch": 31.132930513595166,
      "eval_loss": 1.292081594467163,
      "eval_runtime": 685.3707,
      "eval_samples_per_second": 77.475,
      "eval_steps_per_second": 0.606,
      "step": 103050
    },
    {
      "epoch": 31.148036253776436,
      "grad_norm": 0.4480130076408386,
      "learning_rate": 4.590151057401813e-05,
      "loss": 1.2977,
      "step": 103100
    },
    {
      "epoch": 31.148036253776436,
      "eval_loss": 1.290665626525879,
      "eval_runtime": 712.6649,
      "eval_samples_per_second": 74.508,
      "eval_steps_per_second": 0.582,
      "step": 103100
    },
    {
      "epoch": 31.163141993957705,
      "grad_norm": 0.4773653745651245,
      "learning_rate": 4.589144008056395e-05,
      "loss": 1.2535,
      "step": 103150
    },
    {
      "epoch": 31.163141993957705,
      "eval_loss": 1.2921398878097534,
      "eval_runtime": 700.8018,
      "eval_samples_per_second": 75.769,
      "eval_steps_per_second": 0.592,
      "step": 103150
    },
    {
      "epoch": 31.178247734138974,
      "grad_norm": 0.47614365816116333,
      "learning_rate": 4.588136958710977e-05,
      "loss": 1.243,
      "step": 103200
    },
    {
      "epoch": 31.178247734138974,
      "eval_loss": 1.2923448085784912,
      "eval_runtime": 658.2725,
      "eval_samples_per_second": 80.664,
      "eval_steps_per_second": 0.63,
      "step": 103200
    },
    {
      "epoch": 31.19335347432024,
      "grad_norm": 0.4609460234642029,
      "learning_rate": 4.5871299093655586e-05,
      "loss": 1.2765,
      "step": 103250
    },
    {
      "epoch": 31.19335347432024,
      "eval_loss": 1.292461633682251,
      "eval_runtime": 674.2405,
      "eval_samples_per_second": 78.754,
      "eval_steps_per_second": 0.616,
      "step": 103250
    },
    {
      "epoch": 31.20845921450151,
      "grad_norm": 0.457118421792984,
      "learning_rate": 4.586122860020141e-05,
      "loss": 1.2587,
      "step": 103300
    },
    {
      "epoch": 31.20845921450151,
      "eval_loss": 1.2924431562423706,
      "eval_runtime": 706.595,
      "eval_samples_per_second": 75.148,
      "eval_steps_per_second": 0.587,
      "step": 103300
    },
    {
      "epoch": 31.22356495468278,
      "grad_norm": 0.5272539258003235,
      "learning_rate": 4.585115810674723e-05,
      "loss": 1.2851,
      "step": 103350
    },
    {
      "epoch": 31.22356495468278,
      "eval_loss": 1.2913856506347656,
      "eval_runtime": 634.2607,
      "eval_samples_per_second": 83.718,
      "eval_steps_per_second": 0.654,
      "step": 103350
    },
    {
      "epoch": 31.238670694864048,
      "grad_norm": 0.4471341371536255,
      "learning_rate": 4.5841087613293055e-05,
      "loss": 1.2844,
      "step": 103400
    },
    {
      "epoch": 31.238670694864048,
      "eval_loss": 1.2893826961517334,
      "eval_runtime": 624.5085,
      "eval_samples_per_second": 85.025,
      "eval_steps_per_second": 0.665,
      "step": 103400
    },
    {
      "epoch": 31.253776435045317,
      "grad_norm": 0.42774316668510437,
      "learning_rate": 4.5831017119838874e-05,
      "loss": 1.2796,
      "step": 103450
    },
    {
      "epoch": 31.253776435045317,
      "eval_loss": 1.2910144329071045,
      "eval_runtime": 647.4033,
      "eval_samples_per_second": 82.018,
      "eval_steps_per_second": 0.641,
      "step": 103450
    },
    {
      "epoch": 31.268882175226587,
      "grad_norm": 0.4528256058692932,
      "learning_rate": 4.58209466263847e-05,
      "loss": 1.255,
      "step": 103500
    },
    {
      "epoch": 31.268882175226587,
      "eval_loss": 1.2934001684188843,
      "eval_runtime": 630.4646,
      "eval_samples_per_second": 84.222,
      "eval_steps_per_second": 0.658,
      "step": 103500
    },
    {
      "epoch": 31.283987915407856,
      "grad_norm": 0.43099379539489746,
      "learning_rate": 4.581087613293052e-05,
      "loss": 1.2707,
      "step": 103550
    },
    {
      "epoch": 31.283987915407856,
      "eval_loss": 1.2928756475448608,
      "eval_runtime": 619.487,
      "eval_samples_per_second": 85.714,
      "eval_steps_per_second": 0.67,
      "step": 103550
    },
    {
      "epoch": 31.299093655589125,
      "grad_norm": 0.4842943251132965,
      "learning_rate": 4.580080563947634e-05,
      "loss": 1.2621,
      "step": 103600
    },
    {
      "epoch": 31.299093655589125,
      "eval_loss": 1.291894793510437,
      "eval_runtime": 725.3147,
      "eval_samples_per_second": 73.208,
      "eval_steps_per_second": 0.572,
      "step": 103600
    },
    {
      "epoch": 31.31419939577039,
      "grad_norm": 0.45409080386161804,
      "learning_rate": 4.5790735146022155e-05,
      "loss": 1.2678,
      "step": 103650
    },
    {
      "epoch": 31.31419939577039,
      "eval_loss": 1.29314124584198,
      "eval_runtime": 620.5416,
      "eval_samples_per_second": 85.569,
      "eval_steps_per_second": 0.669,
      "step": 103650
    },
    {
      "epoch": 31.32930513595166,
      "grad_norm": 0.4592350423336029,
      "learning_rate": 4.578066465256798e-05,
      "loss": 1.2614,
      "step": 103700
    },
    {
      "epoch": 31.32930513595166,
      "eval_loss": 1.290881633758545,
      "eval_runtime": 632.9232,
      "eval_samples_per_second": 83.895,
      "eval_steps_per_second": 0.656,
      "step": 103700
    },
    {
      "epoch": 31.34441087613293,
      "grad_norm": 0.47587862610816956,
      "learning_rate": 4.57705941591138e-05,
      "loss": 1.2626,
      "step": 103750
    },
    {
      "epoch": 31.34441087613293,
      "eval_loss": 1.2914263010025024,
      "eval_runtime": 610.1354,
      "eval_samples_per_second": 87.028,
      "eval_steps_per_second": 0.68,
      "step": 103750
    },
    {
      "epoch": 31.3595166163142,
      "grad_norm": 0.40635502338409424,
      "learning_rate": 4.576052366565962e-05,
      "loss": 1.2526,
      "step": 103800
    },
    {
      "epoch": 31.3595166163142,
      "eval_loss": 1.2904430627822876,
      "eval_runtime": 671.5538,
      "eval_samples_per_second": 79.069,
      "eval_steps_per_second": 0.618,
      "step": 103800
    },
    {
      "epoch": 31.37462235649547,
      "grad_norm": 0.4503760039806366,
      "learning_rate": 4.575045317220544e-05,
      "loss": 1.2633,
      "step": 103850
    },
    {
      "epoch": 31.37462235649547,
      "eval_loss": 1.2916738986968994,
      "eval_runtime": 651.7876,
      "eval_samples_per_second": 81.467,
      "eval_steps_per_second": 0.637,
      "step": 103850
    },
    {
      "epoch": 31.389728096676738,
      "grad_norm": 0.44947928190231323,
      "learning_rate": 4.574038267875126e-05,
      "loss": 1.2761,
      "step": 103900
    },
    {
      "epoch": 31.389728096676738,
      "eval_loss": 1.2911880016326904,
      "eval_runtime": 653.3066,
      "eval_samples_per_second": 81.277,
      "eval_steps_per_second": 0.635,
      "step": 103900
    },
    {
      "epoch": 31.404833836858007,
      "grad_norm": 0.4864960312843323,
      "learning_rate": 4.573031218529708e-05,
      "loss": 1.2681,
      "step": 103950
    },
    {
      "epoch": 31.404833836858007,
      "eval_loss": 1.292271375656128,
      "eval_runtime": 638.2904,
      "eval_samples_per_second": 83.189,
      "eval_steps_per_second": 0.65,
      "step": 103950
    },
    {
      "epoch": 31.419939577039276,
      "grad_norm": 0.44031763076782227,
      "learning_rate": 4.57202416918429e-05,
      "loss": 1.2686,
      "step": 104000
    },
    {
      "epoch": 31.419939577039276,
      "eval_loss": 1.2909523248672485,
      "eval_runtime": 679.4427,
      "eval_samples_per_second": 78.151,
      "eval_steps_per_second": 0.611,
      "step": 104000
    },
    {
      "epoch": 31.435045317220546,
      "grad_norm": 0.4838058352470398,
      "learning_rate": 4.571017119838872e-05,
      "loss": 1.2706,
      "step": 104050
    },
    {
      "epoch": 31.435045317220546,
      "eval_loss": 1.2923719882965088,
      "eval_runtime": 674.8135,
      "eval_samples_per_second": 78.687,
      "eval_steps_per_second": 0.615,
      "step": 104050
    },
    {
      "epoch": 31.45015105740181,
      "grad_norm": 0.4248669147491455,
      "learning_rate": 4.5700100704934544e-05,
      "loss": 1.2606,
      "step": 104100
    },
    {
      "epoch": 31.45015105740181,
      "eval_loss": 1.2909862995147705,
      "eval_runtime": 774.3686,
      "eval_samples_per_second": 68.571,
      "eval_steps_per_second": 0.536,
      "step": 104100
    },
    {
      "epoch": 31.46525679758308,
      "grad_norm": 0.4594689607620239,
      "learning_rate": 4.569003021148036e-05,
      "loss": 1.2489,
      "step": 104150
    },
    {
      "epoch": 31.46525679758308,
      "eval_loss": 1.2919554710388184,
      "eval_runtime": 734.7695,
      "eval_samples_per_second": 72.266,
      "eval_steps_per_second": 0.565,
      "step": 104150
    },
    {
      "epoch": 31.48036253776435,
      "grad_norm": 0.4559348225593567,
      "learning_rate": 4.567995971802618e-05,
      "loss": 1.2775,
      "step": 104200
    },
    {
      "epoch": 31.48036253776435,
      "eval_loss": 1.29046630859375,
      "eval_runtime": 649.7848,
      "eval_samples_per_second": 81.718,
      "eval_steps_per_second": 0.639,
      "step": 104200
    },
    {
      "epoch": 31.49546827794562,
      "grad_norm": 0.4394388496875763,
      "learning_rate": 4.566988922457201e-05,
      "loss": 1.262,
      "step": 104250
    },
    {
      "epoch": 31.49546827794562,
      "eval_loss": 1.2931809425354004,
      "eval_runtime": 641.1675,
      "eval_samples_per_second": 82.816,
      "eval_steps_per_second": 0.647,
      "step": 104250
    },
    {
      "epoch": 31.51057401812689,
      "grad_norm": 0.43430960178375244,
      "learning_rate": 4.5659818731117825e-05,
      "loss": 1.2548,
      "step": 104300
    },
    {
      "epoch": 31.51057401812689,
      "eval_loss": 1.2897971868515015,
      "eval_runtime": 634.9999,
      "eval_samples_per_second": 83.62,
      "eval_steps_per_second": 0.654,
      "step": 104300
    },
    {
      "epoch": 31.525679758308158,
      "grad_norm": 0.4293384253978729,
      "learning_rate": 4.5649748237663644e-05,
      "loss": 1.2809,
      "step": 104350
    },
    {
      "epoch": 31.525679758308158,
      "eval_loss": 1.2904424667358398,
      "eval_runtime": 707.5436,
      "eval_samples_per_second": 75.047,
      "eval_steps_per_second": 0.587,
      "step": 104350
    },
    {
      "epoch": 31.540785498489427,
      "grad_norm": 0.468466579914093,
      "learning_rate": 4.563967774420946e-05,
      "loss": 1.2694,
      "step": 104400
    },
    {
      "epoch": 31.540785498489427,
      "eval_loss": 1.2909927368164062,
      "eval_runtime": 612.9196,
      "eval_samples_per_second": 86.633,
      "eval_steps_per_second": 0.677,
      "step": 104400
    },
    {
      "epoch": 31.555891238670696,
      "grad_norm": 0.44684603810310364,
      "learning_rate": 4.562960725075529e-05,
      "loss": 1.2516,
      "step": 104450
    },
    {
      "epoch": 31.555891238670696,
      "eval_loss": 1.29133141040802,
      "eval_runtime": 665.6447,
      "eval_samples_per_second": 79.771,
      "eval_steps_per_second": 0.623,
      "step": 104450
    },
    {
      "epoch": 31.570996978851962,
      "grad_norm": 0.4453972578048706,
      "learning_rate": 4.561953675730111e-05,
      "loss": 1.2346,
      "step": 104500
    },
    {
      "epoch": 31.570996978851962,
      "eval_loss": 1.2907469272613525,
      "eval_runtime": 603.4326,
      "eval_samples_per_second": 87.995,
      "eval_steps_per_second": 0.688,
      "step": 104500
    },
    {
      "epoch": 31.58610271903323,
      "grad_norm": 0.44680020213127136,
      "learning_rate": 4.560946626384693e-05,
      "loss": 1.2704,
      "step": 104550
    },
    {
      "epoch": 31.58610271903323,
      "eval_loss": 1.2897076606750488,
      "eval_runtime": 703.0986,
      "eval_samples_per_second": 75.521,
      "eval_steps_per_second": 0.59,
      "step": 104550
    },
    {
      "epoch": 31.6012084592145,
      "grad_norm": 0.4521462619304657,
      "learning_rate": 4.559939577039275e-05,
      "loss": 1.2679,
      "step": 104600
    },
    {
      "epoch": 31.6012084592145,
      "eval_loss": 1.2940707206726074,
      "eval_runtime": 876.697,
      "eval_samples_per_second": 60.567,
      "eval_steps_per_second": 0.473,
      "step": 104600
    },
    {
      "epoch": 31.61631419939577,
      "grad_norm": 0.5011942386627197,
      "learning_rate": 4.5589325276938577e-05,
      "loss": 1.2607,
      "step": 104650
    },
    {
      "epoch": 31.61631419939577,
      "eval_loss": 1.2916536331176758,
      "eval_runtime": 676.7328,
      "eval_samples_per_second": 78.464,
      "eval_steps_per_second": 0.613,
      "step": 104650
    },
    {
      "epoch": 31.63141993957704,
      "grad_norm": 0.4902641177177429,
      "learning_rate": 4.5579254783484395e-05,
      "loss": 1.2708,
      "step": 104700
    },
    {
      "epoch": 31.63141993957704,
      "eval_loss": 1.2914503812789917,
      "eval_runtime": 690.1858,
      "eval_samples_per_second": 76.934,
      "eval_steps_per_second": 0.601,
      "step": 104700
    },
    {
      "epoch": 31.64652567975831,
      "grad_norm": 0.42920181155204773,
      "learning_rate": 4.5569184290030214e-05,
      "loss": 1.2788,
      "step": 104750
    },
    {
      "epoch": 31.64652567975831,
      "eval_loss": 1.2927793264389038,
      "eval_runtime": 665.5515,
      "eval_samples_per_second": 79.782,
      "eval_steps_per_second": 0.624,
      "step": 104750
    },
    {
      "epoch": 31.661631419939578,
      "grad_norm": 0.42562738060951233,
      "learning_rate": 4.555911379657603e-05,
      "loss": 1.2469,
      "step": 104800
    },
    {
      "epoch": 31.661631419939578,
      "eval_loss": 1.291854977607727,
      "eval_runtime": 702.7133,
      "eval_samples_per_second": 75.563,
      "eval_steps_per_second": 0.591,
      "step": 104800
    },
    {
      "epoch": 31.676737160120847,
      "grad_norm": 0.4314282536506653,
      "learning_rate": 4.554904330312186e-05,
      "loss": 1.26,
      "step": 104850
    },
    {
      "epoch": 31.676737160120847,
      "eval_loss": 1.291839361190796,
      "eval_runtime": 788.434,
      "eval_samples_per_second": 67.347,
      "eval_steps_per_second": 0.526,
      "step": 104850
    },
    {
      "epoch": 31.691842900302113,
      "grad_norm": 0.4359239637851715,
      "learning_rate": 4.553897280966768e-05,
      "loss": 1.2419,
      "step": 104900
    },
    {
      "epoch": 31.691842900302113,
      "eval_loss": 1.289210557937622,
      "eval_runtime": 634.7376,
      "eval_samples_per_second": 83.655,
      "eval_steps_per_second": 0.654,
      "step": 104900
    },
    {
      "epoch": 31.706948640483382,
      "grad_norm": 0.43835729360580444,
      "learning_rate": 4.5528902316213495e-05,
      "loss": 1.2682,
      "step": 104950
    },
    {
      "epoch": 31.706948640483382,
      "eval_loss": 1.2908780574798584,
      "eval_runtime": 667.4575,
      "eval_samples_per_second": 79.554,
      "eval_steps_per_second": 0.622,
      "step": 104950
    },
    {
      "epoch": 31.72205438066465,
      "grad_norm": 0.4669884145259857,
      "learning_rate": 4.5518831822759314e-05,
      "loss": 1.2855,
      "step": 105000
    },
    {
      "epoch": 31.72205438066465,
      "eval_loss": 1.2899459600448608,
      "eval_runtime": 679.3427,
      "eval_samples_per_second": 78.162,
      "eval_steps_per_second": 0.611,
      "step": 105000
    },
    {
      "epoch": 31.73716012084592,
      "grad_norm": 0.4613562822341919,
      "learning_rate": 4.550876132930514e-05,
      "loss": 1.2622,
      "step": 105050
    },
    {
      "epoch": 31.73716012084592,
      "eval_loss": 1.2911155223846436,
      "eval_runtime": 766.9526,
      "eval_samples_per_second": 69.234,
      "eval_steps_per_second": 0.541,
      "step": 105050
    },
    {
      "epoch": 31.75226586102719,
      "grad_norm": 0.45060017704963684,
      "learning_rate": 4.549869083585096e-05,
      "loss": 1.2748,
      "step": 105100
    },
    {
      "epoch": 31.75226586102719,
      "eval_loss": 1.290941596031189,
      "eval_runtime": 643.2582,
      "eval_samples_per_second": 82.547,
      "eval_steps_per_second": 0.645,
      "step": 105100
    },
    {
      "epoch": 31.76737160120846,
      "grad_norm": 0.4426334500312805,
      "learning_rate": 4.548862034239678e-05,
      "loss": 1.262,
      "step": 105150
    },
    {
      "epoch": 31.76737160120846,
      "eval_loss": 1.2893964052200317,
      "eval_runtime": 666.0439,
      "eval_samples_per_second": 79.723,
      "eval_steps_per_second": 0.623,
      "step": 105150
    },
    {
      "epoch": 31.78247734138973,
      "grad_norm": 0.48244237899780273,
      "learning_rate": 4.5478549848942596e-05,
      "loss": 1.2849,
      "step": 105200
    },
    {
      "epoch": 31.78247734138973,
      "eval_loss": 1.2923641204833984,
      "eval_runtime": 704.0913,
      "eval_samples_per_second": 75.415,
      "eval_steps_per_second": 0.589,
      "step": 105200
    },
    {
      "epoch": 31.797583081571,
      "grad_norm": 0.4579329788684845,
      "learning_rate": 4.546847935548842e-05,
      "loss": 1.2584,
      "step": 105250
    },
    {
      "epoch": 31.797583081571,
      "eval_loss": 1.2888399362564087,
      "eval_runtime": 627.5706,
      "eval_samples_per_second": 84.61,
      "eval_steps_per_second": 0.661,
      "step": 105250
    },
    {
      "epoch": 31.812688821752268,
      "grad_norm": 0.4662497341632843,
      "learning_rate": 4.545840886203424e-05,
      "loss": 1.2728,
      "step": 105300
    },
    {
      "epoch": 31.812688821752268,
      "eval_loss": 1.2899861335754395,
      "eval_runtime": 700.2585,
      "eval_samples_per_second": 75.828,
      "eval_steps_per_second": 0.593,
      "step": 105300
    },
    {
      "epoch": 31.827794561933533,
      "grad_norm": 0.5424115657806396,
      "learning_rate": 4.544833836858006e-05,
      "loss": 1.2511,
      "step": 105350
    },
    {
      "epoch": 31.827794561933533,
      "eval_loss": 1.2910704612731934,
      "eval_runtime": 697.4861,
      "eval_samples_per_second": 76.129,
      "eval_steps_per_second": 0.595,
      "step": 105350
    },
    {
      "epoch": 31.842900302114803,
      "grad_norm": 0.4910581409931183,
      "learning_rate": 4.5438267875125884e-05,
      "loss": 1.2693,
      "step": 105400
    },
    {
      "epoch": 31.842900302114803,
      "eval_loss": 1.289212942123413,
      "eval_runtime": 695.904,
      "eval_samples_per_second": 76.302,
      "eval_steps_per_second": 0.596,
      "step": 105400
    },
    {
      "epoch": 31.858006042296072,
      "grad_norm": 0.4780946373939514,
      "learning_rate": 4.54281973816717e-05,
      "loss": 1.2686,
      "step": 105450
    },
    {
      "epoch": 31.858006042296072,
      "eval_loss": 1.2916713953018188,
      "eval_runtime": 611.2499,
      "eval_samples_per_second": 86.87,
      "eval_steps_per_second": 0.679,
      "step": 105450
    },
    {
      "epoch": 31.87311178247734,
      "grad_norm": 0.4513004422187805,
      "learning_rate": 4.541812688821752e-05,
      "loss": 1.2715,
      "step": 105500
    },
    {
      "epoch": 31.87311178247734,
      "eval_loss": 1.2896168231964111,
      "eval_runtime": 647.1893,
      "eval_samples_per_second": 82.046,
      "eval_steps_per_second": 0.641,
      "step": 105500
    },
    {
      "epoch": 31.88821752265861,
      "grad_norm": 0.4659312665462494,
      "learning_rate": 4.540805639476334e-05,
      "loss": 1.2578,
      "step": 105550
    },
    {
      "epoch": 31.88821752265861,
      "eval_loss": 1.2888439893722534,
      "eval_runtime": 691.479,
      "eval_samples_per_second": 76.79,
      "eval_steps_per_second": 0.6,
      "step": 105550
    },
    {
      "epoch": 31.90332326283988,
      "grad_norm": 0.4323904812335968,
      "learning_rate": 4.5397985901309165e-05,
      "loss": 1.2541,
      "step": 105600
    },
    {
      "epoch": 31.90332326283988,
      "eval_loss": 1.2908316850662231,
      "eval_runtime": 699.019,
      "eval_samples_per_second": 75.962,
      "eval_steps_per_second": 0.594,
      "step": 105600
    },
    {
      "epoch": 31.91842900302115,
      "grad_norm": 0.4342065453529358,
      "learning_rate": 4.5387915407854984e-05,
      "loss": 1.2593,
      "step": 105650
    },
    {
      "epoch": 31.91842900302115,
      "eval_loss": 1.2920923233032227,
      "eval_runtime": 600.4457,
      "eval_samples_per_second": 88.433,
      "eval_steps_per_second": 0.691,
      "step": 105650
    },
    {
      "epoch": 31.93353474320242,
      "grad_norm": 0.4382164776325226,
      "learning_rate": 4.537784491440081e-05,
      "loss": 1.2675,
      "step": 105700
    },
    {
      "epoch": 31.93353474320242,
      "eval_loss": 1.2914745807647705,
      "eval_runtime": 619.0804,
      "eval_samples_per_second": 85.771,
      "eval_steps_per_second": 0.67,
      "step": 105700
    },
    {
      "epoch": 31.948640483383684,
      "grad_norm": 0.4874098598957062,
      "learning_rate": 4.536777442094663e-05,
      "loss": 1.2601,
      "step": 105750
    },
    {
      "epoch": 31.948640483383684,
      "eval_loss": 1.290086030960083,
      "eval_runtime": 698.0747,
      "eval_samples_per_second": 76.065,
      "eval_steps_per_second": 0.594,
      "step": 105750
    },
    {
      "epoch": 31.963746223564954,
      "grad_norm": 0.41935020685195923,
      "learning_rate": 4.5357703927492454e-05,
      "loss": 1.2719,
      "step": 105800
    },
    {
      "epoch": 31.963746223564954,
      "eval_loss": 1.2900656461715698,
      "eval_runtime": 632.9049,
      "eval_samples_per_second": 83.897,
      "eval_steps_per_second": 0.656,
      "step": 105800
    },
    {
      "epoch": 31.978851963746223,
      "grad_norm": 0.4420807361602783,
      "learning_rate": 4.534763343403827e-05,
      "loss": 1.2552,
      "step": 105850
    },
    {
      "epoch": 31.978851963746223,
      "eval_loss": 1.2878046035766602,
      "eval_runtime": 605.5188,
      "eval_samples_per_second": 87.692,
      "eval_steps_per_second": 0.685,
      "step": 105850
    },
    {
      "epoch": 31.993957703927492,
      "grad_norm": 0.46773695945739746,
      "learning_rate": 4.533756294058409e-05,
      "loss": 1.2641,
      "step": 105900
    },
    {
      "epoch": 31.993957703927492,
      "eval_loss": 1.287880301475525,
      "eval_runtime": 651.5883,
      "eval_samples_per_second": 81.492,
      "eval_steps_per_second": 0.637,
      "step": 105900
    },
    {
      "epoch": 32.00906344410876,
      "grad_norm": 0.4737047255039215,
      "learning_rate": 4.532749244712991e-05,
      "loss": 1.2772,
      "step": 105950
    },
    {
      "epoch": 32.00906344410876,
      "eval_loss": 1.2892179489135742,
      "eval_runtime": 675.5833,
      "eval_samples_per_second": 78.597,
      "eval_steps_per_second": 0.614,
      "step": 105950
    },
    {
      "epoch": 32.02416918429003,
      "grad_norm": 0.457387775182724,
      "learning_rate": 4.5317421953675735e-05,
      "loss": 1.2666,
      "step": 106000
    },
    {
      "epoch": 32.02416918429003,
      "eval_loss": 1.2911300659179688,
      "eval_runtime": 614.9932,
      "eval_samples_per_second": 86.341,
      "eval_steps_per_second": 0.675,
      "step": 106000
    },
    {
      "epoch": 32.0392749244713,
      "grad_norm": 0.48503854870796204,
      "learning_rate": 4.5307351460221554e-05,
      "loss": 1.2697,
      "step": 106050
    },
    {
      "epoch": 32.0392749244713,
      "eval_loss": 1.2891052961349487,
      "eval_runtime": 622.1839,
      "eval_samples_per_second": 85.343,
      "eval_steps_per_second": 0.667,
      "step": 106050
    },
    {
      "epoch": 32.05438066465257,
      "grad_norm": 0.4548330008983612,
      "learning_rate": 4.529728096676737e-05,
      "loss": 1.2559,
      "step": 106100
    },
    {
      "epoch": 32.05438066465257,
      "eval_loss": 1.2891910076141357,
      "eval_runtime": 662.9515,
      "eval_samples_per_second": 80.095,
      "eval_steps_per_second": 0.626,
      "step": 106100
    },
    {
      "epoch": 32.06948640483384,
      "grad_norm": 0.43830057978630066,
      "learning_rate": 4.528721047331319e-05,
      "loss": 1.261,
      "step": 106150
    },
    {
      "epoch": 32.06948640483384,
      "eval_loss": 1.2887763977050781,
      "eval_runtime": 713.2228,
      "eval_samples_per_second": 74.449,
      "eval_steps_per_second": 0.582,
      "step": 106150
    },
    {
      "epoch": 32.08459214501511,
      "grad_norm": 0.45383554697036743,
      "learning_rate": 4.527713997985902e-05,
      "loss": 1.2638,
      "step": 106200
    },
    {
      "epoch": 32.08459214501511,
      "eval_loss": 1.291172981262207,
      "eval_runtime": 693.7433,
      "eval_samples_per_second": 76.54,
      "eval_steps_per_second": 0.598,
      "step": 106200
    },
    {
      "epoch": 32.09969788519638,
      "grad_norm": 0.4215274453163147,
      "learning_rate": 4.5267069486404835e-05,
      "loss": 1.2542,
      "step": 106250
    },
    {
      "epoch": 32.09969788519638,
      "eval_loss": 1.292037010192871,
      "eval_runtime": 630.9684,
      "eval_samples_per_second": 84.155,
      "eval_steps_per_second": 0.658,
      "step": 106250
    },
    {
      "epoch": 32.11480362537765,
      "grad_norm": 0.45249250531196594,
      "learning_rate": 4.5256998992950654e-05,
      "loss": 1.2646,
      "step": 106300
    },
    {
      "epoch": 32.11480362537765,
      "eval_loss": 1.2883150577545166,
      "eval_runtime": 621.2776,
      "eval_samples_per_second": 85.467,
      "eval_steps_per_second": 0.668,
      "step": 106300
    },
    {
      "epoch": 32.12990936555891,
      "grad_norm": 0.4499654769897461,
      "learning_rate": 4.524692849949647e-05,
      "loss": 1.2703,
      "step": 106350
    },
    {
      "epoch": 32.12990936555891,
      "eval_loss": 1.2898975610733032,
      "eval_runtime": 640.6259,
      "eval_samples_per_second": 82.886,
      "eval_steps_per_second": 0.648,
      "step": 106350
    },
    {
      "epoch": 32.14501510574018,
      "grad_norm": 0.47076737880706787,
      "learning_rate": 4.52368580060423e-05,
      "loss": 1.2592,
      "step": 106400
    },
    {
      "epoch": 32.14501510574018,
      "eval_loss": 1.2897311449050903,
      "eval_runtime": 631.9645,
      "eval_samples_per_second": 84.022,
      "eval_steps_per_second": 0.657,
      "step": 106400
    },
    {
      "epoch": 32.16012084592145,
      "grad_norm": 0.44696977734565735,
      "learning_rate": 4.522678751258812e-05,
      "loss": 1.2779,
      "step": 106450
    },
    {
      "epoch": 32.16012084592145,
      "eval_loss": 1.2876943349838257,
      "eval_runtime": 704.9956,
      "eval_samples_per_second": 75.318,
      "eval_steps_per_second": 0.589,
      "step": 106450
    },
    {
      "epoch": 32.17522658610272,
      "grad_norm": 0.4811650514602661,
      "learning_rate": 4.5216717019133936e-05,
      "loss": 1.2724,
      "step": 106500
    },
    {
      "epoch": 32.17522658610272,
      "eval_loss": 1.2898459434509277,
      "eval_runtime": 692.4249,
      "eval_samples_per_second": 76.686,
      "eval_steps_per_second": 0.599,
      "step": 106500
    },
    {
      "epoch": 32.190332326283986,
      "grad_norm": 0.47286200523376465,
      "learning_rate": 4.520664652567976e-05,
      "loss": 1.2647,
      "step": 106550
    },
    {
      "epoch": 32.190332326283986,
      "eval_loss": 1.2887946367263794,
      "eval_runtime": 705.9804,
      "eval_samples_per_second": 75.213,
      "eval_steps_per_second": 0.588,
      "step": 106550
    },
    {
      "epoch": 32.205438066465256,
      "grad_norm": 0.49803465604782104,
      "learning_rate": 4.519657603222558e-05,
      "loss": 1.2509,
      "step": 106600
    },
    {
      "epoch": 32.205438066465256,
      "eval_loss": 1.288411259651184,
      "eval_runtime": 686.5232,
      "eval_samples_per_second": 77.345,
      "eval_steps_per_second": 0.604,
      "step": 106600
    },
    {
      "epoch": 32.220543806646525,
      "grad_norm": 0.4724535346031189,
      "learning_rate": 4.51865055387714e-05,
      "loss": 1.2579,
      "step": 106650
    },
    {
      "epoch": 32.220543806646525,
      "eval_loss": 1.2899671792984009,
      "eval_runtime": 636.0769,
      "eval_samples_per_second": 83.479,
      "eval_steps_per_second": 0.652,
      "step": 106650
    },
    {
      "epoch": 32.235649546827794,
      "grad_norm": 0.4366934299468994,
      "learning_rate": 4.517643504531722e-05,
      "loss": 1.2625,
      "step": 106700
    },
    {
      "epoch": 32.235649546827794,
      "eval_loss": 1.2882013320922852,
      "eval_runtime": 633.8608,
      "eval_samples_per_second": 83.771,
      "eval_steps_per_second": 0.655,
      "step": 106700
    },
    {
      "epoch": 32.25075528700906,
      "grad_norm": 0.45592910051345825,
      "learning_rate": 4.516636455186304e-05,
      "loss": 1.2679,
      "step": 106750
    },
    {
      "epoch": 32.25075528700906,
      "eval_loss": 1.2888877391815186,
      "eval_runtime": 672.3642,
      "eval_samples_per_second": 78.974,
      "eval_steps_per_second": 0.617,
      "step": 106750
    },
    {
      "epoch": 32.26586102719033,
      "grad_norm": 0.460873544216156,
      "learning_rate": 4.515629405840886e-05,
      "loss": 1.2638,
      "step": 106800
    },
    {
      "epoch": 32.26586102719033,
      "eval_loss": 1.2903780937194824,
      "eval_runtime": 621.143,
      "eval_samples_per_second": 85.486,
      "eval_steps_per_second": 0.668,
      "step": 106800
    },
    {
      "epoch": 32.2809667673716,
      "grad_norm": 0.47218626737594604,
      "learning_rate": 4.514622356495468e-05,
      "loss": 1.2734,
      "step": 106850
    },
    {
      "epoch": 32.2809667673716,
      "eval_loss": 1.2894357442855835,
      "eval_runtime": 659.7296,
      "eval_samples_per_second": 80.486,
      "eval_steps_per_second": 0.629,
      "step": 106850
    },
    {
      "epoch": 32.29607250755287,
      "grad_norm": 0.49664756655693054,
      "learning_rate": 4.5136153071500505e-05,
      "loss": 1.2535,
      "step": 106900
    },
    {
      "epoch": 32.29607250755287,
      "eval_loss": 1.290153980255127,
      "eval_runtime": 685.792,
      "eval_samples_per_second": 77.427,
      "eval_steps_per_second": 0.605,
      "step": 106900
    },
    {
      "epoch": 32.31117824773414,
      "grad_norm": 0.41029900312423706,
      "learning_rate": 4.512608257804633e-05,
      "loss": 1.2653,
      "step": 106950
    },
    {
      "epoch": 32.31117824773414,
      "eval_loss": 1.2878973484039307,
      "eval_runtime": 621.105,
      "eval_samples_per_second": 85.491,
      "eval_steps_per_second": 0.668,
      "step": 106950
    },
    {
      "epoch": 32.32628398791541,
      "grad_norm": 0.4866046905517578,
      "learning_rate": 4.511601208459215e-05,
      "loss": 1.2748,
      "step": 107000
    },
    {
      "epoch": 32.32628398791541,
      "eval_loss": 1.2880682945251465,
      "eval_runtime": 707.5592,
      "eval_samples_per_second": 75.045,
      "eval_steps_per_second": 0.587,
      "step": 107000
    },
    {
      "epoch": 32.34138972809668,
      "grad_norm": 0.4417498707771301,
      "learning_rate": 4.510594159113797e-05,
      "loss": 1.258,
      "step": 107050
    },
    {
      "epoch": 32.34138972809668,
      "eval_loss": 1.2884464263916016,
      "eval_runtime": 623.9728,
      "eval_samples_per_second": 85.098,
      "eval_steps_per_second": 0.665,
      "step": 107050
    },
    {
      "epoch": 32.35649546827795,
      "grad_norm": 0.40790772438049316,
      "learning_rate": 4.509587109768379e-05,
      "loss": 1.266,
      "step": 107100
    },
    {
      "epoch": 32.35649546827795,
      "eval_loss": 1.288288950920105,
      "eval_runtime": 620.0013,
      "eval_samples_per_second": 85.643,
      "eval_steps_per_second": 0.669,
      "step": 107100
    },
    {
      "epoch": 32.37160120845922,
      "grad_norm": 0.44827932119369507,
      "learning_rate": 4.508580060422961e-05,
      "loss": 1.2556,
      "step": 107150
    },
    {
      "epoch": 32.37160120845922,
      "eval_loss": 1.2879589796066284,
      "eval_runtime": 614.2092,
      "eval_samples_per_second": 86.451,
      "eval_steps_per_second": 0.676,
      "step": 107150
    },
    {
      "epoch": 32.38670694864048,
      "grad_norm": 0.4204461872577667,
      "learning_rate": 4.507573011077543e-05,
      "loss": 1.2563,
      "step": 107200
    },
    {
      "epoch": 32.38670694864048,
      "eval_loss": 1.2913134098052979,
      "eval_runtime": 710.1131,
      "eval_samples_per_second": 74.775,
      "eval_steps_per_second": 0.584,
      "step": 107200
    },
    {
      "epoch": 32.40181268882175,
      "grad_norm": 0.4545978605747223,
      "learning_rate": 4.506565961732125e-05,
      "loss": 1.2469,
      "step": 107250
    },
    {
      "epoch": 32.40181268882175,
      "eval_loss": 1.2879329919815063,
      "eval_runtime": 691.4345,
      "eval_samples_per_second": 76.795,
      "eval_steps_per_second": 0.6,
      "step": 107250
    },
    {
      "epoch": 32.41691842900302,
      "grad_norm": 0.4924055337905884,
      "learning_rate": 4.505558912386707e-05,
      "loss": 1.255,
      "step": 107300
    },
    {
      "epoch": 32.41691842900302,
      "eval_loss": 1.2893998622894287,
      "eval_runtime": 708.0804,
      "eval_samples_per_second": 74.99,
      "eval_steps_per_second": 0.586,
      "step": 107300
    },
    {
      "epoch": 32.43202416918429,
      "grad_norm": 0.43452709913253784,
      "learning_rate": 4.5045518630412894e-05,
      "loss": 1.2669,
      "step": 107350
    },
    {
      "epoch": 32.43202416918429,
      "eval_loss": 1.2893182039260864,
      "eval_runtime": 754.0467,
      "eval_samples_per_second": 70.419,
      "eval_steps_per_second": 0.55,
      "step": 107350
    },
    {
      "epoch": 32.44712990936556,
      "grad_norm": 0.5001183152198792,
      "learning_rate": 4.503544813695871e-05,
      "loss": 1.2446,
      "step": 107400
    },
    {
      "epoch": 32.44712990936556,
      "eval_loss": 1.2897833585739136,
      "eval_runtime": 682.0885,
      "eval_samples_per_second": 77.848,
      "eval_steps_per_second": 0.608,
      "step": 107400
    },
    {
      "epoch": 32.46223564954683,
      "grad_norm": 0.4651360511779785,
      "learning_rate": 4.502537764350453e-05,
      "loss": 1.247,
      "step": 107450
    },
    {
      "epoch": 32.46223564954683,
      "eval_loss": 1.2883431911468506,
      "eval_runtime": 680.5083,
      "eval_samples_per_second": 78.028,
      "eval_steps_per_second": 0.61,
      "step": 107450
    },
    {
      "epoch": 32.477341389728096,
      "grad_norm": 0.470040887594223,
      "learning_rate": 4.501530715005035e-05,
      "loss": 1.2893,
      "step": 107500
    },
    {
      "epoch": 32.477341389728096,
      "eval_loss": 1.2890257835388184,
      "eval_runtime": 629.4915,
      "eval_samples_per_second": 84.352,
      "eval_steps_per_second": 0.659,
      "step": 107500
    },
    {
      "epoch": 32.492447129909365,
      "grad_norm": 0.44590288400650024,
      "learning_rate": 4.5005236656596175e-05,
      "loss": 1.2498,
      "step": 107550
    },
    {
      "epoch": 32.492447129909365,
      "eval_loss": 1.2893612384796143,
      "eval_runtime": 601.5459,
      "eval_samples_per_second": 88.271,
      "eval_steps_per_second": 0.69,
      "step": 107550
    },
    {
      "epoch": 32.507552870090635,
      "grad_norm": 0.4244970381259918,
      "learning_rate": 4.4995166163141994e-05,
      "loss": 1.2722,
      "step": 107600
    },
    {
      "epoch": 32.507552870090635,
      "eval_loss": 1.2894073724746704,
      "eval_runtime": 622.2609,
      "eval_samples_per_second": 85.332,
      "eval_steps_per_second": 0.667,
      "step": 107600
    },
    {
      "epoch": 32.522658610271904,
      "grad_norm": 0.4319485127925873,
      "learning_rate": 4.498509566968781e-05,
      "loss": 1.2367,
      "step": 107650
    },
    {
      "epoch": 32.522658610271904,
      "eval_loss": 1.2877682447433472,
      "eval_runtime": 652.7757,
      "eval_samples_per_second": 81.343,
      "eval_steps_per_second": 0.636,
      "step": 107650
    },
    {
      "epoch": 32.53776435045317,
      "grad_norm": 0.43499618768692017,
      "learning_rate": 4.497502517623364e-05,
      "loss": 1.2614,
      "step": 107700
    },
    {
      "epoch": 32.53776435045317,
      "eval_loss": 1.2871577739715576,
      "eval_runtime": 675.9653,
      "eval_samples_per_second": 78.553,
      "eval_steps_per_second": 0.614,
      "step": 107700
    },
    {
      "epoch": 32.55287009063444,
      "grad_norm": 0.4421561360359192,
      "learning_rate": 4.496495468277946e-05,
      "loss": 1.2605,
      "step": 107750
    },
    {
      "epoch": 32.55287009063444,
      "eval_loss": 1.2886157035827637,
      "eval_runtime": 614.6554,
      "eval_samples_per_second": 86.388,
      "eval_steps_per_second": 0.675,
      "step": 107750
    },
    {
      "epoch": 32.56797583081571,
      "grad_norm": 0.4830114245414734,
      "learning_rate": 4.4954884189325276e-05,
      "loss": 1.2778,
      "step": 107800
    },
    {
      "epoch": 32.56797583081571,
      "eval_loss": 1.2875996828079224,
      "eval_runtime": 678.0187,
      "eval_samples_per_second": 78.315,
      "eval_steps_per_second": 0.612,
      "step": 107800
    },
    {
      "epoch": 32.58308157099698,
      "grad_norm": 0.4233280420303345,
      "learning_rate": 4.4944813695871094e-05,
      "loss": 1.2626,
      "step": 107850
    },
    {
      "epoch": 32.58308157099698,
      "eval_loss": 1.2887622117996216,
      "eval_runtime": 734.2457,
      "eval_samples_per_second": 72.318,
      "eval_steps_per_second": 0.565,
      "step": 107850
    },
    {
      "epoch": 32.59818731117825,
      "grad_norm": 0.4439978003501892,
      "learning_rate": 4.493474320241692e-05,
      "loss": 1.2506,
      "step": 107900
    },
    {
      "epoch": 32.59818731117825,
      "eval_loss": 1.286657691001892,
      "eval_runtime": 658.0775,
      "eval_samples_per_second": 80.688,
      "eval_steps_per_second": 0.631,
      "step": 107900
    },
    {
      "epoch": 32.61329305135952,
      "grad_norm": 0.41643816232681274,
      "learning_rate": 4.492467270896274e-05,
      "loss": 1.248,
      "step": 107950
    },
    {
      "epoch": 32.61329305135952,
      "eval_loss": 1.288812279701233,
      "eval_runtime": 659.534,
      "eval_samples_per_second": 80.51,
      "eval_steps_per_second": 0.629,
      "step": 107950
    },
    {
      "epoch": 32.62839879154078,
      "grad_norm": 0.4526420831680298,
      "learning_rate": 4.491460221550856e-05,
      "loss": 1.2865,
      "step": 108000
    },
    {
      "epoch": 32.62839879154078,
      "eval_loss": 1.2897692918777466,
      "eval_runtime": 781.9945,
      "eval_samples_per_second": 67.902,
      "eval_steps_per_second": 0.531,
      "step": 108000
    },
    {
      "epoch": 32.64350453172205,
      "grad_norm": 0.4424575865268707,
      "learning_rate": 4.490453172205438e-05,
      "loss": 1.2518,
      "step": 108050
    },
    {
      "epoch": 32.64350453172205,
      "eval_loss": 1.2874037027359009,
      "eval_runtime": 755.1279,
      "eval_samples_per_second": 70.318,
      "eval_steps_per_second": 0.55,
      "step": 108050
    },
    {
      "epoch": 32.65861027190332,
      "grad_norm": 0.4903242290019989,
      "learning_rate": 4.489446122860021e-05,
      "loss": 1.2618,
      "step": 108100
    },
    {
      "epoch": 32.65861027190332,
      "eval_loss": 1.2871534824371338,
      "eval_runtime": 661.1543,
      "eval_samples_per_second": 80.313,
      "eval_steps_per_second": 0.628,
      "step": 108100
    },
    {
      "epoch": 32.67371601208459,
      "grad_norm": 0.4316314160823822,
      "learning_rate": 4.488439073514603e-05,
      "loss": 1.2485,
      "step": 108150
    },
    {
      "epoch": 32.67371601208459,
      "eval_loss": 1.2881879806518555,
      "eval_runtime": 587.5938,
      "eval_samples_per_second": 90.367,
      "eval_steps_per_second": 0.706,
      "step": 108150
    },
    {
      "epoch": 32.68882175226586,
      "grad_norm": 0.46745315194129944,
      "learning_rate": 4.4874320241691846e-05,
      "loss": 1.2754,
      "step": 108200
    },
    {
      "epoch": 32.68882175226586,
      "eval_loss": 1.2884535789489746,
      "eval_runtime": 603.9396,
      "eval_samples_per_second": 87.921,
      "eval_steps_per_second": 0.687,
      "step": 108200
    },
    {
      "epoch": 32.70392749244713,
      "grad_norm": 0.4544772207736969,
      "learning_rate": 4.4864249748237664e-05,
      "loss": 1.252,
      "step": 108250
    },
    {
      "epoch": 32.70392749244713,
      "eval_loss": 1.2887523174285889,
      "eval_runtime": 719.2721,
      "eval_samples_per_second": 73.823,
      "eval_steps_per_second": 0.577,
      "step": 108250
    },
    {
      "epoch": 32.7190332326284,
      "grad_norm": 0.4552517533302307,
      "learning_rate": 4.485417925478349e-05,
      "loss": 1.2642,
      "step": 108300
    },
    {
      "epoch": 32.7190332326284,
      "eval_loss": 1.2875211238861084,
      "eval_runtime": 712.0386,
      "eval_samples_per_second": 74.573,
      "eval_steps_per_second": 0.583,
      "step": 108300
    },
    {
      "epoch": 32.73413897280967,
      "grad_norm": 0.46116581559181213,
      "learning_rate": 4.484410876132931e-05,
      "loss": 1.2802,
      "step": 108350
    },
    {
      "epoch": 32.73413897280967,
      "eval_loss": 1.2861875295639038,
      "eval_runtime": 624.1997,
      "eval_samples_per_second": 85.067,
      "eval_steps_per_second": 0.665,
      "step": 108350
    },
    {
      "epoch": 32.74924471299094,
      "grad_norm": 0.48049992322921753,
      "learning_rate": 4.483403826787513e-05,
      "loss": 1.2605,
      "step": 108400
    },
    {
      "epoch": 32.74924471299094,
      "eval_loss": 1.28554368019104,
      "eval_runtime": 616.3224,
      "eval_samples_per_second": 86.155,
      "eval_steps_per_second": 0.673,
      "step": 108400
    },
    {
      "epoch": 32.764350453172206,
      "grad_norm": 0.48823219537734985,
      "learning_rate": 4.4823967774420946e-05,
      "loss": 1.2743,
      "step": 108450
    },
    {
      "epoch": 32.764350453172206,
      "eval_loss": 1.2879858016967773,
      "eval_runtime": 641.1889,
      "eval_samples_per_second": 82.813,
      "eval_steps_per_second": 0.647,
      "step": 108450
    },
    {
      "epoch": 32.779456193353475,
      "grad_norm": 0.4469228982925415,
      "learning_rate": 4.481389728096677e-05,
      "loss": 1.2493,
      "step": 108500
    },
    {
      "epoch": 32.779456193353475,
      "eval_loss": 1.289008617401123,
      "eval_runtime": 636.8913,
      "eval_samples_per_second": 83.372,
      "eval_steps_per_second": 0.652,
      "step": 108500
    },
    {
      "epoch": 32.794561933534744,
      "grad_norm": 0.5009257793426514,
      "learning_rate": 4.480382678751259e-05,
      "loss": 1.252,
      "step": 108550
    },
    {
      "epoch": 32.794561933534744,
      "eval_loss": 1.2874188423156738,
      "eval_runtime": 666.8426,
      "eval_samples_per_second": 79.627,
      "eval_steps_per_second": 0.622,
      "step": 108550
    },
    {
      "epoch": 32.809667673716014,
      "grad_norm": 0.48954570293426514,
      "learning_rate": 4.479375629405841e-05,
      "loss": 1.2612,
      "step": 108600
    },
    {
      "epoch": 32.809667673716014,
      "eval_loss": 1.289241075515747,
      "eval_runtime": 657.7265,
      "eval_samples_per_second": 80.731,
      "eval_steps_per_second": 0.631,
      "step": 108600
    },
    {
      "epoch": 32.82477341389728,
      "grad_norm": 0.4672574996948242,
      "learning_rate": 4.478368580060423e-05,
      "loss": 1.2591,
      "step": 108650
    },
    {
      "epoch": 32.82477341389728,
      "eval_loss": 1.2859982252120972,
      "eval_runtime": 603.9228,
      "eval_samples_per_second": 87.923,
      "eval_steps_per_second": 0.687,
      "step": 108650
    },
    {
      "epoch": 32.83987915407855,
      "grad_norm": 0.46723517775535583,
      "learning_rate": 4.477361530715005e-05,
      "loss": 1.2678,
      "step": 108700
    },
    {
      "epoch": 32.83987915407855,
      "eval_loss": 1.287903904914856,
      "eval_runtime": 587.6728,
      "eval_samples_per_second": 90.355,
      "eval_steps_per_second": 0.706,
      "step": 108700
    },
    {
      "epoch": 32.85498489425982,
      "grad_norm": 0.45470333099365234,
      "learning_rate": 4.476354481369587e-05,
      "loss": 1.2434,
      "step": 108750
    },
    {
      "epoch": 32.85498489425982,
      "eval_loss": 1.2885874509811401,
      "eval_runtime": 619.9001,
      "eval_samples_per_second": 85.657,
      "eval_steps_per_second": 0.669,
      "step": 108750
    },
    {
      "epoch": 32.87009063444109,
      "grad_norm": 0.42342808842658997,
      "learning_rate": 4.475347432024169e-05,
      "loss": 1.2709,
      "step": 108800
    },
    {
      "epoch": 32.87009063444109,
      "eval_loss": 1.2859089374542236,
      "eval_runtime": 888.1077,
      "eval_samples_per_second": 59.789,
      "eval_steps_per_second": 0.467,
      "step": 108800
    },
    {
      "epoch": 32.88519637462235,
      "grad_norm": 0.44416284561157227,
      "learning_rate": 4.4743403826787516e-05,
      "loss": 1.2478,
      "step": 108850
    },
    {
      "epoch": 32.88519637462235,
      "eval_loss": 1.2865384817123413,
      "eval_runtime": 673.8701,
      "eval_samples_per_second": 78.797,
      "eval_steps_per_second": 0.616,
      "step": 108850
    },
    {
      "epoch": 32.90030211480362,
      "grad_norm": 0.482320636510849,
      "learning_rate": 4.4733333333333334e-05,
      "loss": 1.2766,
      "step": 108900
    },
    {
      "epoch": 32.90030211480362,
      "eval_loss": 1.2863116264343262,
      "eval_runtime": 622.8592,
      "eval_samples_per_second": 85.25,
      "eval_steps_per_second": 0.666,
      "step": 108900
    },
    {
      "epoch": 32.91540785498489,
      "grad_norm": 0.4648646414279938,
      "learning_rate": 4.472326283987915e-05,
      "loss": 1.2993,
      "step": 108950
    },
    {
      "epoch": 32.91540785498489,
      "eval_loss": 1.2886520624160767,
      "eval_runtime": 623.8998,
      "eval_samples_per_second": 85.108,
      "eval_steps_per_second": 0.665,
      "step": 108950
    },
    {
      "epoch": 32.93051359516616,
      "grad_norm": 0.4636026918888092,
      "learning_rate": 4.471319234642497e-05,
      "loss": 1.2692,
      "step": 109000
    },
    {
      "epoch": 32.93051359516616,
      "eval_loss": 1.2870460748672485,
      "eval_runtime": 652.3389,
      "eval_samples_per_second": 81.398,
      "eval_steps_per_second": 0.636,
      "step": 109000
    },
    {
      "epoch": 32.94561933534743,
      "grad_norm": 0.4422442615032196,
      "learning_rate": 4.47031218529708e-05,
      "loss": 1.2649,
      "step": 109050
    },
    {
      "epoch": 32.94561933534743,
      "eval_loss": 1.2863397598266602,
      "eval_runtime": 623.1744,
      "eval_samples_per_second": 85.207,
      "eval_steps_per_second": 0.666,
      "step": 109050
    },
    {
      "epoch": 32.9607250755287,
      "grad_norm": 0.47017356753349304,
      "learning_rate": 4.4693051359516616e-05,
      "loss": 1.2682,
      "step": 109100
    },
    {
      "epoch": 32.9607250755287,
      "eval_loss": 1.2858073711395264,
      "eval_runtime": 658.8102,
      "eval_samples_per_second": 80.598,
      "eval_steps_per_second": 0.63,
      "step": 109100
    },
    {
      "epoch": 32.97583081570997,
      "grad_norm": 0.4289399981498718,
      "learning_rate": 4.4682980866062434e-05,
      "loss": 1.2697,
      "step": 109150
    },
    {
      "epoch": 32.97583081570997,
      "eval_loss": 1.2858586311340332,
      "eval_runtime": 656.8886,
      "eval_samples_per_second": 80.834,
      "eval_steps_per_second": 0.632,
      "step": 109150
    },
    {
      "epoch": 32.99093655589124,
      "grad_norm": 0.45635345578193665,
      "learning_rate": 4.467291037260826e-05,
      "loss": 1.2882,
      "step": 109200
    },
    {
      "epoch": 32.99093655589124,
      "eval_loss": 1.2879853248596191,
      "eval_runtime": 612.4401,
      "eval_samples_per_second": 86.701,
      "eval_steps_per_second": 0.678,
      "step": 109200
    },
    {
      "epoch": 33.00604229607251,
      "grad_norm": 0.4226705729961395,
      "learning_rate": 4.4662839879154085e-05,
      "loss": 1.2496,
      "step": 109250
    },
    {
      "epoch": 33.00604229607251,
      "eval_loss": 1.287466049194336,
      "eval_runtime": 672.8013,
      "eval_samples_per_second": 78.922,
      "eval_steps_per_second": 0.617,
      "step": 109250
    },
    {
      "epoch": 33.02114803625378,
      "grad_norm": 0.4350350797176361,
      "learning_rate": 4.4652769385699904e-05,
      "loss": 1.2632,
      "step": 109300
    },
    {
      "epoch": 33.02114803625378,
      "eval_loss": 1.2881815433502197,
      "eval_runtime": 693.4397,
      "eval_samples_per_second": 76.573,
      "eval_steps_per_second": 0.598,
      "step": 109300
    },
    {
      "epoch": 33.036253776435046,
      "grad_norm": 0.5312995314598083,
      "learning_rate": 4.464269889224572e-05,
      "loss": 1.2643,
      "step": 109350
    },
    {
      "epoch": 33.036253776435046,
      "eval_loss": 1.2868822813034058,
      "eval_runtime": 665.594,
      "eval_samples_per_second": 79.777,
      "eval_steps_per_second": 0.624,
      "step": 109350
    },
    {
      "epoch": 33.051359516616316,
      "grad_norm": 0.4640202522277832,
      "learning_rate": 4.463262839879154e-05,
      "loss": 1.2485,
      "step": 109400
    },
    {
      "epoch": 33.051359516616316,
      "eval_loss": 1.287197470664978,
      "eval_runtime": 803.0298,
      "eval_samples_per_second": 66.123,
      "eval_steps_per_second": 0.517,
      "step": 109400
    },
    {
      "epoch": 33.066465256797585,
      "grad_norm": 0.436463862657547,
      "learning_rate": 4.462255790533737e-05,
      "loss": 1.2913,
      "step": 109450
    },
    {
      "epoch": 33.066465256797585,
      "eval_loss": 1.2863465547561646,
      "eval_runtime": 656.9139,
      "eval_samples_per_second": 80.831,
      "eval_steps_per_second": 0.632,
      "step": 109450
    },
    {
      "epoch": 33.081570996978854,
      "grad_norm": 0.45596057176589966,
      "learning_rate": 4.4612487411883186e-05,
      "loss": 1.2458,
      "step": 109500
    },
    {
      "epoch": 33.081570996978854,
      "eval_loss": 1.2869508266448975,
      "eval_runtime": 604.6872,
      "eval_samples_per_second": 87.812,
      "eval_steps_per_second": 0.686,
      "step": 109500
    },
    {
      "epoch": 33.096676737160124,
      "grad_norm": 0.4968518912792206,
      "learning_rate": 4.4602416918429004e-05,
      "loss": 1.2556,
      "step": 109550
    },
    {
      "epoch": 33.096676737160124,
      "eval_loss": 1.2874279022216797,
      "eval_runtime": 690.4217,
      "eval_samples_per_second": 76.908,
      "eval_steps_per_second": 0.601,
      "step": 109550
    },
    {
      "epoch": 33.11178247734139,
      "grad_norm": 0.4723747968673706,
      "learning_rate": 4.459234642497482e-05,
      "loss": 1.2667,
      "step": 109600
    },
    {
      "epoch": 33.11178247734139,
      "eval_loss": 1.2853964567184448,
      "eval_runtime": 664.4642,
      "eval_samples_per_second": 79.913,
      "eval_steps_per_second": 0.625,
      "step": 109600
    },
    {
      "epoch": 33.126888217522655,
      "grad_norm": 0.43810075521469116,
      "learning_rate": 4.458227593152065e-05,
      "loss": 1.2734,
      "step": 109650
    },
    {
      "epoch": 33.126888217522655,
      "eval_loss": 1.2859472036361694,
      "eval_runtime": 652.6617,
      "eval_samples_per_second": 81.358,
      "eval_steps_per_second": 0.636,
      "step": 109650
    },
    {
      "epoch": 33.141993957703924,
      "grad_norm": 0.47368869185447693,
      "learning_rate": 4.457220543806647e-05,
      "loss": 1.257,
      "step": 109700
    },
    {
      "epoch": 33.141993957703924,
      "eval_loss": 1.28583562374115,
      "eval_runtime": 633.0859,
      "eval_samples_per_second": 83.873,
      "eval_steps_per_second": 0.656,
      "step": 109700
    },
    {
      "epoch": 33.157099697885194,
      "grad_norm": 0.43602603673934937,
      "learning_rate": 4.4562134944612286e-05,
      "loss": 1.2679,
      "step": 109750
    },
    {
      "epoch": 33.157099697885194,
      "eval_loss": 1.2876008749008179,
      "eval_runtime": 781.4766,
      "eval_samples_per_second": 67.947,
      "eval_steps_per_second": 0.531,
      "step": 109750
    },
    {
      "epoch": 33.17220543806646,
      "grad_norm": 0.4579477608203888,
      "learning_rate": 4.4552064451158104e-05,
      "loss": 1.2649,
      "step": 109800
    },
    {
      "epoch": 33.17220543806646,
      "eval_loss": 1.2887345552444458,
      "eval_runtime": 871.3843,
      "eval_samples_per_second": 60.936,
      "eval_steps_per_second": 0.476,
      "step": 109800
    },
    {
      "epoch": 33.18731117824773,
      "grad_norm": 0.4465799629688263,
      "learning_rate": 4.454199395770393e-05,
      "loss": 1.2544,
      "step": 109850
    },
    {
      "epoch": 33.18731117824773,
      "eval_loss": 1.2864372730255127,
      "eval_runtime": 749.3077,
      "eval_samples_per_second": 70.864,
      "eval_steps_per_second": 0.554,
      "step": 109850
    },
    {
      "epoch": 33.202416918429,
      "grad_norm": 0.4592010974884033,
      "learning_rate": 4.453192346424975e-05,
      "loss": 1.2268,
      "step": 109900
    },
    {
      "epoch": 33.202416918429,
      "eval_loss": 1.2868694067001343,
      "eval_runtime": 658.5857,
      "eval_samples_per_second": 80.626,
      "eval_steps_per_second": 0.63,
      "step": 109900
    },
    {
      "epoch": 33.21752265861027,
      "grad_norm": 0.468286395072937,
      "learning_rate": 4.452185297079557e-05,
      "loss": 1.2583,
      "step": 109950
    },
    {
      "epoch": 33.21752265861027,
      "eval_loss": 1.28519606590271,
      "eval_runtime": 615.5699,
      "eval_samples_per_second": 86.26,
      "eval_steps_per_second": 0.674,
      "step": 109950
    },
    {
      "epoch": 33.23262839879154,
      "grad_norm": 0.4726509749889374,
      "learning_rate": 4.451178247734139e-05,
      "loss": 1.2727,
      "step": 110000
    },
    {
      "epoch": 33.23262839879154,
      "eval_loss": 1.285542368888855,
      "eval_runtime": 661.0905,
      "eval_samples_per_second": 80.32,
      "eval_steps_per_second": 0.628,
      "step": 110000
    },
    {
      "epoch": 33.24773413897281,
      "grad_norm": 0.527956485748291,
      "learning_rate": 4.450171198388721e-05,
      "loss": 1.2565,
      "step": 110050
    },
    {
      "epoch": 33.24773413897281,
      "eval_loss": 1.2862566709518433,
      "eval_runtime": 612.1053,
      "eval_samples_per_second": 86.748,
      "eval_steps_per_second": 0.678,
      "step": 110050
    },
    {
      "epoch": 33.26283987915408,
      "grad_norm": 0.49178656935691833,
      "learning_rate": 4.449164149043303e-05,
      "loss": 1.2628,
      "step": 110100
    },
    {
      "epoch": 33.26283987915408,
      "eval_loss": 1.2845301628112793,
      "eval_runtime": 637.3745,
      "eval_samples_per_second": 83.309,
      "eval_steps_per_second": 0.651,
      "step": 110100
    },
    {
      "epoch": 33.27794561933535,
      "grad_norm": 0.45489218831062317,
      "learning_rate": 4.448157099697885e-05,
      "loss": 1.2845,
      "step": 110150
    },
    {
      "epoch": 33.27794561933535,
      "eval_loss": 1.2844454050064087,
      "eval_runtime": 619.4244,
      "eval_samples_per_second": 85.723,
      "eval_steps_per_second": 0.67,
      "step": 110150
    },
    {
      "epoch": 33.29305135951662,
      "grad_norm": 0.4263555109500885,
      "learning_rate": 4.4471500503524674e-05,
      "loss": 1.2328,
      "step": 110200
    },
    {
      "epoch": 33.29305135951662,
      "eval_loss": 1.2856476306915283,
      "eval_runtime": 665.375,
      "eval_samples_per_second": 79.803,
      "eval_steps_per_second": 0.624,
      "step": 110200
    },
    {
      "epoch": 33.30815709969789,
      "grad_norm": 0.46995511651039124,
      "learning_rate": 4.446143001007049e-05,
      "loss": 1.2474,
      "step": 110250
    },
    {
      "epoch": 33.30815709969789,
      "eval_loss": 1.2863008975982666,
      "eval_runtime": 672.9319,
      "eval_samples_per_second": 78.907,
      "eval_steps_per_second": 0.617,
      "step": 110250
    },
    {
      "epoch": 33.323262839879156,
      "grad_norm": 0.4286808371543884,
      "learning_rate": 4.445135951661631e-05,
      "loss": 1.2631,
      "step": 110300
    },
    {
      "epoch": 33.323262839879156,
      "eval_loss": 1.2877707481384277,
      "eval_runtime": 671.3551,
      "eval_samples_per_second": 79.092,
      "eval_steps_per_second": 0.618,
      "step": 110300
    },
    {
      "epoch": 33.338368580060425,
      "grad_norm": 0.43128108978271484,
      "learning_rate": 4.444128902316214e-05,
      "loss": 1.25,
      "step": 110350
    },
    {
      "epoch": 33.338368580060425,
      "eval_loss": 1.2871237993240356,
      "eval_runtime": 652.8704,
      "eval_samples_per_second": 81.332,
      "eval_steps_per_second": 0.636,
      "step": 110350
    },
    {
      "epoch": 33.353474320241695,
      "grad_norm": 0.44170355796813965,
      "learning_rate": 4.443121852970796e-05,
      "loss": 1.2445,
      "step": 110400
    },
    {
      "epoch": 33.353474320241695,
      "eval_loss": 1.2878921031951904,
      "eval_runtime": 686.4765,
      "eval_samples_per_second": 77.35,
      "eval_steps_per_second": 0.605,
      "step": 110400
    },
    {
      "epoch": 33.368580060422964,
      "grad_norm": 0.4522818326950073,
      "learning_rate": 4.442114803625378e-05,
      "loss": 1.2639,
      "step": 110450
    },
    {
      "epoch": 33.368580060422964,
      "eval_loss": 1.285738229751587,
      "eval_runtime": 650.7457,
      "eval_samples_per_second": 81.597,
      "eval_steps_per_second": 0.638,
      "step": 110450
    },
    {
      "epoch": 33.383685800604226,
      "grad_norm": 0.4282253384590149,
      "learning_rate": 4.44110775427996e-05,
      "loss": 1.2508,
      "step": 110500
    },
    {
      "epoch": 33.383685800604226,
      "eval_loss": 1.2849352359771729,
      "eval_runtime": 646.9564,
      "eval_samples_per_second": 82.075,
      "eval_steps_per_second": 0.641,
      "step": 110500
    },
    {
      "epoch": 33.398791540785496,
      "grad_norm": 0.49807801842689514,
      "learning_rate": 4.440100704934542e-05,
      "loss": 1.2547,
      "step": 110550
    },
    {
      "epoch": 33.398791540785496,
      "eval_loss": 1.2842791080474854,
      "eval_runtime": 677.4873,
      "eval_samples_per_second": 78.376,
      "eval_steps_per_second": 0.613,
      "step": 110550
    },
    {
      "epoch": 33.413897280966765,
      "grad_norm": 0.46957382559776306,
      "learning_rate": 4.4390936555891244e-05,
      "loss": 1.2796,
      "step": 110600
    },
    {
      "epoch": 33.413897280966765,
      "eval_loss": 1.2876611948013306,
      "eval_runtime": 688.6613,
      "eval_samples_per_second": 77.105,
      "eval_steps_per_second": 0.603,
      "step": 110600
    },
    {
      "epoch": 33.429003021148034,
      "grad_norm": 0.46384984254837036,
      "learning_rate": 4.438086606243706e-05,
      "loss": 1.2697,
      "step": 110650
    },
    {
      "epoch": 33.429003021148034,
      "eval_loss": 1.2848020792007446,
      "eval_runtime": 590.4518,
      "eval_samples_per_second": 89.929,
      "eval_steps_per_second": 0.703,
      "step": 110650
    },
    {
      "epoch": 33.4441087613293,
      "grad_norm": 0.45106080174446106,
      "learning_rate": 4.437079556898288e-05,
      "loss": 1.2589,
      "step": 110700
    },
    {
      "epoch": 33.4441087613293,
      "eval_loss": 1.2862074375152588,
      "eval_runtime": 600.7744,
      "eval_samples_per_second": 88.384,
      "eval_steps_per_second": 0.691,
      "step": 110700
    },
    {
      "epoch": 33.45921450151057,
      "grad_norm": 0.44013553857803345,
      "learning_rate": 4.43607250755287e-05,
      "loss": 1.2551,
      "step": 110750
    },
    {
      "epoch": 33.45921450151057,
      "eval_loss": 1.2844780683517456,
      "eval_runtime": 675.5354,
      "eval_samples_per_second": 78.603,
      "eval_steps_per_second": 0.614,
      "step": 110750
    },
    {
      "epoch": 33.47432024169184,
      "grad_norm": 0.497007817029953,
      "learning_rate": 4.4350654582074526e-05,
      "loss": 1.2642,
      "step": 110800
    },
    {
      "epoch": 33.47432024169184,
      "eval_loss": 1.286558985710144,
      "eval_runtime": 602.8518,
      "eval_samples_per_second": 88.08,
      "eval_steps_per_second": 0.688,
      "step": 110800
    },
    {
      "epoch": 33.48942598187311,
      "grad_norm": 0.45765724778175354,
      "learning_rate": 4.4340584088620344e-05,
      "loss": 1.252,
      "step": 110850
    },
    {
      "epoch": 33.48942598187311,
      "eval_loss": 1.2858470678329468,
      "eval_runtime": 643.7033,
      "eval_samples_per_second": 82.49,
      "eval_steps_per_second": 0.645,
      "step": 110850
    },
    {
      "epoch": 33.50453172205438,
      "grad_norm": 0.504818320274353,
      "learning_rate": 4.433051359516616e-05,
      "loss": 1.2618,
      "step": 110900
    },
    {
      "epoch": 33.50453172205438,
      "eval_loss": 1.2836494445800781,
      "eval_runtime": 677.909,
      "eval_samples_per_second": 78.328,
      "eval_steps_per_second": 0.612,
      "step": 110900
    },
    {
      "epoch": 33.51963746223565,
      "grad_norm": 0.5068368911743164,
      "learning_rate": 4.432044310171198e-05,
      "loss": 1.2395,
      "step": 110950
    },
    {
      "epoch": 33.51963746223565,
      "eval_loss": 1.2856837511062622,
      "eval_runtime": 617.4433,
      "eval_samples_per_second": 85.998,
      "eval_steps_per_second": 0.672,
      "step": 110950
    },
    {
      "epoch": 33.53474320241692,
      "grad_norm": 0.44482576847076416,
      "learning_rate": 4.431037260825781e-05,
      "loss": 1.2644,
      "step": 111000
    },
    {
      "epoch": 33.53474320241692,
      "eval_loss": 1.284764051437378,
      "eval_runtime": 660.5315,
      "eval_samples_per_second": 80.388,
      "eval_steps_per_second": 0.628,
      "step": 111000
    },
    {
      "epoch": 33.54984894259819,
      "grad_norm": 0.43967828154563904,
      "learning_rate": 4.4300302114803626e-05,
      "loss": 1.2612,
      "step": 111050
    },
    {
      "epoch": 33.54984894259819,
      "eval_loss": 1.285022258758545,
      "eval_runtime": 699.5735,
      "eval_samples_per_second": 75.902,
      "eval_steps_per_second": 0.593,
      "step": 111050
    },
    {
      "epoch": 33.56495468277946,
      "grad_norm": 0.45340511202812195,
      "learning_rate": 4.4290231621349444e-05,
      "loss": 1.2586,
      "step": 111100
    },
    {
      "epoch": 33.56495468277946,
      "eval_loss": 1.2841733694076538,
      "eval_runtime": 677.3048,
      "eval_samples_per_second": 78.398,
      "eval_steps_per_second": 0.613,
      "step": 111100
    },
    {
      "epoch": 33.58006042296073,
      "grad_norm": 0.4406012296676636,
      "learning_rate": 4.428016112789527e-05,
      "loss": 1.2712,
      "step": 111150
    },
    {
      "epoch": 33.58006042296073,
      "eval_loss": 1.2849035263061523,
      "eval_runtime": 688.1994,
      "eval_samples_per_second": 77.156,
      "eval_steps_per_second": 0.603,
      "step": 111150
    },
    {
      "epoch": 33.595166163142,
      "grad_norm": 0.45813339948654175,
      "learning_rate": 4.427009063444109e-05,
      "loss": 1.2536,
      "step": 111200
    },
    {
      "epoch": 33.595166163142,
      "eval_loss": 1.2840553522109985,
      "eval_runtime": 635.5615,
      "eval_samples_per_second": 83.547,
      "eval_steps_per_second": 0.653,
      "step": 111200
    },
    {
      "epoch": 33.610271903323266,
      "grad_norm": 0.44442352652549744,
      "learning_rate": 4.426002014098691e-05,
      "loss": 1.2714,
      "step": 111250
    },
    {
      "epoch": 33.610271903323266,
      "eval_loss": 1.2841962575912476,
      "eval_runtime": 637.3648,
      "eval_samples_per_second": 83.31,
      "eval_steps_per_second": 0.651,
      "step": 111250
    },
    {
      "epoch": 33.625377643504535,
      "grad_norm": 0.47012072801589966,
      "learning_rate": 4.4249949647532726e-05,
      "loss": 1.2553,
      "step": 111300
    },
    {
      "epoch": 33.625377643504535,
      "eval_loss": 1.2856879234313965,
      "eval_runtime": 672.6979,
      "eval_samples_per_second": 78.934,
      "eval_steps_per_second": 0.617,
      "step": 111300
    },
    {
      "epoch": 33.6404833836858,
      "grad_norm": 0.4524330198764801,
      "learning_rate": 4.423987915407855e-05,
      "loss": 1.2591,
      "step": 111350
    },
    {
      "epoch": 33.6404833836858,
      "eval_loss": 1.2835943698883057,
      "eval_runtime": 635.023,
      "eval_samples_per_second": 83.617,
      "eval_steps_per_second": 0.654,
      "step": 111350
    },
    {
      "epoch": 33.65558912386707,
      "grad_norm": 0.4942053258419037,
      "learning_rate": 4.422980866062437e-05,
      "loss": 1.2465,
      "step": 111400
    },
    {
      "epoch": 33.65558912386707,
      "eval_loss": 1.2837724685668945,
      "eval_runtime": 693.1472,
      "eval_samples_per_second": 76.606,
      "eval_steps_per_second": 0.599,
      "step": 111400
    },
    {
      "epoch": 33.670694864048336,
      "grad_norm": 0.44098013639450073,
      "learning_rate": 4.421973816717019e-05,
      "loss": 1.2599,
      "step": 111450
    },
    {
      "epoch": 33.670694864048336,
      "eval_loss": 1.2858484983444214,
      "eval_runtime": 686.6529,
      "eval_samples_per_second": 77.33,
      "eval_steps_per_second": 0.604,
      "step": 111450
    },
    {
      "epoch": 33.685800604229605,
      "grad_norm": 0.4397702217102051,
      "learning_rate": 4.420966767371601e-05,
      "loss": 1.2703,
      "step": 111500
    },
    {
      "epoch": 33.685800604229605,
      "eval_loss": 1.2855172157287598,
      "eval_runtime": 610.9146,
      "eval_samples_per_second": 86.917,
      "eval_steps_per_second": 0.679,
      "step": 111500
    },
    {
      "epoch": 33.700906344410875,
      "grad_norm": 0.4540596902370453,
      "learning_rate": 4.419959718026184e-05,
      "loss": 1.2624,
      "step": 111550
    },
    {
      "epoch": 33.700906344410875,
      "eval_loss": 1.2851675748825073,
      "eval_runtime": 606.5161,
      "eval_samples_per_second": 87.548,
      "eval_steps_per_second": 0.684,
      "step": 111550
    },
    {
      "epoch": 33.716012084592144,
      "grad_norm": 0.4439554512500763,
      "learning_rate": 4.418952668680766e-05,
      "loss": 1.2578,
      "step": 111600
    },
    {
      "epoch": 33.716012084592144,
      "eval_loss": 1.28386390209198,
      "eval_runtime": 622.1143,
      "eval_samples_per_second": 85.352,
      "eval_steps_per_second": 0.667,
      "step": 111600
    },
    {
      "epoch": 33.73111782477341,
      "grad_norm": 0.47158071398735046,
      "learning_rate": 4.417945619335348e-05,
      "loss": 1.2686,
      "step": 111650
    },
    {
      "epoch": 33.73111782477341,
      "eval_loss": 1.284084677696228,
      "eval_runtime": 698.4144,
      "eval_samples_per_second": 76.028,
      "eval_steps_per_second": 0.594,
      "step": 111650
    },
    {
      "epoch": 33.74622356495468,
      "grad_norm": 0.4410552382469177,
      "learning_rate": 4.4169385699899296e-05,
      "loss": 1.2624,
      "step": 111700
    },
    {
      "epoch": 33.74622356495468,
      "eval_loss": 1.2829266786575317,
      "eval_runtime": 693.0443,
      "eval_samples_per_second": 76.617,
      "eval_steps_per_second": 0.599,
      "step": 111700
    },
    {
      "epoch": 33.76132930513595,
      "grad_norm": 0.4325079917907715,
      "learning_rate": 4.415931520644512e-05,
      "loss": 1.2748,
      "step": 111750
    },
    {
      "epoch": 33.76132930513595,
      "eval_loss": 1.2835172414779663,
      "eval_runtime": 641.029,
      "eval_samples_per_second": 82.834,
      "eval_steps_per_second": 0.647,
      "step": 111750
    },
    {
      "epoch": 33.77643504531722,
      "grad_norm": 0.4635147154331207,
      "learning_rate": 4.414924471299094e-05,
      "loss": 1.2657,
      "step": 111800
    },
    {
      "epoch": 33.77643504531722,
      "eval_loss": 1.2846308946609497,
      "eval_runtime": 683.0611,
      "eval_samples_per_second": 77.737,
      "eval_steps_per_second": 0.608,
      "step": 111800
    },
    {
      "epoch": 33.79154078549849,
      "grad_norm": 0.4635164439678192,
      "learning_rate": 4.413917421953676e-05,
      "loss": 1.2683,
      "step": 111850
    },
    {
      "epoch": 33.79154078549849,
      "eval_loss": 1.2843650579452515,
      "eval_runtime": 589.3903,
      "eval_samples_per_second": 90.091,
      "eval_steps_per_second": 0.704,
      "step": 111850
    },
    {
      "epoch": 33.80664652567976,
      "grad_norm": 0.4605973958969116,
      "learning_rate": 4.412910372608258e-05,
      "loss": 1.2592,
      "step": 111900
    },
    {
      "epoch": 33.80664652567976,
      "eval_loss": 1.2843185663223267,
      "eval_runtime": 613.2832,
      "eval_samples_per_second": 86.582,
      "eval_steps_per_second": 0.677,
      "step": 111900
    },
    {
      "epoch": 33.82175226586103,
      "grad_norm": 0.47248145937919617,
      "learning_rate": 4.41190332326284e-05,
      "loss": 1.2506,
      "step": 111950
    },
    {
      "epoch": 33.82175226586103,
      "eval_loss": 1.282448649406433,
      "eval_runtime": 677.2514,
      "eval_samples_per_second": 78.404,
      "eval_steps_per_second": 0.613,
      "step": 111950
    },
    {
      "epoch": 33.8368580060423,
      "grad_norm": 0.43467846512794495,
      "learning_rate": 4.410896273917422e-05,
      "loss": 1.256,
      "step": 112000
    },
    {
      "epoch": 33.8368580060423,
      "eval_loss": 1.2849780321121216,
      "eval_runtime": 621.749,
      "eval_samples_per_second": 85.403,
      "eval_steps_per_second": 0.667,
      "step": 112000
    },
    {
      "epoch": 33.85196374622357,
      "grad_norm": 0.45281320810317993,
      "learning_rate": 4.409889224572004e-05,
      "loss": 1.2587,
      "step": 112050
    },
    {
      "epoch": 33.85196374622357,
      "eval_loss": 1.282705307006836,
      "eval_runtime": 683.7838,
      "eval_samples_per_second": 77.655,
      "eval_steps_per_second": 0.607,
      "step": 112050
    },
    {
      "epoch": 33.86706948640484,
      "grad_norm": 0.48260632157325745,
      "learning_rate": 4.408882175226586e-05,
      "loss": 1.2751,
      "step": 112100
    },
    {
      "epoch": 33.86706948640484,
      "eval_loss": 1.2833956480026245,
      "eval_runtime": 661.5641,
      "eval_samples_per_second": 80.263,
      "eval_steps_per_second": 0.627,
      "step": 112100
    },
    {
      "epoch": 33.8821752265861,
      "grad_norm": 0.5096926093101501,
      "learning_rate": 4.4078751258811684e-05,
      "loss": 1.2619,
      "step": 112150
    },
    {
      "epoch": 33.8821752265861,
      "eval_loss": 1.2825919389724731,
      "eval_runtime": 710.6408,
      "eval_samples_per_second": 74.72,
      "eval_steps_per_second": 0.584,
      "step": 112150
    },
    {
      "epoch": 33.89728096676737,
      "grad_norm": 0.48085182905197144,
      "learning_rate": 4.40686807653575e-05,
      "loss": 1.2621,
      "step": 112200
    },
    {
      "epoch": 33.89728096676737,
      "eval_loss": 1.2862839698791504,
      "eval_runtime": 950.7737,
      "eval_samples_per_second": 55.848,
      "eval_steps_per_second": 0.436,
      "step": 112200
    },
    {
      "epoch": 33.91238670694864,
      "grad_norm": 0.452984482049942,
      "learning_rate": 4.405861027190332e-05,
      "loss": 1.2494,
      "step": 112250
    },
    {
      "epoch": 33.91238670694864,
      "eval_loss": 1.2832884788513184,
      "eval_runtime": 1130.5856,
      "eval_samples_per_second": 46.966,
      "eval_steps_per_second": 0.367,
      "step": 112250
    },
    {
      "epoch": 33.92749244712991,
      "grad_norm": 0.47662803530693054,
      "learning_rate": 4.404853977844915e-05,
      "loss": 1.2298,
      "step": 112300
    },
    {
      "epoch": 33.92749244712991,
      "eval_loss": 1.2836838960647583,
      "eval_runtime": 682.5399,
      "eval_samples_per_second": 77.796,
      "eval_steps_per_second": 0.608,
      "step": 112300
    },
    {
      "epoch": 33.94259818731118,
      "grad_norm": 0.46384069323539734,
      "learning_rate": 4.4038469284994966e-05,
      "loss": 1.2642,
      "step": 112350
    },
    {
      "epoch": 33.94259818731118,
      "eval_loss": 1.2822121381759644,
      "eval_runtime": 614.6191,
      "eval_samples_per_second": 86.393,
      "eval_steps_per_second": 0.675,
      "step": 112350
    },
    {
      "epoch": 33.957703927492446,
      "grad_norm": 0.433438241481781,
      "learning_rate": 4.4028398791540784e-05,
      "loss": 1.2568,
      "step": 112400
    },
    {
      "epoch": 33.957703927492446,
      "eval_loss": 1.2848610877990723,
      "eval_runtime": 717.5682,
      "eval_samples_per_second": 73.999,
      "eval_steps_per_second": 0.578,
      "step": 112400
    },
    {
      "epoch": 33.972809667673715,
      "grad_norm": 0.4555812180042267,
      "learning_rate": 4.40183282980866e-05,
      "loss": 1.2773,
      "step": 112450
    },
    {
      "epoch": 33.972809667673715,
      "eval_loss": 1.2838969230651855,
      "eval_runtime": 659.1249,
      "eval_samples_per_second": 80.56,
      "eval_steps_per_second": 0.63,
      "step": 112450
    },
    {
      "epoch": 33.987915407854985,
      "grad_norm": 0.46098142862319946,
      "learning_rate": 4.400825780463243e-05,
      "loss": 1.2581,
      "step": 112500
    },
    {
      "epoch": 33.987915407854985,
      "eval_loss": 1.285398006439209,
      "eval_runtime": 680.0527,
      "eval_samples_per_second": 78.081,
      "eval_steps_per_second": 0.61,
      "step": 112500
    },
    {
      "epoch": 34.003021148036254,
      "grad_norm": 0.4713633358478546,
      "learning_rate": 4.399818731117825e-05,
      "loss": 1.2737,
      "step": 112550
    },
    {
      "epoch": 34.003021148036254,
      "eval_loss": 1.2849340438842773,
      "eval_runtime": 587.4676,
      "eval_samples_per_second": 90.386,
      "eval_steps_per_second": 0.706,
      "step": 112550
    },
    {
      "epoch": 34.01812688821752,
      "grad_norm": 0.5320584177970886,
      "learning_rate": 4.3988116817724066e-05,
      "loss": 1.2502,
      "step": 112600
    },
    {
      "epoch": 34.01812688821752,
      "eval_loss": 1.2825380563735962,
      "eval_runtime": 617.7152,
      "eval_samples_per_second": 85.96,
      "eval_steps_per_second": 0.672,
      "step": 112600
    },
    {
      "epoch": 34.03323262839879,
      "grad_norm": 0.4285346567630768,
      "learning_rate": 4.3978046324269885e-05,
      "loss": 1.2689,
      "step": 112650
    },
    {
      "epoch": 34.03323262839879,
      "eval_loss": 1.285079002380371,
      "eval_runtime": 680.6497,
      "eval_samples_per_second": 78.012,
      "eval_steps_per_second": 0.61,
      "step": 112650
    },
    {
      "epoch": 34.04833836858006,
      "grad_norm": 0.46613311767578125,
      "learning_rate": 4.396797583081572e-05,
      "loss": 1.2563,
      "step": 112700
    },
    {
      "epoch": 34.04833836858006,
      "eval_loss": 1.2848527431488037,
      "eval_runtime": 590.0342,
      "eval_samples_per_second": 89.993,
      "eval_steps_per_second": 0.703,
      "step": 112700
    },
    {
      "epoch": 34.06344410876133,
      "grad_norm": 0.4949434697628021,
      "learning_rate": 4.3957905337361536e-05,
      "loss": 1.2401,
      "step": 112750
    },
    {
      "epoch": 34.06344410876133,
      "eval_loss": 1.2818037271499634,
      "eval_runtime": 618.5504,
      "eval_samples_per_second": 85.844,
      "eval_steps_per_second": 0.671,
      "step": 112750
    },
    {
      "epoch": 34.0785498489426,
      "grad_norm": 0.4793579876422882,
      "learning_rate": 4.3947834843907354e-05,
      "loss": 1.2301,
      "step": 112800
    },
    {
      "epoch": 34.0785498489426,
      "eval_loss": 1.2810856103897095,
      "eval_runtime": 621.4243,
      "eval_samples_per_second": 85.447,
      "eval_steps_per_second": 0.668,
      "step": 112800
    },
    {
      "epoch": 34.09365558912387,
      "grad_norm": 0.43154287338256836,
      "learning_rate": 4.393776435045317e-05,
      "loss": 1.2358,
      "step": 112850
    },
    {
      "epoch": 34.09365558912387,
      "eval_loss": 1.282616138458252,
      "eval_runtime": 616.8977,
      "eval_samples_per_second": 86.074,
      "eval_steps_per_second": 0.673,
      "step": 112850
    },
    {
      "epoch": 34.10876132930514,
      "grad_norm": 0.4676538407802582,
      "learning_rate": 4.3927693856999e-05,
      "loss": 1.2658,
      "step": 112900
    },
    {
      "epoch": 34.10876132930514,
      "eval_loss": 1.2852027416229248,
      "eval_runtime": 607.4116,
      "eval_samples_per_second": 87.418,
      "eval_steps_per_second": 0.683,
      "step": 112900
    },
    {
      "epoch": 34.12386706948641,
      "grad_norm": 0.4519863724708557,
      "learning_rate": 4.391762336354482e-05,
      "loss": 1.2605,
      "step": 112950
    },
    {
      "epoch": 34.12386706948641,
      "eval_loss": 1.2842222452163696,
      "eval_runtime": 659.9601,
      "eval_samples_per_second": 80.458,
      "eval_steps_per_second": 0.629,
      "step": 112950
    },
    {
      "epoch": 34.13897280966767,
      "grad_norm": 0.4434220790863037,
      "learning_rate": 4.3907552870090636e-05,
      "loss": 1.2528,
      "step": 113000
    },
    {
      "epoch": 34.13897280966767,
      "eval_loss": 1.2830252647399902,
      "eval_runtime": 686.144,
      "eval_samples_per_second": 77.388,
      "eval_steps_per_second": 0.605,
      "step": 113000
    },
    {
      "epoch": 34.15407854984894,
      "grad_norm": 0.46622538566589355,
      "learning_rate": 4.3897482376636454e-05,
      "loss": 1.2581,
      "step": 113050
    },
    {
      "epoch": 34.15407854984894,
      "eval_loss": 1.2833162546157837,
      "eval_runtime": 689.3061,
      "eval_samples_per_second": 77.033,
      "eval_steps_per_second": 0.602,
      "step": 113050
    },
    {
      "epoch": 34.16918429003021,
      "grad_norm": 0.4527648687362671,
      "learning_rate": 4.388741188318228e-05,
      "loss": 1.2606,
      "step": 113100
    },
    {
      "epoch": 34.16918429003021,
      "eval_loss": 1.2843868732452393,
      "eval_runtime": 676.3289,
      "eval_samples_per_second": 78.511,
      "eval_steps_per_second": 0.614,
      "step": 113100
    },
    {
      "epoch": 34.18429003021148,
      "grad_norm": 0.45057621598243713,
      "learning_rate": 4.38773413897281e-05,
      "loss": 1.2577,
      "step": 113150
    },
    {
      "epoch": 34.18429003021148,
      "eval_loss": 1.2854721546173096,
      "eval_runtime": 664.036,
      "eval_samples_per_second": 79.964,
      "eval_steps_per_second": 0.625,
      "step": 113150
    },
    {
      "epoch": 34.19939577039275,
      "grad_norm": 0.4936307370662689,
      "learning_rate": 4.386727089627392e-05,
      "loss": 1.2722,
      "step": 113200
    },
    {
      "epoch": 34.19939577039275,
      "eval_loss": 1.2832863330841064,
      "eval_runtime": 612.8331,
      "eval_samples_per_second": 86.645,
      "eval_steps_per_second": 0.677,
      "step": 113200
    },
    {
      "epoch": 34.21450151057402,
      "grad_norm": 0.49679040908813477,
      "learning_rate": 4.3857200402819736e-05,
      "loss": 1.2526,
      "step": 113250
    },
    {
      "epoch": 34.21450151057402,
      "eval_loss": 1.2834961414337158,
      "eval_runtime": 630.9621,
      "eval_samples_per_second": 84.156,
      "eval_steps_per_second": 0.658,
      "step": 113250
    },
    {
      "epoch": 34.229607250755286,
      "grad_norm": 0.4625118374824524,
      "learning_rate": 4.384712990936556e-05,
      "loss": 1.2668,
      "step": 113300
    },
    {
      "epoch": 34.229607250755286,
      "eval_loss": 1.2830238342285156,
      "eval_runtime": 616.4639,
      "eval_samples_per_second": 86.135,
      "eval_steps_per_second": 0.673,
      "step": 113300
    },
    {
      "epoch": 34.244712990936556,
      "grad_norm": 0.42648810148239136,
      "learning_rate": 4.383705941591138e-05,
      "loss": 1.2391,
      "step": 113350
    },
    {
      "epoch": 34.244712990936556,
      "eval_loss": 1.283412218093872,
      "eval_runtime": 617.0635,
      "eval_samples_per_second": 86.051,
      "eval_steps_per_second": 0.673,
      "step": 113350
    },
    {
      "epoch": 34.259818731117825,
      "grad_norm": 0.4929460287094116,
      "learning_rate": 4.38269889224572e-05,
      "loss": 1.2457,
      "step": 113400
    },
    {
      "epoch": 34.259818731117825,
      "eval_loss": 1.2839692831039429,
      "eval_runtime": 663.5636,
      "eval_samples_per_second": 80.021,
      "eval_steps_per_second": 0.625,
      "step": 113400
    },
    {
      "epoch": 34.274924471299094,
      "grad_norm": 0.42069727182388306,
      "learning_rate": 4.3816918429003024e-05,
      "loss": 1.2738,
      "step": 113450
    },
    {
      "epoch": 34.274924471299094,
      "eval_loss": 1.2834265232086182,
      "eval_runtime": 588.2798,
      "eval_samples_per_second": 90.261,
      "eval_steps_per_second": 0.705,
      "step": 113450
    },
    {
      "epoch": 34.290030211480364,
      "grad_norm": 0.4624803960323334,
      "learning_rate": 4.380684793554884e-05,
      "loss": 1.2558,
      "step": 113500
    },
    {
      "epoch": 34.290030211480364,
      "eval_loss": 1.2815316915512085,
      "eval_runtime": 617.3009,
      "eval_samples_per_second": 86.018,
      "eval_steps_per_second": 0.672,
      "step": 113500
    },
    {
      "epoch": 34.30513595166163,
      "grad_norm": 0.4588742256164551,
      "learning_rate": 4.379677744209466e-05,
      "loss": 1.2678,
      "step": 113550
    },
    {
      "epoch": 34.30513595166163,
      "eval_loss": 1.2827112674713135,
      "eval_runtime": 571.4187,
      "eval_samples_per_second": 92.925,
      "eval_steps_per_second": 0.726,
      "step": 113550
    },
    {
      "epoch": 34.3202416918429,
      "grad_norm": 0.43427059054374695,
      "learning_rate": 4.378670694864048e-05,
      "loss": 1.2556,
      "step": 113600
    },
    {
      "epoch": 34.3202416918429,
      "eval_loss": 1.2834066152572632,
      "eval_runtime": 678.899,
      "eval_samples_per_second": 78.213,
      "eval_steps_per_second": 0.611,
      "step": 113600
    },
    {
      "epoch": 34.33534743202417,
      "grad_norm": 0.4850444495677948,
      "learning_rate": 4.3776636455186306e-05,
      "loss": 1.2464,
      "step": 113650
    },
    {
      "epoch": 34.33534743202417,
      "eval_loss": 1.2826001644134521,
      "eval_runtime": 654.609,
      "eval_samples_per_second": 81.116,
      "eval_steps_per_second": 0.634,
      "step": 113650
    },
    {
      "epoch": 34.35045317220544,
      "grad_norm": 0.47514864802360535,
      "learning_rate": 4.3766565961732124e-05,
      "loss": 1.2729,
      "step": 113700
    },
    {
      "epoch": 34.35045317220544,
      "eval_loss": 1.2808258533477783,
      "eval_runtime": 576.2127,
      "eval_samples_per_second": 92.152,
      "eval_steps_per_second": 0.72,
      "step": 113700
    },
    {
      "epoch": 34.36555891238671,
      "grad_norm": 0.4481438398361206,
      "learning_rate": 4.375649546827794e-05,
      "loss": 1.2784,
      "step": 113750
    },
    {
      "epoch": 34.36555891238671,
      "eval_loss": 1.282586932182312,
      "eval_runtime": 622.0522,
      "eval_samples_per_second": 85.361,
      "eval_steps_per_second": 0.667,
      "step": 113750
    },
    {
      "epoch": 34.38066465256797,
      "grad_norm": 0.4280337989330292,
      "learning_rate": 4.374642497482376e-05,
      "loss": 1.254,
      "step": 113800
    },
    {
      "epoch": 34.38066465256797,
      "eval_loss": 1.2846659421920776,
      "eval_runtime": 658.9554,
      "eval_samples_per_second": 80.581,
      "eval_steps_per_second": 0.63,
      "step": 113800
    },
    {
      "epoch": 34.39577039274924,
      "grad_norm": 0.43938541412353516,
      "learning_rate": 4.3736354481369594e-05,
      "loss": 1.2513,
      "step": 113850
    },
    {
      "epoch": 34.39577039274924,
      "eval_loss": 1.2836428880691528,
      "eval_runtime": 616.4746,
      "eval_samples_per_second": 86.133,
      "eval_steps_per_second": 0.673,
      "step": 113850
    },
    {
      "epoch": 34.41087613293051,
      "grad_norm": 0.4360353350639343,
      "learning_rate": 4.372628398791541e-05,
      "loss": 1.2693,
      "step": 113900
    },
    {
      "epoch": 34.41087613293051,
      "eval_loss": 1.2844421863555908,
      "eval_runtime": 694.5706,
      "eval_samples_per_second": 76.449,
      "eval_steps_per_second": 0.597,
      "step": 113900
    },
    {
      "epoch": 34.42598187311178,
      "grad_norm": 0.4636264443397522,
      "learning_rate": 4.371621349446123e-05,
      "loss": 1.2586,
      "step": 113950
    },
    {
      "epoch": 34.42598187311178,
      "eval_loss": 1.2834159135818481,
      "eval_runtime": 644.7794,
      "eval_samples_per_second": 82.352,
      "eval_steps_per_second": 0.644,
      "step": 113950
    },
    {
      "epoch": 34.44108761329305,
      "grad_norm": 0.4461175501346588,
      "learning_rate": 4.370614300100705e-05,
      "loss": 1.2549,
      "step": 114000
    },
    {
      "epoch": 34.44108761329305,
      "eval_loss": 1.2821786403656006,
      "eval_runtime": 664.1486,
      "eval_samples_per_second": 79.95,
      "eval_steps_per_second": 0.625,
      "step": 114000
    },
    {
      "epoch": 34.45619335347432,
      "grad_norm": 0.42999061942100525,
      "learning_rate": 4.3696072507552876e-05,
      "loss": 1.2449,
      "step": 114050
    },
    {
      "epoch": 34.45619335347432,
      "eval_loss": 1.280837059020996,
      "eval_runtime": 696.2636,
      "eval_samples_per_second": 76.263,
      "eval_steps_per_second": 0.596,
      "step": 114050
    },
    {
      "epoch": 34.47129909365559,
      "grad_norm": 0.494922399520874,
      "learning_rate": 4.3686002014098694e-05,
      "loss": 1.2711,
      "step": 114100
    },
    {
      "epoch": 34.47129909365559,
      "eval_loss": 1.2827807664871216,
      "eval_runtime": 652.1961,
      "eval_samples_per_second": 81.416,
      "eval_steps_per_second": 0.636,
      "step": 114100
    },
    {
      "epoch": 34.48640483383686,
      "grad_norm": 0.4840962588787079,
      "learning_rate": 4.367593152064451e-05,
      "loss": 1.2516,
      "step": 114150
    },
    {
      "epoch": 34.48640483383686,
      "eval_loss": 1.2822290658950806,
      "eval_runtime": 674.5065,
      "eval_samples_per_second": 78.723,
      "eval_steps_per_second": 0.615,
      "step": 114150
    },
    {
      "epoch": 34.50151057401813,
      "grad_norm": 0.5190343856811523,
      "learning_rate": 4.366586102719033e-05,
      "loss": 1.2454,
      "step": 114200
    },
    {
      "epoch": 34.50151057401813,
      "eval_loss": 1.2823326587677002,
      "eval_runtime": 628.9119,
      "eval_samples_per_second": 84.43,
      "eval_steps_per_second": 0.66,
      "step": 114200
    },
    {
      "epoch": 34.516616314199396,
      "grad_norm": 0.45843932032585144,
      "learning_rate": 4.365579053373616e-05,
      "loss": 1.2396,
      "step": 114250
    },
    {
      "epoch": 34.516616314199396,
      "eval_loss": 1.2807304859161377,
      "eval_runtime": 657.7382,
      "eval_samples_per_second": 80.73,
      "eval_steps_per_second": 0.631,
      "step": 114250
    },
    {
      "epoch": 34.531722054380666,
      "grad_norm": 0.4735889136791229,
      "learning_rate": 4.3645720040281976e-05,
      "loss": 1.2327,
      "step": 114300
    },
    {
      "epoch": 34.531722054380666,
      "eval_loss": 1.283471703529358,
      "eval_runtime": 669.5315,
      "eval_samples_per_second": 79.308,
      "eval_steps_per_second": 0.62,
      "step": 114300
    },
    {
      "epoch": 34.546827794561935,
      "grad_norm": 0.46565333008766174,
      "learning_rate": 4.3635649546827795e-05,
      "loss": 1.2649,
      "step": 114350
    },
    {
      "epoch": 34.546827794561935,
      "eval_loss": 1.282939076423645,
      "eval_runtime": 641.4423,
      "eval_samples_per_second": 82.781,
      "eval_steps_per_second": 0.647,
      "step": 114350
    },
    {
      "epoch": 34.561933534743204,
      "grad_norm": 0.4318026602268219,
      "learning_rate": 4.362557905337361e-05,
      "loss": 1.2535,
      "step": 114400
    },
    {
      "epoch": 34.561933534743204,
      "eval_loss": 1.283408761024475,
      "eval_runtime": 625.111,
      "eval_samples_per_second": 84.943,
      "eval_steps_per_second": 0.664,
      "step": 114400
    },
    {
      "epoch": 34.57703927492447,
      "grad_norm": 0.44382330775260925,
      "learning_rate": 4.361550855991944e-05,
      "loss": 1.2704,
      "step": 114450
    },
    {
      "epoch": 34.57703927492447,
      "eval_loss": 1.2844679355621338,
      "eval_runtime": 641.5604,
      "eval_samples_per_second": 82.765,
      "eval_steps_per_second": 0.647,
      "step": 114450
    },
    {
      "epoch": 34.59214501510574,
      "grad_norm": 0.4215069115161896,
      "learning_rate": 4.360543806646526e-05,
      "loss": 1.2567,
      "step": 114500
    },
    {
      "epoch": 34.59214501510574,
      "eval_loss": 1.2832633256912231,
      "eval_runtime": 623.7121,
      "eval_samples_per_second": 85.134,
      "eval_steps_per_second": 0.665,
      "step": 114500
    },
    {
      "epoch": 34.60725075528701,
      "grad_norm": 0.47963348031044006,
      "learning_rate": 4.3595367573011076e-05,
      "loss": 1.2716,
      "step": 114550
    },
    {
      "epoch": 34.60725075528701,
      "eval_loss": 1.2794816493988037,
      "eval_runtime": 617.7791,
      "eval_samples_per_second": 85.951,
      "eval_steps_per_second": 0.672,
      "step": 114550
    },
    {
      "epoch": 34.62235649546828,
      "grad_norm": 0.487256795167923,
      "learning_rate": 4.35852970795569e-05,
      "loss": 1.2597,
      "step": 114600
    },
    {
      "epoch": 34.62235649546828,
      "eval_loss": 1.2839840650558472,
      "eval_runtime": 678.7,
      "eval_samples_per_second": 78.236,
      "eval_steps_per_second": 0.611,
      "step": 114600
    },
    {
      "epoch": 34.637462235649544,
      "grad_norm": 0.4541254937648773,
      "learning_rate": 4.357522658610272e-05,
      "loss": 1.2297,
      "step": 114650
    },
    {
      "epoch": 34.637462235649544,
      "eval_loss": 1.2832551002502441,
      "eval_runtime": 642.7226,
      "eval_samples_per_second": 82.616,
      "eval_steps_per_second": 0.646,
      "step": 114650
    },
    {
      "epoch": 34.65256797583081,
      "grad_norm": 0.43620792031288147,
      "learning_rate": 4.356515609264854e-05,
      "loss": 1.2456,
      "step": 114700
    },
    {
      "epoch": 34.65256797583081,
      "eval_loss": 1.2817164659500122,
      "eval_runtime": 616.251,
      "eval_samples_per_second": 86.165,
      "eval_steps_per_second": 0.673,
      "step": 114700
    },
    {
      "epoch": 34.66767371601208,
      "grad_norm": 0.4282855987548828,
      "learning_rate": 4.355508559919436e-05,
      "loss": 1.2748,
      "step": 114750
    },
    {
      "epoch": 34.66767371601208,
      "eval_loss": 1.2822951078414917,
      "eval_runtime": 637.0727,
      "eval_samples_per_second": 83.348,
      "eval_steps_per_second": 0.651,
      "step": 114750
    },
    {
      "epoch": 34.68277945619335,
      "grad_norm": 0.4550686180591583,
      "learning_rate": 4.354501510574018e-05,
      "loss": 1.2672,
      "step": 114800
    },
    {
      "epoch": 34.68277945619335,
      "eval_loss": 1.2829101085662842,
      "eval_runtime": 607.5432,
      "eval_samples_per_second": 87.4,
      "eval_steps_per_second": 0.683,
      "step": 114800
    },
    {
      "epoch": 34.69788519637462,
      "grad_norm": 0.4638780355453491,
      "learning_rate": 4.3534944612286e-05,
      "loss": 1.2735,
      "step": 114850
    },
    {
      "epoch": 34.69788519637462,
      "eval_loss": 1.28279709815979,
      "eval_runtime": 621.0749,
      "eval_samples_per_second": 85.495,
      "eval_steps_per_second": 0.668,
      "step": 114850
    },
    {
      "epoch": 34.71299093655589,
      "grad_norm": 0.48343899846076965,
      "learning_rate": 4.352487411883182e-05,
      "loss": 1.2733,
      "step": 114900
    },
    {
      "epoch": 34.71299093655589,
      "eval_loss": 1.2827997207641602,
      "eval_runtime": 625.4656,
      "eval_samples_per_second": 84.895,
      "eval_steps_per_second": 0.664,
      "step": 114900
    },
    {
      "epoch": 34.72809667673716,
      "grad_norm": 0.43100979924201965,
      "learning_rate": 4.351480362537764e-05,
      "loss": 1.2443,
      "step": 114950
    },
    {
      "epoch": 34.72809667673716,
      "eval_loss": 1.2797553539276123,
      "eval_runtime": 611.6927,
      "eval_samples_per_second": 86.807,
      "eval_steps_per_second": 0.678,
      "step": 114950
    },
    {
      "epoch": 34.74320241691843,
      "grad_norm": 0.44573017954826355,
      "learning_rate": 4.3504733131923465e-05,
      "loss": 1.2453,
      "step": 115000
    },
    {
      "epoch": 34.74320241691843,
      "eval_loss": 1.2823913097381592,
      "eval_runtime": 610.6887,
      "eval_samples_per_second": 86.949,
      "eval_steps_per_second": 0.68,
      "step": 115000
    },
    {
      "epoch": 34.7583081570997,
      "grad_norm": 0.515248715877533,
      "learning_rate": 4.349466263846929e-05,
      "loss": 1.2569,
      "step": 115050
    },
    {
      "epoch": 34.7583081570997,
      "eval_loss": 1.2815407514572144,
      "eval_runtime": 659.8101,
      "eval_samples_per_second": 80.476,
      "eval_steps_per_second": 0.629,
      "step": 115050
    },
    {
      "epoch": 34.77341389728097,
      "grad_norm": 0.42704492807388306,
      "learning_rate": 4.348459214501511e-05,
      "loss": 1.2685,
      "step": 115100
    },
    {
      "epoch": 34.77341389728097,
      "eval_loss": 1.2827155590057373,
      "eval_runtime": 604.454,
      "eval_samples_per_second": 87.846,
      "eval_steps_per_second": 0.687,
      "step": 115100
    },
    {
      "epoch": 34.78851963746224,
      "grad_norm": 0.4437238872051239,
      "learning_rate": 4.347452165156093e-05,
      "loss": 1.2588,
      "step": 115150
    },
    {
      "epoch": 34.78851963746224,
      "eval_loss": 1.2814140319824219,
      "eval_runtime": 618.3734,
      "eval_samples_per_second": 85.869,
      "eval_steps_per_second": 0.671,
      "step": 115150
    },
    {
      "epoch": 34.803625377643506,
      "grad_norm": 0.4432884156703949,
      "learning_rate": 4.346445115810675e-05,
      "loss": 1.2554,
      "step": 115200
    },
    {
      "epoch": 34.803625377643506,
      "eval_loss": 1.2801406383514404,
      "eval_runtime": 617.5249,
      "eval_samples_per_second": 85.987,
      "eval_steps_per_second": 0.672,
      "step": 115200
    },
    {
      "epoch": 34.818731117824775,
      "grad_norm": 0.4500657320022583,
      "learning_rate": 4.345438066465257e-05,
      "loss": 1.2808,
      "step": 115250
    },
    {
      "epoch": 34.818731117824775,
      "eval_loss": 1.2826112508773804,
      "eval_runtime": 592.8564,
      "eval_samples_per_second": 89.565,
      "eval_steps_per_second": 0.7,
      "step": 115250
    },
    {
      "epoch": 34.833836858006045,
      "grad_norm": 0.4718102216720581,
      "learning_rate": 4.344431017119839e-05,
      "loss": 1.2636,
      "step": 115300
    },
    {
      "epoch": 34.833836858006045,
      "eval_loss": 1.280187726020813,
      "eval_runtime": 664.7822,
      "eval_samples_per_second": 79.874,
      "eval_steps_per_second": 0.624,
      "step": 115300
    },
    {
      "epoch": 34.848942598187314,
      "grad_norm": 0.4782857596874237,
      "learning_rate": 4.343423967774421e-05,
      "loss": 1.2589,
      "step": 115350
    },
    {
      "epoch": 34.848942598187314,
      "eval_loss": 1.2818679809570312,
      "eval_runtime": 591.6119,
      "eval_samples_per_second": 89.753,
      "eval_steps_per_second": 0.701,
      "step": 115350
    },
    {
      "epoch": 34.86404833836858,
      "grad_norm": 0.47997206449508667,
      "learning_rate": 4.3424169184290034e-05,
      "loss": 1.2418,
      "step": 115400
    },
    {
      "epoch": 34.86404833836858,
      "eval_loss": 1.2786725759506226,
      "eval_runtime": 614.4219,
      "eval_samples_per_second": 86.421,
      "eval_steps_per_second": 0.675,
      "step": 115400
    },
    {
      "epoch": 34.879154078549846,
      "grad_norm": 0.44665563106536865,
      "learning_rate": 4.341409869083585e-05,
      "loss": 1.2649,
      "step": 115450
    },
    {
      "epoch": 34.879154078549846,
      "eval_loss": 1.2810204029083252,
      "eval_runtime": 697.8415,
      "eval_samples_per_second": 76.09,
      "eval_steps_per_second": 0.595,
      "step": 115450
    },
    {
      "epoch": 34.894259818731115,
      "grad_norm": 0.47568100690841675,
      "learning_rate": 4.340402819738167e-05,
      "loss": 1.2558,
      "step": 115500
    },
    {
      "epoch": 34.894259818731115,
      "eval_loss": 1.2846685647964478,
      "eval_runtime": 697.0236,
      "eval_samples_per_second": 76.18,
      "eval_steps_per_second": 0.595,
      "step": 115500
    },
    {
      "epoch": 34.909365558912384,
      "grad_norm": 0.47073081135749817,
      "learning_rate": 4.339395770392749e-05,
      "loss": 1.2563,
      "step": 115550
    },
    {
      "epoch": 34.909365558912384,
      "eval_loss": 1.2814024686813354,
      "eval_runtime": 692.0424,
      "eval_samples_per_second": 76.728,
      "eval_steps_per_second": 0.6,
      "step": 115550
    },
    {
      "epoch": 34.92447129909365,
      "grad_norm": 0.4695785641670227,
      "learning_rate": 4.3383887210473316e-05,
      "loss": 1.2517,
      "step": 115600
    },
    {
      "epoch": 34.92447129909365,
      "eval_loss": 1.2823928594589233,
      "eval_runtime": 666.0773,
      "eval_samples_per_second": 79.719,
      "eval_steps_per_second": 0.623,
      "step": 115600
    },
    {
      "epoch": 34.93957703927492,
      "grad_norm": 0.4626633822917938,
      "learning_rate": 4.3373816717019135e-05,
      "loss": 1.2645,
      "step": 115650
    },
    {
      "epoch": 34.93957703927492,
      "eval_loss": 1.2817912101745605,
      "eval_runtime": 637.2267,
      "eval_samples_per_second": 83.328,
      "eval_steps_per_second": 0.651,
      "step": 115650
    },
    {
      "epoch": 34.95468277945619,
      "grad_norm": 0.5340902805328369,
      "learning_rate": 4.336374622356495e-05,
      "loss": 1.2655,
      "step": 115700
    },
    {
      "epoch": 34.95468277945619,
      "eval_loss": 1.2811378240585327,
      "eval_runtime": 663.3224,
      "eval_samples_per_second": 80.05,
      "eval_steps_per_second": 0.626,
      "step": 115700
    },
    {
      "epoch": 34.96978851963746,
      "grad_norm": 0.44509434700012207,
      "learning_rate": 4.335367573011078e-05,
      "loss": 1.2585,
      "step": 115750
    },
    {
      "epoch": 34.96978851963746,
      "eval_loss": 1.2830382585525513,
      "eval_runtime": 606.5125,
      "eval_samples_per_second": 87.548,
      "eval_steps_per_second": 0.684,
      "step": 115750
    },
    {
      "epoch": 34.98489425981873,
      "grad_norm": 0.44899317622184753,
      "learning_rate": 4.33436052366566e-05,
      "loss": 1.2544,
      "step": 115800
    },
    {
      "epoch": 34.98489425981873,
      "eval_loss": 1.2826310396194458,
      "eval_runtime": 633.5185,
      "eval_samples_per_second": 83.816,
      "eval_steps_per_second": 0.655,
      "step": 115800
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.47307297587394714,
      "learning_rate": 4.3333534743202416e-05,
      "loss": 1.2516,
      "step": 115850
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.2813408374786377,
      "eval_runtime": 583.8406,
      "eval_samples_per_second": 90.948,
      "eval_steps_per_second": 0.711,
      "step": 115850
    },
    {
      "epoch": 35.01510574018127,
      "grad_norm": 0.46938636898994446,
      "learning_rate": 4.3323464249748235e-05,
      "loss": 1.2513,
      "step": 115900
    },
    {
      "epoch": 35.01510574018127,
      "eval_loss": 1.2823110818862915,
      "eval_runtime": 627.27,
      "eval_samples_per_second": 84.651,
      "eval_steps_per_second": 0.662,
      "step": 115900
    },
    {
      "epoch": 35.03021148036254,
      "grad_norm": 0.44764024019241333,
      "learning_rate": 4.331339375629406e-05,
      "loss": 1.2694,
      "step": 115950
    },
    {
      "epoch": 35.03021148036254,
      "eval_loss": 1.279829978942871,
      "eval_runtime": 654.4072,
      "eval_samples_per_second": 81.141,
      "eval_steps_per_second": 0.634,
      "step": 115950
    },
    {
      "epoch": 35.04531722054381,
      "grad_norm": 0.4462844133377075,
      "learning_rate": 4.330332326283988e-05,
      "loss": 1.2343,
      "step": 116000
    },
    {
      "epoch": 35.04531722054381,
      "eval_loss": 1.2795792818069458,
      "eval_runtime": 604.8993,
      "eval_samples_per_second": 87.782,
      "eval_steps_per_second": 0.686,
      "step": 116000
    },
    {
      "epoch": 35.06042296072508,
      "grad_norm": 0.4833783805370331,
      "learning_rate": 4.32932527693857e-05,
      "loss": 1.2632,
      "step": 116050
    },
    {
      "epoch": 35.06042296072508,
      "eval_loss": 1.2790104150772095,
      "eval_runtime": 638.9602,
      "eval_samples_per_second": 83.102,
      "eval_steps_per_second": 0.649,
      "step": 116050
    },
    {
      "epoch": 35.07552870090635,
      "grad_norm": 0.5047513842582703,
      "learning_rate": 4.3283182275931516e-05,
      "loss": 1.2534,
      "step": 116100
    },
    {
      "epoch": 35.07552870090635,
      "eval_loss": 1.2799749374389648,
      "eval_runtime": 649.1908,
      "eval_samples_per_second": 81.793,
      "eval_steps_per_second": 0.639,
      "step": 116100
    },
    {
      "epoch": 35.090634441087616,
      "grad_norm": 0.4794389009475708,
      "learning_rate": 4.327311178247734e-05,
      "loss": 1.2563,
      "step": 116150
    },
    {
      "epoch": 35.090634441087616,
      "eval_loss": 1.2805174589157104,
      "eval_runtime": 612.9283,
      "eval_samples_per_second": 86.632,
      "eval_steps_per_second": 0.677,
      "step": 116150
    },
    {
      "epoch": 35.105740181268885,
      "grad_norm": 0.4640446603298187,
      "learning_rate": 4.326304128902317e-05,
      "loss": 1.2478,
      "step": 116200
    },
    {
      "epoch": 35.105740181268885,
      "eval_loss": 1.2795084714889526,
      "eval_runtime": 654.45,
      "eval_samples_per_second": 81.135,
      "eval_steps_per_second": 0.634,
      "step": 116200
    },
    {
      "epoch": 35.120845921450154,
      "grad_norm": 0.48264098167419434,
      "learning_rate": 4.3252970795568986e-05,
      "loss": 1.2763,
      "step": 116250
    },
    {
      "epoch": 35.120845921450154,
      "eval_loss": 1.2796399593353271,
      "eval_runtime": 678.2102,
      "eval_samples_per_second": 78.293,
      "eval_steps_per_second": 0.612,
      "step": 116250
    },
    {
      "epoch": 35.13595166163142,
      "grad_norm": 0.42033687233924866,
      "learning_rate": 4.3242900302114805e-05,
      "loss": 1.2667,
      "step": 116300
    },
    {
      "epoch": 35.13595166163142,
      "eval_loss": 1.2794904708862305,
      "eval_runtime": 683.9479,
      "eval_samples_per_second": 77.636,
      "eval_steps_per_second": 0.607,
      "step": 116300
    },
    {
      "epoch": 35.151057401812686,
      "grad_norm": 0.4843786358833313,
      "learning_rate": 4.323282980866063e-05,
      "loss": 1.2734,
      "step": 116350
    },
    {
      "epoch": 35.151057401812686,
      "eval_loss": 1.282853364944458,
      "eval_runtime": 676.7029,
      "eval_samples_per_second": 78.467,
      "eval_steps_per_second": 0.613,
      "step": 116350
    },
    {
      "epoch": 35.166163141993955,
      "grad_norm": 0.47714972496032715,
      "learning_rate": 4.322275931520645e-05,
      "loss": 1.2514,
      "step": 116400
    },
    {
      "epoch": 35.166163141993955,
      "eval_loss": 1.2790921926498413,
      "eval_runtime": 592.363,
      "eval_samples_per_second": 89.639,
      "eval_steps_per_second": 0.701,
      "step": 116400
    },
    {
      "epoch": 35.181268882175225,
      "grad_norm": 0.4601905345916748,
      "learning_rate": 4.321268882175227e-05,
      "loss": 1.2642,
      "step": 116450
    },
    {
      "epoch": 35.181268882175225,
      "eval_loss": 1.2826145887374878,
      "eval_runtime": 686.2831,
      "eval_samples_per_second": 77.372,
      "eval_steps_per_second": 0.605,
      "step": 116450
    },
    {
      "epoch": 35.196374622356494,
      "grad_norm": 0.40660035610198975,
      "learning_rate": 4.3202618328298086e-05,
      "loss": 1.2484,
      "step": 116500
    },
    {
      "epoch": 35.196374622356494,
      "eval_loss": 1.280256986618042,
      "eval_runtime": 656.4007,
      "eval_samples_per_second": 80.894,
      "eval_steps_per_second": 0.632,
      "step": 116500
    },
    {
      "epoch": 35.21148036253776,
      "grad_norm": 0.4911511540412903,
      "learning_rate": 4.319254783484391e-05,
      "loss": 1.2486,
      "step": 116550
    },
    {
      "epoch": 35.21148036253776,
      "eval_loss": 1.2797070741653442,
      "eval_runtime": 649.8581,
      "eval_samples_per_second": 81.709,
      "eval_steps_per_second": 0.639,
      "step": 116550
    },
    {
      "epoch": 35.22658610271903,
      "grad_norm": 0.4547388553619385,
      "learning_rate": 4.318247734138973e-05,
      "loss": 1.2539,
      "step": 116600
    },
    {
      "epoch": 35.22658610271903,
      "eval_loss": 1.2814897298812866,
      "eval_runtime": 687.0816,
      "eval_samples_per_second": 77.282,
      "eval_steps_per_second": 0.604,
      "step": 116600
    },
    {
      "epoch": 35.2416918429003,
      "grad_norm": 0.46801862120628357,
      "learning_rate": 4.317240684793555e-05,
      "loss": 1.2481,
      "step": 116650
    },
    {
      "epoch": 35.2416918429003,
      "eval_loss": 1.2815333604812622,
      "eval_runtime": 665.2801,
      "eval_samples_per_second": 79.815,
      "eval_steps_per_second": 0.624,
      "step": 116650
    },
    {
      "epoch": 35.25679758308157,
      "grad_norm": 0.46411481499671936,
      "learning_rate": 4.316233635448137e-05,
      "loss": 1.2746,
      "step": 116700
    },
    {
      "epoch": 35.25679758308157,
      "eval_loss": 1.2799420356750488,
      "eval_runtime": 611.4681,
      "eval_samples_per_second": 86.839,
      "eval_steps_per_second": 0.679,
      "step": 116700
    },
    {
      "epoch": 35.27190332326284,
      "grad_norm": 0.4632638394832611,
      "learning_rate": 4.315226586102719e-05,
      "loss": 1.2349,
      "step": 116750
    },
    {
      "epoch": 35.27190332326284,
      "eval_loss": 1.2812057733535767,
      "eval_runtime": 600.5049,
      "eval_samples_per_second": 88.424,
      "eval_steps_per_second": 0.691,
      "step": 116750
    },
    {
      "epoch": 35.28700906344411,
      "grad_norm": 0.46782058477401733,
      "learning_rate": 4.314219536757301e-05,
      "loss": 1.2613,
      "step": 116800
    },
    {
      "epoch": 35.28700906344411,
      "eval_loss": 1.2800483703613281,
      "eval_runtime": 690.3614,
      "eval_samples_per_second": 76.915,
      "eval_steps_per_second": 0.601,
      "step": 116800
    },
    {
      "epoch": 35.30211480362538,
      "grad_norm": 0.47888827323913574,
      "learning_rate": 4.313212487411883e-05,
      "loss": 1.2602,
      "step": 116850
    },
    {
      "epoch": 35.30211480362538,
      "eval_loss": 1.2809154987335205,
      "eval_runtime": 687.9474,
      "eval_samples_per_second": 77.185,
      "eval_steps_per_second": 0.603,
      "step": 116850
    },
    {
      "epoch": 35.31722054380665,
      "grad_norm": 0.4908435046672821,
      "learning_rate": 4.3122054380664656e-05,
      "loss": 1.2495,
      "step": 116900
    },
    {
      "epoch": 35.31722054380665,
      "eval_loss": 1.2817389965057373,
      "eval_runtime": 628.1427,
      "eval_samples_per_second": 84.533,
      "eval_steps_per_second": 0.661,
      "step": 116900
    },
    {
      "epoch": 35.33232628398792,
      "grad_norm": 0.4569527208805084,
      "learning_rate": 4.3111983887210475e-05,
      "loss": 1.2533,
      "step": 116950
    },
    {
      "epoch": 35.33232628398792,
      "eval_loss": 1.2786173820495605,
      "eval_runtime": 673.4713,
      "eval_samples_per_second": 78.844,
      "eval_steps_per_second": 0.616,
      "step": 116950
    },
    {
      "epoch": 35.34743202416919,
      "grad_norm": 0.4453672468662262,
      "learning_rate": 4.310191339375629e-05,
      "loss": 1.2567,
      "step": 117000
    },
    {
      "epoch": 35.34743202416919,
      "eval_loss": 1.2781058549880981,
      "eval_runtime": 615.3905,
      "eval_samples_per_second": 86.285,
      "eval_steps_per_second": 0.674,
      "step": 117000
    },
    {
      "epoch": 35.362537764350456,
      "grad_norm": 0.45400887727737427,
      "learning_rate": 4.309184290030211e-05,
      "loss": 1.276,
      "step": 117050
    },
    {
      "epoch": 35.362537764350456,
      "eval_loss": 1.2812690734863281,
      "eval_runtime": 659.9032,
      "eval_samples_per_second": 80.465,
      "eval_steps_per_second": 0.629,
      "step": 117050
    },
    {
      "epoch": 35.37764350453172,
      "grad_norm": 0.4525665044784546,
      "learning_rate": 4.308177240684794e-05,
      "loss": 1.2381,
      "step": 117100
    },
    {
      "epoch": 35.37764350453172,
      "eval_loss": 1.2809635400772095,
      "eval_runtime": 616.7483,
      "eval_samples_per_second": 86.095,
      "eval_steps_per_second": 0.673,
      "step": 117100
    },
    {
      "epoch": 35.39274924471299,
      "grad_norm": 0.5374383330345154,
      "learning_rate": 4.3071701913393756e-05,
      "loss": 1.2637,
      "step": 117150
    },
    {
      "epoch": 35.39274924471299,
      "eval_loss": 1.279987096786499,
      "eval_runtime": 628.7827,
      "eval_samples_per_second": 84.447,
      "eval_steps_per_second": 0.66,
      "step": 117150
    },
    {
      "epoch": 35.40785498489426,
      "grad_norm": 0.4877801835536957,
      "learning_rate": 4.3061631419939575e-05,
      "loss": 1.2503,
      "step": 117200
    },
    {
      "epoch": 35.40785498489426,
      "eval_loss": 1.2810240983963013,
      "eval_runtime": 676.8356,
      "eval_samples_per_second": 78.452,
      "eval_steps_per_second": 0.613,
      "step": 117200
    },
    {
      "epoch": 35.42296072507553,
      "grad_norm": 0.4453921318054199,
      "learning_rate": 4.3051560926485393e-05,
      "loss": 1.2647,
      "step": 117250
    },
    {
      "epoch": 35.42296072507553,
      "eval_loss": 1.2810781002044678,
      "eval_runtime": 642.9843,
      "eval_samples_per_second": 82.582,
      "eval_steps_per_second": 0.645,
      "step": 117250
    },
    {
      "epoch": 35.438066465256796,
      "grad_norm": 0.42594337463378906,
      "learning_rate": 4.304149043303122e-05,
      "loss": 1.2633,
      "step": 117300
    },
    {
      "epoch": 35.438066465256796,
      "eval_loss": 1.280882716178894,
      "eval_runtime": 576.3532,
      "eval_samples_per_second": 92.129,
      "eval_steps_per_second": 0.72,
      "step": 117300
    },
    {
      "epoch": 35.453172205438065,
      "grad_norm": 0.47991687059402466,
      "learning_rate": 4.3031419939577044e-05,
      "loss": 1.2563,
      "step": 117350
    },
    {
      "epoch": 35.453172205438065,
      "eval_loss": 1.2798579931259155,
      "eval_runtime": 617.3827,
      "eval_samples_per_second": 86.007,
      "eval_steps_per_second": 0.672,
      "step": 117350
    },
    {
      "epoch": 35.468277945619334,
      "grad_norm": 0.4451366066932678,
      "learning_rate": 4.302134944612286e-05,
      "loss": 1.264,
      "step": 117400
    },
    {
      "epoch": 35.468277945619334,
      "eval_loss": 1.2814489603042603,
      "eval_runtime": 651.1518,
      "eval_samples_per_second": 81.546,
      "eval_steps_per_second": 0.637,
      "step": 117400
    },
    {
      "epoch": 35.483383685800604,
      "grad_norm": 0.44173380732536316,
      "learning_rate": 4.301127895266868e-05,
      "loss": 1.2586,
      "step": 117450
    },
    {
      "epoch": 35.483383685800604,
      "eval_loss": 1.2791234254837036,
      "eval_runtime": 671.4547,
      "eval_samples_per_second": 79.081,
      "eval_steps_per_second": 0.618,
      "step": 117450
    },
    {
      "epoch": 35.49848942598187,
      "grad_norm": 0.4446711838245392,
      "learning_rate": 4.300120845921451e-05,
      "loss": 1.2514,
      "step": 117500
    },
    {
      "epoch": 35.49848942598187,
      "eval_loss": 1.2799915075302124,
      "eval_runtime": 649.2449,
      "eval_samples_per_second": 81.786,
      "eval_steps_per_second": 0.639,
      "step": 117500
    },
    {
      "epoch": 35.51359516616314,
      "grad_norm": 0.44268837571144104,
      "learning_rate": 4.2991137965760326e-05,
      "loss": 1.249,
      "step": 117550
    },
    {
      "epoch": 35.51359516616314,
      "eval_loss": 1.281103491783142,
      "eval_runtime": 644.6109,
      "eval_samples_per_second": 82.374,
      "eval_steps_per_second": 0.644,
      "step": 117550
    },
    {
      "epoch": 35.52870090634441,
      "grad_norm": 0.4537413418292999,
      "learning_rate": 4.2981067472306145e-05,
      "loss": 1.2509,
      "step": 117600
    },
    {
      "epoch": 35.52870090634441,
      "eval_loss": 1.2783117294311523,
      "eval_runtime": 652.2007,
      "eval_samples_per_second": 81.415,
      "eval_steps_per_second": 0.636,
      "step": 117600
    },
    {
      "epoch": 35.54380664652568,
      "grad_norm": 0.4592597186565399,
      "learning_rate": 4.297099697885196e-05,
      "loss": 1.2665,
      "step": 117650
    },
    {
      "epoch": 35.54380664652568,
      "eval_loss": 1.2794549465179443,
      "eval_runtime": 597.9837,
      "eval_samples_per_second": 88.797,
      "eval_steps_per_second": 0.694,
      "step": 117650
    },
    {
      "epoch": 35.55891238670695,
      "grad_norm": 0.49867966771125793,
      "learning_rate": 4.296092648539779e-05,
      "loss": 1.2532,
      "step": 117700
    },
    {
      "epoch": 35.55891238670695,
      "eval_loss": 1.2790504693984985,
      "eval_runtime": 651.5001,
      "eval_samples_per_second": 81.503,
      "eval_steps_per_second": 0.637,
      "step": 117700
    },
    {
      "epoch": 35.57401812688822,
      "grad_norm": 0.4603518545627594,
      "learning_rate": 4.295085599194361e-05,
      "loss": 1.2562,
      "step": 117750
    },
    {
      "epoch": 35.57401812688822,
      "eval_loss": 1.279524803161621,
      "eval_runtime": 637.0102,
      "eval_samples_per_second": 83.357,
      "eval_steps_per_second": 0.651,
      "step": 117750
    },
    {
      "epoch": 35.58912386706949,
      "grad_norm": 0.4420073628425598,
      "learning_rate": 4.2940785498489426e-05,
      "loss": 1.2503,
      "step": 117800
    },
    {
      "epoch": 35.58912386706949,
      "eval_loss": 1.279746174812317,
      "eval_runtime": 614.2852,
      "eval_samples_per_second": 86.44,
      "eval_steps_per_second": 0.676,
      "step": 117800
    },
    {
      "epoch": 35.60422960725076,
      "grad_norm": 0.4520737826824188,
      "learning_rate": 4.2930715005035245e-05,
      "loss": 1.2592,
      "step": 117850
    },
    {
      "epoch": 35.60422960725076,
      "eval_loss": 1.2791508436203003,
      "eval_runtime": 694.1596,
      "eval_samples_per_second": 76.494,
      "eval_steps_per_second": 0.598,
      "step": 117850
    },
    {
      "epoch": 35.61933534743203,
      "grad_norm": 0.44609686732292175,
      "learning_rate": 4.292064451158107e-05,
      "loss": 1.2566,
      "step": 117900
    },
    {
      "epoch": 35.61933534743203,
      "eval_loss": 1.2802112102508545,
      "eval_runtime": 618.296,
      "eval_samples_per_second": 85.88,
      "eval_steps_per_second": 0.671,
      "step": 117900
    },
    {
      "epoch": 35.63444108761329,
      "grad_norm": 0.44761690497398376,
      "learning_rate": 4.291057401812689e-05,
      "loss": 1.2627,
      "step": 117950
    },
    {
      "epoch": 35.63444108761329,
      "eval_loss": 1.2808420658111572,
      "eval_runtime": 697.0136,
      "eval_samples_per_second": 76.181,
      "eval_steps_per_second": 0.595,
      "step": 117950
    },
    {
      "epoch": 35.64954682779456,
      "grad_norm": 0.41806942224502563,
      "learning_rate": 4.290050352467271e-05,
      "loss": 1.261,
      "step": 118000
    },
    {
      "epoch": 35.64954682779456,
      "eval_loss": 1.2811272144317627,
      "eval_runtime": 605.9689,
      "eval_samples_per_second": 87.627,
      "eval_steps_per_second": 0.685,
      "step": 118000
    },
    {
      "epoch": 35.66465256797583,
      "grad_norm": 0.46303367614746094,
      "learning_rate": 4.289043303121853e-05,
      "loss": 1.2384,
      "step": 118050
    },
    {
      "epoch": 35.66465256797583,
      "eval_loss": 1.2786684036254883,
      "eval_runtime": 700.4986,
      "eval_samples_per_second": 75.802,
      "eval_steps_per_second": 0.592,
      "step": 118050
    },
    {
      "epoch": 35.6797583081571,
      "grad_norm": 0.4939921796321869,
      "learning_rate": 4.288036253776435e-05,
      "loss": 1.2462,
      "step": 118100
    },
    {
      "epoch": 35.6797583081571,
      "eval_loss": 1.278704047203064,
      "eval_runtime": 700.4613,
      "eval_samples_per_second": 75.806,
      "eval_steps_per_second": 0.592,
      "step": 118100
    },
    {
      "epoch": 35.69486404833837,
      "grad_norm": 0.4985118508338928,
      "learning_rate": 4.287029204431017e-05,
      "loss": 1.2667,
      "step": 118150
    },
    {
      "epoch": 35.69486404833837,
      "eval_loss": 1.2777185440063477,
      "eval_runtime": 674.557,
      "eval_samples_per_second": 78.717,
      "eval_steps_per_second": 0.615,
      "step": 118150
    },
    {
      "epoch": 35.709969788519636,
      "grad_norm": 0.48900848627090454,
      "learning_rate": 4.286022155085599e-05,
      "loss": 1.2403,
      "step": 118200
    },
    {
      "epoch": 35.709969788519636,
      "eval_loss": 1.2799592018127441,
      "eval_runtime": 635.766,
      "eval_samples_per_second": 83.52,
      "eval_steps_per_second": 0.653,
      "step": 118200
    },
    {
      "epoch": 35.725075528700906,
      "grad_norm": 0.3998563289642334,
      "learning_rate": 4.2850151057401815e-05,
      "loss": 1.2688,
      "step": 118250
    },
    {
      "epoch": 35.725075528700906,
      "eval_loss": 1.278961420059204,
      "eval_runtime": 701.8445,
      "eval_samples_per_second": 75.656,
      "eval_steps_per_second": 0.591,
      "step": 118250
    },
    {
      "epoch": 35.740181268882175,
      "grad_norm": 0.4659721851348877,
      "learning_rate": 4.284008056394763e-05,
      "loss": 1.257,
      "step": 118300
    },
    {
      "epoch": 35.740181268882175,
      "eval_loss": 1.280707836151123,
      "eval_runtime": 657.1301,
      "eval_samples_per_second": 80.804,
      "eval_steps_per_second": 0.632,
      "step": 118300
    },
    {
      "epoch": 35.755287009063444,
      "grad_norm": 0.45192790031433105,
      "learning_rate": 4.283001007049345e-05,
      "loss": 1.2551,
      "step": 118350
    },
    {
      "epoch": 35.755287009063444,
      "eval_loss": 1.2790642976760864,
      "eval_runtime": 663.7477,
      "eval_samples_per_second": 79.999,
      "eval_steps_per_second": 0.625,
      "step": 118350
    },
    {
      "epoch": 35.770392749244714,
      "grad_norm": 0.42994245886802673,
      "learning_rate": 4.281993957703927e-05,
      "loss": 1.2663,
      "step": 118400
    },
    {
      "epoch": 35.770392749244714,
      "eval_loss": 1.2797311544418335,
      "eval_runtime": 940.7573,
      "eval_samples_per_second": 56.443,
      "eval_steps_per_second": 0.441,
      "step": 118400
    },
    {
      "epoch": 35.78549848942598,
      "grad_norm": 0.4429912269115448,
      "learning_rate": 4.2809869083585096e-05,
      "loss": 1.2414,
      "step": 118450
    },
    {
      "epoch": 35.78549848942598,
      "eval_loss": 1.2791941165924072,
      "eval_runtime": 633.3889,
      "eval_samples_per_second": 83.833,
      "eval_steps_per_second": 0.655,
      "step": 118450
    },
    {
      "epoch": 35.80060422960725,
      "grad_norm": 0.4577656388282776,
      "learning_rate": 4.279979859013092e-05,
      "loss": 1.2347,
      "step": 118500
    },
    {
      "epoch": 35.80060422960725,
      "eval_loss": 1.2806599140167236,
      "eval_runtime": 690.1345,
      "eval_samples_per_second": 76.94,
      "eval_steps_per_second": 0.601,
      "step": 118500
    },
    {
      "epoch": 35.81570996978852,
      "grad_norm": 0.45072850584983826,
      "learning_rate": 4.278972809667674e-05,
      "loss": 1.2606,
      "step": 118550
    },
    {
      "epoch": 35.81570996978852,
      "eval_loss": 1.2806075811386108,
      "eval_runtime": 670.123,
      "eval_samples_per_second": 79.238,
      "eval_steps_per_second": 0.619,
      "step": 118550
    },
    {
      "epoch": 35.83081570996979,
      "grad_norm": 0.42668256163597107,
      "learning_rate": 4.277965760322256e-05,
      "loss": 1.2577,
      "step": 118600
    },
    {
      "epoch": 35.83081570996979,
      "eval_loss": 1.2807835340499878,
      "eval_runtime": 624.7443,
      "eval_samples_per_second": 84.993,
      "eval_steps_per_second": 0.664,
      "step": 118600
    },
    {
      "epoch": 35.84592145015106,
      "grad_norm": 0.4268309473991394,
      "learning_rate": 4.2769587109768384e-05,
      "loss": 1.2478,
      "step": 118650
    },
    {
      "epoch": 35.84592145015106,
      "eval_loss": 1.2814387083053589,
      "eval_runtime": 559.4214,
      "eval_samples_per_second": 94.918,
      "eval_steps_per_second": 0.742,
      "step": 118650
    },
    {
      "epoch": 35.86102719033233,
      "grad_norm": 0.4559769630432129,
      "learning_rate": 4.27595166163142e-05,
      "loss": 1.2504,
      "step": 118700
    },
    {
      "epoch": 35.86102719033233,
      "eval_loss": 1.2793192863464355,
      "eval_runtime": 631.3794,
      "eval_samples_per_second": 84.1,
      "eval_steps_per_second": 0.657,
      "step": 118700
    },
    {
      "epoch": 35.87613293051359,
      "grad_norm": 0.4797828793525696,
      "learning_rate": 4.274944612286002e-05,
      "loss": 1.2391,
      "step": 118750
    },
    {
      "epoch": 35.87613293051359,
      "eval_loss": 1.279150128364563,
      "eval_runtime": 689.7687,
      "eval_samples_per_second": 76.981,
      "eval_steps_per_second": 0.602,
      "step": 118750
    },
    {
      "epoch": 35.89123867069486,
      "grad_norm": 0.4637172520160675,
      "learning_rate": 4.273937562940584e-05,
      "loss": 1.2779,
      "step": 118800
    },
    {
      "epoch": 35.89123867069486,
      "eval_loss": 1.2755533456802368,
      "eval_runtime": 688.4597,
      "eval_samples_per_second": 77.127,
      "eval_steps_per_second": 0.603,
      "step": 118800
    },
    {
      "epoch": 35.90634441087613,
      "grad_norm": 0.49090227484703064,
      "learning_rate": 4.2729305135951666e-05,
      "loss": 1.2584,
      "step": 118850
    },
    {
      "epoch": 35.90634441087613,
      "eval_loss": 1.2786401510238647,
      "eval_runtime": 640.1099,
      "eval_samples_per_second": 82.953,
      "eval_steps_per_second": 0.648,
      "step": 118850
    },
    {
      "epoch": 35.9214501510574,
      "grad_norm": 0.48131507635116577,
      "learning_rate": 4.2719234642497485e-05,
      "loss": 1.2405,
      "step": 118900
    },
    {
      "epoch": 35.9214501510574,
      "eval_loss": 1.2782984972000122,
      "eval_runtime": 594.9813,
      "eval_samples_per_second": 89.245,
      "eval_steps_per_second": 0.698,
      "step": 118900
    },
    {
      "epoch": 35.93655589123867,
      "grad_norm": 0.42940372228622437,
      "learning_rate": 4.27091641490433e-05,
      "loss": 1.2512,
      "step": 118950
    },
    {
      "epoch": 35.93655589123867,
      "eval_loss": 1.2798309326171875,
      "eval_runtime": 660.8211,
      "eval_samples_per_second": 80.353,
      "eval_steps_per_second": 0.628,
      "step": 118950
    },
    {
      "epoch": 35.95166163141994,
      "grad_norm": 0.43987542390823364,
      "learning_rate": 4.269909365558913e-05,
      "loss": 1.2658,
      "step": 119000
    },
    {
      "epoch": 35.95166163141994,
      "eval_loss": 1.280282735824585,
      "eval_runtime": 598.1218,
      "eval_samples_per_second": 88.776,
      "eval_steps_per_second": 0.694,
      "step": 119000
    },
    {
      "epoch": 35.96676737160121,
      "grad_norm": 0.45052674412727356,
      "learning_rate": 4.268902316213495e-05,
      "loss": 1.2605,
      "step": 119050
    },
    {
      "epoch": 35.96676737160121,
      "eval_loss": 1.278110384941101,
      "eval_runtime": 670.4487,
      "eval_samples_per_second": 79.199,
      "eval_steps_per_second": 0.619,
      "step": 119050
    },
    {
      "epoch": 35.98187311178248,
      "grad_norm": 0.4774671792984009,
      "learning_rate": 4.2678952668680766e-05,
      "loss": 1.2512,
      "step": 119100
    },
    {
      "epoch": 35.98187311178248,
      "eval_loss": 1.277453064918518,
      "eval_runtime": 617.4801,
      "eval_samples_per_second": 85.993,
      "eval_steps_per_second": 0.672,
      "step": 119100
    },
    {
      "epoch": 35.996978851963746,
      "grad_norm": 0.4864044487476349,
      "learning_rate": 4.2668882175226585e-05,
      "loss": 1.2622,
      "step": 119150
    },
    {
      "epoch": 35.996978851963746,
      "eval_loss": 1.2769712209701538,
      "eval_runtime": 584.7395,
      "eval_samples_per_second": 90.808,
      "eval_steps_per_second": 0.71,
      "step": 119150
    },
    {
      "epoch": 36.012084592145015,
      "grad_norm": 0.4747788906097412,
      "learning_rate": 4.265881168177241e-05,
      "loss": 1.2484,
      "step": 119200
    },
    {
      "epoch": 36.012084592145015,
      "eval_loss": 1.278611660003662,
      "eval_runtime": 624.5105,
      "eval_samples_per_second": 85.025,
      "eval_steps_per_second": 0.665,
      "step": 119200
    },
    {
      "epoch": 36.027190332326285,
      "grad_norm": 0.43974143266677856,
      "learning_rate": 4.264874118831823e-05,
      "loss": 1.2455,
      "step": 119250
    },
    {
      "epoch": 36.027190332326285,
      "eval_loss": 1.280134916305542,
      "eval_runtime": 602.7188,
      "eval_samples_per_second": 88.099,
      "eval_steps_per_second": 0.689,
      "step": 119250
    },
    {
      "epoch": 36.042296072507554,
      "grad_norm": 0.4512867033481598,
      "learning_rate": 4.263867069486405e-05,
      "loss": 1.2363,
      "step": 119300
    },
    {
      "epoch": 36.042296072507554,
      "eval_loss": 1.2782927751541138,
      "eval_runtime": 668.3795,
      "eval_samples_per_second": 79.444,
      "eval_steps_per_second": 0.621,
      "step": 119300
    },
    {
      "epoch": 36.05740181268882,
      "grad_norm": 0.46121835708618164,
      "learning_rate": 4.2628600201409866e-05,
      "loss": 1.2454,
      "step": 119350
    },
    {
      "epoch": 36.05740181268882,
      "eval_loss": 1.2783576250076294,
      "eval_runtime": 688.8056,
      "eval_samples_per_second": 77.089,
      "eval_steps_per_second": 0.602,
      "step": 119350
    },
    {
      "epoch": 36.07250755287009,
      "grad_norm": 0.4503942131996155,
      "learning_rate": 4.261852970795569e-05,
      "loss": 1.2529,
      "step": 119400
    },
    {
      "epoch": 36.07250755287009,
      "eval_loss": 1.2780137062072754,
      "eval_runtime": 687.5041,
      "eval_samples_per_second": 77.234,
      "eval_steps_per_second": 0.604,
      "step": 119400
    },
    {
      "epoch": 36.08761329305136,
      "grad_norm": 0.45721325278282166,
      "learning_rate": 4.260845921450151e-05,
      "loss": 1.2378,
      "step": 119450
    },
    {
      "epoch": 36.08761329305136,
      "eval_loss": 1.2795581817626953,
      "eval_runtime": 636.5293,
      "eval_samples_per_second": 83.42,
      "eval_steps_per_second": 0.652,
      "step": 119450
    },
    {
      "epoch": 36.10271903323263,
      "grad_norm": 0.45408618450164795,
      "learning_rate": 4.259838872104733e-05,
      "loss": 1.2574,
      "step": 119500
    },
    {
      "epoch": 36.10271903323263,
      "eval_loss": 1.2789584398269653,
      "eval_runtime": 693.5104,
      "eval_samples_per_second": 76.566,
      "eval_steps_per_second": 0.598,
      "step": 119500
    },
    {
      "epoch": 36.1178247734139,
      "grad_norm": 0.43775877356529236,
      "learning_rate": 4.258831822759315e-05,
      "loss": 1.2596,
      "step": 119550
    },
    {
      "epoch": 36.1178247734139,
      "eval_loss": 1.276524305343628,
      "eval_runtime": 646.3245,
      "eval_samples_per_second": 82.155,
      "eval_steps_per_second": 0.642,
      "step": 119550
    },
    {
      "epoch": 36.13293051359516,
      "grad_norm": 0.5274514555931091,
      "learning_rate": 4.257824773413897e-05,
      "loss": 1.2615,
      "step": 119600
    },
    {
      "epoch": 36.13293051359516,
      "eval_loss": 1.2786318063735962,
      "eval_runtime": 649.9569,
      "eval_samples_per_second": 81.696,
      "eval_steps_per_second": 0.639,
      "step": 119600
    },
    {
      "epoch": 36.14803625377643,
      "grad_norm": 0.4474021792411804,
      "learning_rate": 4.256817724068479e-05,
      "loss": 1.243,
      "step": 119650
    },
    {
      "epoch": 36.14803625377643,
      "eval_loss": 1.2794901132583618,
      "eval_runtime": 681.2462,
      "eval_samples_per_second": 77.944,
      "eval_steps_per_second": 0.609,
      "step": 119650
    },
    {
      "epoch": 36.1631419939577,
      "grad_norm": 0.45246341824531555,
      "learning_rate": 4.255810674723062e-05,
      "loss": 1.2352,
      "step": 119700
    },
    {
      "epoch": 36.1631419939577,
      "eval_loss": 1.2775872945785522,
      "eval_runtime": 746.5063,
      "eval_samples_per_second": 71.13,
      "eval_steps_per_second": 0.556,
      "step": 119700
    },
    {
      "epoch": 36.17824773413897,
      "grad_norm": 0.46061018109321594,
      "learning_rate": 4.2548036253776436e-05,
      "loss": 1.2429,
      "step": 119750
    },
    {
      "epoch": 36.17824773413897,
      "eval_loss": 1.2783046960830688,
      "eval_runtime": 680.8825,
      "eval_samples_per_second": 77.986,
      "eval_steps_per_second": 0.61,
      "step": 119750
    },
    {
      "epoch": 36.19335347432024,
      "grad_norm": 0.41604381799697876,
      "learning_rate": 4.253796576032226e-05,
      "loss": 1.2401,
      "step": 119800
    },
    {
      "epoch": 36.19335347432024,
      "eval_loss": 1.2786370515823364,
      "eval_runtime": 608.453,
      "eval_samples_per_second": 87.269,
      "eval_steps_per_second": 0.682,
      "step": 119800
    },
    {
      "epoch": 36.20845921450151,
      "grad_norm": 0.4331178069114685,
      "learning_rate": 4.252789526686808e-05,
      "loss": 1.2466,
      "step": 119850
    },
    {
      "epoch": 36.20845921450151,
      "eval_loss": 1.2779804468154907,
      "eval_runtime": 644.9928,
      "eval_samples_per_second": 82.325,
      "eval_steps_per_second": 0.643,
      "step": 119850
    },
    {
      "epoch": 36.22356495468278,
      "grad_norm": 0.5095526576042175,
      "learning_rate": 4.25178247734139e-05,
      "loss": 1.2638,
      "step": 119900
    },
    {
      "epoch": 36.22356495468278,
      "eval_loss": 1.2785388231277466,
      "eval_runtime": 655.6097,
      "eval_samples_per_second": 80.992,
      "eval_steps_per_second": 0.633,
      "step": 119900
    },
    {
      "epoch": 36.23867069486405,
      "grad_norm": 0.4986393451690674,
      "learning_rate": 4.250775427995972e-05,
      "loss": 1.2798,
      "step": 119950
    },
    {
      "epoch": 36.23867069486405,
      "eval_loss": 1.2790558338165283,
      "eval_runtime": 650.2903,
      "eval_samples_per_second": 81.654,
      "eval_steps_per_second": 0.638,
      "step": 119950
    },
    {
      "epoch": 36.25377643504532,
      "grad_norm": 0.4536193907260895,
      "learning_rate": 4.249768378650554e-05,
      "loss": 1.2651,
      "step": 120000
    },
    {
      "epoch": 36.25377643504532,
      "eval_loss": 1.2794811725616455,
      "eval_runtime": 693.6819,
      "eval_samples_per_second": 76.547,
      "eval_steps_per_second": 0.598,
      "step": 120000
    },
    {
      "epoch": 36.26888217522659,
      "grad_norm": 0.42568519711494446,
      "learning_rate": 4.248761329305136e-05,
      "loss": 1.2429,
      "step": 120050
    },
    {
      "epoch": 36.26888217522659,
      "eval_loss": 1.2786192893981934,
      "eval_runtime": 569.2592,
      "eval_samples_per_second": 93.277,
      "eval_steps_per_second": 0.729,
      "step": 120050
    },
    {
      "epoch": 36.283987915407856,
      "grad_norm": 0.453421950340271,
      "learning_rate": 4.247754279959718e-05,
      "loss": 1.2716,
      "step": 120100
    },
    {
      "epoch": 36.283987915407856,
      "eval_loss": 1.2783859968185425,
      "eval_runtime": 603.7736,
      "eval_samples_per_second": 87.945,
      "eval_steps_per_second": 0.687,
      "step": 120100
    },
    {
      "epoch": 36.299093655589125,
      "grad_norm": 0.43801626563072205,
      "learning_rate": 4.2467472306143006e-05,
      "loss": 1.2597,
      "step": 120150
    },
    {
      "epoch": 36.299093655589125,
      "eval_loss": 1.2788589000701904,
      "eval_runtime": 637.9051,
      "eval_samples_per_second": 83.24,
      "eval_steps_per_second": 0.651,
      "step": 120150
    },
    {
      "epoch": 36.314199395770395,
      "grad_norm": 0.4887956380844116,
      "learning_rate": 4.2457401812688825e-05,
      "loss": 1.2599,
      "step": 120200
    },
    {
      "epoch": 36.314199395770395,
      "eval_loss": 1.2768816947937012,
      "eval_runtime": 655.6619,
      "eval_samples_per_second": 80.985,
      "eval_steps_per_second": 0.633,
      "step": 120200
    },
    {
      "epoch": 36.329305135951664,
      "grad_norm": 0.44965463876724243,
      "learning_rate": 4.244733131923464e-05,
      "loss": 1.2437,
      "step": 120250
    },
    {
      "epoch": 36.329305135951664,
      "eval_loss": 1.27909255027771,
      "eval_runtime": 666.6697,
      "eval_samples_per_second": 79.648,
      "eval_steps_per_second": 0.622,
      "step": 120250
    },
    {
      "epoch": 36.34441087613293,
      "grad_norm": 0.4399096369743347,
      "learning_rate": 4.243726082578046e-05,
      "loss": 1.245,
      "step": 120300
    },
    {
      "epoch": 36.34441087613293,
      "eval_loss": 1.2775105237960815,
      "eval_runtime": 629.1944,
      "eval_samples_per_second": 84.392,
      "eval_steps_per_second": 0.66,
      "step": 120300
    },
    {
      "epoch": 36.3595166163142,
      "grad_norm": 0.44312769174575806,
      "learning_rate": 4.242719033232629e-05,
      "loss": 1.2375,
      "step": 120350
    },
    {
      "epoch": 36.3595166163142,
      "eval_loss": 1.2765039205551147,
      "eval_runtime": 672.2396,
      "eval_samples_per_second": 78.988,
      "eval_steps_per_second": 0.617,
      "step": 120350
    },
    {
      "epoch": 36.374622356495465,
      "grad_norm": 0.44022905826568604,
      "learning_rate": 4.2417119838872106e-05,
      "loss": 1.2648,
      "step": 120400
    },
    {
      "epoch": 36.374622356495465,
      "eval_loss": 1.2777974605560303,
      "eval_runtime": 629.7384,
      "eval_samples_per_second": 84.319,
      "eval_steps_per_second": 0.659,
      "step": 120400
    },
    {
      "epoch": 36.389728096676734,
      "grad_norm": 0.44287386536598206,
      "learning_rate": 4.2407049345417925e-05,
      "loss": 1.2775,
      "step": 120450
    },
    {
      "epoch": 36.389728096676734,
      "eval_loss": 1.2771663665771484,
      "eval_runtime": 641.5041,
      "eval_samples_per_second": 82.773,
      "eval_steps_per_second": 0.647,
      "step": 120450
    },
    {
      "epoch": 36.404833836858,
      "grad_norm": 0.42351657152175903,
      "learning_rate": 4.2396978851963744e-05,
      "loss": 1.2376,
      "step": 120500
    },
    {
      "epoch": 36.404833836858,
      "eval_loss": 1.2765878438949585,
      "eval_runtime": 680.0461,
      "eval_samples_per_second": 78.081,
      "eval_steps_per_second": 0.61,
      "step": 120500
    },
    {
      "epoch": 36.41993957703927,
      "grad_norm": 0.44794827699661255,
      "learning_rate": 4.238690835850957e-05,
      "loss": 1.2514,
      "step": 120550
    },
    {
      "epoch": 36.41993957703927,
      "eval_loss": 1.2774821519851685,
      "eval_runtime": 637.3201,
      "eval_samples_per_second": 83.316,
      "eval_steps_per_second": 0.651,
      "step": 120550
    },
    {
      "epoch": 36.43504531722054,
      "grad_norm": 0.4339633882045746,
      "learning_rate": 4.237683786505539e-05,
      "loss": 1.2261,
      "step": 120600
    },
    {
      "epoch": 36.43504531722054,
      "eval_loss": 1.276437759399414,
      "eval_runtime": 715.0085,
      "eval_samples_per_second": 74.263,
      "eval_steps_per_second": 0.58,
      "step": 120600
    },
    {
      "epoch": 36.45015105740181,
      "grad_norm": 0.43343913555145264,
      "learning_rate": 4.2366767371601206e-05,
      "loss": 1.2549,
      "step": 120650
    },
    {
      "epoch": 36.45015105740181,
      "eval_loss": 1.2778114080429077,
      "eval_runtime": 696.9738,
      "eval_samples_per_second": 76.185,
      "eval_steps_per_second": 0.595,
      "step": 120650
    },
    {
      "epoch": 36.46525679758308,
      "grad_norm": 0.48294761776924133,
      "learning_rate": 4.2356696878147025e-05,
      "loss": 1.2825,
      "step": 120700
    },
    {
      "epoch": 36.46525679758308,
      "eval_loss": 1.278050184249878,
      "eval_runtime": 656.9754,
      "eval_samples_per_second": 80.823,
      "eval_steps_per_second": 0.632,
      "step": 120700
    },
    {
      "epoch": 36.48036253776435,
      "grad_norm": 0.4595741033554077,
      "learning_rate": 4.234662638469285e-05,
      "loss": 1.2475,
      "step": 120750
    },
    {
      "epoch": 36.48036253776435,
      "eval_loss": 1.2783138751983643,
      "eval_runtime": 659.4358,
      "eval_samples_per_second": 80.522,
      "eval_steps_per_second": 0.629,
      "step": 120750
    },
    {
      "epoch": 36.49546827794562,
      "grad_norm": 0.4583403766155243,
      "learning_rate": 4.233655589123867e-05,
      "loss": 1.2782,
      "step": 120800
    },
    {
      "epoch": 36.49546827794562,
      "eval_loss": 1.2781810760498047,
      "eval_runtime": 620.5855,
      "eval_samples_per_second": 85.563,
      "eval_steps_per_second": 0.669,
      "step": 120800
    },
    {
      "epoch": 36.51057401812689,
      "grad_norm": 0.4474130868911743,
      "learning_rate": 4.2326485397784495e-05,
      "loss": 1.2596,
      "step": 120850
    },
    {
      "epoch": 36.51057401812689,
      "eval_loss": 1.2760696411132812,
      "eval_runtime": 578.6113,
      "eval_samples_per_second": 91.77,
      "eval_steps_per_second": 0.717,
      "step": 120850
    },
    {
      "epoch": 36.52567975830816,
      "grad_norm": 0.4491167962551117,
      "learning_rate": 4.231641490433031e-05,
      "loss": 1.2584,
      "step": 120900
    },
    {
      "epoch": 36.52567975830816,
      "eval_loss": 1.2776765823364258,
      "eval_runtime": 646.1332,
      "eval_samples_per_second": 82.18,
      "eval_steps_per_second": 0.642,
      "step": 120900
    },
    {
      "epoch": 36.54078549848943,
      "grad_norm": 0.44828474521636963,
      "learning_rate": 4.230634441087614e-05,
      "loss": 1.2472,
      "step": 120950
    },
    {
      "epoch": 36.54078549848943,
      "eval_loss": 1.2767055034637451,
      "eval_runtime": 646.0908,
      "eval_samples_per_second": 82.185,
      "eval_steps_per_second": 0.642,
      "step": 120950
    },
    {
      "epoch": 36.5558912386707,
      "grad_norm": 0.42942187190055847,
      "learning_rate": 4.229627391742196e-05,
      "loss": 1.2465,
      "step": 121000
    },
    {
      "epoch": 36.5558912386707,
      "eval_loss": 1.2756195068359375,
      "eval_runtime": 665.0228,
      "eval_samples_per_second": 79.845,
      "eval_steps_per_second": 0.624,
      "step": 121000
    },
    {
      "epoch": 36.570996978851966,
      "grad_norm": 0.44545674324035645,
      "learning_rate": 4.2286203423967776e-05,
      "loss": 1.2495,
      "step": 121050
    },
    {
      "epoch": 36.570996978851966,
      "eval_loss": 1.276340126991272,
      "eval_runtime": 653.1514,
      "eval_samples_per_second": 81.297,
      "eval_steps_per_second": 0.635,
      "step": 121050
    },
    {
      "epoch": 36.586102719033235,
      "grad_norm": 0.4967345595359802,
      "learning_rate": 4.2276132930513595e-05,
      "loss": 1.2609,
      "step": 121100
    },
    {
      "epoch": 36.586102719033235,
      "eval_loss": 1.2760589122772217,
      "eval_runtime": 701.3432,
      "eval_samples_per_second": 75.71,
      "eval_steps_per_second": 0.592,
      "step": 121100
    },
    {
      "epoch": 36.601208459214504,
      "grad_norm": 0.4481871426105499,
      "learning_rate": 4.226606243705942e-05,
      "loss": 1.2772,
      "step": 121150
    },
    {
      "epoch": 36.601208459214504,
      "eval_loss": 1.2794697284698486,
      "eval_runtime": 647.6742,
      "eval_samples_per_second": 81.984,
      "eval_steps_per_second": 0.641,
      "step": 121150
    },
    {
      "epoch": 36.616314199395774,
      "grad_norm": 0.4608267843723297,
      "learning_rate": 4.225599194360524e-05,
      "loss": 1.2553,
      "step": 121200
    },
    {
      "epoch": 36.616314199395774,
      "eval_loss": 1.2787829637527466,
      "eval_runtime": 654.2583,
      "eval_samples_per_second": 81.159,
      "eval_steps_per_second": 0.634,
      "step": 121200
    },
    {
      "epoch": 36.631419939577036,
      "grad_norm": 0.46641093492507935,
      "learning_rate": 4.224592145015106e-05,
      "loss": 1.2417,
      "step": 121250
    },
    {
      "epoch": 36.631419939577036,
      "eval_loss": 1.276647686958313,
      "eval_runtime": 607.4707,
      "eval_samples_per_second": 87.41,
      "eval_steps_per_second": 0.683,
      "step": 121250
    },
    {
      "epoch": 36.646525679758305,
      "grad_norm": 0.4124431908130646,
      "learning_rate": 4.223585095669688e-05,
      "loss": 1.2568,
      "step": 121300
    },
    {
      "epoch": 36.646525679758305,
      "eval_loss": 1.2783327102661133,
      "eval_runtime": 633.5185,
      "eval_samples_per_second": 83.816,
      "eval_steps_per_second": 0.655,
      "step": 121300
    },
    {
      "epoch": 36.661631419939575,
      "grad_norm": 0.47424644231796265,
      "learning_rate": 4.22257804632427e-05,
      "loss": 1.2372,
      "step": 121350
    },
    {
      "epoch": 36.661631419939575,
      "eval_loss": 1.2772531509399414,
      "eval_runtime": 674.9758,
      "eval_samples_per_second": 78.668,
      "eval_steps_per_second": 0.615,
      "step": 121350
    },
    {
      "epoch": 36.676737160120844,
      "grad_norm": 0.4033539295196533,
      "learning_rate": 4.221570996978852e-05,
      "loss": 1.2526,
      "step": 121400
    },
    {
      "epoch": 36.676737160120844,
      "eval_loss": 1.2768981456756592,
      "eval_runtime": 677.0855,
      "eval_samples_per_second": 78.423,
      "eval_steps_per_second": 0.613,
      "step": 121400
    },
    {
      "epoch": 36.69184290030211,
      "grad_norm": 0.450726181268692,
      "learning_rate": 4.220563947633434e-05,
      "loss": 1.2452,
      "step": 121450
    },
    {
      "epoch": 36.69184290030211,
      "eval_loss": 1.2780678272247314,
      "eval_runtime": 666.4286,
      "eval_samples_per_second": 79.677,
      "eval_steps_per_second": 0.623,
      "step": 121450
    },
    {
      "epoch": 36.70694864048338,
      "grad_norm": 0.5105371475219727,
      "learning_rate": 4.2195568982880165e-05,
      "loss": 1.2656,
      "step": 121500
    },
    {
      "epoch": 36.70694864048338,
      "eval_loss": 1.276354193687439,
      "eval_runtime": 632.7743,
      "eval_samples_per_second": 83.915,
      "eval_steps_per_second": 0.656,
      "step": 121500
    },
    {
      "epoch": 36.72205438066465,
      "grad_norm": 0.4330506920814514,
      "learning_rate": 4.218549848942598e-05,
      "loss": 1.2554,
      "step": 121550
    },
    {
      "epoch": 36.72205438066465,
      "eval_loss": 1.2755663394927979,
      "eval_runtime": 629.0677,
      "eval_samples_per_second": 84.409,
      "eval_steps_per_second": 0.66,
      "step": 121550
    },
    {
      "epoch": 36.73716012084592,
      "grad_norm": 0.42242667078971863,
      "learning_rate": 4.21754279959718e-05,
      "loss": 1.2445,
      "step": 121600
    },
    {
      "epoch": 36.73716012084592,
      "eval_loss": 1.2780704498291016,
      "eval_runtime": 698.062,
      "eval_samples_per_second": 76.066,
      "eval_steps_per_second": 0.595,
      "step": 121600
    },
    {
      "epoch": 36.75226586102719,
      "grad_norm": 0.5260747671127319,
      "learning_rate": 4.216535750251762e-05,
      "loss": 1.254,
      "step": 121650
    },
    {
      "epoch": 36.75226586102719,
      "eval_loss": 1.2762959003448486,
      "eval_runtime": 620.3251,
      "eval_samples_per_second": 85.599,
      "eval_steps_per_second": 0.669,
      "step": 121650
    },
    {
      "epoch": 36.76737160120846,
      "grad_norm": 0.46712881326675415,
      "learning_rate": 4.2155287009063446e-05,
      "loss": 1.2492,
      "step": 121700
    },
    {
      "epoch": 36.76737160120846,
      "eval_loss": 1.2751641273498535,
      "eval_runtime": 628.3038,
      "eval_samples_per_second": 84.512,
      "eval_steps_per_second": 0.661,
      "step": 121700
    },
    {
      "epoch": 36.78247734138973,
      "grad_norm": 0.5468864440917969,
      "learning_rate": 4.2145216515609265e-05,
      "loss": 1.2574,
      "step": 121750
    },
    {
      "epoch": 36.78247734138973,
      "eval_loss": 1.2762105464935303,
      "eval_runtime": 608.2397,
      "eval_samples_per_second": 87.299,
      "eval_steps_per_second": 0.682,
      "step": 121750
    },
    {
      "epoch": 36.797583081571,
      "grad_norm": 0.424839049577713,
      "learning_rate": 4.2135146022155084e-05,
      "loss": 1.2465,
      "step": 121800
    },
    {
      "epoch": 36.797583081571,
      "eval_loss": 1.2782031297683716,
      "eval_runtime": 620.7665,
      "eval_samples_per_second": 85.538,
      "eval_steps_per_second": 0.669,
      "step": 121800
    },
    {
      "epoch": 36.81268882175227,
      "grad_norm": 0.4578010141849518,
      "learning_rate": 4.21250755287009e-05,
      "loss": 1.2268,
      "step": 121850
    },
    {
      "epoch": 36.81268882175227,
      "eval_loss": 1.2788307666778564,
      "eval_runtime": 688.2291,
      "eval_samples_per_second": 77.153,
      "eval_steps_per_second": 0.603,
      "step": 121850
    },
    {
      "epoch": 36.82779456193354,
      "grad_norm": 0.4583183526992798,
      "learning_rate": 4.211500503524673e-05,
      "loss": 1.2597,
      "step": 121900
    },
    {
      "epoch": 36.82779456193354,
      "eval_loss": 1.2771940231323242,
      "eval_runtime": 671.5486,
      "eval_samples_per_second": 79.069,
      "eval_steps_per_second": 0.618,
      "step": 121900
    },
    {
      "epoch": 36.842900302114806,
      "grad_norm": 0.4549044370651245,
      "learning_rate": 4.2104934541792546e-05,
      "loss": 1.2545,
      "step": 121950
    },
    {
      "epoch": 36.842900302114806,
      "eval_loss": 1.2771711349487305,
      "eval_runtime": 642.6837,
      "eval_samples_per_second": 82.621,
      "eval_steps_per_second": 0.646,
      "step": 121950
    },
    {
      "epoch": 36.858006042296076,
      "grad_norm": 0.4480248689651489,
      "learning_rate": 4.209486404833837e-05,
      "loss": 1.2344,
      "step": 122000
    },
    {
      "epoch": 36.858006042296076,
      "eval_loss": 1.2784004211425781,
      "eval_runtime": 685.1652,
      "eval_samples_per_second": 77.498,
      "eval_steps_per_second": 0.606,
      "step": 122000
    },
    {
      "epoch": 36.87311178247734,
      "grad_norm": 0.43178585171699524,
      "learning_rate": 4.208479355488419e-05,
      "loss": 1.2486,
      "step": 122050
    },
    {
      "epoch": 36.87311178247734,
      "eval_loss": 1.278212070465088,
      "eval_runtime": 629.2135,
      "eval_samples_per_second": 84.389,
      "eval_steps_per_second": 0.66,
      "step": 122050
    },
    {
      "epoch": 36.88821752265861,
      "grad_norm": 0.46489447355270386,
      "learning_rate": 4.2074723061430016e-05,
      "loss": 1.2491,
      "step": 122100
    },
    {
      "epoch": 36.88821752265861,
      "eval_loss": 1.2767939567565918,
      "eval_runtime": 687.6213,
      "eval_samples_per_second": 77.221,
      "eval_steps_per_second": 0.604,
      "step": 122100
    },
    {
      "epoch": 36.903323262839876,
      "grad_norm": 0.42110687494277954,
      "learning_rate": 4.2064652567975835e-05,
      "loss": 1.2393,
      "step": 122150
    },
    {
      "epoch": 36.903323262839876,
      "eval_loss": 1.2764928340911865,
      "eval_runtime": 640.8378,
      "eval_samples_per_second": 82.859,
      "eval_steps_per_second": 0.648,
      "step": 122150
    },
    {
      "epoch": 36.918429003021146,
      "grad_norm": 0.4966869652271271,
      "learning_rate": 4.205458207452165e-05,
      "loss": 1.2483,
      "step": 122200
    },
    {
      "epoch": 36.918429003021146,
      "eval_loss": 1.2790991067886353,
      "eval_runtime": 637.1551,
      "eval_samples_per_second": 83.338,
      "eval_steps_per_second": 0.651,
      "step": 122200
    },
    {
      "epoch": 36.933534743202415,
      "grad_norm": 0.43728533387184143,
      "learning_rate": 4.204451158106747e-05,
      "loss": 1.2394,
      "step": 122250
    },
    {
      "epoch": 36.933534743202415,
      "eval_loss": 1.277669906616211,
      "eval_runtime": 698.6154,
      "eval_samples_per_second": 76.006,
      "eval_steps_per_second": 0.594,
      "step": 122250
    },
    {
      "epoch": 36.948640483383684,
      "grad_norm": 0.4039117097854614,
      "learning_rate": 4.20344410876133e-05,
      "loss": 1.2604,
      "step": 122300
    },
    {
      "epoch": 36.948640483383684,
      "eval_loss": 1.276747703552246,
      "eval_runtime": 589.0961,
      "eval_samples_per_second": 90.136,
      "eval_steps_per_second": 0.704,
      "step": 122300
    },
    {
      "epoch": 36.963746223564954,
      "grad_norm": 0.4799923002719879,
      "learning_rate": 4.2024370594159116e-05,
      "loss": 1.263,
      "step": 122350
    },
    {
      "epoch": 36.963746223564954,
      "eval_loss": 1.273210883140564,
      "eval_runtime": 643.4503,
      "eval_samples_per_second": 82.522,
      "eval_steps_per_second": 0.645,
      "step": 122350
    },
    {
      "epoch": 36.97885196374622,
      "grad_norm": 0.42493516206741333,
      "learning_rate": 4.2014300100704935e-05,
      "loss": 1.2482,
      "step": 122400
    },
    {
      "epoch": 36.97885196374622,
      "eval_loss": 1.276469111442566,
      "eval_runtime": 624.8177,
      "eval_samples_per_second": 84.983,
      "eval_steps_per_second": 0.664,
      "step": 122400
    },
    {
      "epoch": 36.99395770392749,
      "grad_norm": 0.447503000497818,
      "learning_rate": 4.200422960725076e-05,
      "loss": 1.2547,
      "step": 122450
    },
    {
      "epoch": 36.99395770392749,
      "eval_loss": 1.275237798690796,
      "eval_runtime": 675.1728,
      "eval_samples_per_second": 78.645,
      "eval_steps_per_second": 0.615,
      "step": 122450
    },
    {
      "epoch": 37.00906344410876,
      "grad_norm": 0.4751191735267639,
      "learning_rate": 4.199415911379658e-05,
      "loss": 1.2645,
      "step": 122500
    },
    {
      "epoch": 37.00906344410876,
      "eval_loss": 1.2770678997039795,
      "eval_runtime": 631.449,
      "eval_samples_per_second": 84.091,
      "eval_steps_per_second": 0.657,
      "step": 122500
    },
    {
      "epoch": 37.02416918429003,
      "grad_norm": 0.450568288564682,
      "learning_rate": 4.19840886203424e-05,
      "loss": 1.2471,
      "step": 122550
    },
    {
      "epoch": 37.02416918429003,
      "eval_loss": 1.2751108407974243,
      "eval_runtime": 667.3025,
      "eval_samples_per_second": 79.573,
      "eval_steps_per_second": 0.622,
      "step": 122550
    },
    {
      "epoch": 37.0392749244713,
      "grad_norm": 0.47166845202445984,
      "learning_rate": 4.1974018126888216e-05,
      "loss": 1.2273,
      "step": 122600
    },
    {
      "epoch": 37.0392749244713,
      "eval_loss": 1.2760947942733765,
      "eval_runtime": 624.1797,
      "eval_samples_per_second": 85.07,
      "eval_steps_per_second": 0.665,
      "step": 122600
    },
    {
      "epoch": 37.05438066465257,
      "grad_norm": 0.45502322912216187,
      "learning_rate": 4.196394763343404e-05,
      "loss": 1.2545,
      "step": 122650
    },
    {
      "epoch": 37.05438066465257,
      "eval_loss": 1.2769291400909424,
      "eval_runtime": 689.0489,
      "eval_samples_per_second": 77.061,
      "eval_steps_per_second": 0.602,
      "step": 122650
    },
    {
      "epoch": 37.06948640483384,
      "grad_norm": 0.4743496775627136,
      "learning_rate": 4.195387713997986e-05,
      "loss": 1.2411,
      "step": 122700
    },
    {
      "epoch": 37.06948640483384,
      "eval_loss": 1.2771391868591309,
      "eval_runtime": 574.1586,
      "eval_samples_per_second": 92.481,
      "eval_steps_per_second": 0.723,
      "step": 122700
    },
    {
      "epoch": 37.08459214501511,
      "grad_norm": 0.439602792263031,
      "learning_rate": 4.194380664652568e-05,
      "loss": 1.2439,
      "step": 122750
    },
    {
      "epoch": 37.08459214501511,
      "eval_loss": 1.277309536933899,
      "eval_runtime": 588.4714,
      "eval_samples_per_second": 90.232,
      "eval_steps_per_second": 0.705,
      "step": 122750
    },
    {
      "epoch": 37.09969788519638,
      "grad_norm": 0.46420979499816895,
      "learning_rate": 4.19337361530715e-05,
      "loss": 1.2376,
      "step": 122800
    },
    {
      "epoch": 37.09969788519638,
      "eval_loss": 1.2775412797927856,
      "eval_runtime": 602.7294,
      "eval_samples_per_second": 88.098,
      "eval_steps_per_second": 0.689,
      "step": 122800
    },
    {
      "epoch": 37.11480362537765,
      "grad_norm": 0.4432883560657501,
      "learning_rate": 4.192366565961732e-05,
      "loss": 1.247,
      "step": 122850
    },
    {
      "epoch": 37.11480362537765,
      "eval_loss": 1.2762434482574463,
      "eval_runtime": 689.7958,
      "eval_samples_per_second": 76.978,
      "eval_steps_per_second": 0.602,
      "step": 122850
    },
    {
      "epoch": 37.12990936555891,
      "grad_norm": 0.5096030831336975,
      "learning_rate": 4.191359516616314e-05,
      "loss": 1.2778,
      "step": 122900
    },
    {
      "epoch": 37.12990936555891,
      "eval_loss": 1.2756980657577515,
      "eval_runtime": 583.6889,
      "eval_samples_per_second": 90.971,
      "eval_steps_per_second": 0.711,
      "step": 122900
    },
    {
      "epoch": 37.14501510574018,
      "grad_norm": 0.4700428247451782,
      "learning_rate": 4.190352467270896e-05,
      "loss": 1.2267,
      "step": 122950
    },
    {
      "epoch": 37.14501510574018,
      "eval_loss": 1.2771236896514893,
      "eval_runtime": 678.1627,
      "eval_samples_per_second": 78.298,
      "eval_steps_per_second": 0.612,
      "step": 122950
    },
    {
      "epoch": 37.16012084592145,
      "grad_norm": 0.48533666133880615,
      "learning_rate": 4.189345417925478e-05,
      "loss": 1.2727,
      "step": 123000
    },
    {
      "epoch": 37.16012084592145,
      "eval_loss": 1.2760009765625,
      "eval_runtime": 678.0763,
      "eval_samples_per_second": 78.308,
      "eval_steps_per_second": 0.612,
      "step": 123000
    }
  ],
  "logging_steps": 50,
  "max_steps": 331000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.430419555998237e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
